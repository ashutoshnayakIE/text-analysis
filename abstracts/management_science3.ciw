FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU WANG, SH
TI THE UNPREDICTABILITY OF STANDARD BACK-PROPAGATION NEURAL NETWORKS IN
   CLASSIFICATION APPLICATIONS
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 555
EP 559
DI 10.1287/mnsc.41.3.555
PD MAR 1995
PY 1995
AB This note offers an extension of Tam and Kiang (1992). First the
   weakness of the standard back propagation neural network learning
   algorithm is discussed, and then a warning is issued regarding
   applications of artificial neural networks in the management science
   field. Also suggested is a possible way of improving the performance of
   neural networks in managerial applications.
ZR 0
ZB 0
Z8 0
ZA 0
ZS 0
TC 48
Z9 48
SN 0025-1909
UT WOS:A1995RN11500012
ER

PT J
AU SESHADRI, S
TI BIDDING FOR CONTESTS
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 561
EP 576
DI 10.1287/mnsc.41.4.561
PD APR 1995
PY 1995
AB The procurement of product development and production services brings
   special strategic considerations to the buyer-seller relationship in
   industrial and institutional markets. Multiple sourcing, in particular
   dual sourcing, is a likely way of dealing with the increased risks faced
   by buyers. However, there is lack of dual sourcing models that analyze
   the selection and control process in an integrated fashion. This
   omission has led to apparently contradictory findings in agency and
   auction theory. The paper models the strategic issues for a cost
   containment contest between two suppliers. The suppliers are drawn from
   several vendors who participate in a bidding competition. The supplier
   with the lower final cost in the contest wins a larger share of the
   pooled profit fee. Propositions are derived for the optimal cost-plus
   contest, and comparisons are made with the common incentive contract for
   the integrated selection and control model. The larger the winner's
   share, the greater the effort. The buyer can make a credible commitment
   to the optimal winner's share. As the winner's share rises, however, the
   bid prices increase due to increased contract risk. This incentive-risk
   tradeoff determines (a) the optimal winner's share that minimizes
   expected procurement price, (b) the corresponding profit fee bid by
   suppliers, (c) the ensuing cost control effort, and (d) the final price
   for the procurement. Comparisons with the common incentive contract tell
   us when the cost-plus contest induces more effort, and when bidding for
   a contest results in a lower final procurement price.
ZR 0
TC 13
Z8 1
ZS 0
ZB 0
Z9 14
SN 0025-1909
UT WOS:A1995RN11600001
ER

PT J
AU JORDAN, WC
   GRAVES, SC
TI PRINCIPLES ON THE BENEFITS OF MANUFACTURING PROCESS FLEXIBILITY
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 577
EP 594
DI 10.1287/mnsc.41.4.577
PD APR 1995
PY 1995
AB Increasing manufacturing flexibility is a key strategy for efficiently
   improving market responsiveness in the face of uncertain future product
   demand. Process flexibility results from being able to build different
   types of products in the same plant or production facility at the same
   time. In Part I of this paper, we develop several principles on the
   benefits of process flexibility. These principles are that 1) limited
   flexibility (i.e., each plant builds only a few products), configured in
   the right way, yields most of the benefits of total flexibility (i.e.,
   each plant builds all products) and 2) limited flexibility has the
   greatest benefits when configured to chain products and plants together
   to the greatest extent possible. In Part II, we provide analytic support
   and justification for these principles. Based on a planning model for
   assigning production to plants, we demonstrate that, for realistic
   assumptions on demand uncertainty, limited flexibility configurations
   (i.e., how products are assigned to plants) have sales benefits that are
   approximately equivalent to those for total flexibility.
   Furthermore, from this analysis we develop a simple measure for the
   flexibility in a given product-plant configuration. Such a measure is
   desirable because of the complexity of computing expected sales for a
   given configuration. The measure is II(M*), the maximal probability over
   all groupings or sets of products (M) that there will be unfilled demand
   for a set of products while simultaneously there is excess capacity at
   plants building other products. This measure is easily computed and can
   be used to guide the search for good limited flexibility configurations.
Z8 9
TC 402
ZA 0
ZR 0
ZS 1
ZB 1
Z9 412
SN 0025-1909
UT WOS:A1995RN11600002
ER

PT J
AU THOMPSON, GM
TI IMPROVED IMPLICIT OPTIMAL MODELING OF THE LABOR SHIFT SCHEDULING PROBLEM
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 595
EP 607
DI 10.1287/mnsc.41.4.595
PD APR 1995
PY 1995
AB This paper presents an integer programming model for developing optimal
   shift schedules while allowing extensive flexibility in terms of
   alternate shift starting times, shift lengths, and break placement. The
   model combines the work of Moondra (1976) and Bechtold and Jacobs (1990)
   by implicitly matching meal breaks to implicitly represented shifts.
   Moreover, the new model extends the work of these authors to enable the
   scheduling of overtime and the scheduling of rest breaks.
   We compare the new model to Bechtold and Jacobs' model over a diverse
   set of 588 test problems. The new model generates optimal solutions more
   rapidly, solves problems with more shift alternatives, and does not
   generate schedules violating the operative restrictions on break timing.
ZR 0
ZS 0
ZB 0
ZA 0
TC 80
Z8 1
Z9 81
SN 0025-1909
UT WOS:A1995RN11600003
ER

PT J
AU DUENYAS, I
TI SINGLE FACILITY DUE-DATE SETTING WITH MULTIPLE CUSTOMER CLASSES
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 608
EP 619
DI 10.1287/mnsc.41.4.608
PD APR 1995
PY 1995
AB We consider the interrelated problems of (1) quoting a due date to each
   customer arriving to a production system modeled as a single-server
   queue and (2) sequencing customer orders once they are in the system. We
   allow several different classes of customers, each with different
   preferences for lead time and price. We first formulate the problem of
   quoting due dates under the assumption that customer orders are
   processed on a FCFS basis. Next, we consider the case where the firm has
   the option to schedule orders in other than FCFS order. For this case,
   we develop a heuristic for quoting due dates and sequencing orders.
   Simulation results suggest that policies that take into account customer
   price and due date preferences in scheduling and quoting due dates
   significantly outperform due date setting policies that do not.
ZB 0
ZR 0
ZA 0
Z8 2
ZS 0
TC 81
Z9 83
SN 0025-1909
UT WOS:A1995RN11600004
ER

PT J
AU SO, KC
   TANG, CS
TI OPTIMAL OPERATING POLICY FOR A BOTTLENECK WITH RANDOM REWORK
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 620
EP 636
DI 10.1287/mnsc.41.4.620
PD APR 1995
PY 1995
AB This paper presents a model of a bottleneck facility that performs two
   distinct types of operations: ''regular'' and ''rework.'' Each job is
   subjected to a test after completing the regular operation at the
   bottleneck. If the job passes the test, then it continues its process
   downstream. Otherwise, the job will cycle back to the bottleneck stage
   for rework operation. Upon the completion of a batch of regular jobs, Me
   decision maker observes the amount of rework and decides on whether to
   switch over to process the reworks or continue to process another batch
   of regular jobs. It is assumed that both switch-over time and cost are
   incurred when the facility switches from performing one type of
   operation to a different type. The goal of the analysis is to
   characterize Me optimal operating policy for the bottleneck so that the
   average operating cost is minimized. In order to characterize the
   optimal operating policy, we first formulate the problem as a
   semi-Markov decision process. Then we show that there exists an optimal
   ''threshold'' operating policy that can be described as follows: upon
   completion of a batch of regular jobs, switch over to process the
   reworks only if the number of reworks exceeds a critical value. In
   addition, we develop a simple procedure to compute the critical value
   that specifies the optimal threshold policy. Moreover, we evaluate the
   impact of batch sizes, yield, and switch-over time on the optimal
   threshold policy.
OI tang, christopher/0000-0001-9597-7620
Z8 0
ZS 0
ZR 0
ZB 0
TC 17
ZA 0
Z9 17
SN 0025-1909
UT WOS:A1995RN11600005
ER

PT J
AU CALABRESE, JM
TI BAYESIAN PROCESS-CONTROL FOR ATTRIBUTES
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 637
EP 645
DI 10.1287/mnsc.41.4.637
PD APR 1995
PY 1995
AB We consider a process control procedure with fixed sample sizes and
   sampling intervals, where the fraction defective is the quality variable
   of interest, a standard attributes control chart methodology. We show
   that relatively standard cost assumptions lead to formulation of the
   process control problem as a partially observed Markov decision process,
   where the posterior probability of a process shift is a sufficient
   statistic for decision making. We characterize features of the optimal
   solution and show that the optimal policy has a simple control limit
   structure. Numerical results are provided which indicate that the
   procedure may provide significant savings over non-Bayesian techniques.
ZR 0
TC 53
ZA 0
ZB 0
ZS 1
Z8 4
Z9 57
SN 0025-1909
UT WOS:A1995RN11600006
ER

PT J
AU RADHAKRISHNAN, S
   BALACHANDRAN, KR
TI DELAY COST AND INCENTIVE SCHEMES FOR MULTIPLE USERS
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 646
EP 652
DI 10.1287/mnsc.41.4.646
PD APR 1995
PY 1995
AB This paper examines the role of cost application in the presence of
   delay and agency costs. Two risk neutral division managers share a
   common (production) facility and decide on (a) the demand (usage) rates,
   and (b) productive action, Each division manager causes costly delays at
   the common production facility for the other division manager. The
   expected delay depends on the demand rates chosen by the division
   managers. An M/G/1 queuing framework is used to characterize delay
   costs. The unobservability of demand rates leads to stochastic choice
   hazard, and the unobservability of productive actions leads to moral
   hazard problems. The headquarters designs incentive schemes such that
   the use of the common facility is optimal for the firm.
   We show that a franchise contract is necessary to implement the
   first-best solution (similar to Harris and Raviv 1979), but is not
   sufficient. Specifically, when the action aversion of one division
   manager is small, the use of a franchise contract leads to ''greedy''
   behavior by that division manager. The cost application required is
   greater than the expected marginal cost of delay to preclude the greedy
   behavior and ensure a stable equilibrium.
ZS 0
ZR 0
Z8 0
ZB 0
TC 3
Z9 3
SN 0025-1909
UT WOS:A1995RN11600007
ER

PT J
AU ALLEN, S
   RAMANAN, R
TI INSIDER TRADING, EARNINGS CHANGES, AND STOCK-PRICES
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 653
EP 668
DI 10.1287/mnsc.41.4.653
PD APR 1995
PY 1995
AB This study empirically examines the relation between reportable insider
   trading and the information captured by annual unexpected earnings for a
   large sample of firms, spanning a ten-year period (1978-87). Each
   observation is assigned to one of four groups based on the direction of
   net insider trading(Buy, Sell) and the sign (+,-) of unexpected
   earnings. For each of these groups, 15-month cumulative abnormal returns
   are regressed on annual unexpected earnings. The slope coefficient is
   the largest for the group where insiders are net purchasers and the sign
   of unexpected earnings is positive. This is consistent with an inference
   that insider buying interactively confirms the favorable information
   captured by positive unexpected earnings and this interaction reduces
   the noise in unexpected earnings. The result with regard to the
   unfavorable information captured by the group with insider selling and
   negative unexpected earnings is similar but less pronounced. The
   analysis also suggests that insider trading conveys information not
   fully captured by that year's earnings.
ZA 0
ZS 0
ZB 0
ZR 0
TC 11
Z8 0
Z9 11
SN 0025-1909
UT WOS:A1995RN11600008
ER

PT J
AU MAZZOLA, JB
   SCHANTZ, RH
TI SINGLE-FACILITY RESOURCE-ALLOCATION UNDER CAPACITY-BASED ECONOMIES AND
   DISECONOMICS OF SCOPE
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 669
EP 689
DI 10.1287/mnsc.41.4.669
PD APR 1995
PY 1995
AB We consider the optimal allocation of a resource in a single-facility
   production environment in the presence of capacity-based economies and
   diseconomies of scope. This setting generalizes the usual approach to
   single-facility resource allocation by allowing for the effective
   capacity of a facility to be a (nonlinear) function of the number of
   different items produced or the services delivered by the facility.
   Economies or diseconomies of scope are attributable to factors such as
   production changeover time, overall process management requirements, and
   complementary production requirements that vary with the product or
   service mix. We consider the problem setting in which the effective
   capacity depends on the number of tasks assigned to the facility. The
   resulting model(SCOPE) generalizes the well-known 0-1 knapsack problem.
   We also consider the more general problem(GENCAP) in which capacity
   consumption depends on the specific set of tasks assigned to the
   facility. We define tabu-search heuristics, as well as exact
   branch-and-bound algorithms for SCOPE and GENCAP. On the basis of
   extensive computational experience, the solution procedures are seen to
   be extremely effective. In particular, the heuristics consistently
   obtain high-quality solutions to the test problems. Furthermore, the
   tractability of solving problems to optimality is demonstrated through
   the solution of SCOPE problems having as many as 500 tasks and GENCAP
   problems involving as many as 50 tasks and more than 16,500 nonlinear
   capacity interactions.
Z8 0
ZS 0
ZA 0
ZR 0
ZB 0
TC 14
Z9 14
SN 0025-1909
UT WOS:A1995RN11600009
ER

PT J
AU ZIPKIN, PH
TI PERFORMANCE ANALYSIS OF A MULTIITEM PRODUCTION-INVENTORY SYSTEM UNDER
   ALTERNATIVE POLICIES
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 690
EP 703
DI 10.1287/mnsc.41.4.690
PD APR 1995
PY 1995
AB This paper explores the performance of a multi-item production-inventory
   system. We compare two alternative policies, representing different
   modes of collecting and utilizing information. We derive a closed-form
   measure of performance for one of them, the familiar
   first-come-first-served (FCFS) policy, and propose a comparable
   approximation for the other, the longest-queue (LQ) policy. These
   results are illustrated and tested through simulations. In this way we
   address several basic managerial issues: What is the value of
   centralized information in complex systems? How does the breadth of the
   product line affect performance?
ZA 0
ZS 0
Z8 2
TC 57
ZR 0
ZB 0
Z9 59
SN 0025-1909
UT WOS:A1995RN11600010
ER

PT J
AU CHARDAIRE, P
   SUTTER, A
TI A DECOMPOSITION METHOD FOR QUADRATIC ZERO-ONE PROGRAMMING
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 704
EP 712
DI 10.1287/mnsc.41.4.704
PD APR 1995
PY 1995
AB This paper proposes a decomposition method to compute a lower bound for
   unconstrained quadratic zero-one minimization. First, we show that any
   quadratic function can be expressed as a sum of particular quadratic
   functions whose minima can be computed by a simple branch and bound
   algorithm. Then, assuming some hypothesis, we prove that, among all
   possible decompositions, the best one can be found by a Lagrangian
   decomposition method. Moreover, we show that our algorithm gives at
   least the roof dual bound and should give better results in practice.
   Eventually, computational results and comparisons with Pardalos and
   Rodgers' algorithm demonstrate the efficiency of our method for medium
   size problems (up to 100 variables).
TC 50
Z8 1
ZB 1
ZR 0
ZA 0
ZS 3
Z9 54
SN 0025-1909
UT WOS:A1995RN11600011
ER

PT J
AU OKELLY, M
   SKORINKAPOV, D
   SKORINKAPOV, J
TI LOWER BOUNDS FOR THE HUB LOCATION PROBLEM
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 713
EP 721
DI 10.1287/mnsc.41.4.713
PD APR 1995
PY 1995
AB We present a new lower bound for the Hub Location Problem (HLP) where
   distances satisfy the triangle inequality. Our lower bound is based on a
   linearization of the problem and its modification obtained by
   incorporating the knowledge of a known heuristic solution. A lower bound
   was computed for some standard data sets from the literature ranging
   between 10 and 25 nodes, with 2, 3, and 4 hubs, and for different values
   for the parameter alpha, representing the discount far the flow between
   hubs. The novel approach of using a known heuristic solution to derive a
   lower bound in all cases reduced the difference between the upper and
   lower bound. This difference measures the quality of the best known
   heuristic solution in percentages above the best lower bound. As a
   result of this research, for smaller problems (all instances with 10 and
   15 nodes) the average difference is reduced to 3.3%. For larger sets (20
   and 25 nodes) the average difference is reduced to 5.9%.
TC 49
ZS 0
ZA 0
Z8 2
ZB 0
ZR 0
Z9 50
SN 0025-1909
UT WOS:A1995RN11600012
ER

PT J
AU BICK, A
TI QUADRATIC-VARIATION-BASED DYNAMIC STRATEGIES
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 722
EP 732
DI 10.1287/mnsc.41.4.722
PD APR 1995
PY 1995
AB The paper analyzes a family of dynamic trading strategies which do not
   rely on any stochastic process assumptions (aside from continuity and
   positivity) and in particular do not require predicting future
   volatilities. Derivative payoffs can still be replicated, except that
   this occurs at the stopping time at which the ''realized cumulative
   squared volatility'' hits a predetermined level. The application of
   these results to portfolio insurance is emphasized, and hedging
   strategies studied by Black and Jones and by Brennan and Schwartz are
   generalized. Classical results on European-style options arise as
   special cases. For example, the initial cost of replicating a call or a
   put under the new method is given by a generalized Black-Scholes
   formula, which yields the ordinary Black-Scholes formula when the
   volatility is deterministic.
ZR 0
TC 17
ZA 0
ZS 0
ZB 0
Z8 0
Z9 17
SN 0025-1909
UT WOS:A1995RN11600013
ER

PT J
AU DICICCIO, TJ
   GLYNN, PW
TI NOTE - ON THE VALUE OF FUNCTION EVALUATION LOCATION INFORMATION IN
   MONTE-CARLO SIMULATION
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 733
EP 737
DI 10.1287/mnsc.41.4.733
PD APR 1995
PY 1995
AB The point estimator used in naive Monte Carlo sampling weights all the
   computed function evaluations equally, and it does not take into account
   the precise locations at which the function evaluations are made. In
   this note, we consider one-dimensional integration problems in which the
   integrand is twice continuously differentiable. It is shown that if the
   weights are suitably modified to reflect the location information
   present in the sample, then the convergence rate of the Monte Carlo
   estimator can be dramatically improved from order n(-1/2) to order
   n(-2), where n is the number of function evaluations computed.
Z8 0
ZR 0
ZS 0
ZB 0
TC 1
Z9 1
SN 0025-1909
UT WOS:A1995RN11600014
ER

PT J
AU LECUYER, P
TI NOTE - ON THE INTERCHANGE OF DERIVATIVE AND EXPECTATION FOR LIKELIHOOD
   RATIO DERIVATIVE ESTIMATORS
SO MANAGEMENT SCIENCE
VL 41
IS 4
BP 738
EP 748
DI 10.1287/mnsc.41.4.738
PD APR 1995
PY 1995
AB Sufficient conditions for the validity of interchange between derivative
   and expectation, in the context of likelihood ratio gradient estimation,
   were given in L'Ecuyer (1990). The aim of this paper is to shed
   additional light on these conditions and introduce specific variants of
   them, which are often easier to check. Sufficient conditions for the
   derivative estimator to have finite moments up to a given order are also
   given and illustrated by examples. In particular, we give an example of
   an unbiased derivative estimator which satisfies the interchange
   conditions but which has infinite variance.
RI L'Ecuyer, Pierre/O-6577-2019
OI L'Ecuyer, Pierre/0000-0002-3184-0796
ZB 0
ZA 0
TC 31
Z8 0
ZR 0
ZS 0
Z9 31
SN 0025-1909
UT WOS:A1995RN11600015
ER

PT J
AU NESLIN, SA
   POWELL, SG
   STONE, LS
TI THE EFFECTS OF RETAILER AND CONSUMER RESPONSE ON OPTIMAL MANUFACTURER
   ADVERTISING AND TRADE PROMOTION STRATEGIES
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 749
EP 766
DI 10.1287/mnsc.41.5.749
PD MAY 1995
PY 1995
AB This research examines how retailer and consumer responses influence a
   manufacturer's optimal advertising and trade promotion plans. We develop
   a dynamic optimization model which considers the actions of the
   manufacturer, retailers, and consumers. The manufacturer attempts to
   maximize its profits by advertising directly to consumers and offering
   periodic trade deal discounts to the retailer in the hope that the
   retailer will in turn ''pass through'' a retailer promotion to the
   consumer. We show how the manufacturer's optimal allocation depends on
   consumer response to advertising, consumer response to retailer
   promotions, retailer inventory carrying cost, and retailer passthrough
   behavior. For example, we find that retailer carrying costs and
   promotion wearout play a central role in constraining expenditures on
   trade promotions. We predict that as trade promotions are designed to
   eliminate forward buying, manufacturers will find it in their interest
   to promote more steeply. We also find a natural tendency for advertising
   and trade dealing to substitute for each other in an optimal plan.
ZA 0
TC 40
ZB 1
ZS 0
ZR 0
Z8 1
Z9 41
SN 0025-1909
UT WOS:A1995RN55000002
ER

PT J
AU NAIR, SK
   THAKUR, LS
   WEN, KW
TI NEAR-OPTIMAL SOLUTIONS FOR PRODUCT LINE DESIGN AND SELECTION - BEAM
   SEARCH HEURISTICS
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 767
EP 785
DI 10.1287/mnsc.41.5.767
PD MAY 1995
PY 1995
AB Many practical product line design problems have large numbers of
   attributes and levels. In this case, if most attribute level
   combinations define feasible products, constructing product lines
   directly from part-worths data is necessary. For three typical
   formulations of this important problem, Kohli and Sukumar (1990) present
   state-of-the-art heuristics to find good solutions. In this paper, we
   develop improved heuristics based on a beam search approach for solving
   these problems.
   In our computations for 435 simulated problems, significant improvements
   occur in five important performance measures used. Our heuristic
   solutions are closer to the optimal, have smaller standard deviation
   over replicates, take less computation time, obtain optimal solutions
   more often and identify a number of ''good'' product lines explicitly.
   Computation times for these problems are no more than 22 seconds on a
   PC, small enough for adequate sensitivity analysis. We also apply the
   heuristics to a real data set and clarify computational steps by giving
   a detailed example.
ZS 0
ZR 0
ZA 0
ZB 0
TC 98
Z8 1
Z9 99
SN 0025-1909
UT WOS:A1995RN55000003
ER

PT J
AU EECKHOUDT, L
   GOLLIER, C
   SCHLESINGER, H
TI THE RISK-AVERSE (AND PRUDENT) NEWSBOY
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 786
EP 794
DI 10.1287/mnsc.41.5.786
PD MAY 1995
PY 1995
AB The effects of risk and risk aversion in the single-period inventory
   (''newsboy'') problem are examined. Comparative-static effects of
   changes in the various price and cost parameters are determined and
   related to the newsboy's risk aversion. The addition of a random
   background wealth and of an increase in the riskiness of newspaper
   demand are also examined. Although many of the comparative effects
   generally are ambiguous, some fairly simple restrictions on preferences
   and/or risk increases are shown to lead to qualitatively deterministic
   results.
RI Gollier, Christian/G-4476-2012; Schlesinger, Harris/A-7626-2009
ZS 0
ZR 0
TC 306
ZB 1
ZA 0
Z8 61
Z9 362
SN 0025-1909
UT WOS:A1995RN55000004
ER

PT J
AU SMITH, JE
   NAU, RF
TI VALUING RISKY PROJECTS - OPTION PRICING THEORY AND DECISION-ANALYSIS
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 795
EP 816
DI 10.1287/mnsc.41.5.795
PD MAY 1995
PY 1995
AB In the academic literature and professional practice, there are a number
   of alternative and apparently competing methods for valuing risky
   projects. In this paper, we compare and contrast three different
   approaches: risk-adjusted discount-rate analysis, option pricing
   analysis, and decision analysis, focusing on the last two. We show that,
   in contrast to some of the claims made in the ''real options''
   literature, when both option pricing and decision analysis methods are
   correctly applied, they must give consistent results. We also explore
   ways in which option pricing and decision analysis methods can be
   profitably integrated. In particular, we show how option pricing
   techniques can be used to simplify decision analyses when some risks can
   be hedged by trading and, conversely, how decision analysis techniques
   can be used to extend option pricing techniques to problems with
   incomplete securities markets.
ZB 1
ZA 1
Z8 5
TC 228
ZR 0
ZS 9
Z9 239
SN 0025-1909
UT WOS:A1995RN55000005
ER

PT J
AU MEYER, RJ
   SHI, Y
TI SEQUENTIAL CHOICE UNDER AMBIGUITY - INTUITIVE SOLUTIONS TO THE
   ARMED-BANDIT PROBLEM
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 817
EP 834
DI 10.1287/mnsc.41.5.817
PD MAY 1995
PY 1995
AB The process by which individuals learn from feedback when making
   recurrent choices among ambiguous alternatives is explored. We describe
   an experiment in which subjects solve a variant of the classic
   armed-bandit problem of dynamic decision theory, set in the context of
   airline choice. Subjects are asked to make repeated choices between two
   hypothetical airlines, one having an on-time departure probability which
   is known a priori, and the other has an ambiguous probability whose true
   value can only be discovered by making sample trips on the airline.
   Subjects attempt to make choices in such a way as to maximize the total
   number of one-time departures over a fixed planning horizon. We examine
   the extent to which actual choice patterns over time are consistent with
   those which would be made by a decision maker acting as an optimal
   Bernoulli sampler. The data offer support for a number of expected-and
   some unexpected-departures from optimality, including a tendency to
   underexperiment with promising options and overexperiment with
   unpromising options, and a tendency to increasingly switch between
   airlines as the average base rate of departures decreases. Implications
   of the work for the descriptive validity of normative dynamic decision
   models is explored, as well as for the generalizability of previous
   findings about choice under ambiguity to dynamic settings.
ZR 0
TC 51
ZS 0
ZB 4
ZA 0
Z8 0
Z9 51
SN 0025-1909
UT WOS:A1995RN55000006
ER

PT J
AU LEE, JK
   SONG, YU
TI UNIFICATION OF LINEAR-PROGRAMMING WITH A RULE-BASED SYSTEM BY THE
   POST-MODEL ANALYSIS APPROACH
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 835
EP 847
DI 10.1287/mnsc.41.5.835
PD MAY 1995
PY 1995
AB We attempt to unify a linear programming model with a rule-based system
   via overlapped decision variables. Since a rule base can be regarded as
   an acyclic AND/OR digraph, the unified model is virtually a
   multiobjective decision making problem that considers both numeric and
   symbolic objectives and decision variables. To solve this problem, the
   Post-model Analysis approach is adopted. An essential feature of the
   Post-model Analysis is that it supports nondominated tradeoffs among the
   numeric and symbolic objectives. So, this paper proposes a set of
   methods for computing the nondominated solutions. A prototype UNIK-PMA
   that realizes the idea is developed as a subsystem of the UNIK (UNIfied
   Knowledge) system.
RI Lee, Jae Kyu/C-1910-2011
ZA 0
ZS 0
TC 7
Z8 0
ZB 0
ZR 0
Z9 7
SN 0025-1909
UT WOS:A1995RN55000007
ER

PT J
AU KATZ, R
   TUSHMAN, M
   ALLEN, TJ
TI THE INFLUENCE OF SUPERVISORY PROMOTION AND NETWORK LOCATION ON
   SUBORDINATE CAREERS IN A DUAL LADDER RD-AND-E SETTING
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 848
EP 863
DI 10.1287/mnsc.41.5.848
PD MAY 1995
PY 1995
AB This longitudinal study examines the impacts of supervisors' promotion
   paths and gatekeeper status on the career outcomes of technical
   subordinates in a dual ladder system. Results indicate that project
   supervisors significantly affect the chances of one's promotion along
   each track. Professionals reporting to supervisors promoted to the
   technical ladder were significantly more likely to also be promoted
   technically, especially in research. On the other hand, professionals
   reporting to gatekeeping supervisors in development were significantly
   more likely to be promoted up the managerial ladder. Gatekeeper status
   was more important in influencing subordinates' communication activities
   and subsequent promotions than supervisors' promotion path. These
   results underscore the importance of managing socialization and the
   career paths of gatekeepers and those reporting to them for enhancing
   the success of dual ladder reward systems.
ZB 0
ZR 0
ZA 0
Z8 0
ZS 0
TC 24
Z9 24
SN 0025-1909
UT WOS:A1995RN55000008
ER

PT J
AU CHENG, DW
TI LINE REVERSIBILITY OF TANDEM QUEUES WITH GENERAL BLOCKING
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 864
EP 873
DI 10.1287/mnsc.41.5.864
PD MAY 1995
PY 1995
AB We extend the ''line reversibility'' property to a serial production
   system controlled using the ''general blocking'' scheme. The control
   mechanism is characterized by three vectors of integer parameters (a, b,
   k) which are, respectively, control parameters for the number of raw
   jobs, finished jobs, and buffer positions at each stage. We establish
   conditions under which the time to process a given set of jobs in a
   system does not change when the control parameters are in the reversed
   order. For cases where reversibility does not hold, we introduce a more
   restrictive form of reversibility-referred to as
   ''semi-reversibility''-and establish conditions under which the property
   holds. Our results imply reversibility of the kanban system and provide
   an alternative proof for previous results established for the
   communication and the manufacturing blockings. Our approach is simple
   and readily extends to closed systems where the number of jobs in the
   system is kept constant. Finally, we show, via an example, that in
   general reversibility does not prevail for this blocking mechanism.
ZR 0
TC 10
ZS 0
Z8 0
ZB 0
Z9 10
SN 0025-1909
UT WOS:A1995RN55000009
ER

PT J
AU FEDERGRUEN, A
   TZUR, M
TI FAST SOLUTION AND DETECTION OF MINIMAL FORECAST HORIZONS IN DYNAMIC
   PROGRAMS WITH A SINGLE INDICATOR OF THE FUTURE - APPLICATIONS TO DYNAMIC
   LOT-SIZING MODELS
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 874
EP 893
DI 10.1287/mnsc.41.5.874
PD MAY 1995
PY 1995
AB In most dynamic planning problems, one observes that an optimal decision
   at any given stage depends on limited information, i.e. information
   pertaining to a limited set of adjacent or nearby stages. This holds in
   particular for planning problems over time, where an optimal decision in
   a given period depends on information related to a limited future time
   horizon, a so-called forecast horizon, only. In this paper we identify a
   general class of dynamic programs in which an efficient forward
   algorithm can be designed to solve the problem and to identify minimal
   forecast horizons. Such a procedure specifies necessary and sufficient
   conditions for a stage to arise as a forecast horizon. This class of
   dynamic programs includes the single-item dynamic lot-sizing model with
   general concave costs, both with and without backlogging, to which
   special attention is given.
RI Tzur, Michal/L-1474-2019
ZB 1
ZR 0
ZA 0
ZS 0
TC 13
Z8 0
Z9 13
SN 0025-1909
UT WOS:A1995RN55000010
ER

PT J
AU SO, KC
   TANG, CS
TI OPTIMAL BATCH SIZING AND REPAIR STRATEGIES FOR OPERATIONS WITH
   REPAIRABLE JOBS
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 894
EP 908
DI 10.1287/mnsc.41.5.894
PD MAY 1995
PY 1995
AB This paper presents a model of a bottleneck facility that performs two
   distinct types of operations: ''regular'' and ''repair.'' Both
   switch-over time and cost are incurred when the facility switches from
   performing one type of operation to a different type, Upon the
   completion of a batch of jobs in the regular mode, each batch is
   subjected to a test, where the entire batch (of jobs) will be classified
   accordingly as either nondefective, repairable, or nonrepairable. A
   nondefective batch continues its process downstream, a nonrepairable
   batch is scrapped, and a repairable batch can be cycled back to the
   bottleneck facility for repair. The objective of this paper is to
   determine the optimal repair policy for the bottleneck facility so that
   the long run average operating profit is maximized. We first
   characterize the optimal repair policy by showing that the optimal
   repair policy must take one of the two forms: a ''repair-none'' policy
   under which all repairable batches are scrapped, or a ''repair-all''
   policy under which all repairable batches are repaired. We then develop
   optimality conditions for the repair-none policy and the repair-all
   policy. When the repair-all policy is optimal, we further show that
   there exists an optimal ''threshold'' operating policy that can be
   described as follows: upon completion of a regular batch, switch over to
   the repair mode only if the number of available repairable batches
   exceeds a certain threshold value. We also evaluate the impact of batch
   sizes, yield, and switch-over cost on the optimal operating policy.
TC 16
ZB 0
Z8 0
ZA 0
ZS 0
ZR 0
Z9 16
SN 0025-1909
UT WOS:A1995RN55000011
ER

PT J
AU XIE, JH
   SIRBU, M
TI PRICE-COMPETITION AND COMPATIBILITY IN THE PRESENCE OF POSITIVE DEMAND
   EXTERNALITIES
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 909
EP 926
DI 10.1287/mnsc.41.5.909
PD MAY 1995
PY 1995
AB In many cases, the benefit to a consumer of a product increases with the
   number of other users of the same product. These demand
   interdependencies are referred to in the literature as positive demand
   externalities or network externalities. This paper examines the dynamic
   pricing behaviors of an incumbent and a later entrant, with special
   attention to the impacts of demand externalities, compatibility, and
   competition on prices and profits. Defining market power as the ability
   to price above a competitor without losing market share, we show how
   demand externalities and installed base combine to confer market power.
   We model optimal pricing as a differential game with the optimal price
   trajectory established as Nash open-loop controls. For a duopoly durable
   goods market with strong demand externalities, the results show an
   increasing price trajectory can be optimal. As expected, a new entrant
   is better off if its products are compatible with those of the
   incumbent, especially when demand externalities are strong and the
   installed base of the incumbent is large. Less intuitively, the
   incumbent as well may be better off agreeing on common standards. The
   comparison of monopoly and duopoly shows that under strong demand
   externalities and a small installed base, the incumbent profits from
   compatible entry.
OI Sirbu, Marvin/0000-0002-4424-2023
ZS 0
TC 80
ZB 0
ZA 0
Z8 7
ZR 0
Z9 87
SN 0025-1909
UT WOS:A1995RN55000012
ER

PT J
AU BRILL, PH
   CHAOUCH, BA
TI AN EOQ MODEL WITH RANDOM VARIATIONS IN DEMAND
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP 927
EP 936
DI 10.1287/mnsc.41.5.927
PD MAY 1995
PY 1995
AB This paper presents a model that incorporates variations in the demand
   rate at random time points into the inventory planning decision. These
   changes in demand may occur due to economic recessions, labor strife
   starting or ending, or other events that result in a period of time
   during which the rate of demand is shifted up or down from its current
   level. The paper uses system-point level-crossing theory to derive
   expressions for the distribution and expected value of on-hand
   inventory, ordering rate, and the expected total cost rate for a given
   ordering policy. A sensitivity analysis is conducted, and a number of
   qualitative properties are provided to illustrate the use of the results
   to obtain optimal order quantities.
ZB 0
ZA 0
ZR 0
TC 18
ZS 0
Z8 2
Z9 20
SN 0025-1909
UT WOS:A1995RN55000013
ER

PT J
AU CLEMEN, RT
   KELLER, LR
TI EDITORIAL OBJECTIVES - DECISION-ANALYSIS
SO MANAGEMENT SCIENCE
VL 41
IS 5
BP U3
EP U3
PD MAY 1995
PY 1995
ZB 0
Z8 0
ZS 0
ZR 0
TC 0
Z9 0
SN 0025-1909
UT WOS:A1995RN55000001
ER

PT J
AU SEAVER, BL
   TRIANTIS, KP
TI THE IMPACT OF OUTLIERS AND LEVERAGE POINTS FOR TECHNICAL EFFICIENCY
   MEASUREMENT USING HIGH BREAKDOWN PROCEDURES
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 937
EP 956
DI 10.1287/mnsc.41.6.937
PD JUN 1995
PY 1995
AB Given that most data used for production studies have not been
   accumulated for such purposes, it is important that the quantitative
   tools for messy data which can affect the accuracy of computed technical
   efficiency measures be found. In this study, high breakdown robust
   methods are used in conjunction with a robust distance measure defined
   relative to the minimum volume ellipsoid estimator. The standardized
   robust residuals from the high breakdown estimators and the robust
   distance measures are used to statistically and graphically depict both
   multivariate outliers and leverage points.
   Once these points are found, their relationship to those observations
   that exhibit strong technically efficient or inefficient behavior, scale
   inefficiency and/or unusual production characteristics is analyzed for
   three linerboard manufacturing facilities. Additionally, the impact of
   the outliers and leverage points on the estimated least squares
   coefficients which are used by the corrected ordinary least squares
   methodology to compute the full-frontier technical efficiency measures
   is explored. Finally, a sensitivity analysis of the impact of outliers
   and leverage points on the computed linear programming based technical
   efficiency measures is presented.
ZA 0
ZB 1
ZR 0
Z8 0
ZS 1
TC 26
Z9 27
SN 0025-1909
UT WOS:A1995RV13000001
ER

PT J
AU RAJU, JS
   SETHURAMAN, R
   DHAR, SK
TI THE INTRODUCTION AND PERFORMANCE OF STORE BRANDS
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 957
EP 978
DI 10.1287/mnsc.41.6.957
PD JUN 1995
PY 1995
AB We present an analytical framework for understanding what makes a
   product category more conducive for store brand introduction. We also
   investigate market characteristics that help explain differences in
   store brand market share across product categories. Our findings suggest
   that the introduction of a store brand is likely to increase retailer's
   profits in a product category if the cross-price sensitivity among
   national brands is low and the cross-price sensitivity between the
   national brands and the store brand is high. Our model predicts that the
   store brand share would also be greater under these conditions. In
   addition, we find that the introduction of a store brand is more likely
   to lead to an increase in category profits if the category consists of a
   large number of national brands-even though the store brand market share
   is expected to be lower when there are a large number of national
   brands. We compare the key predictions of our model with data on 426
   grocery product categories. The data are consistent with the predictions
   of the model.
RI Sethuraman, Raj/F-2526-2010
ZR 0
TC 219
Z8 12
ZB 1
ZS 1
ZA 0
Z9 230
SN 0025-1909
UT WOS:A1995RV13000002
ER

PT J
AU CASEY, JT
TI PREDICTING BUYER-SELLER PRICING DISPARITIES
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 979
EP 999
DI 10.1287/mnsc.41.6.979
PD JUN 1995
PY 1995
AB Numerous studies have shown that compensation demanded (CD) to give up a
   commodity often greatly exceeds willingness to pay (WTP) to obtain the
   same commodity, even in incentive compatible experiments that penalize
   strategic misrepresentation. Observed CD/WTP disparities are too large
   to be reconciled with traditional assumptions of economic rationality. A
   prospect theory-based behavioral framework for predicting CD and WTP is
   proposed which produces five distinct transaction encoding rules, any
   one of which can in principle apply to a buyer or a seller. According to
   this framework, CD/WTP gaps occur when buyers and sellers encode the
   prospective transaction differently, and gaps can occur in multiple
   ways, and vary in size, depending on encoding. The transaction encoding
   framework was tested in two experiments. In Experiment 1, model fits to
   subjects' CD and WTP for lottery tickets were consistent with the
   hypothesis that buyers and sellers encode transaction problems
   differently. Moreover, the quite large observed CD/WTP gaps were
   explained fully by encoding: When differences between buyers' and
   sellers' encoding processes were taken into account, their estimated
   utility (value) and probability weighting functions did not differ. The
   present framework and results show that the widely cited endowment
   effect is but one of several ways in which loss aversion can give rise
   to CD/WTP gaps. Consistent with this broadened perspective, Experiment 2
   demonstrated CD/WTP gaps in the absence of an endowment effect (and in
   the absence of rational economic causes). The transaction encoding
   framework (1) provides a structured approach for predicting and testing
   the effects of a variety of task factors on pricing behavior and
   transaction outcomes, and (2) reveals the useful property that, in many
   cases, the ratio CD/WTP can be interpreted as a direct measure of the
   degree of loss aversion.
ZS 0
ZA 0
TC 22
ZR 0
Z8 0
ZB 1
Z9 22
SN 0025-1909
UT WOS:A1995RV13000003
ER

PT J
AU OU, JH
   WEIN, LM
TI DYNAMIC SCHEDULING OF A PRODUCTION INVENTORY SYSTEM WITH BY-PRODUCTS AND
   RANDOM YIELD
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 1000
EP 1017
DI 10.1287/mnsc.41.6.1000
PD JUN 1995
PY 1995
AB Motivated by semiconductor wafer fabrication, we consider a scheduling
   problem for a single-server multiclass queue. A single workstation
   fabricates semiconductor wafers according to a variety of different
   processes, where each process consists of multiple stages of service
   with a different general service time distribution at each stage. A
   batch (or lot) of wafers produced according to a particular process
   randomly yields chips of many different product types, and completed
   chips of each type enter a finished goods inventory that services
   exogenous customer demand for that type. The scheduling problem is to
   dynamically decide whether the server should be idle or working, and in
   the latter case, to decide which stage of which process type to serve
   next. The objective is to minimize the long run expected average cost,
   which includes costs for holding work-in-process inventory (which may
   differ by process type and service stage) and backordering and holding
   finished goods inventory (which may differ by product type). We assume
   the workstation must be busy the great majority of the time in order to
   satisfy customer demand, and approximate the scheduling problem by a
   control problem involving Brownian motion. A scheduling policy is
   derived by interpreting the exact solution to the Brownian control
   problem in terms of the production/inventory system. The proposed
   dynamic scheduling policy takes a relatively simple form and appears to
   be effective in numerical studies.
ZB 0
TC 9
ZA 0
ZS 0
ZR 0
Z8 0
Z9 9
SN 0025-1909
UT WOS:A1995RV13000004
ER

PT J
AU BELL, PC
   OKEEFE, RM
TI AN EXPERIMENTAL INVESTIGATION INTO THE EFFICACY OF VISUAL INTERACTIVE
   SIMULATION
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 1018
EP 1038
DI 10.1287/mnsc.41.6.1018
PD JUN 1995
PY 1995
AB The use of a Visual Interactive Simulation (VIS) model for experimental
   analysis, where the user initiates runs and gathers information as
   desired without necessarily any respect for formal analysis, is
   encouraged by some proponents of VIS and VIS software packages.
   Proponents of formal output analysis view this approach as dangerous and
   irresponsible.
   We designed and executed a laboratory experiment in which 51 subjects
   solved a case study based around the allocation of trucks in a mining
   operation in order to investigate the efficacy of VIS to model
   experimentation. Subjects were provided with a VIS, developed by the
   authors, which contained a terminating simulation of the system and two
   different displays: an animation and a dynamically changing histogram.
   The user could halt execution of the model and change the truck
   allocation at any time.
   We found that subjects performed badly relative to a known solution
   obtained through detailed formal experimentation but performed well
   compared to solutions they provided prior to use of the model. Use of
   the animated display was not associated with correct solutions but was
   associated with more efficient use of the VIS. Subjects who obtained a
   correct solution investigated fewer alternatives and used fewer
   interactions than those obtaining incorrect solutions. Finally, we found
   a significant difference in the process used between subjects providing
   correct and incorrect solutions.
ZR 0
ZS 0
Z8 0
TC 16
ZA 0
ZB 0
Z9 16
SN 0025-1909
UT WOS:A1995RV13000005
ER

PT J
AU AVIITZHAK, B
   LEVY, H
TI A SEQUENCE OF SERVERS WITH ARBITRARY INPUT AND REGULAR SERVICE TIMES
   REVISITED - IN MEMORY OF YADIN,MICHA
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 1039
EP 1047
DI 10.1287/mnsc.41.6.1039
PD JUN 1995
PY 1995
AB The March 1965 issue of Management Science saw a sequence of two papers
   by Avi-Itzhak and Yadin, the first presenting analysis of a two-server
   tandem system, with manufacturing blocking and no intermediate queue,
   leading to the second paper, which analyzes an arbitrary number of
   tandem servers with manufacturing blocking.
   In this work we present generalized results for the same systems under
   k-stage blocking. One-stage blocking is the so-called manufacturing
   blocking in which a job entering the jth service position in the
   sequence requires attendance by the jth server only. Upon completion of
   service the job will move to position (j + 1) if that position is not
   occupied. Otherwise, it will continue to stay in position j, blocking
   it, until the next position is vacated. Two-stage blocking is the
   so-called communication blocking in which a job entering the jth
   position needs simultaneous attendance by the jth and the (j + 1)-th
   servers. Thus, start of service may be delayed until the (j + 1)-th
   server is freed. In k-stage blocking, the job requires at each position
   in the sequence the joint attendance of the server of that position
   together with the servers of the next k - 1 positions.
   One interesting result is that for k > 1 the waiting times are not
   order-insensitive while the G/D/1 equivalence is maintained.
ZA 0
ZR 0
ZS 0
Z8 0
ZB 0
TC 10
Z9 10
SN 0025-1909
UT WOS:A1995RV13000006
ER

PT J
AU LO, VSY
   BACONSHONE, J
   BUSCHE, K
TI THE APPLICATION OF RANKING PROBABILITY-MODELS TO RACETRACK BETTING
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 1048
EP 1059
DI 10.1287/mnsc.41.6.1048
PD JUN 1995
PY 1995
AB Hausch et al. (HZR) (1981) developed a betting system that demonstrated
   positive profits at two racetracks. The system assumes running times are
   distributed exponentially, but other distributions for running times
   (Henery 1981 and Stem 1990) have been shown to produce a better fit in
   Bacon-Shone et al. (1992a), Lo (1994), and Lo and Bacon-Shone (1994)
   using data from Hong Kong, the Meadowlands, and Japan. The better fit is
   at the cost of severely increased complexity in computing ranking
   probabilities, though. In response, Lo and Bacon-Shone (1992) proposed a
   simple model of computing ranking probabilities which closely
   approximates those based on the Henery and the Stern models and fits the
   data as well. This paper couples the Lo and Bacon-Shone model and the
   HZR system. For data sets from the United States and Hong Kong, we show
   improved profit over the HZR system at lower levels of risk using final
   betting data assuming zero computational costs. With data from Japan,
   our model shows little difference in profits from the HZR system.
CT ORSA/TIMS Conference
CY NOV, 1993
CL PHOENIX, AZ
SP ORSA; TIMS
RI Bacon-Shone, John/B-8040-2008
OI Bacon-Shone, John/0000-0002-9827-1815
ZS 0
TC 12
ZB 0
ZR 0
Z8 0
ZA 0
Z9 12
SN 0025-1909
UT WOS:A1995RV13000007
ER

PT J
AU PAVIA, TM
TI PROFIT MAXIMIZING COST ALLOCATION FOR FIRMS USING COST-BASED PRICING
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 1060
EP 1072
DI 10.1287/mnsc.41.6.1060
PD JUN 1995
PY 1995
AB This work develops a profit maximizing cost allocation scheme for firms
   that allocate all costs to their various outputs and then use these
   costs to set prices, a process known as fully-distributed cost-based
   pricing. If the costs incurred by the firm are not easily traced to a
   particular output (for example, the electric bill for a shared
   manufacturing plant), the costs must be allocated. The demand for a
   given output is assumed to be a function of the price. Hence, the cost
   allocation scheme that is selected will affect both the price and the
   demand for the output. The allocation of common costs that maximizes the
   firm's overall profit under these conditions is identified. Frequently,
   the profit maximizing allocation allocates none of the untraceable
   common costs to one or more of the outputs. This allocation scheme
   stands in contrast to common practices of sharing costs equally or
   proportionally across outputs. Examples explore the implications of such
   a profit maximizing cost allocation on prices and demand in four
   scenarios: i) no constraints, ii) constraints on maximum allowable
   prices, iii) a change in market size, and iv) cost containment
   incentives.
ZB 0
ZA 0
Z8 0
ZS 0
TC 4
ZR 0
Z9 4
SN 0025-1909
UT WOS:A1995RV13000008
ER

PT J
AU BOWDEN, RJ
TI PRODUCTION ORGANIZATION AND RISK CONTROL WHEN MARKET INSTRUMENTS ARE
   AVAILABLE
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 1073
EP 1082
DI 10.1287/mnsc.41.6.1073
PD JUN 1995
PY 1995
AB A standard result in the theory of production under price risk is that
   if forward cover is available, production is determined in terms of the
   known, quoted forward or futures price, rather than expectations of
   future prices. In practice, however, primary production often involves
   joint or substitutable products, so that a natural hedge may be
   available. In addition, costs such as input prices or interest rates are
   highly variable and may be correlated with output prices. Supply risk
   adds to this variation. This paper considers the demand for market-based
   hedging instruments in relation to such natural hedges and to the
   possible use of storage for hedging purposes. Under normality of
   conditional price/cost variation it is shown that for relatively
   arbitrary nonlinear production technologies and attitudes to risk,
   producers can plan production and derive their demand for futures by
   decomposing the organisation into a number of activity centres,
   involving planning, marketing, cost, and treasury functions. Adding up
   the hedging demands from each centre, and equating to the effective
   supply of each type of hedge (natural and market), yields a linear
   system that may be solved for the optimum quantities of each hedge
   contract.
Z8 0
TC 1
ZS 0
ZA 0
ZR 0
ZB 0
Z9 1
SN 0025-1909
UT WOS:A1995RV13000009
ER

PT J
AU CHOWDHRY, B
TI CORPORATE HEDGING OF EXCHANGE RISK WHEN FOREIGN-CURRENCY CASH FLOW IS
   UNCERTAIN
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 1083
EP 1090
DI 10.1287/mnsc.41.6.1083
PD JUN 1995
PY 1995
AB We analyze hedging policies for a corporation that generates a foreign
   currency cash flow that is not known with certainty. We obtain an
   intriguing result that the probability of bankruptcy for a firm that
   attempts to minimize this probability is lower when there is some
   uncertainty in the exchange rates than when there is no uncertainty in
   the exchange rates: the firm reduces the probability of bankruptcy by
   borrowing more than its financing needs through foreign currency
   borrowing alone and by investing the excess funds in domestic risk-free
   securities.
TC 11
ZR 0
ZS 1
Z8 0
ZA 0
ZB 0
Z9 12
SN 0025-1909
UT WOS:A1995RV13000010
ER

PT J
AU PEREZ, J
TI SOME COMMENTS ON SAATYS AHP
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 1091
EP 1095
DI 10.1287/mnsc.41.6.1091
PD JUN 1995
PY 1995
AB The purpose of this short paper is to help clarify some questions which
   have arisen with respect to the suitability, or even the correctness, of
   the way Saaty's AHP method handles criteria weights, sometimes causing
   the rank reversal phenomenon. The position set forth in this paper is
   that this undesirable effect does not, per se, invalidate that method,
   but it does make it necessary to identify the kind of situations in
   which the method is suitable.
ZA 0
ZS 2
TC 70
ZB 4
ZR 0
Z8 1
Z9 73
SN 0025-1909
UT WOS:A1995RV13000011
ER

PT J
AU GLYNN, PW
   IGLEHART, DL
TI TRADING SECURITIES USING TRAILING STOPS
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 1096
EP 1106
DI 10.1287/mnsc.41.6.1096
PD JUN 1995
PY 1995
AB In financial markets traders often protect their position from a
   significant decline by using a trailing stop. Assume the trader is long
   the market (owns the security). A trailing stop is an order to sell the
   security at the market, if the price of the security drops to the stop
   price. The stop price is always less than the market price when the stop
   is entered. As the price fluctuates, the stop is raised to remain a
   fixed distance from the maximum price at which the security trades. In
   this paper we consider two models for the price process: a discrete time
   random walk and continuous time Brownian motion, both with positive
   drift. For these price processes we compute the distribution, mean, and
   variance of the gain to the trader as well as the duration of the trade
   when a trailing stop strategy is used. Also discussed is the question of
   optimizing the distance from the current price to the stop.
TC 14
Z8 0
ZR 0
ZA 0
ZB 0
ZS 0
Z9 14
SN 0025-1909
UT WOS:A1995RV13000012
ER

PT J
AU DAVIS, JL
   MASSEY, WA
   WHITT, W
TI SENSITIVITY TO THE SERVICE-TIME DISTRIBUTION IN THE NONSTATIONARY ERLANG
   LOSS MODEL
SO MANAGEMENT SCIENCE
VL 41
IS 6
BP 1107
EP 1116
DI 10.1287/mnsc.41.6.1107
PD JUN 1995
PY 1995
AB The stationary Erlang loss model is a classic example of an insensitive
   queueing system: the steady-state distribution of the number of busy
   servers depends on the service-time distribution only through its mean.
   However, when the arrival process is a nonstationary Poisson process,
   the insensitivity property is lost. We develop a simple, effective
   numerical algorithm for the M(t)/PH/s/0 model with two service phases
   and a nonhomogeneous Poisson arrival process, and apply it to show that
   the time-dependent blocking probability with nonstationary input can be
   strongly influenced by the service-time distribution beyond the mean.
   With sinusoidal arrival rates, the peak blocking probability typically
   increases as the service-time distribution gets less variable. The
   influence of the service-time distribution, including this seemingly
   anomalous behavior, can be understood and predicted from the
   modified-offered-load and stationary-peakedness approximations, which
   exploit exact results for related infinite-server models.
RI Whitt, Ward/D-5337-2013
OI Whitt, Ward/0000-0003-4298-9964
ZB 0
ZS 0
ZR 0
ZA 0
TC 32
Z8 1
Z9 32
SN 0025-1909
UT WOS:A1995RV13000013
ER

PT J
AU LENK, PJ
   RAO, AG
TI TRANSITION TIMES - DISTRIBUTIONS ARISING FROM TIME HETEROGENEOUS POISSON
   PROCESSES
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1117
EP 1129
DI 10.1287/mnsc.41.7.1117
PD JUL 1995
PY 1995
AB The units of a heterogeneous population are subjected to shocks. A unit
   fails, or more generally, undergoes a change of state after a sufficient
   number of shocks. The shocks for a particular unit are assumed to arrive
   according to a time heterogeneous Poisson process. The time to a change
   of state, the transition time, for the unit has a generalized Gamma
   (gamma) distribution. We assume that the intensity of the Poisson
   process and the number of shocks until the change of state vary
   independently across the units according to a Gamma and negative
   binomial distribution, respectively. The distribution of the transition
   time is shown to be the generalized F distribution, which includes a
   number of standard distributions as special cases. We illustrate these
   results with two empirical examples: modelling coupon redemptions and
   traffic accidents. In the latter case, the intensity function of the
   Poisson process includes time varying predictor variables.
ZB 0
ZR 0
Z8 0
TC 5
ZA 0
ZS 0
Z9 5
SN 0025-1909
UT WOS:A1995TC16400001
ER

PT J
AU FISHBURN, P
   WAKKER, P
TI THE INVENTION OF THE INDEPENDENCE CONDITION FOR PREFERENCES
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1130
EP 1144
DI 10.1287/mnsc.41.7.1130
PD JUL 1995
PY 1995
AB This paper discusses the history and interrelations of three central
   ideas in preference theory: the independence condition in decision under
   risk, the sure-thing principle in decision under uncertainty, and
   conjoint independence for multiattribute decisions and consumer theory.
   Independence was recognized as an important component of decision under
   risk in the late 1940s by Jacob Marschak, John Nash, Herman Rubin, and
   Norman Dalkey, and first appeared in publication in Marschak (1950) and
   Nash (1950). The sure-thing principle can be credited to Savage (1953,
   1954). Conjoint independence for consumer theory was introduced by Sono
   (1943) and Leontief (1947a, b); a form of it can also be recognized in
   Samuelson (1947), presented earlier in Samuelson (1940).
   Independence and the sure-thing principle are equivalent for decision
   under risk, but in a less elementary way than has sometimes been
   thought. The sure-thing principle for decision under uncertainty and
   conjoint independence are identical in a mathematical sense.
   The mathematics underlying our three preference conditions has an older
   history. The independence condition for decision under risk can be
   recognized in the characterization of ''associative means,'' and
   conjoint independence for multiattribute decisions in solutions to the
   ''generalized associativity functional equation.''
ZS 1
Z8 1
ZR 0
TC 40
ZA 0
ZB 0
Z9 42
SN 0025-1909
UT WOS:A1995TC16400002
ER

PT J
AU BELL, DE
TI A CONTEXTUAL UNCERTAINTY CONDITION FOR BEHAVIOR UNDER RISK
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1145
EP 1150
DI 10.1287/mnsc.41.7.1145
PD JUL 1995
PY 1995
AB Suppose that your choice between uncertain financial prospects is made
   more difficult by two independent contextual uncertainties concerning
   the size of your existing wealth. One contextual uncertainty has a
   greater spread than the other. If you could resolve one of these
   contextual uncertainties before making your choice, would you rather it
   be the larger or the smaller? In this paper we explore the intuitive
   notion that it ought to be more advantageous to resolve larger rather
   than smaller contextual uncertainties. The utility function for wealth
   u(w) = aw - be(-cw) (a, b, c greater than or equal to 0) is the only
   utility function that satisfies this condition and that is also
   increasing and risk averse at all wealth levels.
ZB 0
ZA 0
ZR 0
TC 18
ZS 0
Z8 1
Z9 19
SN 0025-1909
UT WOS:A1995TC16400003
ER

PT J
AU LEE, SW
   CHANG, KP
TI MEAN-VARIANCE-INSTABILITY PORTFOLIO ANALYSIS - A CASE OF TAIWAN
   STOCK-MARKET
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1151
EP 1157
DI 10.1287/mnsc.41.7.1151
PD JUL 1995
PY 1995
AB This paper applies Talpaz, Harpaz, and Penson's (THP) (1983)
   mean-variance-instability portfolio selection model to eight selected
   Taiwan stocks during 1980-89 to demonstrate how instability preference
   affects the traditional mean-variance frontier. In contrast to THP's
   finding, the empirical results show that Taiwan's high-frequency stocks
   have high, not low, variance. This indicates that Taiwan investors,
   unlike U.S. investors, prefer to speculate in high-variance stocks. The
   empirical results also show that short selling may increase the risk of
   the portfolio when the investor is instability preferred.
ZB 0
ZR 0
ZA 0
TC 3
Z8 0
ZS 0
Z9 3
SN 0025-1909
UT WOS:A1995TC16400004
ER

PT J
AU KOKSALAN, MM
   SAGALA, PNS
TI INTERACTIVE APPROACHES FOR DISCRETE ALTERNATIVE MULTIPLE CRITERIA
   DECISION-MAKING WITH MONOTONE UTILITY-FUNCTIONS
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1158
EP 1171
DI 10.1287/mnsc.41.7.1158
PD JUL 1995
PY 1995
AB In this paper we develop interactive approaches for the discrete
   alternative multiple criteria decisionmaking problem. We develop an
   algorithm that finds the most preferred alternative of a decision maker
   (DM) assuming only that the DM has a monotonic utility function. The
   algorithm divides the criteria space into a number of smaller subspaces
   and then uses the ideal points of these subspaces to eliminate
   alternatives. We also develop a more efficient version of the algorithm
   for the more restrictive case of a monotonic quasiconcave utility
   function. We present favorable computational results in terms of the
   required number of pairwise comparisons for both versions of the
   algorithm. We then develop a general algorithm that first identifies the
   type of the DM's utility function and then employs the approach that is
   compatible with the identified utility function type. We also present
   computational results for the general algorithm.
RI Koksalan, Murat/A-9116-2016
OI Koksalan, Murat/0000-0002-5423-3905
ZB 1
ZA 0
ZS 0
ZR 0
Z8 0
TC 46
Z9 46
SN 0025-1909
UT WOS:A1995TC16400005
ER

PT J
AU GOLANY, B
   TAMIR, E
TI EVALUATING EFFICIENCY-EFFECTIVENESS-EQUALITY TRADE-OFFS - A DATA
   ENVELOPMENT ANALYSIS APPROACH
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1172
EP 1184
DI 10.1287/mnsc.41.7.1172
PD JUL 1995
PY 1995
AB This paper presents a resource allocation model based on Data
   Envelopment Analysis (DEA). The model extends the original objective of
   the DEA methodology from measuring efficiency to include the evaluation
   of various aspects of effectiveness and equality considerations. The
   model is formulated as a linear program that can be solved by means of a
   Dantzig-Wolfe decomposition algorithm. Theoretical properties of the
   model are compared with those corresponding to the model developed by
   Mandell (1991) to evaluate the trade-off between equity and
   effectiveness. A numerical example is used to illustrate the comparison
   between the models.
ZR 0
TC 89
ZA 0
Z8 9
ZS 1
ZB 2
Z9 97
SN 0025-1909
UT WOS:A1995TC16400006
ER

PT J
AU MCLAUGHLIN, CP
   YANG, ST
   VANDIERDONCK, R
TI PROFESSIONAL SERVICE ORGANIZATIONS AND FOCUS
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1185
EP 1193
DI 10.1287/mnsc.41.7.1185
PD JUL 1995
PY 1995
AB This paper suggests a framework for operations managers to use in making
   focus decisions in professional services. This framework is supported
   empirically from data from the health care industry using three types of
   data: (1) industry statistics, (2) case studies, and (3) questionnaire
   surveys. Our objective has been to: (1) gain a better understanding of
   the concept of focus as it applies to the health care sector, (2)
   develop a framework to assist service operations managers with focus
   decisions, and (3) develop a base from which to generalize about
   microfocusing decisions in professional services.
ZA 0
ZB 0
Z8 0
ZS 0
TC 21
ZR 0
Z9 21
SN 0025-1909
UT WOS:A1995TC16400007
ER

PT J
AU INGENE, CA
   PARRY, ME
TI A NOTE ON MULTI-REGIONAL MARKETING
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1194
EP 1201
DI 10.1287/mnsc.41.7.1194
PD JUL 1995
PY 1995
AB This paper examines the profit maximizing behavior of a vertically
   integrated firm that operates in ''n'' geographically distinct regions.
   A pair of alternative managerial decision scenarios are considered. In
   one scenario, all marketing mix variables are manipulated at the
   regional level, so that each region may choose different levels of each
   marketing variable. In the second scenario, one marketing variable is
   manipulated ''globally,'' so that its level is identical in all regions.
   The first scenario generates an n-region version of the
   ''Dorfman-Steiner'' first-order conditions for profit maximization.
   However, under some cost structures the profits associated with this
   Dorfman-Steiner scenario are dominated by those associated with the
   second, ''Global-Regional'' scenario. This second scenario yields an
   optimal solution in which the global marketing variable may have a
   negative marginal impact on sales in some regions. As a result, some
   managerial implications of the second scenario differ strikingly from
   those of the Dorfman-Steiner scenario.
ZR 0
ZS 0
ZB 0
Z8 0
TC 5
ZA 0
Z9 5
SN 0025-1909
UT WOS:A1995TC16400008
ER

PT J
AU RAATIKAINEN, KEE
TI SIMULATION-BASED ESTIMATION OF PROPORTIONS
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1202
EP 1223
DI 10.1287/mnsc.41.7.1202
PD JUL 1995
PY 1995
AB Simulated estimates for several proportions are needed in many
   simulation studies. We propose a method for controlling the length of a
   simulation run so that the proportions estimated satisfy a prespecified
   precision requirement.
   The method applies the arcsin transform in order to generate confidence
   intervals with the desired width. The Bonferroni inequality is applied
   in a new way to construct a rectangular confidence area for the
   proportions being estimated. Since we are using the Bonferroni
   inequality, we can use the existing methods developed for estimating the
   variance of a single mean.
   The properties of the method proposed depend on three factors: 1) the
   arcsin transform, 2) the proposed way of applying the Bonferroni
   inequality, and 3) the method for estimating the variance. We examine
   the effects that the transform and the way of applying the Bonferroni
   inequality have.
   Empirical results indicate that the method provides estimates that
   satisfy the prespecified precision requirement, when the spectral method
   is used to estimate the variances of the proportions. In addition,
   simulation runs, when estimating either several proportions or the
   corresponding mean, are about the same lengths.
ZS 0
ZA 0
ZR 0
Z8 0
TC 2
ZB 0
Z9 2
SN 0025-1909
UT WOS:A1995TC16400009
ER

PT J
AU ETTLIE, JE
TI PRODUCT-PROCESS DEVELOPMENT INTEGRATION IN MANUFACTURING
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1224
EP 1237
DI 10.1287/mnsc.41.7.1224
PD JUL 1995
PY 1995
AB Organizations vary greatly in their approaches and success in the
   introduction of new products and services. In this study, it was
   proposed that much of this variance can be captured by understanding the
   extent to which product design and process design are integrated in new
   program launches. A mailed survey of 43 domestic firms was used to test
   four propositions concerning product-process development practices.
   Significantly, it was found that firms using the more rare
   design-manufacturing personnel integrating mechanisms (engineering job
   rotation and mobility) have higher sales per employee. Results of a
   discriminant analysis show that firms benchmarking on product
   development practices, as contrasted with performance benchmarks, were
   significantly more likely to use both the rare and the more common forms
   of design-manufacturing integration (i.e., train personnel in new
   design, methods, have manufacturing sign-off on design reviews, and
   restructure, e.g., use teams). Significantly, these firms also report a
   greater proportion of degreed manufacturing engineers. Not surprisingly,
   larger firms and business units were found to take longer to develop new
   products.
TC 111
ZB 0
ZR 0
ZS 1
Z8 2
ZA 0
Z9 114
SN 0025-1909
UT WOS:A1995TC16400010
ER

PT J
AU FLADMOELINDQUIST, K
   JACQUE, LL
TI CONTROL MODES IN INTERNATIONAL SERVICE OPERATIONS - THE PROPENSITY TO
   FRANCHISE
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1238
EP 1249
DI 10.1287/mnsc.41.7.1238
PD JUL 1995
PY 1995
AB What determines a service firm's organizational choice between
   equity-based control and franchising? This question, which has elicited
   some theoretical answers and a few empirical tests in a domestic
   setting, has never been addressed in an international context before.
   This study explains the mode of control chosen in terms of a theoretical
   framework which borrows from agency theory and transaction cost
   analysis. The propensity to franchise internationally was found to be
   directly related to (i) monitoring costs associated with geographical
   and ''cultural'' distance between the principal (franchisor) and its
   foreign agents (franchisees), (ii) the principal's international
   experience, and (iii) the degree of host countries' contextual
   uncertainty but inversely related to the service firm level of brand
   name asset specificity.
ZR 0
ZA 1
ZS 5
TC 168
Z8 2
ZB 1
Z9 176
SN 0025-1909
UT WOS:A1995TC16400011
ER

PT J
AU APTE, UM
   MASON, RO
TI GLOBAL DISAGGREGATION OF INFORMATION-INTENSIVE SERVICES
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1250
EP 1262
DI 10.1287/mnsc.41.7.1250
PD JUL 1995
PY 1995
AB Information-intensive services are being globally disaggregated as
   corporations respond to the pressures of increasing global competition,
   and take advantage of the opportunities made available by the progress
   of information technology and the emerging global work force. In order
   to globally disaggregate services, corporations must decide whether or
   not to carry out a service activity within the organization, and where
   to locate it, within or outside the geographic boundary of the home-base
   country. This paper analyzes the opportunities and challenges of global
   disaggregation of information-intensive services. Specifically, the
   paper proposes a taxonomy of disaggregation, and develops a theoretical
   framework that identifies the criteria and guidelines for successfully
   selecting service activities to be globally disaggregated.
ZR 0
ZA 0
ZB 0
Z8 1
ZS 1
TC 162
Z9 163
SN 0025-1909
UT WOS:A1995TC16400012
ER

PT J
AU SAMADDAR, S
   KAUL, T
TI EFFECTS OF SETUP AND PROCESSING TIME REDUCTIONS ON WIP IN THE JIT
   PRODUCTION SYSTEMS
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1263
EP 1265
DI 10.1287/mnsc.41.7.1263
PD JUL 1995
PY 1995
AB Sarkar and Zangwill (S-Z, 1998) have shown that in the presence of
   variance, setup and processing time reductions can have ''detrimental''
   effects on the work-in-process (WIP) inventory in both push and pull
   (JIT) systems. In this note, we point out that the merits of such a
   warning for JIT production systems are questionable.
   If we treat a setup as a PERT network, it is difficult to accept S-Z
   claim that waiting queues can grow without bound when setup time is
   reduced. Furthermore, we show that the amount of setup cut, in addition
   to the level of variance, can determine whether waiting time grows or
   not. This finding can help in planning a viable setup reduction project.
   Additionally, we use S-Z example to show that, even when the variances
   are not reduced proportionately, the expected waiting time does not
   necessarily increase.
ZR 0
TC 7
ZA 0
ZB 0
Z8 0
ZS 0
Z9 7
SN 0025-1909
UT WOS:A1995TC16400013
ER

PT J
AU ZAHEER, A
   VENKATRAMAN, N
TI DETERMINANTS OF ELECTRONIC INTEGRATION IN THE INSURANCE INDUSTRY - AN
   EMPIRICAL-TEST (VOL 40, PG 549, 1994)
SO MANAGEMENT SCIENCE
VL 41
IS 7
BP 1266
EP 1266
PD JUL 1995
PY 1995
RI Venkatraman, N. Venkat/AAB-2555-2019
TC 0
ZR 0
ZS 0
ZA 0
Z8 0
ZB 0
Z9 0
SN 0025-1909
UT WOS:A1995TC16400014
ER

PT J
AU BUGHIN, J
TI UNION-FIRM BARGAINING AND THE INFLUENCE OF PRODUCT MARKET POWER AND
   PRODUCTION TECHNOLOGY ON SYSTEMATIC-RISK
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1267
EP 1278
DI 10.1287/mnsc.41.8.1267
PD AUG 1995
PY 1995
AB The relationship between the CAPM firm beta and the firm's microeconomic
   decisions is studied by a model under uncertainty, which combines the
   feature of an ex ante ''inputs substituable'' production technology and
   the existence of a union which bargains over various economic dimensions
   of the firm.
   It is shown that the earlier findings of a relationship between the firm
   beta, the firm product market power, and the labor-capital ratio may be
   reinforced through the indirect channel of labor market bargaining, but
   the relationship becomes more complex, and heavily depends on the scope
   of the union-firm bargaining process.
   This yields the empirical prediction, confirmed for a panel of Belgian
   firms, that any proper estimation of the determinants of firm beta, must
   control for firms in the sample being unionized.
CT XI Latin-American Meeting of the Econometric-Society
CY SEP, 1992
CL MEXICO
SP Econometr Soc
ZS 0
TC 3
ZR 0
ZA 0
Z8 0
ZB 0
Z9 3
SN 0025-1909
UT WOS:A1995TD41100001
ER

PT J
AU PETERSON, MD
   BERTSIMAS, DJ
   ODONI, AR
TI MODELS AND ALGORITHMS FOR TRANSIENT QUEUING CONGESTION AT AIRPORTS
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1279
EP 1295
DI 10.1287/mnsc.41.8.1279
PD AUG 1995
PY 1995
AB We develop a new model for studying the phenomenon of congestion in a
   transient environment, focusing on the problem of aircraft landings at a
   busy ''hub'' airport. Our model is based on a Markov/semi-Markov
   treatment of changes in the weather, the principal source of uncertainty
   governing service times, together with a treatment of the arrival stream
   as time-varying but deterministic. The model is employed to compute
   moments of queue length and waiting time via a recursive algorithm. To
   test the model, we conduct a case study using traffic and capacity data
   for Dallas-Fort Worth International Airport. Our results show that the
   model's estimates are reasonable, though substantial data difficulties
   make validation difficult. We explore, as examples of the model's
   potential usefulness, two policy questions: schedule interference
   between the two principal carriers, and the likely effects of demand
   smoothing policies on queueing delays.
ZR 0
ZA 0
ZS 0
ZB 0
TC 42
Z8 2
Z9 44
SN 0025-1909
EI 1526-5501
UT WOS:A1995TD41100002
ER

PT J
AU LIBERATORE, MJ
   STYLIANOU, AC
TI EXPERT SUPPORT SYSTEMS FOR NEW PRODUCT DEVELOPMENT DECISION-MAKING - A
   MODELING FRAMEWORK AND APPLICATIONS
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1296
EP 1316
DI 10.1287/mnsc.41.8.1296
PD AUG 1995
PY 1995
AB A modeling framework that merges knowledge-based expert systems and
   decision support systems with management science methods for project
   evaluation is presented. In particular, the strategic decision to commit
   to full-scale development of a new product is considered. At the core of
   the framework are the methods and techniques used for acquiring,
   modeling and processing the expert knowledge and data. Methods and
   techniques used include scoring models, logic tables, the analytic
   hierarchy process, discriminant analysis, and rule-based systems. The
   suggested modeling approach obtains the benefits of normative modeling
   as well as the flexibility and developmental advantages of expert
   systems. Additional benefits include reduced information processing and
   gathering time, which can help to accelerate the product development
   cycle. Potential spin-offs of this research include applications for
   project evaluation throughout the product development cycle and other
   areas such as capital budgeting. Finally, a series of related case
   studies that have successfully implemented this framework is described.
ZA 0
Z8 0
TC 52
ZS 0
ZR 0
ZB 0
Z9 52
SN 0025-1909
UT WOS:A1995TD41100003
ER

PT J
AU KLOTZ, DE
   CHATTERJEE, K
TI DUAL SOURCING IN REPEATED PROCUREMENT COMPETITIONS
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1317
EP 1327
DI 10.1287/mnsc.41.8.1317
PD AUG 1995
PY 1995
AB The issue of maintaining competition over time in a repeated procurement
   setting is important for both government and private sector buyers. The
   U.S. Department of Defense has experimented with splitting production
   quantities between two or more contractors in an effort to make
   government business more attractive for the private sector. This paper
   analyzes the effectiveness of this strategy. We find that in a
   two-period model with production learning and entry costs, dual
   sourcing, even for the specific mechanism we consider, in some cases,
   reduces overall expected cost. Moreover, if buyers are unable to commit
   to long-term contracts or suppliers are unable to bid away anticipated
   gains, the incentives to dual source are often stronger.
Z8 0
ZR 1
TC 40
ZS 0
ZB 0
ZA 0
Z9 41
SN 0025-1909
UT WOS:A1995TD41100004
ER

PT J
AU STRAUB, D
   LIMAYEM, M
   KARAHANNAEVARISTO, E
TI MEASURING SYSTEM USAGE - IMPLICATIONS FOR IS THEORY TESTING
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1328
EP 1342
DI 10.1287/mnsc.41.8.1328
PD AUG 1995
PY 1995
AB There is widespread agreement among researchers that system usage,
   defined as the utilization of information technology (IT) by
   individuals, groups, or organizations, is the primary variable through
   which IT affects white collar performance. Despite the number of studies
   targeted at explaining system usage, there are crucial differences in
   the way the variable has been conceptualized and operationalized. This
   wide variation of system usage measures hinders the efforts of MIS
   researchers to compare findings across studies, thus impeding the
   accumulation of knowledge and theory in this area.
   The purpose of this paper is to address conceptual as well as
   methodological issues related to measuring system usage. First, via
   LISREL measurement modeling techniques, we compare subjective and
   objective measures of system usage, namely, self-reported versus
   computer-recorded measures. Next, using a modified form of Davis'
   Technology Acceptance Model (TAM) as a nomological net, we test the
   nomological validity of these system usage constructs and measures.
   Results of the LISREL measurement and nomological net analysis suggest
   that system usage should be factored into self-reported system usage and
   computer-recorded system usage. Contrary to expectations, these
   constructs do not appear to be strongly related to each other. Moreover,
   while self-reported measures of system usage are related to
   self-reported measures of TAM independent variables, objective,
   computer-recorded measures show distinctly weaker links.
   In the face of such counter-evidence, it is tempting to argue that
   research that has relied on subjective measures of system usage (for
   example, research confirming TAM) may be artifactual. There are several
   alternative explanations, though, that maintain the integrity of TAM and
   studies that measure system usage subjectively. These alternative
   explanations suggest directions for further research as well as new
   approaches to measurement.
RI Tavares, Antonio JV/A-7115-2008
ZB 2
TC 429
ZS 4
ZR 0
ZA 1
Z8 0
Z9 433
SN 0025-1909
EI 1526-5501
UT WOS:A1995TD41100005
ER

PT J
AU WHANG, SJ
TI MARKET PROVISION OF CUSTOM SOFTWARE - LEARNING EFFECTS AND LOW BALLING
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1343
EP 1352
DI 10.1287/mnsc.41.8.1343
PD AUG 1995
PY 1995
AB Due to reusability of program code and learning effects in software
   development, development cost of custom software typically decreases in
   time and experience. This creates a first-mover advantage to software
   developers. The paper studies whether the benefits of declining
   development costs are passed on to buyers in the form of lower prices
   when developers bid strategically. By using a model of bidding auctions
   we characterize equilibrium bidding strategies of two software
   developers. In order to become the first mover and attain future market
   dominance, developers find it optimal to forgo profits from the first
   projects. As a result, bid prices (= development cost plus a profit
   margin to the developer) to the buyers may not necessarily decrease over
   time, and even if so, not as fast as development cost drops. We also
   show that bidders expect a higher profit margin from a high-variance
   project. Thus, if there exist high-variance projects in the future,
   developers are more likely to submit below-cost bid prices or ''low
   ball.''
ZB 0
TC 12
ZS 0
Z8 0
ZA 0
ZR 0
Z9 12
SN 0025-1909
UT WOS:A1995TD41100006
ER

PT J
AU GREEN, LV
   KOLESAR, PJ
TI ON THE ACCURACY OF THE SIMPLE PEAK HOUR APPROXIMATION FOR MARKOVIAN
   QUEUES
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1353
EP 1370
DI 10.1287/mnsc.41.8.1353
PD AUG 1995
PY 1995
AB We empirically explore the accuracy of the simple stationary peak hour
   approximation (SPHA) for estimating peak hour performance in multiserver
   queuing systems with exponential service times and periodic (sinusoidal)
   Poisson arrival processes. We show that the SPHA is very good for a
   range of parameter values corresponding to a reasonably broad spectrum
   of real systems. However, we do find and document that there are many
   situations in which this approximation will be very inaccurate.
   We postulate and then support empirically a set of hypotheses that link
   the accuracy of the SPHA and the related point-wise stationary
   approximation (PSA) to key parameter values and model characteristics.
   We also present results on the time-dependent behavior of these systems
   as a function of key parameters.
   Finally we present results which indicate that our findings, developed
   for models with sinusoidal input streams, may apply to a much broader
   range of Markovian models with more general cyclic inputs.
TC 19
ZB 0
ZR 0
Z8 0
ZS 0
ZA 0
Z9 19
SN 0025-1909
UT WOS:A1995TD41100007
ER

PT J
AU FENG, YY
   GALLEGO, G
TI OPTIMAL STARTING TIMES FOR END-OF-SEASON SALES AND OPTIMAL
   STOPPING-TIMES FOR PROMOTIONAL FARES
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1371
EP 1391
DI 10.1287/mnsc.41.8.1371
PD AUG 1995
PY 1995
AB Many industries face the problem of selling a fixed stock of items over
   a finite horizon. These industries include airlines selling seats before
   planes depart, hotels renting rooms before midnight, theaters selling
   seats before curtain time, and retailers selling seasonal goods such as
   air-conditioners or winter coats before the end of the season. Given a
   fixed number of seats, rooms, or coats, the objective for these
   industries is to maximize revenues in excess of salvage value. When
   demand is price sensitive and stochastic, pricing is an effective tool
   to maximize revenues. In this paper we address the problem of deciding
   the optimal timing or a single price change from a given initial price
   to either a given lower or higher second price. Under mild conditions,
   we show that it is optimal to decrease (resp., to increase) the initial
   price as soon as the time-to-go falls below (resp., above) a time
   threshold that depends on the number of yet unsold items.
RI Escarabajal, Juan Antonio/C-5644-2012; Gallego, Guillermo/AAK-1549-2020
OI Gallego, Guillermo/0000-0002-9664-3750
ZS 0
TC 178
ZB 0
ZR 0
Z8 26
ZA 0
Z9 203
SN 0025-1909
UT WOS:A1995TD41100008
ER

PT J
AU ELGERS, PT
   LO, MH
   MURRAY, D
TI NOTE ON ADJUSTMENTS TO ANALYSTS EARNINGS FORECASTS BASED UPON SYSTEMATIC
   CROSS-SECTIONAL COMPONENTS OF PRIOR-PERIOD ERRORS
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1392
EP 1396
DI 10.1287/mnsc.41.8.1392
PD AUG 1995
PY 1995
AB This study assesses the effectiveness of using systematic components of
   cross-sectional forecast errors from prior years in order to adjust
   current analysts' earnings forecasts. The empirical results document
   that a significant component of the cross-sectional MSE in analysts'
   forecasts is systematic, and that parameter estimates from earlier
   periods enable the elimination of a substantial portion of the
   systematic errors in current forecasts. Further improvements in forecast
   accuracy are attained by the incorporation of prior-year excess security
   returns in order to reduce unsystematic error.
Z8 0
ZB 0
ZS 0
ZA 0
TC 13
ZR 0
Z9 13
SN 0025-1909
UT WOS:A1995TD41100009
ER

PT J
AU ROBINSON, SM
TI CONVERGENCE OF SUBDIFFERENTIALS UNDER STRONG STOCHASTIC CONVEXITY
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1397
EP 1401
DI 10.1287/mnsc.41.8.1397
PD AUG 1995
PY 1995
AB We show that if a sequence of random functions satisfies strong
   stochastic convexity with respect to a parameter, and if the sequence
   converges pointwise with probability one, then any sequence of elements
   extracted from the subdifferentials of the functions in the sequence
   will converge to the subdifferential of the limiting function, again
   with probability one. This result holds with no differentiability
   assumption on the limiting function, and even if the limiting function
   is itself random. It thus extends earlier work, in particular results by
   Glynn and by Hu. One application is in proving an extended form of
   strong consistency for infinitesimal perturbation analysis (IPA) when
   suitable convexity properties hold.
ZR 0
ZA 0
ZB 0
Z8 0
TC 5
ZS 0
Z9 5
SN 0025-1909
UT WOS:A1995TD41100010
ER

PT J
AU AVIITZHAK, B
   HALFIN, S
TI A NOTE ON EVALUATING THE OVERFLOW PROBABILITY USING THE INFINITE QUEUE
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1402
EP 1403
DI 10.1287/mnsc.41.8.1402
PD AUG 1995
PY 1995
AB This note evaluates the approximation of overflow probability put
   forward by Sakasegawa et al (in a paper published recently in Management
   Science [5]), and its level of accuracy when applied to traffic
   generated by bursty sources.
TC 0
ZB 0
ZR 0
Z8 0
ZS 0
Z9 0
SN 0025-1909
UT WOS:A1995TD41100011
ER

PT J
AU PAIK, TY
   SEN, PK
TI PROJECT EVALUATION AND CONTROL IN DECENTRALIZED FIRMS - IS CAPITAL
   RATIONING ALWAYS OPTIMAL
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1404
EP 1414
DI 10.1287/mnsc.41.8.1404
PD AUG 1995
PY 1995
AB When capital investments are made in an agency setting, we show that,
   even without risk considerations, capital rationing need not be the only
   rational outcome. We analyze a principal-agent model with risk
   neutrality and with two productive inputs: the agent's efforts and
   capital investment. The two inputs can be either economic complements or
   substitutes. The agent has pre-contract private information about his
   own type. The output is measured with an additive noise. We show that
   when the two inputs are substitutes, the optimal solution entails a
   marginal capital rationing. But when the two inputs are complements,
   then either a marginal capital rationing or a marginal leniency could be
   the optimal response. Our results, therefore, provide an explanation for
   why firms may employ a capital rationing for a project that may increase
   manufacturing complexity and hence may reduce (managerial) labor
   productivity, yet employ a less strict criterion for evaluating a
   productivity-enhancing project. This result contrasts with earlier
   results where only a capital rationing is shown to be optimal.
RI Sen, Pradyot/I-7030-2013
OI Sen, Pradyot/0000-0003-4446-2613
ZA 0
ZR 0
ZB 0
Z8 0
ZS 0
TC 6
Z9 6
SN 0025-1909
UT WOS:A1995TD41100012
ER

PT J
AU ZARAS, K
TI A NOTE ON APPLICATION OF SD RULES TO THE SELECTION OF PARAMETER
   ESTIMATORS
SO MANAGEMENT SCIENCE
VL 41
IS 8
BP 1415
EP 1416
DI 10.1287/mnsc.41.8.1415
PD AUG 1995
PY 1995
ZR 0
Z8 0
ZA 0
ZS 0
TC 1
ZB 0
Z9 1
SN 0025-1909
UT WOS:A1995TD41100013
ER

PT J
AU KARABATI, S
   KOUVELIS, P
   YU, G
TI THE DISCRETE RESOURCE-ALLOCATION PROBLEM IN FLOW LINES
SO MANAGEMENT SCIENCE
VL 41
IS 9
BP 1417
EP 1430
DI 10.1287/mnsc.41.9.1417
PD SEP 1995
PY 1995
AB In this paper we address the discrete resource allocation problem in a
   deterministic flow Line. We assume that the processing times are convex
   and nonincreasing in the amount of resources allocated to the machines.
   We consider the resource allocation problem for a fixed sequence of jobs
   for various performance criteria (makespan, weighted sum of completion
   times, cycle time for cyclic schedules), and develop a formulation of
   the problem as a convex program, where the number of constraints grows
   exponentially with the number of jobs and machines. We also present a
   generalization of the formulation for resource allocation problems in
   acyclic directed graphs. We demonstrate that the problem is NP-complete
   in the strong sense and present an effective solution procedure. The
   solution procedure is an implicit enumeration scheme where a surrogate
   relaxation of the formulation is used to generate upper and lower bounds
   on the optimal objective function value. Finally, we address the
   simultaneous scheduling and resource allocation problem, and we present
   an approximate and iterative solution procedure for the problem.
RI Kouvelis, Panos/ABG-2350-2020; Karabati, Selcuk/D-8348-2019
OI Karabati, Selcuk/0000-0001-6976-5405
TC 6
ZA 0
ZS 0
ZB 0
ZR 0
Z8 0
Z9 6
SN 0025-1909
UT WOS:A1995TJ10700001
ER

PT J
AU HA, AY
   PORTEUS, EL
TI OPTIMAL TIMING OF REVIEWS IN CONCURRENT DESIGN FOR MANUFACTURABILITY
SO MANAGEMENT SCIENCE
VL 41
IS 9
BP 1431
EP 1447
DI 10.1287/mnsc.41.9.1431
PD SEP 1995
PY 1995
AB Concurrent design can reduce the time required to develop new products
   and redesign old ones. In contrast to the conventional approach, in
   which the product design is (nearly) completed before it is ''thrown
   over the wall'' to the process design group, concurrent design for
   manufacturability, as conceptualized here, conducts a number of progress
   reviews during the product design process. Frequent reviews have two
   benefits: (1) (Parallel Development) process designers receive
   sufficient information about the design to enable them to work in
   parallel with the product designers, and (2) (Quality Control) flaws in
   the design are discovered soon after they are introduced, saving the
   time and resources required for redesign later. The disadvantage of
   frequent reviews is that each review requires setup/penalty time that
   otherwise would not be required. The optimal policy is derived for some
   special stationary cases of the model. When the parallel development
   benefit dominates, the review periods either increase or decrease
   according to the rate at which product design work empowers useful
   process design work to be conducted. When the quality control benefit
   dominates, the review periods will vary only to the extent that the
   quality related parameters change. Numerical examples illustrate the
   insights gained from the analysis.
Z8 5
ZR 0
ZA 0
TC 112
ZS 1
ZB 0
Z9 117
SN 0025-1909
UT WOS:A1995TJ10700002
ER

PT J
AU VENTURA, JA
   WENG, MX
TI MINIMIZING SINGLE-MACHINE COMPLETION-TIME VARIANCE
SO MANAGEMENT SCIENCE
VL 41
IS 9
BP 1448
EP 1455
DI 10.1287/mnsc.41.9.1448
PD SEP 1995
PY 1995
AB In this article the problem of minimizing the completion time variance
   in n-job, single-machine scheduling is considered. The release times for
   all jobs are assumed to be zero. A new quadratic integer programming
   formulation is introduced. A Lagrangian relaxation (LR) procedure is
   developed to find a lower bound (LB) to the optimal objective value.
   When the number of jobs is between 100 and 500, our computational study
   shows that the lower bounds obtained by the LR procedure are very close
   to the best known objective values. A new heuristic algorithm is also
   described. The first phase of the heuristic algorithm is a construction
   procedure whose purpose is to identify a good initial. sequence. The
   second phase is an improvement procedure based on pairwise interchanges.
   The new heuristic-algorithm provides improved solutions compared to the
   best known heuristic.
TC 17
ZS 0
Z8 0
ZR 0
ZB 0
ZA 0
Z9 17
SN 0025-1909
UT WOS:A1995TJ10700003
ER

PT J
AU KEKRE, S
   KRISHNAN, MS
   SRINIVASAN, K
TI DRIVERS OF CUSTOMER SATISFACTION FOR SOFTWARE PRODUCTS - IMPLICATIONS
   FOR DESIGN AND SERVICE SUPPORT
SO MANAGEMENT SCIENCE
VL 41
IS 9
BP 1456
EP 1470
DI 10.1287/mnsc.41.9.1456
PD SEP 1995
PY 1995
AB We study the key determinants of customer satisfaction with software
   products. Our analysis, based upon a large sample of over 2,500 customer
   responses, suggests that capability and usability are the critical
   drivers of overall customer satisfaction. We also find that the
   importance of seven key satisfaction factors differs across customer and
   product segments. Our results have significant implications for Quality
   Function Deployment in making design and service support choices for
   software products.
ZR 0
TC 79
ZS 0
ZA 0
ZB 1
Z8 1
Z9 80
SN 0025-1909
UT WOS:A1995TJ10700004
ER

PT J
AU BENSAOU, M
   VENKATRAMAN, N
TI CONFIGURATIONS OF INTERORGANIZATIONAL RELATIONSHIPS - A COMPARISON
   BETWEEN US AND JAPANESE AUTOMAKERS
SO MANAGEMENT SCIENCE
VL 41
IS 9
BP 1471
EP 1492
DI 10.1287/mnsc.41.9.1471
PD SEP 1995
PY 1995
AB This paper seeks to uncover dominant configurations of
   interorganizational relationships across the United States and Japan in
   the automotive industry. We integrate relevant theoretical concepts from
   transaction cost economics, organization theory and political economy to
   develop a conceptual model of interorganizational relationships based on
   the fit between information processing needs and information processing
   capabilities. This model is employed to collect data on 447
   buyer-supplier relationships in these two countries. We empirically
   uncover a set of five naturally occurring patterns of
   interorganizational relationships. These configurations provide rich
   explanations of the complexity of interorganizational relationships as
   well as offer differential insights across United States and Japan. We
   discuss implications for further research pertaining to the logic and
   development of configurations.
RI Venkatraman, N. Venkat/AAB-2555-2019
ZA 0
ZS 5
TC 325
Z8 6
ZB 2
ZR 0
Z9 334
SN 0025-1909
UT WOS:A1995TJ10700005
ER

PT J
AU AXELROD, R
   MITCHELL, W
   THOMAS, RE
   BENNETT, DS
   BRUDERER, E
TI COALITION-FORMATION IN STANDARD-SETTING ALLIANCES
SO MANAGEMENT SCIENCE
VL 41
IS 9
BP 1493
EP 1508
DI 10.1287/mnsc.41.9.1493
PD SEP 1995
PY 1995
AB We present a theory for predicting how business firms form alliances to
   develop and sponsor technical standards. Our basic assumptions are that
   the utility of a firm for joining a particular standard-setting alliance
   increases with the size of the alliance and decreases with the presence
   of rivals in the alliance, especially close rivals. The predicted
   alliance configurations are simply the Nash equilibria, i.e., those sets
   of alliances for which no single firm has an incentive to switch to
   another alliance. We illustrate our theory by estimating the choices of
   nine computer companies to join one of two alliances sponsoring
   competing Unix operating system standards in 1988.
RI Pepper, John W/O-1662-2013
OI Pepper, John W/0000-0001-9888-0437
ZR 0
ZB 1
ZA 0
TC 138
ZS 2
Z8 4
Z9 142
SN 0025-1909
EI 1526-5501
UT WOS:A1995TJ10700006
ER

PT J
AU WENG, ZK
TI CHANNEL COORDINATION AND QUANTITY DISCOUNTS
SO MANAGEMENT SCIENCE
VL 41
IS 9
BP 1509
EP 1522
DI 10.1287/mnsc.41.9.1509
PD SEP 1995
PY 1995
AB This paper presents a model for analyzing the impact of joint decision
   policies on channel coordination in a system consisting of a supplier
   and a group of homogeneous buyers. The joint decision policy
   characterized by the unit selling price and the order quantity is
   coordinated through quantity discounts and franchise fees. Both the
   annual demand rate and the operating cost-including the purchase,
   ordering, and inventory holding costs-depend on the joint decision
   policy employed. This paper contributes by integrating work addressing
   quantity discounts on inventory and ordering policies and work focusing
   on the control mechanism provided by quantity discounts in channel
   coordination. It is shown that the optimal all-unit quantity discount
   policy is equivalent to the optimal incremental quantity discount policy
   in achieving channel coordination. Furthermore, it is shown that
   quantity discounts alone are not sufficient to guarantee joint profit
   maximization. The analyses of the general models are illustrated by
   specific analytical results obtained for a given demand function.
ZR 0
TC 476
ZB 2
ZA 0
ZS 1
Z8 93
Z9 567
SN 0025-1909
UT WOS:A1995TJ10700007
ER

PT J
AU BOINEY, LG
TI WHEN EFFICIENT IS INSUFFICIENT - FAIRNESS IN DECISIONS AFFECTING A GROUP
SO MANAGEMENT SCIENCE
VL 41
IS 9
BP 1523
EP 1537
DI 10.1287/mnsc.41.9.1523
PD SEP 1995
PY 1995
AB Many key decisions have significant consequences for a group of people,
   rather than a single individual. In some cases, traditional group
   decision making techniques such as negotiation, voting, or compromise
   can be employed by the group members themselves to determine a
   satisfactory course of action. In other instances, however, the
   intervention of a central decision maker may be necessary. Intervening
   on behalf of a group raises additional concerns for the decision maker,
   one of which is fairness. This paper builds upon envy-based fairness
   concepts from the fair allocation literature and theories of ex ante and
   ex post equitable distributions from the social risk literature to
   develop a model for choice among limited options under uncertainty when
   preferences are heterogeneous. The model is therefore appropriate when
   other existing models are not.
   An example demonstrates an application of the model for choice under
   uncertainty and contrasts the approach and decision recommendation with
   that of existing models. By quantifying the degree of envy rather than
   treating it dichotomously, the approach captures the balance between
   fairness and efficiency; some envy may be tolerated if it brings greater
   overall utility and/or if some envy already exists in the status quo
   option. Lastly, implementation issues and the impact of differing
   preferences and attitudes toward risk on fairness and efficiency
   considerations are explored.
Z8 1
ZB 0
ZS 0
ZR 0
ZA 0
TC 10
Z9 11
SN 0025-1909
UT WOS:A1995TJ10700008
ER

PT J
AU CLYMAN, DR
TI UNREASONABLE RATIONALITY
SO MANAGEMENT SCIENCE
VL 41
IS 9
BP 1538
EP 1548
DI 10.1287/mnsc.41.9.1538
PD SEP 1995
PY 1995
AB This paper explores how fractional demands (the optimal fraction of
   wealth invested in a security) change upon exogenous changes in security
   returns and wealth. In the first part of the paper, the analysis is
   conducted in an Arrow-Debreu framework. Here we demonstrate the
   counterintuitive but completely rational result that fractional demands
   can remain unchanged or in fact decrease upon an exogenous increase in
   return. Furthermore, we show that this can occur without any offsetting
   wealth effect. In the second part of the paper, we apply these results
   to ordinary securities (those composed of fixed portfolios of
   Arrow-Debreu securities). Here eve derive a complete analytical solution
   and show that portfolio managers should beware. Even correct information
   that the return from holding an underlying pure security will improve is
   not sufficient to conclude that one should increase (or decrease) one's
   holdings of any particular stock.
Z8 0
ZR 0
ZS 0
ZB 0
TC 2
ZA 0
Z9 2
SN 0025-1909
UT WOS:A1995TJ10700009
ER

PT J
AU MURALIDHAR, K
   BATRA, D
   KIRS, PJ
TI ACCESSIBILITY, SECURITY, AND ACCURACY IN STATISTICAL DATABASES - THE
   CASE FOR THE MULTIPLICATIVE FIXED DATA PERTURBATION APPROACH
SO MANAGEMENT SCIENCE
VL 41
IS 9
BP 1549
EP 1564
DI 10.1287/mnsc.41.9.1549
PD SEP 1995
PY 1995
AB Organizations store data regarding their operations, employees,
   consumers, and suppliers in their databases. Some of the data are
   considered confidential, and by law, the organization is required to
   provide appropriate security measures in order to preserve privacy. Yet
   a number of companies have little or no security measures. The reason
   for this lack of security may, at least in part, be attributed to a lack
   of awareness and empirical evidence about the relative effectiveness of
   security mechanisms. This study investigates the effectiveness of
   different security mechanisms for protecting numerical database
   attributes. The trade-off between security, accessibility, and accuracy
   are examined. A comparison of different security mechanisms reveals that
   fixed data perturbation is preferred because it maximizes both security
   and accessibility. An investigation of the different approaches to fixed
   data perturbation indicates that multiplicative method best meets these
   criteria.
RI Muralidhar, Krishnamurty/A-7618-2009
ZR 0
Z8 0
ZB 1
ZA 0
ZS 0
TC 23
Z9 23
SN 0025-1909
UT WOS:A1995TJ10700010
ER

PT J
AU Bates, KA
   Amundson, SD
   Schroeder, RG
   Morris, WT
TI The crucial interrelationship between manufacturing strategy and
   organizational culture
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1565
EP 1580
DI 10.1287/mnsc.41.10.1565
PD OCT 1995
PY 1995
AB This paper proposes a relationship between manufacturing strategy and
   organizational culture, based on an examination of the research
   literature. Survey data were collected from 822 respondents in 41 plants
   in the transportation, electronics, and machinery industries in the U.S.
   These plants included random samples of U.S.-owned and Japanese-owned
   manufacturers in the U.S., and manufacturers reputed to use advanced
   manufacturing practices. Analysis indicates that manufacturing strategy
   and organizational culture are related, and that a manufacturer with a
   well-aligned and implemented manufacturing strategy exhibits a
   collectivist or group-oriented organizational culture with coordinated
   decision making, decentralized authority, and a loyal work force.
ZB 0
ZS 3
Z8 1
ZR 0
ZA 0
TC 106
Z9 110
SN 0025-1909
EI 1526-5501
UT WOS:A1995TR47500001
ER

PT J
AU Reyniers, DJ
   Tapiero, CS
TI The delivery and control of quality in supplier producer contracts
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1581
EP 1589
DI 10.1287/mnsc.41.10.1581
PD OCT 1995
PY 1995
AB We model the effect of contract parameters such as price rebates and
   after-sales warranty costs on the choice of quality by a supplier, the
   inspection policy of a producer, and the resulting end product quality.
   Both noncooperative and cooperative settings are explored. The paper's
   contribution is to highlight the importance of strategic and contractual
   issues in quality management.
ZA 1
Z8 41
ZB 1
ZR 0
TC 145
ZS 1
Z9 186
SN 0025-1909
UT WOS:A1995TR47500002
ER

PT J
AU Demeulemeester, E
TI Minimizing resource availability costs in time-limited project networks
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1590
EP 1598
DI 10.1287/mnsc.41.10.1590
PD OCT 1995
PY 1995
AB We consider the problem of minimizing renewable resource availability
   costs in an activity-on-the-node project network subject to a project
   due date. Project activities have fixed durations and may require the
   use of multiple renewable resources in constant amounts throughout their
   duration. Various assumptions may be made about the type of precedence
   relations, ready times, due dates, and task interruptability. Given a
   discrete, non-decreasing cost function of the constant resource
   availability for every resource type, the objective is to determine the
   resource availability levels in order to minimize the sum of the
   availability costs over all resource types. An effective optimal
   algorithm is described and extensive computational experience is
   reported.
ZB 2
ZS 2
Z8 6
TC 93
ZR 0
ZA 0
Z9 101
SN 0025-1909
UT WOS:A1995TR47500003
ER

PT J
AU Hariharan, R
   Zipkin, P
TI Customer-order information, leadtimes, and inventories
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1599
EP 1607
DI 10.1287/mnsc.41.10.1599
PD OCT 1995
PY 1995
AB We have an inventory to manage. The scenario is standard in all respects
   save one: Instead of arriving unannounced, customers provide advance
   warning of their demands. How should we use this information, and what
   is its effect on system performance? The answers turn out to be
   strikingly simple: There are very simple policies which perform
   effectively, in some cases optimally. Also, such ''demand leadtimes''
   improve performance, in precisely the same way that replenishment
   leadtimes degrade it.
Z8 4
ZS 0
ZR 0
TC 155
ZB 1
ZA 0
Z9 159
SN 0025-1909
UT WOS:A1995TR47500004
ER

PT J
AU Desai, PS
   Srinivasan, K
TI Demand signalling under unobservable effort in franchising: Linear and
   nonlinear price contracts
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1608
EP 1623
DI 10.1287/mnsc.41.10.1608
PD OCT 1995
PY 1995
AB We study the signalling strategy of a principal who is privately
   informed about its high demand potential to an uninformed risk-neutral
   agent. We analyze the model in the context of a contract between a
   franchisor and a franchisee. We examine the distortions of a two-parr
   pricing scheme necessary to credibly inform the franchisee (agent). We
   also study whether the inability of the franchisor (principal) to
   observe the agent's effort moderates or exaggerates the distortions from
   the first-best two-part pricing scheme. A surprising outcome is that
   even though the principal incurs greater signalling cost, the magnitude
   of distortion in the two-part scheme is smaller when service is
   unobservable than when it is not. Thus, a signalling strategy employing
   the fixed and variable fees is harder to detect under moral hazard.
   Empirical studies failing to control for moral hazard may incorrectly
   conclude that signalling strategy does not occur. We later consider a
   three-part scheme to verify whether or not the scheme reduces signalling
   cost. Interestingly, we find that there exists a unique three-part
   scheme that results in the first-best profit even in the presence of
   two-sided information asymmetries. While the two-part scheme can never
   achieve the first-best profit, the three-part scheme always achieves the
   first-best profit, The costless three-part separating scheme relies on
   variable income to induce the agent to undertake first-best service. The
   reliance on variable income to alleviate moral hazard contrasts with the
   two-part scheme's focus on reducing the variable income to overcome the
   inability to monitor. The finding provides additional empirical
   implications.
ZB 0
ZR 0
Z8 10
ZA 0
ZS 0
TC 123
Z9 133
SN 0025-1909
UT WOS:A1995TR47500005
ER

PT J
AU Monteverde, K
TI Technical dialog as an incentive for vertical integration in the
   semiconductor industry
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1624
EP 1638
DI 10.1287/mnsc.41.10.1624
PD OCT 1995
PY 1995
AB A curious structural change observed in the American semiconductor
   industry (the appearance of a class of ''fabless'' firms) is examined
   within a general transaction costs framework. The framework is refined
   for empirical application with the introduction of the construct
   ''unstructured technical dialog.'' The necessary level of this form of
   interpersonal communication between engineers in the design and
   fabrication stages of production is hypothesized to be positively
   related to the efficiency of a vertically integrated structure in which
   both stages are organized under a single hierarchy. ''Fablessness''
   (i.e., the organizational separation of the design and fabrication
   stages) is argued to be efficient for only these firms whose particular
   product portfolios have only a minimal requirement for such unstructured
   technical dialog. The hypothesis is tested upon a set of relatively
   young semiconductor firms. Support is found for the theoretically
   derived relationship even after controlling for rival explanations found
   in the literature.
ZA 0
ZB 0
ZS 0
ZR 1
Z8 0
TC 168
Z9 169
SN 0025-1909
UT WOS:A1995TR47500006
ER

PT J
AU Benson, PG
   Curley, SP
   Smith, GF
TI Belief assessment: An underdeveloped phase of probability elicitation
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1639
EP 1653
DI 10.1287/mnsc.41.10.1639
PD OCT 1995
PY 1995
AB A cognitive analysis of subjective probability is applied to the
   evaluation of techniques used by decision analysts for eliciting:
   probabilities from experts. The construction of a subjective probability
   requires both the formation of a belief and the assessment of a
   probability that qualifies the belief. The former process involves
   judgment and reasoning; the latter ig purely judgmental. Subjective
   probabilities have traditionally been portrayed and studied as arising
   from judgment: Consequently, belief assessment procedures have been
   particularly underdeveloped. Procedures currently used by analysts to
   aid belief assessment are classified and evaluated. Although such
   procedures facilitate the communication of beliefs and offer important
   guidance for constructing probabilities, additional prescriptive
   development is possible. It is argued that significant improvements in
   assessment practice can be realized by providing better support for the
   reasoning employed by experts in belief assessment. Opportunities for
   descriptive and prescriptive research in belief assessment are
   identified.
ZR 0
ZS 0
TC 19
ZA 0
ZB 0
Z8 0
Z9 19
SN 0025-1909
EI 1526-5501
UT WOS:A1995TR47500007
ER

PT J
AU Gautier, A
   Granot, F
TI Forest management: A multicommodity flow formulation and sensitivity
   analysis
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1654
EP 1668
DI 10.1287/mnsc.41.10.1654
PD OCT 1995
PY 1995
AB We formulate the Forest Management Problem as a Multicommodity Network
   Flow Problem with a convex cost function, We then show how to transfer
   the problem to an equivalent Single-Commodity Network Flow formulation
   in order to address several sensitivity analysis questions using results
   by Granot and Veinott (1985). The answers can subsequently be used to
   help forest managers respond to changes in the environment such as fires
   or changes in market prices, without any additional computation.
   Furthermore, the characterization of the response we provide requires no
   prior knowledge of optimal management policies.
Z8 0
ZS 0
TC 4
ZR 0
ZA 0
ZB 0
Z9 4
SN 0025-1909
UT WOS:A1995TR47500008
ER

PT J
AU FernandezGaucherand, E
   Jain, S
   Lee, HL
   Rao, AG
   Rao, MR
TI Improving productivity by periodic performance evaluation: A Bayesian
   stochastic model
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1669
EP 1678
DI 10.1287/mnsc.41.10.1669
PD OCT 1995
PY 1995
AB We model the situation where the productivity of members of a group,
   such as a salesforce, is periodically evaluated; those whose performance
   is sub-par are dismissed and replaced by new members. Individual
   productivity is modeled as a random variable, the distribution of which
   is a function of an unknown parameter. This parameter varies across the
   members of the group and is specified by a prior distribution. In this
   manner, the heterogeneity in the group is explicitly accounted for. We
   model the situation as a parameter adaptive Bayesian stochastic control
   problem, and use dynamic programming techniques and the appropriate
   optimality equations to obtain solutions. We prove the existence of an
   optimal policy in the general case. Further, for the case when the sales
   process can be characterized by a Beta-Binomial or a Gamma-Poisson
   distribution, we show that the optimal policy is of the threshold type
   at each evaluation period, depending only on the accumulated performance
   up to a given period. We present a computational procedure to solve for
   the optimal thresholds. Results of computational experiments show that
   an increase in the heterogeneity of the group can lead to more stringent
   levels of minimal acceptable performance.
Z8 0
ZR 0
ZB 0
ZS 0
ZA 0
TC 5
Z9 5
SN 0025-1909
UT WOS:A1995TR47500009
ER

PT J
AU Spector, YH
   Tishler, A
   Ye, YY
TI Minimal adjustment costs and the optimal choice of inputs under
   time-of-use electricity rates
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1679
EP 1692
DI 10.1287/mnsc.41.10.1679
PD OCT 1995
PY 1995
AB In Time-of-Use (TOU) pricing schemes, utilities charge rates that depend
   on the time of day and the season of the year at which electricity is
   used. Estimates of the effects of TOU rates on business customers in the
   U.S. and Israel demonstrate that most firms do not appear to respond at
   all to newly introduced TOU rates, but those that do respond make
   substantial adjustments. In this paper we show that adjustment costs
   associated with changing the level of employment can explain the
   observed pattern of behavior in the U.S. and Israel. We apply our model
   to large industrial firms in Israel and show that it predicts their
   actual responses to TOU rates quite well.
ZB 0
Z8 0
TC 3
ZR 0
ZS 0
Z9 3
SN 0025-1909
UT WOS:A1995TR47500010
ER

PT J
AU Kolisch, R
   Sprecher, A
   Drexl, A
TI Characterization and generation of a general class of
   resource-constrained project scheduling problems
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1693
EP 1703
DI 10.1287/mnsc.41.10.1693
PD OCT 1995
PY 1995
AB This paper addresses the issue of how to generate problem instances of
   controlled difficulty. It focuses on precedence- and
   resource-constrained (project) scheduling problems, but similar ideas
   may be applied to other network optimization problems. It describes a
   network construction procedure that takes into account a) constraints on
   the network topology, b) a resource factor that reflects the density of
   the coefficient matrix, and c) a resource strength, which measures the
   availability of resources. The strong impact of the chosen parametric
   characterization of the problems is shown via an in depth computational
   study. Instances for the single- and multi-mode resource-constrained
   project scheduling problem are benchmarked by using the state of the art
   (branch and bound) procedures. The results provided, demonstrate that
   the classical benchmark instances used by several researchers over
   decades belong to the subset of the very easy ones. In addition, it is
   shown that hard instances, being far more smaller in size than presumed
   in the literature, may not be solved to optimality even within a large
   amount of computation time.
RI Kolisch, Rainer/W-7505-2019
OI Kolisch, Rainer/0000-0002-8001-3009
ZS 0
ZA 0
ZR 0
Z8 17
ZB 2
TC 374
Z9 389
SN 0025-1909
UT WOS:A1995TR47500011
ER

PT J
AU Whitt, W
TI Variability functions for parametric-decomposition approximations of
   queueing networks
SO MANAGEMENT SCIENCE
VL 41
IS 10
BP 1704
EP 1715
DI 10.1287/mnsc.41.10.1704
PD OCT 1995
PY 1995
AB We propose an enhancement to the parametric-decomposition method for
   calculating approximate steady-state performance measures of open
   queueing networks with non-Poisson arrival processes and nonexponential
   service-time distributions. Instead of using a variability parameter
   c(a)(2) for each arrival process, we suggest using a variability
   function c(a)(2)(rho) 0 < rho < 1, for each arrival process; i.e., the
   variability parameter should be regarded as a function of the traffic
   intensity rho of a queue to which the arrival process might go.
   Variability functions provide a convenient representation of different
   levels of variability in different time scales for arrival processes
   that are not nearly renewal processes. Variability functions enable the
   approximations to account for long-range effects in queueing networks
   that cannot be addressed by variability parameters. For example, the
   variability functions provide a way to address the heavy-traffic
   bottleneck phenomenon, in which exceptional variability(either high or
   low) in the input has Little impact in a series of queues with
   low-to-moderate traffic intensities, and then has a big impact when it
   reaches a later queue with a relatively high traffic intensity. The
   variability functions also enable the approximations to characterize
   irregular periodic deterministic external arrival processes in a
   reasonable way; i.e., if there are no batches, then c(a)(2)(rho) should
   be 0 for rho near 0 or 1, but c(a)(2)(rho) can assume arbitrarily large
   values for appropriate intermediate p. We present a full network
   algorithm with variability functions, showing that the idea is
   implementable. We also show how simulations of single queues can be
   effectively exploited to determine variability functions for difficult
   external arrival processes.
RI Whitt, Ward/D-5337-2013
OI Whitt, Ward/0000-0003-4298-9964
TC 34
ZA 0
ZS 1
ZB 0
Z8 0
ZR 0
Z9 35
SN 0025-1909
UT WOS:A1995TR47500012
ER

PT J
AU NUTT, PC
TI IMPLEMENTATION STYLE AND USE OF IMPLEMENTATION APPROACHES
SO OMEGA-INTERNATIONAL JOURNAL OF MANAGEMENT SCIENCE
VL 23
IS 5
BP 469
EP 484
DI 10.1016/0305-0483(95)00022-G
PD OCT 1995
PY 1995
AB Managers are called on to select among implementation approaches
   according to situational demands. This paper examines factors that
   influence this selection. To conduct such a study, managers' views of
   the pragmatics (prospects of success and resistance), potential use, and
   ethics of several implementation approaches were systematically
   collected. Explanatory variables included the participating managers'
   characteristics (level, gender, and experience) and the situation
   (participative or control-oriented climates). 'Implementation style',
   which measures a manager's preferences for a given implementation
   approach, was also included as an explanatory factor. The study found
   that managers had a repertoire of implementation approaches and used
   some of the approaches contingently. However, managers preferred to me
   implementation approaches that did not match the demands of the
   situation. Also, the managers' implementation style influenced their
   selection and use of implementation approaches. The implications of
   these findings for managers and management are discussed.
TC 7
ZB 0
ZR 0
Z8 0
ZS 0
ZA 0
Z9 7
SN 0305-0483
UT WOS:A1995TB88500001
ER

PT J
AU Chase, RB
   Heskett, JL
TI Introduction to the focused issue on service management
SO MANAGEMENT SCIENCE
VL 41
IS 11
BP 1717
EP 1719
DI 10.1287/mnsc.41.11.1717
PD NOV 1995
PY 1995
ZS 0
ZB 0
Z8 0
TC 2
ZR 0
Z9 2
SN 0025-1909
UT WOS:A1995TW42700002
ER

PT J
AU Roth, AV
   Jackson, WE
TI Strategic determinants of service quality and performance: Evidence from
   the banking industry
SO MANAGEMENT SCIENCE
VL 41
IS 11
BP 1720
EP 1733
DI 10.1287/mnsc.41.11.1720
PD NOV 1995
PY 1995
AB This paper focuses on an important new service management strategy: the
   operations capabilities-service quality-performance (C-SQ-P) triad. In
   order to understand what generic operations capabilities influence the
   strategic behavior of high performing service firms, we explore three
   related questions: What generic operations capabilities are among the
   strategic determinants of service quality? Does service quality affect
   market performance? How is market conduct related to the C-SQ-P triad?
   These questions are investigated using a stylized capabilities-based
   model of service quality that simultaneously assesses their impact upon
   a firm's market performance. Several insights emerge from our research:
   a) generic operations capabilities affect service quality and
   performance, although not all relationships are direct; b) service
   quality know-how and innovations can be directly observed and imitated;
   c) the effects of technological leadership and market acuity on service
   quality are moderated by the absorptive capacity of employees to
   recognize and exploit their potential, and hence, investments in people
   are critical to success; d) market conduct influences the generic
   capabilities of the firm more than market performance, ceteris paribus;
   and e) total factor productivity and service quality are negatively
   correlated.
Z8 4
ZA 1
TC 177
ZB 1
ZR 1
ZS 1
Z9 184
SN 0025-1909
EI 1526-5501
UT WOS:A1995TW42700003
ER

PT J
AU Kellogg, DL
   Chase, RB
TI Constructing an empirically derived measure for customer contact
SO MANAGEMENT SCIENCE
VL 41
IS 11
BP 1734
EP 1749
DI 10.1287/mnsc.41.11.1734
PD NOV 1995
PY 1995
AB This research provides an empirically derived measurement model for
   customer contact, a widely used construct in service management. The
   model was created by applying two psychometric scaling techniques,
   Multidimensional Scaling (MDS) and the method of paired comparisons, and
   Content Analysis, to the ratings and responses of service research
   experts. MDS showed that the construct of Customer Contact is
   multidimensional and complex. An interval scale was developed using the
   paired comparison methodology, and a measurement model was developed
   using this contact scale. The central finding was that the degree or
   level of contact can be measured at the episode level by averaging the
   normalized values of communication time, the information richness, and
   the level of intimacy. The uses of the measurement model include
   refining current research and reevaluating past research, developing
   contingency models for service quality and design, and providing
   practitioners with a richer understanding of customer contact to
   facilitate service system design.
Z8 1
ZR 0
ZS 0
TC 131
ZB 0
ZA 0
Z9 132
SN 0025-1909
EI 1526-5501
UT WOS:A1995TW42700004
ER

PT J
AU Darr, ED
   Argote, L
   Epple, D
TI The acquisition, transfer, and depreciation of knowledge in service
   organizations: Productivity in franchises
SO MANAGEMENT SCIENCE
VL 41
IS 11
BP 1750
EP 1762
DI 10.1287/mnsc.41.11.1750
PD NOV 1995
PY 1995
AB The paper examines the acquisition, depreciation and transfer of
   knowledge acquired through learning by doing in service organizations.
   The analysis is based on weekly data collected over a one and a half
   year period from 36 pizza stores located in Southwestern Pennsylvania.
   The 36 stores, which are franchised from the same corporation, are owned
   by 10 different franchisees. We find evidence of learning in these
   service organizations: as the organizations gain experience in
   production, the unit cost of production declines significantly.
   Knowledge acquired through learning by doing is found to depreciate
   rapidly in these organizations. Knowledge is found to transfer across
   stores owned by the same franchisee but not across stores owned by
   different franchisees. Theoretical and practical implications of the
   work are discussed.
OI Epple, Dennis/0000-0002-7354-5728
ZR 1
TC 712
ZB 2
Z8 12
ZS 4
ZA 0
Z9 727
SN 0025-1909
UT WOS:A1995TW42700005
ER

PT J
AU Sulek, JM
   Lind, MR
   Marucheck, AS
TI The impact of a customer service intervention and facility design on
   firm performance
SO MANAGEMENT SCIENCE
VL 41
IS 11
BP 1763
EP 1773
DI 10.1287/mnsc.41.11.1763
PD NOV 1995
PY 1995
AB The purpose of this research was to investigate the impact of a customer
   service intervention and store design on store performance within a
   regional food retailing chain. A longitudinal study examines the
   organization's implementation of a customer service intervention which
   utilized new service standards and customer feedback mechanisms.
   Moreover, the chain provided a natural experiment, since the forty-six
   stores in this chain represented three levels of facility design ranging
   from the traditional supermarket to the extended ''store of the future''
   format. A theoretical model relating the customer service intervention,
   variations in store design, and customer satisfaction to sales
   performance was developed. Using both operational performance data from
   each of the stores and 1,537 responses from customer satisfaction
   surveys, a LISREL model was used to test the predictive fit of the
   model. The results indicate that both the store design and the customer
   service intervention had a significant, positive impact on customer
   satisfaction which, in turn, significantly affected sales performance
   (sales per labor hour). In addition, the customer service intervention
   had a direct effect on sales performance, although there was no support
   for a direct relationship between store design and sales performance.
   This research provides a theoretical basis in helping management
   understand how to leverage customer service for improved sales
   performance.
ZR 0
Z8 0
ZB 1
ZS 0
TC 24
ZA 0
Z9 24
SN 0025-1909
EI 1526-5501
UT WOS:A1995TW42700006
ER

PT J
AU GalOr, E
TI Maintaining quality standards in franchise chains
SO MANAGEMENT SCIENCE
VL 41
IS 11
BP 1774
EP 1792
DI 10.1287/mnsc.41.11.1774
PD NOV 1995
PY 1995
AB In the present paper we identify those characteristics of the markets
   served by a franchise chain which determine the relative incentives of
   the owner of the chain to monitor the behavior of individual
   franchisees. We find that the owner has greater incentives to monitor
   the outlets that serve the relatively smaller markets and those that are
   subject to greater fluctuations in the state of the demand confronting
   them. We also find that the extent of competition with other chains has
   an ambiguous effect on the incentives to monitor the franchisees.
ZA 0
ZR 0
Z8 2
ZS 1
ZB 0
TC 18
Z9 21
SN 0025-1909
UT WOS:A1995TW42700007
ER

PT J
AU Dobbs, IM
TI Hiring and leasing with nonlinear prices
SO MANAGEMENT SCIENCE
VL 41
IS 11
BP 1793
EP 1805
DI 10.1287/mnsc.41.11.1793
PD NOV 1995
PY 1995
AB This paper examines the problem of a monopolist setting an optimal
   nonlinear pricing schedule in the face of consumers of unknown type who
   arrive randomly over time and self-select a choice of hire period. The
   major determinant of pricing policy is the customer arrival
   distribution, with the overall level of price higher than in the
   atemporal yield management/nonuniform pricing solution by a margin which
   increases with the average frequency with which potential customers
   arrive. By contrast, the solution is generally fairly insensitive to
   variations in the time rate of discount, although there is a tendency
   for the rate of price discount to increase with increases in the time
   discount rate.
Z8 0
ZA 0
TC 3
ZR 0
ZS 0
ZB 0
Z9 3
SN 0025-1909
UT WOS:A1995TW42700008
ER

PT J
AU Carmon, Z
   Shanthikumar, JG
   Carmon, TF
TI A psychological perspective on service segmentation models: The
   significance of accounting for consumers' perceptions of waiting and
   service
SO MANAGEMENT SCIENCE
VL 41
IS 11
BP 1806
EP 1815
DI 10.1287/mnsc.41.11.1806
PD NOV 1995
PY 1995
AB We examine how service should be divided and scheduled when it can be
   provided in multiple separate segments. We analyze variants of this
   problem using a model with a conventional function describing the
   waiting cost, that is modified to account for some aspects of the
   psychological cost of waiting in line. We show that consideration of the
   psychological cost can result in prescriptions that are inconsistent
   with the common wisdom of queuing theorists derived according to the
   conventional approach (e.g., equal load assignments). More generally,
   our intention in this paper is to illustrate that aspects of the
   psychological cost of waiting can be accounted for in the analysis of
   queuing systems, and that this may have significant implications for the
   service schemes that are derived.
RI Shanthikumar, George/L-4837-2019; Carmon, Ziv/A-6161-2009
TC 64
ZS 0
Z8 0
ZB 0
ZA 0
ZR 0
Z9 64
SN 0025-1909
EI 1526-5501
UT WOS:A1995TW42700009
ER

PT J
AU Sampson, SE
   Weiss, EN
TI Increasing service levels in conference and educational scheduling: A
   heuristic approach
SO MANAGEMENT SCIENCE
VL 41
IS 11
BP 1816
EP 1825
DI 10.1287/mnsc.41.11.1816
PD NOV 1995
PY 1995
AB This paper explores a technique for developing a conference (or class)
   schedule that maximizes the servicing of participant requests for
   sessions. Data regarding participant interests are collected before the
   time the schedule is generated. The problem contains two principal
   parts: (1) to feasibly assign session offerings to time periods and
   rooms, and (2) to assign participants to sections of multiple-offering
   sessions. A heuristic procedure that simultaneously solves both parts is
   described and tested. The procedure considers not only the participants'
   requests for sessions, but also the relative importance of the various
   requests. Benefits of request prioritization are described. Results show
   that this approach can result in significantly improved participant
   satisfaction and equity when compared with traditional conference- and
   class-scheduling approaches.
ZR 0
ZS 0
ZB 0
Z8 0
TC 11
ZA 0
Z9 11
SN 0025-1909
UT WOS:A1995TW42700010
ER

PT J
AU Argote, L
TI Editorial objectives - Organizational performance, strategy, and design
SO MANAGEMENT SCIENCE
VL 41
IS 11
BP U3
EP U3
PD NOV 1995
PY 1995
ZB 0
TC 0
ZR 0
ZS 0
Z8 0
Z9 0
SN 0025-1909
UT WOS:A1995TW42700001
ER

PT J
AU Goodhue, DL
TI Understanding user evaluations of information systems
SO MANAGEMENT SCIENCE
VL 41
IS 12
BP 1827
EP 1844
DI 10.1287/mnsc.41.12.1827
PD DEC 1995
PY 1995
AB Organizations spend millions of dollars on information systems to
   improve organizational or individual performance, but objective measures
   of system success are extremely difficult to achieve. For this reason,
   many MIS researchers (and potentially MIS practitioners) rely on user
   evaluations of systems as a surrogate for MIS success. However, these
   measures have been strongly criticized as lacking strong theoretical
   underpinnings. Furthermore, empirical evidence of their efficacy is
   surprisingly weak.
   Part of the explanation for the theoretical and empirical problems with
   user evaluations is that they are really a measurement technique rather
   than a single theoretical construct. User evaluations are elicited
   beliefs or attitudes about something, and they have been used to measure
   a variety of different ''somethings.'' What is needed for user
   evaluations to be an effective measure of IS success is the
   identification of some specific user evaluation construct, defined
   within a theoretical perspective that can usefully link underlying
   systems to their relevant impacts. We propose task-technology fit (TTF)
   as such a user evaluation construct.
   The TTF perspective views technology as a means by which a goal-directed
   individual performs tasks. TTF focuses on the degree to which systems
   characteristics match user task needs. We posit that higher
   task-technology fit will result in better performance. Further, we posit
   that users can successfully evaluate task-technology fit. This latter
   proposition is strongly supported in a survey of 259 users in 9
   companies.
RI Tavares, Antonio JV/A-7115-2008
ZA 2
ZS 2
ZB 14
ZR 0
Z8 7
TC 483
Z9 495
SN 0025-1909
EI 1526-5501
UT WOS:A1995TX07000001
ER

PT J
AU Poppo, L
TI Influence activities and strategic coordination: Two distinctions of
   internal and external markets
SO MANAGEMENT SCIENCE
VL 41
IS 12
BP 1845
EP 1859
DI 10.1287/mnsc.41.12.1845
PD DEC 1995
PY 1995
AB This paper examines empirically two distinctions of internal and
   external markets: influence activities and strategic coordination.
   Influence activities that arise from decentralization, imperfect
   monitoring, and a relative performance system are a potential liability
   of internal markets; coordination may be worse in internal markets than
   in external markets. However, strategic coordination is an advantage of
   internal markets: a hierarchy can more effectively implement strategic
   policies in internal markets than external markets. The results of this
   study show that profit center managers engage in influence activities by
   haggling over price adjustments, causing greater renegotiation costs in
   internal markets than in comparable external markets. However,
   implementation of cost reduction, which is a strategic policy, appears
   to be more effective in internal markets: the results show that
   supplying profit centers disclose more private cost information than
   external market suppliers. Thus cooperation and competition appear to
   operate simultaneously in internal markets. In addition, the results
   suggest that internal markets appear to undermine one advantage of a
   vertical integration strategy: the creation of unique assets, an
   organizational resource that can generate rents. These results, which
   are based on data gathered from the internal and external markets of one
   Fortune 100 company, are exploratory and further work is needed to
   generalize the findings.
ZS 0
Z8 0
ZR 0
ZA 0
TC 35
ZB 0
Z9 35
SN 0025-1909
UT WOS:A1995TX07000002
ER

PT J
AU Covaliu, Z
   Oliver, RM
TI Representation and solution of decision problems using sequential
   decision diagrams
SO MANAGEMENT SCIENCE
VL 41
IS 12
BP 1860
EP 1881
DI 10.1287/mnsc.41.12.1860
PD DEC 1995
PY 1995
AB In this paper we introduce a new graph, the sequential decision diagram,
   to aid in modeling, formulation, and solution of sequential decision
   problems under uncertainty. While as compact as an influence diagram,
   the sequential diagram captures the asymmetric and sequential aspects of
   decision problems as effectively as decision trees. We show that a
   unified framework, consisting of a sequential diagram, an influence
   diagram, and a common formulation table for the problem's data, suffices
   for compact and consistent representation, economical formulation, and
   efficient solution of (asymmetric) decision problems. In addition to
   asymmetry, the framework exploits other sources of computational
   efficiency, such as conditional independence and value function
   decomposition, making it also useful in evaluating dynamic-programming
   problems. The formulation table and recursive algorithm can be readily
   implemented in computers for solving large-scale problems. Examples are
   provided to illustrate the methodology in both asymmetric and symmetric
   cases.
ZA 0
ZR 0
Z8 1
TC 29
ZB 0
ZS 0
Z9 30
SN 0025-1909
UT WOS:A1995TX07000003
ER

PT J
AU Barraquand, J
TI Numerical valuation of high dimensional multivariate European securities
SO MANAGEMENT SCIENCE
VL 41
IS 12
BP 1882
EP 1891
DI 10.1287/mnsc.41.12.1882
PD DEC 1995
PY 1995
AB We consider the problem of pricing a contingent claim whose payoff
   depends on several sources of uncertainty. Using classical assumptions
   from the Arbitrage Pricing Theory, the theoretical price can be computed
   as the discounted expected value of future cash flows under the modified
   risk-neutral information process. Although analytical solutions have
   been developed elsewhere for a few particular option pricing problems,
   computing the arbitrage prices of securities under several sources of
   uncertainty is still an open problem in many instances. In this paper,
   we present efficient numerical techniques based upon Monte Carlo
   simulation for pricing European contingent claims depending on an
   arbitrary number of risk sources. We introduce in particular the method
   of quadratic resampling (QR), a new powerful error reduction technique
   for Monte Carlo simulation. Quadratic resampling can be efficiently
   combined with classical variance reduction methods such as importance
   sampling. Our numerical experiments show that the method is practical
   for pricing claims depending on up to one hundred underlying assets.
ZA 0
TC 21
Z8 2
ZB 0
ZS 1
ZR 0
Z9 23
SN 0025-1909
UT WOS:A1995TX07000004
ER

PT J
AU Hilliard, JE
   Kau, JB
   Keenan, DC
   Muller, WJ
TI Pricing a class of American and European path dependent securities
SO MANAGEMENT SCIENCE
VL 41
IS 12
BP 1892
EP 1899
DI 10.1287/mnsc.41.12.1892
PD DEC 1995
PY 1995
AB Path dependent securities depend on current and past values of
   underlying state variables. Consequently, the usual backward evaluation
   technique is difficult to apply since state variable values existing
   earlier in real time are unknown. This paper develops a series of
   propositions which makes possible the pricing of a certain class of both
   American and European versions of these path dependent securities.
ZS 0
ZR 0
ZB 0
Z8 0
TC 1
Z9 1
SN 0025-1909
UT WOS:A1995TX07000005
ER

PT J
AU Rathnam, S
   Mahajan, V
   Whinston, AB
TI Facilitating coordination in customer support teams: A framework and its
   implications for the design of information technology
SO MANAGEMENT SCIENCE
VL 41
IS 12
BP 1900
EP 1921
DI 10.1287/mnsc.41.12.1900
PD DEC 1995
PY 1995
AB The management of coordination gaps is critical to the effective
   functioning of a customer support team. To address the managerial
   challenge of designing Information Technology (IT) to facilitate
   coordination in customer support teams, this paper develops a framework
   describing the drivers of coordination gaps in customer support teams.
   Measures for the characteristics of problem resolution processes, the
   characteristics of IT that assist in the management of coordination
   gaps, and coordination gaps are developed and validated. Results from a
   field study administered to 399 respondents from 41 teams in Apple,
   Dell, Hewlett-Packard, IBM, Seton Hospital, and Southwestern Bell
   support the proposition that coordination gaps arise from a lack of fit
   between the characteristics of problem resolution processes used and the
   characteristics of IT used. What is more important, the results also
   indicate that processes with differing characteristics require different
   kinds of IT.
RI Mahajan, Vijay/L-3952-2019
ZA 0
ZB 0
Z8 0
ZR 0
ZS 0
TC 30
Z9 30
SN 0025-1909
UT WOS:A1995TX07000006
ER

PT J
AU Guler, O
   Roos, C
   Terlaky, T
   Vial, JP
TI A survey of the implications of the behavior of the central path for the
   duality theory of Linear Programming
SO MANAGEMENT SCIENCE
VL 41
IS 12
BP 1922
EP 1934
DI 10.1287/mnsc.41.12.1922
PD DEC 1995
PY 1995
AB The literature in the field of interior point methods for Linear
   Programming has been almost exclusively algorithmic oriented. Very few
   contributions have been made towards the theory of Linear Programming
   itself. In particular none of them offer a simple, self-contained
   introduction to the theory of Linear Programming and linear
   inequalities. The purpose of this paper is to show that the interior
   point methodology can be used to introduce the field of Linear
   Programming. Starting from scratch, and using only elementary results
   from calculus and linear algebra, we prove that for every value of the
   barrier parameter, the logarithmic barrier function for the primal-dual
   problem has a unique minimizer, and that the path of these minimizers
   (the central path) converges to a strictly complementary pair of optimal
   solutions. These results were proved more than a decade ago with
   advanced mathematical arguments. Our proofs are new: they are also
   simpler and often more natural than the ones currently known. They
   provide a new approach to the fundamental results of Linear Programming,
   including the existence of a strictly complementary solution, and the
   strong duality theorem.
Z8 0
ZR 0
ZS 0
ZB 0
TC 2
Z9 2
SN 0025-1909
UT WOS:A1995TX07000007
ER

PT J
AU Nelson, BL
   Matejcik, FJ
TI Using common random numbers for indifference-zone selection and multiple
   comparisons in simulation
SO MANAGEMENT SCIENCE
VL 41
IS 12
BP 1935
EP 1945
DI 10.1287/mnsc.41.12.1935
PD DEC 1995
PY 1995
AB We present a general recipe for constructing experiment design and
   analysis procedures that simultaneously provide indifference-zone
   selection and multiple-comparison inference for choosing the best among
   k simulated systems. We then exhibit two such procedures that exploit
   the variance-reduction technique of common random numbers to reduce the
   sample size required to attain a fixed precision. One procedure is based
   on the Bonferroni inequality and is guaranteed to be statistically
   conservative. The other procedure is exact under a specific dependence
   structure, but may be slightly liberal otherwise. Both are easy to
   apply, requiring only simple calculations and tabled constants. We
   illustrate the procedures with a numerical example.
RI Nelson, Barry L/B-7490-2009
ZA 0
ZR 0
Z8 0
ZB 3
ZS 0
TC 83
Z9 83
SN 0025-1909
UT WOS:A1995TX07000008
ER

PT J
AU Andradottir, S
TI A method for discrete stochastic optimization
SO MANAGEMENT SCIENCE
VL 41
IS 12
BP 1946
EP 1961
DI 10.1287/mnsc.41.12.1946
PD DEC 1995
PY 1995
AB This paper addresses the problem of optimizing a function over a finite
   or countably infinite set of alternatives, in situations where this
   objective function cannot be evaluated exactly, but has to be estimated
   or measured. A special focus is on situations where simulation is used
   to evaluate the objective function. We present two versions of a new
   iterative method for solving such discrete stochastic optimization
   problems. In each iteration of the proposed method, a neighbor of the
   ''current'' alternative is selected, and estimates of the objective
   function evaluated at the current and neighboring alternatives are
   compared. The alternative that has a better observed function value
   becomes the next current alternative. We show how one version of the
   proposed method can be used to solve discrete optimization problems
   where the objective function is evaluated using transient or
   steady-state simulation, and we show how the other version can be
   applied to solve a special class of discrete stochastic optimization
   problems and present some numerical results. A major strength of the
   proposed method is that it spends most of the computational effort at
   local minimizers of the objective function. In fact, we show that for
   both versions of the proposed method, the alternative that has been
   visited most often in the first m iterations converges almost surely to
   a local optimizer of the objective function as m goes to infinity.
ZS 1
ZA 0
ZB 0
Z8 2
ZR 0
TC 81
Z9 84
SN 0025-1909
UT WOS:A1995TX07000009
ER

PT J
AU Beroggi, GEG
   Wallace, WA
TI Operational control of the transportation of hazardous materials: An
   assessment of alternative decision models
SO MANAGEMENT SCIENCE
VL 41
IS 12
BP 1962
EP 1977
DI 10.1287/mnsc.41.12.1962
PD DEC 1995
PY 1995
AB Commercially available tracking systems based on advanced communications
   and computing technology allow a dispatcher of hazardous material
   transports to monitor the movement of vehicles on a transportation
   network in real time. When unexpected events occur, a dispatcher working
   with this new technology can identify the regions surrounding the
   transportation network that are affected by these events and determine
   safe and cost-effective routes for the vehicles that plan to drive
   through those regions. Four decision models for rerouting hazardous
   material vehicles in real-time have been assessed in an experimental
   setting. The first model supports a dispatcher in finding alternative
   routes (visually), while the second model adds to the display, for each
   vehicle, an alternative route based on a conservative heuristic. The
   other two models are based on an ordinal preference and a numerical
   utility structure to support the dispatcher in determining the impact of
   the events on transportation safety and costs. The models were embedded
   into four decision support systems that use multimedia technology to
   simulate the dispatchers workstations. These systems were then used in
   an experiment at the dispatching school in Wil, Switzerland, with 32
   experienced dispatchers and truck drivers to assess efficiency and
   accuracy of the four models. The results show that assessing risks and
   costs with the ordinal preference structure, prior to making routing
   decisions, is significantly more efficient and accurate than searching
   directly for new routes. Using a numerical scale for safety and cost
   assessment was disliked by the subjects and led to inferior results.
TC 14
ZR 0
ZB 0
ZA 0
Z8 0
ZS 0
Z9 14
SN 0025-1909
UT WOS:A1995TX07000010
ER

PT J
AU Graves, SC
TI A multiechelon inventory model with fixed replenishment intervals
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 1
EP 18
DI 10.1287/mnsc.42.1.1
PD JAN 1996
PY 1996
AB This paper develops a new model for studying multiechelon inventory
   systems with stochastic demand. For the model we assume that each site
   in the system orders at preset times according to an order-up-to policy,
   that delivery times are deterministic, and that the demand processes are
   stochastic with independent increments. We introduce a new scheme for
   allocating stock in short supply, which we call virtual allocation and
   which permits significant tractability. We exercise the model on a set
   of test problems for two-echelon systems to get insight into the
   structure of good policies. The primary findings are that both the
   central warehouse (upper echelon) and the retail sites (lower echelon)
   should hold safety stock, but that most of the safety stock should be at
   the retail sites. Consequently, the central warehouse will stock out
   with high probability. Furthermore, we show that the virtual allocation
   rule is near optimal for the set of test problems.
Z8 15
ZS 0
TC 102
ZR 0
ZB 0
ZA 0
Z9 117
SN 0025-1909
UT WOS:A1996UE44100001
ER

PT J
AU Harrison, TP
   Lewis, HS
TI Lot sizing in serial assembly systems with multiple constrained
   resources
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 19
EP 36
DI 10.1287/mnsc.42.1.19
PD JAN 1996
PY 1996
AB We present a heuristic for lot sizing in serial assembly systems with
   multiple constrained resources. This procedure, the Coefficient
   Modification Heuristic (CMH), exploits a special problem structure by
   solving repetitively a small linear programming restriction of the
   original problem. The key idea is to modify the constraint coefficients
   of certain variables in the LP restriction to implicitly account for the
   capacity consumed in setups.
   We compare the performance of the CMH with the commercial code,
   Optimization System Library (OSL), on three families of test problems.
   The first set is a collection of small-scale random problems that are
   solved to optimality to provide known benchmarks. The second is a set of
   problems based on a real printed circuit board manufacturing situation.
   The third group is a set of medium-scale randomly generated problems
   based on the underlying structure of the printed circuit board set.
   Overall, the CMH found solutions that averaged 18% better than time
   constrained OSL runs in a small fraction of the corresponding CPU times.
ZS 0
Z8 1
ZR 0
ZA 0
TC 20
ZB 0
Z9 21
SN 0025-1909
UT WOS:A1996UE44100002
ER

PT J
AU White, DJ
TI Decision roll and horizon roll processes in infinite horizon discounted
   Markov decision processes
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 37
EP 50
DI 10.1287/mnsc.42.1.37
PD JAN 1996
PY 1996
AB In this paper we look at some aspects of infinite horizon Markov
   decision processes in which information regarding parameter values is
   restricted to a finite time horizon, and in which decisions are based
   upon the finite horizon data but are recomputed as we move forward in
   time and gain knowledge of later parametric values. A general framework
   is given. Bounds on the loss of optimality arising from two planning
   horizon decision processes are given, and the choice of decision process
   and planning horizon is examined.
TC 4
ZB 0
ZR 0
ZS 0
ZA 0
Z8 0
Z9 4
SN 0025-1909
UT WOS:A1996UE44100003
ER

PT J
AU Hoch, SJ
   Schkade, DA
TI A psychological approach to decision support systems
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 51
EP 64
DI 10.1287/mnsc.42.1.51
PD JAN 1996
PY 1996
AB Rapid advances in information technology have brought decision makers
   the mixed blessing of an increasingly vast amount of easily available
   data. Designers of decision support systems (DSS) have focused on
   incorporating the latest technology with little attention to whether
   these new systems are compatible with the psychology of decision makers.
   Our premise is that DSS should be designed to take advantage of the
   distinctive competencies of decision makers while using technology to
   compensate for their inherent weaknesses. In this study we apply this
   approach to a forecasting task. We find that to arrive at a forecast
   decision makers often search their experience for a situation similar to
   the one at hand and then make small adjustments to this previous
   situation. Our theoretical model of the performance of this intuitively
   appealing strategy shows that it performs reasonably well in highly
   predictable environments, but performs quite poorly in less predictable
   environments. Results from an experiment confirm these predictions and
   show that providing decision makers with a simple linear model in
   combination with a computerized database of historical cases improves
   performance significantly. We conclude by discussing how these results
   can be used to help improve forecasting in applied contexts, such as
   promotion forecasting in the retail grocery industry.
Z8 1
ZA 0
ZS 0
ZR 0
ZB 3
TC 100
Z9 101
SN 0025-1909
UT WOS:A1996UE44100004
ER

PT J
AU Feinberg, FM
   Huber, J
TI A theory of cutoff formation under imperfect information
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 65
EP 84
DI 10.1287/mnsc.42.1.65
PD JAN 1996
PY 1996
AB Numerous models in the Management Science literature contain
   constructions that are a variant of the following: A decision-maker must
   choose from a set of alternatives based on imperfect information as to
   their relative quality, while further evaluation, though costly,
   provides more accurate information. We examine decision heuristics in
   which the optimal search policy entails a screening strategy limiting
   the number of alternatives in the subsequent, costly evaluation. There
   are two general methods for accomplishing this screening: Quota cutoffs
   operate by selecting the optimal number of alternatives to evaluate;
   Level cutoffs operate by specifying a minimally-acceptable level of the
   imperfect screening indicator. The present paper has three main
   objectives. First, to define the Level and Quota cutoff methods, broadly
   characterize optimal behavior for each and determine what aspects of the
   decision environment predispose one to be superior to the other; second,
   to introduce the concomitants of order statistics as a methodology for
   exploring decision problems when information is imperfectly known; and
   third, to discuss the pivotal role of default, or fallback, options in a
   broad class of search problems.
   Quota and Level strategies restrict the number of alternatives passing
   the cutoff-based screen. Because restrictive cutoffs reduce evaluation
   costs while lowering the expected quality of the item finally selected,
   changes in the decision environment making the evaluation process less
   beneficial or increasing its cost drive the optimal cutoff to be more
   restrictive. In particular, increases in unit evaluation cost,
   improvement in the quality of a fallback option, decreases in the total
   number of alternatives available or improvement in the precision of the
   final evaluation process all lead to more restrictive cutoffs at
   optimum. These results hold over a remarkably broad range of assumptions
   and conditions. We also find that a better screening indicator leads to
   more restrictive screening when evaluation costs are low but,
   surprisingly, to less restrictive screening when costs are high.
   Comparing the two strategies, we find the unexpected result that the
   Quota cutoff strategy is generally superior to the Level, except under
   one of two fairly uncommon sets of circumstances: when evaluation cost
   is prohibitively high, or when there is a fallback option of very high
   quality.
RI Feinberg, Fred/ABB-7766-2020
OI Feinberg, Fred/0000-0003-2238-0721
Z8 0
TC 20
ZS 0
ZR 0
ZB 0
ZA 0
Z9 20
SN 0025-1909
UT WOS:A1996UE44100005
ER

PT J
AU Szajna, B
TI Empirical evaluation of the revised technology acceptance model
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 85
EP 92
DI 10.1287/mnsc.42.1.85
PD JAN 1996
PY 1996
AB Davis et al. (1989) proposed, tested, and revised the Technology
   Acceptance Model (TAM), which attempts to explain and predict why users
   sometimes accept and sometimes reject information systems (IS). The
   research reported here (1) provides a confirmatory, empirical test of
   the revised TAM and (2) introduces an objective measure of technology
   acceptance, actual usage rather than self-report usage. Subjects'
   beliefs about the usefulness and ease of use of an electronic mail
   system, their intentions to use the system, and their usage of it 15
   weeks later were measured in a longitudinal study. The results confirmed
   that the TAM is a valuable tool for predicting intentions to use an IS.
   The findings here combined with results from other studies in this area
   suggest that the original TAM may be more appropriate than the
   two-version revised TAM. However, the addition of an experience
   component to the original TAM may be a significant enhancement. In
   addition, the results support that self-report usage may not be an
   appropriate surrogate measure for actual usage.
TC 685
ZS 8
ZA 1
ZB 13
ZR 0
Z8 4
Z9 695
SN 0025-1909
UT WOS:A1996UE44100006
ER

PT J
AU Chi, TL
TI Performance verifiability and output sharing in collaborative ventures
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 93
EP 109
DI 10.1287/mnsc.42.1.93
PD JAN 1996
PY 1996
AB This paper studies the problem of contracting between two firms when
   they try to exploit their complementary resources in a collaborative
   venture (CV), but their performance in the CV cannot be precisely
   verified by the other party or by a third-party arbiter. Using a
   mathematical model that treats performance verifiability as a continuous
   variable, the paper first establishes that a party whose performance
   cannot be perfectly verified has an incentive to shirk if it is paid
   only a flat fee and that this shirking problem is more severe as its
   performance is less verifiable. Then, the paper shows in a general
   setting that a contract under which each party shares a fraction of the
   output is superior to a contract under which one of them is paid only a
   flat fee when performance verifiability is sufficiently low. In
   addition, with some specific assumptions about the forms of the revenue
   and cost functions, the paper also shows that a party's share of the
   venture's residual output in the equilibrium is an increasing function
   of its productivity and a decreasing function of its opportunity cost.
   Finally, the numerical examples constructed in the paper suggest that a
   contract which combines the self-enforcing mechanism of output sharing
   with the third-party enforcement mechanism of arbitration generally
   performs better than a contract that utilizes only one of these
   mechanisms.
ZS 0
ZA 0
Z8 1
ZR 0
ZB 0
TC 13
Z9 14
SN 0025-1909
UT WOS:A1996UE44100007
ER

PT J
AU Burgess, JF
   Wilson, PW
TI Hospital ownership and technical inefficiency
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 110
EP 123
DI 10.1287/mnsc.42.1.110
PD JAN 1996
PY 1996
AB The theoretical industrial organization literature cites varying factors
   which might influence the degree of technical efficiency achieved under
   different ownership structures in the US hospital industry.
   Unfortunately, this literature offers no consensus regarding the net
   direction and magnitude of these various effects. This study analyzes
   the four types of ownership structure in the US hospital
   industry-private nonprofit, private for-profit, federal, and state and
   local government. Distance functions are used to measure technical
   efficiency of hospitals producing multiple outputs relative to other
   hospitals in the sample, allowing comparisons among the different
   ownership types.
OI Wilson, Paul W/0000-0002-9865-033X
ZA 0
ZR 0
ZB 0
Z8 0
TC 59
ZS 0
Z9 59
SN 0025-1909
UT WOS:A1996UE44100008
ER

PT J
AU Anupindi, R
   Morton, TE
   Pentico, D
TI The nonstationary stochastic lead-time inventory problem: Near-myopic
   bounds, heuristics, and testing
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 124
EP 129
DI 10.1287/mnsc.42.1.124
PD JAN 1996
PY 1996
AB The purpose of the current paper is to combine the classical results of
   Kaplan (1970) and Ehrhardt (1984) for stochastic leadtime problems with
   recent work of Morton and Pentico (1991), which assumed zero lag, to
   obtain near-myopic bounds and heuristics for the nonstationary
   stochastic leadtime problem with arbitrary sequences of demand
   distributions, and to obtain planning horizon results. Four heuristics
   have been tested on a number of different demand scenarios over a number
   of random trials for four different leadtime distributions. The myopic
   (simplest) heuristic performs well only for moderately varying problems
   without heavy end of season salvaging, giving errors for this type of
   problem that are less than 1.5%. However, the average error for the
   myopic heuristic over all scenarios tested is 20.0%. The most accurate
   heuristic is the near-myopic heuristic which averages 0.5% from optimal
   across all leadtime distributions with a maximum error of 4.7%. The
   average error increases with increase in variance of the leadtime
   distribution.
ZR 0
ZS 0
TC 18
Z8 0
ZB 0
Z9 18
SN 0025-1909
UT WOS:A1996UE44100009
ER

PT J
AU Wang, YZ
   Gerchak, Y
TI Periodic review production models with variable capacity, random yield,
   and uncertain demand
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 130
EP 137
DI 10.1287/mnsc.42.1.130
PD JAN 1996
PY 1996
AB We investigate a production planning problem in a periodic review
   environment with variable production capacity, random yields, and
   uncertain demand. The implications of random yields and variable
   capacity for lot sizing previously have been explored separately, but
   not jointly. Many production environments are likely to be subject to
   both types of uncertainties. To minimize the total discounted expected
   costs (production, holding, and shortage costs), we formulate the
   problem as a stochastic dynamic program. For the finite-horizon problem,
   we prove that the objective function is quasi-convex and that the
   structure of the optimal policy is characterized by a single critical
   point for the initial stock level at each period. That is, if the
   initial stock is greater than this critical point, the optimal planned
   production is zero; Otherwise, it is greater than zero. Expressions for
   solving the critical point and the optimal planned production are
   obtained. We further show that the solution for the finite-horizon
   problem converges to that of the infinite-horizon problem.
ZS 0
ZA 0
TC 143
ZR 0
ZB 0
Z8 11
Z9 153
SN 0025-1909
UT WOS:A1996UE44100010
ER

PT J
AU Nath, R
TI A note on testing for skewness persistence
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 138
EP 141
DI 10.1287/mnsc.42.1.138
PD JAN 1996
PY 1996
AB This paper shows that the tests of skewness persistence considered by
   Muralidhar (1993) far exceed the true Type I error. That is, the
   probabilities of detecting an increase (decrease) in skewness from one
   time period to another when in fact there is no change are inflated.
   Consequently, the higher power achieved by these tests comes at the cost
   of a higher than specified level of Type I error. We propose a new test
   which maintains the specified Type I error levels. Additionally, the
   power of this test for lognormal distributions is reported.
ZB 0
Z8 0
ZR 0
ZS 0
TC 3
Z9 3
SN 0025-1909
UT WOS:A1996UE44100011
ER

PT J
AU vanHoesel, CPM
   Wagelmans, APM
TI An O(T-3) algorithm for the economic lot-sizing problem with constant
   capacities
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 142
EP 150
DI 10.1287/mnsc.42.1.142
PD JAN 1996
PY 1996
AB We develop an algorithm that solves the constant capacities economic
   lot-sizing problem with concave production costs and linear holding
   costs in O(T-3) time. The algorithm is based on the standard dynamic
   programming approach which requires the computation of the minimal costs
   for all possible subplans of the production plan. Instead of computing
   these costs in a straightforward manner, we use structural properties of
   optimal subplans to arrive at a more efficient implementation. Our
   algorithm improves upon the O(T-4) running time of an earlier algorithm.
ZA 0
ZR 0
ZS 0
TC 106
ZB 0
Z8 1
Z9 106
SN 0025-1909
UT WOS:A1996UE44100012
ER

PT J
AU Bushman, R
   Kanodia, C
TI A note on strategic sampling in agencies
SO MANAGEMENT SCIENCE
VL 42
IS 1
BP 151
EP 156
DI 10.1287/mnsc.42.1.151
PD JAN 1996
PY 1996
AB This paper studies sample design for process control in principal-agent
   settings where deterrence rather than ex post detection is the main
   issue. We show how the magnitude of gains from additional sampling can
   be calculated and traded off against sampling costs. It is shown that
   the optimal sample size shrinks as target defect rates are lowered.
ZB 0
ZR 0
ZA 0
Z8 0
ZS 0
TC 4
Z9 4
SN 0025-1909
UT WOS:A1996UE44100013
ER

PT J
AU Rhee, BD
TI Consumer heterogeneity and strategic quality decisions
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 157
EP 172
DI 10.1287/mnsc.42.2.157
PD FEB 1996
PY 1996
AB Though recent studies show that quality differentiation is an
   equilibrium outcome, products of similar qualities frequently are
   observed in the marketplace. This inconsistency may be explained by
   incorporating consumer heterogeneity along unobservable attributes into
   a model of competition. In this paper, consumers not only take into
   account the quality and price of a product but also their heterogeneous
   tastes along other attributes which are unobservable to firms. We
   investigate the effect of heterogeneity along the unobservable
   attributes on both quality and price equilibrium in a two-stage game
   framework. We show that when consumers are sufficiently heterogeneous
   along the unobservable attributes, the firms offer products of identical
   qualities in equilibrium. Under low levels of heterogeneity along the
   unobservable attributes, however, our results are consistent with past
   research which argues for quality differentiation.
ZB 0
ZA 0
ZR 0
ZS 0
Z8 1
TC 29
Z9 30
SN 0025-1909
UT WOS:A1996WG41600001
ER

PT J
AU Cohen, MA
   Eliashberg, J
   Ho, TH
TI New product development: The performance and time-to-market tradeoff
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 173
EP 186
DI 10.1287/mnsc.42.2.173
PD FEB 1996
PY 1996
AB Reduction of new product development cycle time and improvements in
   product performance have become strategic objectives for many
   technology-driven firms. These goals may conflict, however, and firms
   must explicitly consider the tradeoff between them. In this paper we
   introduce a multistage model of new product development process which
   captures this trade-off explicitly. We show that if product improvements
   are additive (over stages), it is optimal to allocate maximal time to
   the most productive development stage. We then indicate how optimal
   time-to-market and its implied product performance targets vary with
   exogenous factors such as the size of the potential market, the presence
   of existing and new products, profit margins, the length of the window
   of opportunity, the firm's speed of product improvement, and competitor
   product performance. We show that some new product development metrics
   employed in practice, such as minimizing break-even time, can be
   sub-optimal if firms are striving to maximize profits. We also determine
   the minimal speed of product improvement required for profitably
   undertaking new product development, and discuss the implications of
   product replacement which can occur whenever firms introduce successive
   generations of new products. Finally, we show that an improvement in the
   speed of product development does not necessarily lead to an earlier
   time-to-market, but always leads to enhanced products.
RI Ho, Teck-Hua/D-1630-2013
OI Ho, Teck-Hua/0000-0001-5210-4977
ZR 0
ZB 0
TC 245
ZS 0
ZA 0
Z8 6
Z9 251
SN 0025-1909
UT WOS:A1996WG41600002
ER

PT J
AU YasaiArdekani, M
   Nystrom, PC
TI Designs for environmental scanning systems: Tests of a contingency
   theory
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 187
EP 204
DI 10.1287/mnsc.42.2.187
PD FEB 1996
PY 1996
AB This study compared the relationships between organizational context and
   the designs of environmental scanning systems for organizations with
   effective and ineffective scanning systems. The study analyzed data from
   over 100 North American business organizations. Results indicate that
   organizations with effective scanning systems tend to align their
   scanning designs with the requirements of their context. On the other
   hand, the results show that organizations with ineffective scanning
   systems typically fail to exhibit the requisite level of alignment
   between contexts and scanning design.
Z8 0
ZB 0
ZA 0
ZS 2
TC 68
ZR 0
Z9 70
SN 0025-1909
UT WOS:A1996WG41600003
ER

PT J
AU Olesen, OB
   Petersen, NC
TI Indicators of ill-conditioned data sets and model misspecification in
   Data Envelopment Analysis: An extended facet approach
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 205
EP 219
DI 10.1287/mnsc.42.2.205
PD FEB 1996
PY 1996
AB Data Envelopment Analysis (DEA) employs mathematical programming to
   measure the relative efficiency of Decision Making Units (DMUs). This
   paper is concerned with development of indicators to determine whether
   or not the specification of the input and output space is supported by
   data in the sense that the variation in data is sufficient for
   estimation of a frontier of the same dimension as the input output
   space. Insufficient variation in data implies that some inputs/outputs
   can be substituted along the efficient frontier but only in fixed
   proportions. Data thus locally supports variation in a subspace of a
   lower dimension rather than in the input output space of full dimension.
   Each segment of the efficient frontier is in this sense subject to local
   collinearity. Insufficient variation in data provides a bound on
   admissible disaggregations in cases where substitution in fixed
   proportions is incompatible with a priori information concerning the
   production process. A data set incapable of estimating a frontier of
   full dimension will in this case be denoted ill-conditioned. It is shown
   that the existence of well-defined marginal rates of substitution along
   the estimated strongly efficient frontier segments requires the
   existence of Full Dimensional Efficient Facets (FDEFs). A test for the
   existence of FDEFs is developed, and an operational two-stage procedure
   for efficiency evaluation relative to an overall non-fixed technology is
   developed; the two-stage procedure provides a lower and an upper bound
   on the efficiency index for each DMU.
ZS 2
ZA 0
ZB 0
TC 72
ZR 0
Z8 0
Z9 74
SN 0025-1909
UT WOS:A1996WG41600004
ER

PT J
AU Lindsey, JH
   Samuelson, W
   Zeckhauser, R
TI Selling procedures with private information and common values
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 220
EP 231
DI 10.1287/mnsc.42.2.220
PD FEB 1996
PY 1996
AB The seller posted-price procedure is probably the most common method for
   making transactions in modern economies. We analyze the performance of
   posted pricing for transactions having significant common-value
   elements. In a model of two-sided private information, we characterize
   the fully revealing, perfect equilibrium offer strategy of the seller.
   We also characterize equilibrium behavior under two other pricing
   procedures-a sealed-bid procedure and a direct revelation mechanism.
   Finally, we examine the efficiency of these procedures and show that as
   the degree of common values increases, fewer mutually beneficial
   agreements are attained.
Z8 0
ZR 0
ZS 0
ZB 0
TC 2
Z9 2
SN 0025-1909
UT WOS:A1996WG41600005
ER

PT J
AU Bhoovaraghavan, S
   Vasudevan, A
   Chandran, R
TI Resolving the process vs product innovation dilemma: A consumer choice
   theoretic approach
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 232
EP 246
DI 10.1287/mnsc.42.2.232
PD FEB 1996
PY 1996
AB There has been considerable emphasis on the strategic importance of
   process and product innovation in the management literature. What
   actually constitutes process and product innovation, however, is a
   confused issue in the current literature. Are product and process
   innovations separate, or are they on a continuum? The importance of
   addressing this issue is that research over the past few decades has
   attributed Japan's increasing competitiveness to its propensity to
   process innovate. This paper uses a consumer-based approach to
   distinguish between process and product innovation using a model based
   on choice theory. An empirical illustration of the model is also
   presented. The model is then used to emphasize the need to pursue an
   integrated strategy of process and product innovation in response to
   consumer wants. The model also helps managers decide on the appropriate
   mix of process innovation relative to product innovation for R&D
   resource allocation purposes.
ZB 0
ZR 0
ZA 0
Z8 1
TC 37
ZS 1
Z9 39
SN 0025-1909
UT WOS:A1996WG41600006
ER

PT J
AU Balachandran, BV
   Ramakrishnan, RTS
TI Joint cost allocation for multiple lots
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 247
EP 258
DI 10.1287/mnsc.42.2.247
PD FEB 1996
PY 1996
AB We consider the joint cost allocation problem that arises when several
   lots or resources are available to serve different products or
   divisions. We provide a two-phase model, wherein the first phase the
   optimal set of lots to be acquired is chosen and given the optimal set,
   and the products using each acquired lot is also determined. In the
   second phase, a stable full cost allocation method is developed that
   will not induce the divisions to form coalitions to reduce the allocated
   joint costs. Utilizing the optimal dual solution of the lot selection
   phase, we provide a joint cost allocation mechanism based on the concept
   of propensity to contribute and show that this allocation is also
   stable. If in the first phase there is a dual gap, then we show that
   there is no cost allocation in the core. A numerical illustration is
   provided.
ZS 0
Z8 0
ZR 0
ZB 1
TC 6
Z9 6
SN 0025-1909
UT WOS:A1996WG41600007
ER

PT J
AU Rubio, R
   Wein, LM
TI Setting base stock levels using product-form queueing networks
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 259
EP 268
DI 10.1287/mnsc.42.2.259
PD FEB 1996
PY 1996
AB A manufacturing facility produces multiple products in a make-to-stock
   manner, and unsatisfied demand is backordered. A simple production
   control policy is analyzed: When the amount of work-in-process inventory
   plus finished goods inventory for a particular product falls below a
   base stock level, then release another unit of that product onto the
   shop floor. Assuming that the work-in-process inventory has a steady
   state distribution and that there are different costs incurred for
   carrying in-process, completed and backordered units, we show that the
   cost minimizing base stock level for each product is a critical fractile
   of the steady state distribution of the product's total work-in-process
   inventory. By exploiting the relationship between the make-to-stock
   system and an open queueing network, we identify specific formulas for
   the base stock levels under standard product-form assumptions. For the
   lost sales case, a similar relation to a closed queueing network can be
   used to characterize the optimal control parameters.
Z8 0
ZS 0
ZR 0
ZB 0
ZA 0
TC 26
Z9 26
SN 0025-1909
UT WOS:A1996WG41600008
ER

PT J
AU Broadie, M
   Glasserman, P
TI Estimating security price derivatives using simulation
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 269
EP 285
DI 10.1287/mnsc.42.2.269
PD FEB 1996
PY 1996
AB Simulation has proved to be a valuable tool for estimating security
   prices for which simple closed form solutions do not exist. In this
   paper we present two direct methods, a pathwise method and a likelihood
   ratio method, for estimating derivatives of security prices using
   simulation. With the direct methods, the information from a single
   simulation can be used to estimate multiple derivatives along with a
   security's price. The main advantage of the direct methods over
   resimulation is increased computational speed. Another advantage is that
   the direct methods give unbiased estimates of derivatives, whereas the
   estimates obtained by resimulation are biased. Computational results are
   given for both direct methods, and comparisons are made to the standard
   method of resimulation to estimate derivatives. The methods are
   illustrated for a path independent model (European options), a path
   dependent model (Asian options), and a model with multiple state
   variables (options with stochastic volatility).
ZR 0
ZA 0
Z8 2
ZB 1
ZS 1
TC 171
Z9 174
SN 0025-1909
UT WOS:A1996WG41600009
ER

PT J
AU Oh, GT
TI Some results in the CAPM with nontraded endowments
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 286
EP 293
DI 10.1287/mnsc.42.2.286
PD FEB 1996
PY 1996
AB The paper establishes a positive security market line in the CAPM with
   nontraded endowments. The effects of a market structure change on the
   security market line are analyzed when the equilibrium allocation is
   affected by the change.
ZR 0
Z8 0
TC 12
ZS 0
ZB 0
Z9 12
SN 0025-1909
EI 1526-5501
UT WOS:A1996WG41600010
ER

PT J
AU vandenNouweland, A
   Borm, P
   Brouwers, WV
   Bruinderink, RG
   Tijs, S
TI A game theoretic approach to problems in telecommunication
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 294
EP 303
DI 10.1287/mnsc.42.2.294
PD FEB 1996
PY 1996
AB This paper considers two specific problems in telecommunication, namely
   the Terrestrial Flight Telephone System and the rerouting of
   international telephone calls. Both situations are modelled as
   coalitional games, and game theoretic techniques are used to tackle the
   problems. It is shown that a special class of coalitional games emerges
   from the situations under consideration and that the structure of the
   situations has theoretical implications, including the coincidence of
   several game theoretic solution concepts. The implications of these
   theoretical results for the two practical problems are discussed.
RI van den Nouweland, Anne/I-5038-2012; Borm, Peter/
OI van den Nouweland, Anne/0000-0002-8057-2329; Borm,
   Peter/0000-0002-2710-1827
Z8 0
ZB 1
ZS 0
ZA 0
ZR 0
TC 44
Z9 44
SN 0025-1909
EI 1526-5501
UT WOS:A1996WG41600011
ER

PT J
AU Nourie, FJ
   Venta, ER
TI Note: Microcomputer performance of OptPack on Hoffmann's data sets:
   Comparison with Eureka and FABLE
SO MANAGEMENT SCIENCE
VL 42
IS 2
BP 304
EP 306
DI 10.1287/mnsc.42.2.304
PD FEB 1996
PY 1996
AB OptPack (Nourie and Venta 1991) was published between the publication
   times of FABLE and EUREKA. This communication reports microcomputer
   computational experience with OptPack on Hoffmann's data sets following
   the pattern of Johnson (1993a). Some insights about the computational
   effectiveness of the algorithms and some additional difficult problems
   are also presented.
TC 3
ZR 0
ZA 0
Z8 0
ZS 0
ZB 0
Z9 3
SN 0025-1909
UT WOS:A1996WG41600012
ER

PT J
AU Nault, BR
TI Equivalence of taxes and subsidies in the control of production
   externalities
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 307
EP 320
DI 10.1287/mnsc.42.3.307
PD MAR 1996
PY 1996
AB We are always better off having many policies that can achieve a given
   objective because it extends the criteria that can be included in policy
   selection. This paper studies the equivalence between taxes and
   subsidies in the control of negative production externalities. In our
   models, under the tax regime, firms that take no treatment action to
   mitigate the damage caused by their negative externalities are punished,
   whereas under the subsidy regime, firms are rewarded for externality
   treatment activities. We employ a formulation where firms differ in the
   vintage of their production technology and as a result differ in
   profitability, negative externality generation, and the cost of
   treatment. We consider three measures as policy objectives: total
   output, total damage from negative externalities, and social welfare. We
   find reasonable conditions where, with an appropriate setting of uniform
   lump-sum and unit subsidies, the policy maker can achieve a pair of
   policy objectives equivalent to those obtained using unit taxes. Thus,
   either tax or subsidy regimes can be used to achieve desired levels of
   one or two policy objectives, allowing other factors such as fairness,
   equity, or international trade issues to be considered in policy
   selection.
ZS 0
TC 12
ZB 0
Z8 0
ZR 0
ZA 0
Z9 12
SN 0025-1909
UT WOS:A1996WG41700001
ER

PT J
AU Gerchak, Y
   Gupta, D
   Henig, M
TI Reservation planning for elective surgery under uncertain demand for
   emergency surgery
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 321
EP 334
DI 10.1287/mnsc.42.3.321
PD MAR 1996
PY 1996
AB This work concerns the advance scheduling of elective surgery when the
   operating rooms' capacity utilization by emergency surgery, as well as
   by elective procedures, is uncertain. New requests for bookings of
   elective surgery arrive each day. Such procedures preferably would be
   performed as soon as possible, but admitting too many patients may
   result in exceeding a day's capacity, possibly necessitating turning
   away some emergency cases. So the problem facing the hospital at the
   start of each day is how many of the additional requests for elective
   surgery to assign for that day. We provide a stochastic dynamic
   programming model for this aggregate advance scheduling problem. The
   model has some novel mathematical features. We analyze it and
   characterize the nature of the optimal policy, which is not necessarily
   of a control-limit type. Plausible numerical examples which confirm our
   theoretical results and provide additional insights are reported.
TC 137
ZS 0
ZB 4
ZR 0
ZA 0
Z8 2
Z9 139
SN 0025-1909
EI 1526-5501
UT WOS:A1996WG41700002
ER

PT J
AU Genest, C
   Zhang, SS
TI A graphical analysis of ratio-scaled paired comparison data
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 335
EP 349
DI 10.1287/mnsc.42.3.335
PD MAR 1996
PY 1996
AB One of the building blocks of the Analytic Hierarchy Process (Saaty
   1977) is the ratio-scaled assessment of an agent's preferences between
   pairs of alternatives. This article shows how it is possible to
   visualize such data and to detect cardinal and ordinal inconsistencies
   in the respondent's judgments. The graphical method used to display
   preferences is not new in itself: it dates back at least to the work of
   Gower (1977), and many variants of his technique can be found in the
   literature. But Gower plots provide an especially valuable diagnostic
   tool in the context of AHP, as discussed and abundantly illustrated
   herein.
Z8 3
ZB 0
ZA 0
ZS 0
ZR 0
TC 18
Z9 21
SN 0025-1909
UT WOS:A1996WG41700003
ER

PT J
AU MacDuffie, JP
   Sethuraman, K
   Fisher, ML
TI Product variety and manufacturing performance: Evidence from the
   International Automotive Assembly Plant Study
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 350
EP 369
DI 10.1287/mnsc.42.3.350
PD MAR 1996
PY 1996
AB This paper examines the effect of product variety on manufacturing
   performance, defined here as total labor productivity and
   consumer-perceived product quality. Using data from the International
   Motor Vehicle Program (M.I.T.) study of 70 assembly plants worldwide,
   the paper examines three dimensions of product variety, at fundamental,
   peripheral, and intermediate levels. The international sample reveals
   great variation in the distribution of each type of product variety in
   different regions, reflecting in part different: strategies for variety.
   Furthermore, the impact of different kinds of product variety on
   performance varies, and is generally much less than the conventional
   manufacturing wisdom would predict. However, an intermediate type of
   product variety, here called parts complexity, was found to have a
   persistent negative impact on produc tivity. Finally, the study provides
   partial support for the hypothesis that management policies, in both
   operations and human resource areas, can facilitate the absorption of
   higher levels of product variety, i.e. that ''lean production'' plants
   are capable of handling higher levels of product variety with less
   adverse effect on total labor productivity than traditional ''mass
   production'' plants.
ZB 0
TC 290
ZS 5
ZA 0
Z8 1
ZR 0
Z9 294
SN 0025-1909
UT WOS:A1996WG41700004
ER

PT J
AU Pasa, M
   Shugan, SM
TI The value of marketing expertise
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 370
EP 388
DI 10.1287/mnsc.42.3.370
PD MAR 1996
PY 1996
AB This paper has three objectives: (1) to construct a theoretical model
   that aids in evaluating marketing expertise, (2) to use that theoretical
   model to identify factors influencing the Value of marketing expertise,
   and (3) to empirically test the model by observing how different market
   conditions influence whether companies emphasize marketing expertise. We
   accomplish these objectives as follows.
   First, we use decision theory to find an expression far the expected
   value of marketing expertise. We do not use decision-analysis in the
   normative tradition. Nor do we assume that firms actually use formal
   decision-analysis. Rather, we assume that firms are rational and that
   decision theory describes their actions. Given that assumption, we
   predict how firms should evaluate marketing. Here, marketing expertise
   helps a firm make better marketing decisions (at least on average).
   Hence, the value of marketing expertise increases as marketing decisions
   become more important.
   Second, consistent with decision theory, we predict that marketing
   decisions become more important with increases in the instability of the
   marketing environment (i.e., predictability), the profit impact of
   marketing decisions (i.e., opportunity profit), and the loss from
   marketing mistakes (i.e., potential loss).
   Third, we construct empirical measures of our theoretical constructs
   with data from 592 firms. Our empirical results are consistent with our
   predictions and reveal factors influencing the value of marketing
   expertise. For example, greater market instability and market presence
   increase the value of marketing expertise, while larger organization
   size, organization instability, and competition decrease its value.
ZA 0
ZR 0
TC 17
Z8 0
ZB 0
ZS 0
Z9 17
SN 0025-1909
UT WOS:A1996WG41700005
ER

PT J
AU McGrath, RG
   Tsai, MH
   Venkataraman, S
   MacMillan, IC
TI Innovation, competitive advantage and rent: A model and test
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 389
EP 403
DI 10.1287/mnsc.42.3.389
PD MAR 1996
PY 1996
AB Four antecedents, it is argued, are necessary precursors for a firm to
   capture rents from innovation. The antecedents are causal understanding;
   innovation team proficiency; emergence and mobilization of new
   competences; and creation of competitive advantages, each of which are
   conceptually distinct and precisely defined in the paper. These
   constructs are linked together in a stage model and subsequently
   operationalized and tested using LISREL. Substantial support is found
   for the central thesis, that achieving each of the four antecedent
   processes increases the predicted rents from an innovation project.
RI Pawson, Mark C/A-6085-2010; Cardoso, Andre/E-1841-2012
OI Cardoso, Andre/0000-0002-6213-8123
TC 135
ZA 0
ZS 7
ZB 0
ZR 0
Z8 1
Z9 141
SN 0025-1909
UT WOS:A1996WG41700006
ER

PT J
AU Wirl, F
TI The design of optimal conservation programs by electric utilities
   considering strategic consumer behavior
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 404
EP 414
DI 10.1287/mnsc.42.3.404
PD MAR 1996
PY 1996
AB The practice of utility demand side conservation programs, one of the
   most topical issues of utility management, provokes strategic reactions
   of consumers. As a solution to this moral. hazard, optimal conservation
   programs are characterized when the consumers differ either with respect
   to their subjective time preference or with respect to the level oi
   dem;ind. In particular, we derive incentive compatible conservation
   schemes that mitigate strategic behavior. These incentives differ
   starkly from actual programs. First, the costs of conservation may
   exceed the avoided costs, yet accepting such high costs (at the margin)
   need not imply a large conservation. Second, such incentive scheme
   should bypass the inefficient consumers (e.g., the ''poor'') bu; should
   instead target consumers who act efficiently and have a high demand
   (e.g., the ''rich'').
RI Wirl, Franz/C-9486-2017; Wirl, Franz/P-2861-2019
OI Wirl, Franz/0000-0002-2168-8049; Wirl, Franz/0000-0002-2168-8049
ZS 0
ZA 0
ZR 0
TC 3
Z8 0
ZB 0
Z9 3
SN 0025-1909
UT WOS:A1996WG41700007
ER

PT J
AU Hendricks, KB
   Singhal, VR
TI Quality awards and the market value of the firm: An empirical
   investigation
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 415
EP 436
DI 10.1287/mnsc.42.3.415
PD MAR 1996
PY 1996
AB This paper empirically investigates the impact of winning a quality
   award on the market value of firms by estimating the mean ''abnormal''
   change in the stock prices of a sample of firms on the date when
   information about winning a quality award was publicly announced. We
   note that the abnormal returns generated by the quality award winning
   announcements provide a lower bound for the impact of implementing an
   effective quality improvement program. Our results show that the stock
   market reacts positively to quality award announcements. Statistically
   significant mean abnormal returns on the day of the announcements ranged
   from a low of 0.59% to a high of 0.67% depending on the model used to
   generate the abnormal returns. The reaction was particularly strong for
   smaller firms (mean abnormal returns ranged from low of 1.16% to a high
   of 1.26%), and for firms that won awards from independent organizations
   such as Malcolm Baldrige, Philip Crosby, etc. (mean abnormal returns
   ranged from a low of 1.31% to a high of 1.65%). Winning a quality award
   also conveys information about the systematic risk of the firm. We find
   a statistically significant decrease in the equity and the asset betas
   after the quality award announcement. There is also evidence to suggest
   that large firms experience negative stock price performance in the
   second year before winning quality awards, which is followed by a year
   of positive performance. Small firms experience a positive stock price
   performance in the second year before winning quality awards but no
   negative performance before winning quality awards.
RI van Lent, Laurence/G-5298-2010
ZR 0
Z8 1
ZS 2
TC 212
ZA 1
ZB 1
Z9 215
SN 0025-1909
UT WOS:A1996WG41700008
ER

PT J
AU Srinivasan, MM
   Gupta, D
TI When should a roving server be patient?
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 437
EP 451
DI 10.1287/mnsc.42.3.437
PD MAR 1996
PY 1996
AB When polling systems are used to model real-world systems, it is
   typically assumed that the server switches continuously (''roves'') even
   when there are no waiting jobs in the system. However, requiring the
   server to be patient, instead of having it rove, might be more
   realistic. Furthermore, operational control of these systems can be
   improved by knowing answers to questions like ''under what circumstances
   should a roving server be patient?'' and ''at which stations?''
   This paper analyzes the patient server model and provides explicit
   expressions for the waiting time distributions, the mean waiting times
   and the pseudo-conservation law. Several variants of the patient server
   model are considered. We show that while the patient server mechanism is
   generally better than the roving server mechanism in the work-in-process
   (WIP) reduction sense, there do exist cases where roving is better.
   Counter-intuitive examples where reducing switchover time can increase
   WIP are also reported.
TC 13
ZB 0
ZR 0
Z8 0
ZA 0
ZS 0
Z9 13
SN 0025-1909
UT WOS:A1996WG41700009
ER

PT J
AU Wilson, JG
TI Note on variance reducing group maintenance policies
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 452
EP 456
DI 10.1287/mnsc.42.3.452
PD MAR 1996
PY 1996
AB Group replacement policies for machines operating in parallel are
   generally evaluated by computing the associated expected cost per unit
   tine. However; as with all stochastically evolving systems, variance
   should play an important managerial role. Mo matter which policy is used
   by the maintenance manager, knowledge of the associated variance
   provides important information about the variability of the costs that
   will be incurred by using this policy. Additionally, there will be cases
   where a decision maker is willing to incur increased expected cost per
   unit time in order to reduce the variability of the costs among cycles.
   This paper demonstrates that it is feasible and practicable to calculate
   the variance of the cost per unit time associated with group maintenance
   policies.
ZR 0
ZA 0
ZB 0
TC 2
ZS 0
Z8 0
Z9 2
SN 0025-1909
UT WOS:A1996WG41700010
ER

PT J
AU Bogetoft, P
TI DEA on relaxed convexity assumptions
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 457
EP 465
DI 10.1287/mnsc.42.3.457
PD MAR 1996
PY 1996
AB In a recent paper, Petersen (1990) proposed to relax the convexity
   assumptions invoked in traditional Data Envelopment Analysis (DEA).
   Unfortunately, the new approach is not consistent with the relaxed
   assumptions. Also, the efficiency evaluations in input and output spaces
   are based on different technological assumptions. The aim of this paper
   is to clarify which assumptions are actually involved and to develop
   modifications such that the input and output based measures are
   consistent. In effect, a family of DEA methods based on relaxed
   convexity assumptions is identified.
ZB 2
ZS 1
Z8 1
TC 74
ZA 0
ZR 0
Z9 75
SN 0025-1909
UT WOS:A1996WG41700011
ER

PT J
AU Brockett, PL
   Golany, B
TI Using rank statistics for determining programmatic efficiency
   differences in Data Envelopment Analysis
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 466
EP 472
DI 10.1287/mnsc.42.3.466
PD MAR 1996
PY 1996
AB This paper presents an analytical approach, based on rank statistics, to
   the issue of comparing programs within Data Envelopment Analysis (DEA)
   efficiency evaluation framework. The program evaluation procedure
   distinguishes between managerial and programmatic inefficiency and uses
   the Mann-Whitney rank statistic to evaluate the statistical significance
   of the differences observed between a treatment program and its control
   group program after adjusting for differences in managerial efficiency
   between the programs. A numerical example, based on the data used to
   evaluate the educational enhancement of the Program Follow Through, is
   used to illustrate the proposed statistical procedures.
TC 154
ZA 0
ZS 1
ZB 7
Z8 1
ZR 0
Z9 156
SN 0025-1909
UT WOS:A1996WG41700012
ER

PT J
AU McDonald, J
TI Note: A problem with the decomposition of technical inefficiency into
   scale and congestion components
SO MANAGEMENT SCIENCE
VL 42
IS 3
BP 473
EP 474
DI 10.1287/mnsc.42.3.473
PD MAR 1996
PY 1996
AB In 1988, Byrnes, Fare, Grosskopf and Lovell define a decomposition of
   inefficiency differentials into scale and congestion components. This
   note shows that the decomposition may be sensitive to the order in which
   the two components are calculated, and, consequently, use of the
   decomposition may result in misleading signals being given to
   management.
ZS 0
ZR 0
Z8 0
ZB 0
TC 13
ZA 0
Z9 13
SN 0025-1909
UT WOS:A1996WG41700013
ER

PT J
AU Andradottir, S
TI A scaled stochastic approximation algorithm
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 475
EP 498
DI 10.1287/mnsc.42.4.475
PD APR 1996
PY 1996
AB Consider a stochastic system of such complexity that its performance can
   only be evaluated by using simulation or direct experimentation. To
   optimize the expected performance of such systems as a function of
   several continuous input parameters (decision variables), we present a
   ''scaled'' stochastic approximation algorithm for finding the zero
   (root) of the gradient of the response function. In each iteration of
   the scaled algorithm, two independent gradient estimates are sampled at
   the current estimate of the optimal input-parameter vector to compute a
   scale-free estimate of the next search direction. We establish
   sufficient conditions to ensure strong consistency and asymptotic
   normality of the resulting estimator of the optimal input-parameter
   vector. Strong consistency is also established for a variant of the
   scaled algorithm with Kesten's acceleration. An experimental performance
   comparison of the scaled algorithm and the classical Robbins-Monro
   algorithm in two simple queueing systems reveals some of the practical
   advantages of the scaled algorithm.
TC 28
ZB 1
ZA 0
ZS 2
ZR 0
Z8 1
Z9 31
SN 0025-1909
UT WOS:A1996WG41800001
ER

PT J
AU Kim, WC
   Mauborgne, RA
TI Procedural justice and managers' in-role and extra-role behavior: The
   case of the multinational
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 499
EP 515
DI 10.1287/mnsc.42.4.499
PD APR 1996
PY 1996
AB Existing procedural justice studies to date offer only pieces of the
   picture on how procedural justice judgments affect behavior. Besides,
   these studies have been conducted primarily in the legal context. This
   paper develops a comprehensive picture of how procedural justice affects
   managers' in-role and extra-role behavior in the business context. It
   does so by examining the direct and indirect effects of procedural
   justice judgments on the in-role and extra-role behavior of
   multinationals' subsidiary top management in the context of the global
   resource allocation decision process. Especially, this paper advances
   and tests a theory which predicts that the attitude of commitment to
   support decisions provides a bridge between procedural justice and
   extra-role behavior. Based on an analysis of 119 subsidiary top
   managers, we offer evidence in support of this theory. Besides its
   contribution to the procedural justice literature, our study also sheds
   light on one of the most pressing issues outstanding in the field of
   international management: how multinationals can motivate subsidiary top
   managers to implement their global resource allocation decisions. The
   results suggest that the exercise of procedural justice inspires
   managers to go beyond the call of duty and engage in innovative actions,
   spontaneous cooperation, and creative behavior on behalf of the
   organization in their execution of decisions.
OI Vescovi, Edo/0000-0001-7209-8527
ZA 0
Z8 0
ZS 2
ZB 1
TC 67
ZR 0
Z9 69
SN 0025-1909
UT WOS:A1996WG41800002
ER

PT J
AU Azaiez, MN
   Bier, VM
TI Aggregation error in Bayesian analysis of reliability systems
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 516
EP 528
DI 10.1287/mnsc.42.4.516
PD APR 1996
PY 1996
AB Perfect aggregation in Bayesian system reliability analysis has been
   shown to be extremely unlikely. In other words, aggregation error is
   almost inevitable. Consequently, analysts have to deal with the
   following dilemma: on one hand, an aggregate analysis (i.e., an analysis
   at the system level), while relatively inexpensive, may be misleading.
   On the other hand, a disaggregate analysis (i.e., at the component
   level) provides more accurate results, but may be costly and
   impractical. Therefore, simple techniques to estimate the size of
   aggregation error are necessary to help analysts choose the most
   appropriate level of detail for an analysis. In this paper, reasonable
   bounds on the aggregation error are derived for a variety of reliability
   models. Ln particular, these bounds will never be more than twice the
   actual error. Tools to compute these bounds (and in some cases the
   actual error) are also provided.
TC 6
ZS 0
ZB 0
ZR 0
Z8 0
Z9 6
SN 0025-1909
UT WOS:A1996WG41800003
ER

PT J
AU Greenleaf, EA
   Sinha, AR
TI Combining buy-in penalties with commissions at auction houses
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 529
EP 540
DI 10.1287/mnsc.42.4.529
PD APR 1996
PY 1996
AB Most auction sellers consign property to auction houses rather than
   holding the auction themselves. In addition to charging sellers a
   commission on property that sells in the auction, many auction houses
   also specify buy-in penalties in auction contracts. This is an amount
   the seller must pay the auction house if the property fails to sell at
   auction. An important managerial question for auction houses is whether
   and when buy-in penalties can increase revenues of the auction house,
   seller, or both, and what combinations of commission and buy-in penalty
   to use. We show that auctions which combine buy-in penalties with lower
   commissions Pareto-dominate auctions that use only commissions. This
   strategy motivates the seller to set a lower reserve, which creates a
   surplus in auction revenues that can go to one or both parties. This
   strategy is Pareto-dominant even if the auction house and the seller are
   uncertain about the number of bidders at the auction, or the auction
   house is uncertain about the seller's own valuation for the property, at
   the time the buy-in penalty, commission, and reserve are contractually
   set. We also discuss the incentive issues raised by this strategy.
RI Greenleaf, Eric A/A-6552-2008
TC 12
ZR 0
ZS 0
ZA 0
ZB 0
Z8 0
Z9 12
SN 0025-1909
UT WOS:A1996WG41800004
ER

PT J
AU Brynjolfsson, E
   Hitt, L
TI Paradox lost? Firm-level evidence on the returns to information systems
   spending
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 541
EP 558
DI 10.1287/mnsc.42.4.541
PD APR 1996
PY 1996
AB The ''productivity paradox'' of information systems (IS) is that,
   despite enormous improvements in the underlying technology, the benefits
   of IS spending have not been found in aggregate output statistics. One
   explanation is that IS spending may lead to increases in product quality
   or variety which tend to be overlooked in the aggregate statistics, even
   if they increase output at the firm-level. Furthermore, the
   restructuring and cost-cutting that are often necessary to realize the
   potential benefits of IS have only recently been undertaken in many
   firms.
   Our study uses new firm-level data on several components of IS spending
   for 1987-1991. The dataset includes 367 large firms which generated
   approximately 1.8 trillion dollars in output in 1992. We supplemented
   the IS data with data on other inputs, output, and price deflators from
   other sources. As a result, we could assess several econometric models
   of the contribution of IS to firm-level productivity.
   Our results indicate that IS spending has made a substantial and
   statistically significant contribution to firm output. We find that the
   gross marginal product (MP) for computer capital averaged 81% for the
   firms in our sample. We find that the MP for computer capital is at
   least as large as the marginal product of other types of capital
   investment and that, dollar for dollar, IS labor spending generates at
   least as much output as spending on non-IS labor and expenses. Because
   the models we applied were similar to those that have been previously
   used to assess the contribution of IS and other factors of production,
   we attribute the different results to the fact that our data set is more
   current and larger than others explored. We conclude that the
   productivity paradox disappeared by 1991, at least in our sample of
   firms.
RI Brynjolfsson, Erik/H-2412-2012
ZA 1
ZR 2
ZB 0
ZS 13
Z8 10
TC 834
Z9 853
SN 0025-1909
UT WOS:A1996WG41800005
ER

PT J
AU Gallagher, MA
   Bauer, KW
   Maybeck, PS
TI Initial data truncation for univariate output of discrete-event
   simulations using the Kalman filter
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 559
EP 575
DI 10.1287/mnsc.42.4.559
PD APR 1996
PY 1996
AB Data truncation is a commonly accepted method of dealing with
   initialization bias in discrete-event simulation. An algorithm for
   determining the appropriate initial-data truncation point for univariate
   output is proposed. The technique entails averaging across independent
   replications and estimating a steady-state output model in a state-space
   framework. A Bayesian technique called Multiple Model Adaptive
   Estimation (MMAE) is applied to compute a time varying estimate of the
   output's steady-state mean. This MMAE implementation features the use,
   in parallel, of a bank of three Kalman filters. Each filter is
   constructed under a different assumption about the output's steady-state
   mean. One of the filters assumes that the steady-state mean is
   accurately reflected by an estimate, called the ''assumed steady-state
   mean,'' taken from the last half of the simulation data. This filter is
   called the reference filter. The remaining filters are calibrated with
   steady-state means corresponding to simple functions of the minimum and
   maximum data values, respectively. As the filters process the output
   through the effective transient, the reference filter becomes more
   likely (in a Bayesian sense) to be the best filter to represent the
   data, and the MMAE mean estimator is influenced increasingly towards the
   assumed steady-state mean. The estimated truncation point is selected
   when the MMAE mean estimate is within a small tolerance of the assumed
   steady-state mean.
   A Monte Carlo analysis using data generated from twelve simulation
   models is used to evaluate the technique. The evaluation criteria
   include the ability to estimate accurately and to construct reliable
   confidence intervals for the mean of the response based on the truncated
   sequences.
ZR 0
ZS 0
ZB 0
TC 5
Z8 0
Z9 5
SN 0025-1909
UT WOS:A1996WG41800006
ER

PT J
AU Desruelle, P
   Steudel, HJ
TI A queuing network model of a single-operator manufacturing workcell with
   machine/operator interference
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 576
EP 590
DI 10.1287/mnsc.42.4.576
PD APR 1996
PY 1996
AB We present an analytical approach to evaluate the performance of a
   manufacturing workcell tended by a single operator when operator-induced
   machine interference occurs. Each part must be processed at every
   workstation in the workcell. The fact that one or more machines can
   request an operator service while the operator is busy at another
   machine induces machine interference. If the reduction of the workcell's
   capacity due to this interference becomes too great, then the customer
   demand may not be satisfied. Our approach determines quickly whether the
   workcell can meet a required demand under its current configuration and
   operating parameters. We do this by modeling the workcell as two
   interacting queuing networks: an open part/machine network, and a closed
   machine/operator network. In the open network, parts arrive in batches
   of a fixed size for each part type, but with exponentially distributed
   interarrival times between parts. In both networks, service times follow
   general distributions that are characterized by their first two moments.
ZB 0
ZR 0
TC 11
ZA 0
Z8 1
ZS 0
Z9 12
SN 0025-1909
UT WOS:A1996WG41800007
ER

PT J
AU Aykin, T
TI Optimal shift scheduling with multiple break windows
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 591
EP 602
DI 10.1287/mnsc.42.4.591
PD APR 1996
PY 1996
AB This paper presents a new integer programming model for optimal shift
   scheduling with multiple rest and lunch breaks, and break windows. A
   set-covering approach for this problem was originally developed by
   Dantzig (1954). Since then, a number of set-covering-based formulations
   have been proposed in the literature. These formulations require an
   integer variable for every shift type, shift start time, and rest/lunch
   break placement combination. Unfortunately, the number of integer
   variables required is rather large, making them impractical to solve for
   an optimal solution in most applications. We present a new approach in
   which a set of break variables is introduced for every shift-break type
   combination to determine the break placements. This approach leads to a
   significantly improved integer programming model requiring substantially
   smaller number of variables and computer memory. We tested the proposed
   approach with 40 test problems involving between 1,728 and 8,640 shift
   variations, and five demand patterns. Our results showed that the
   proposed formulation is very useful in solving large shift scheduling
   problems optimally.
ZB 0
ZA 0
ZR 0
ZS 1
TC 86
Z8 1
Z9 88
SN 0025-1909
UT WOS:A1996WG41800008
ER

PT J
AU Schmidt, RL
TI A stochastic optimization model to improve production planning and R&D
   resource allocation in biopharmaceutical production processes
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 603
EP 617
DI 10.1287/mnsc.42.4.603
PD APR 1996
PY 1996
AB The increasing cost of health care has brought pressure to reduce
   pharmaceutical costs, and because manufacturing and R&D are significant
   cost factors, these areas have been targeted as potential sources of
   cost reduction. Manufacturing costs are particularly high in the
   biotechnology industry because process technologies are relatively new.
   Contamination, genetic instability, and other factors complicate
   production planning and make bioprocess systems unreliable. This paper
   presents a Markov decision process model that combines features of
   engineering design models and aggregate production planning models to
   obtain a hybrid model that links biological and engineering parameters
   to optimize operations performance. Using tissue plasminogen activator
   as a specific example, the paper shows how the hybrid modeling approach
   not only improves production planning, but also provides accurate
   information on the operating performance of bioprocesses that can be
   used to predict the financial impact of process changes. Therefore, the
   model can be used to guide investments in manufacturing process
   improvement and R&D (e.g., genetic modifications). Although stochastic
   production models are not commonly used in process design, this paper
   shows how a combined engineering production model can facilitate a
   concurrent design approach to reduce cost in bioprocess development.
RI Schmidt, Robert L/B-8483-2013
OI Schmidt, Robert L/0000-0003-4414-0139
ZR 0
ZS 0
Z8 3
ZA 0
TC 10
ZB 0
Z9 12
SN 0025-1909
UT WOS:A1996WG41800009
ER

PT J
AU Hassin, R
TI On the advantage of being the first server
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 618
EP 623
DI 10.1287/mnsc.42.4.618
PD APR 1996
PY 1996
AB The following example illustrates the problem treated in this paper: Two
   gas stations are located one after the other on a main road. A driver
   who needs to fill his tank sees the queue situation at the first station
   but not at the second one. The driver estimates the expected waiting
   time at the first station, compares it to the conditional expected
   waiting time at the second one, and decides which station to enter. The
   second station is assumed to be on the driver's route so that no extra
   cost is involved in choosing it. Is it true that the first station
   always gets a higher share of the demand than the second one? We model
   the situation in terms of queueing theory and answer the question.
TC 18
ZB 0
ZR 0
ZA 0
Z8 0
ZS 0
Z9 18
SN 0025-1909
EI 1526-5501
UT WOS:A1996WG41800010
ER

PT J
AU White, DJ
TI Maximising a function over a finite set of actions - Technical note
SO MANAGEMENT SCIENCE
VL 42
IS 4
BP 624
EP 627
DI 10.1287/mnsc.42.4.624
PD APR 1996
PY 1996
AB In this technical note we examine a method of extending a problem over a
   finite set of actions, to problem of maximising a function over a
   bi-product set. The solution set is characterised in terms of fixed
   point solutions and partial solutions, and two improvement algorithms
   are given.
Z8 0
TC 1
ZS 0
ZB 0
ZR 0
Z9 1
SN 0025-1909
UT WOS:A1996WG41800011
ER

PT J
AU Ahn, JH
   Hornberger, JC
TI Involving patients in the cadaveric kidney transplant allocation
   process: A decision-theoretic perspective
SO MANAGEMENT SCIENCE
VL 42
IS 5
BP 629
EP 641
DI 10.1287/mnsc.42.5.629
PD MAY 1996
PY 1996
AB The United Network for Organ Sharing system of allocating cadaveric
   kidneys for transplantation permits only minimal involvement of patients
   in the selection process. The system ignores potential variations in the
   importance that patients may attach to outcomes associated with the
   transplant decision. For instance, some patients may prefer only kidneys
   that will give them a very favorable chance to achieve a successful
   transplant. We designed a decision model in which patients are surveyed
   about their preferences for health states that in turn affect decisions
   about the type of donor kidneys that would be acceptable for
   transplantation. Our analyses show that patients with favorable
   transplant characteristics (e.g., young age, good health, good
   immunologic match between the donor kidney and the recipient) or who
   expect a minimal improvement in quality of life after successful
   transplantation can afford to be selective when considering which
   kidneys to accept for transplantation. Involving patients in selecting
   the optimal donor-kidney should improve patients' quality and duration
   of life with end-stage renal disease, and thereby improve the overall
   efficiency of the U.S. kidney transplantation program.
RI Hornberger, John/M-4932-2019; Ahn, Jae-Hyeon/C-1561-2011
ZR 0
Z8 2
ZB 4
ZS 0
ZA 0
TC 43
Z9 45
SN 0025-1909
UT WOS:A1996WG41900001
ER

PT J
AU Pollack, H
   Zeckhauser, R
TI Budgets as dynamic gatekeepers
SO MANAGEMENT SCIENCE
VL 42
IS 5
BP 642
EP 658
DI 10.1287/mnsc.42.5.642
PD MAY 1996
PY 1996
AB Most large organizations allocate resources by means of fixed budgets:
   each subunit is normally entitled to spend a defined amount over a fixed
   period, usually one year. Fixed budgets create clear incentives for
   subunits to control costs. Yet such arrangements create major incentives
   for dynamic inefficiency, for example by encouraging subunits to exhaust
   their budgets toward the end of the fiscal year.
   This paper develops a dynamic optimization model to examine the
   incentives fostered by budget systems. It invokes the metaphor of
   physicians involved in a health care delivery system to examine
   incentives created by decentralized ''gatekeeping'' as a mechanism to
   control medical costs. The paper also discusses some methods to reduce
   the incentives for dynamic inefficiency that fixed budgets create.
RI Pollack, Harold A/A-1166-2007
TC 16
ZR 0
Z8 0
ZA 0
ZB 0
ZS 0
Z9 16
SN 0025-1909
UT WOS:A1996WG41900002
ER

PT J
AU Ho, TH
   Weigelt, K
TI Task complexity, equilibrium selection, and learning: An experimental
   study
SO MANAGEMENT SCIENCE
VL 42
IS 5
BP 659
EP 679
DI 10.1287/mnsc.42.5.659
PD MAY 1996
PY 1996
AB We consider several coordination games with multiple equilibria each of
   which is a different division of a fixed pie. Laboratory experiments are
   conducted to address whether ''task complexity'' affects the selection
   of equilibrium by subjects. Three measures of task
   complexity-cardinality of choice space, level of iterative knowledge of
   rationality, and level of iterative knowledge of strategy-are
   manipulated and tested. Results suggest the three measures can predict
   choice behavior. Since strategically equivalent games can have different
   task complexity measures, our results imply that subjects are sensitive
   to game form presentation. We also fit data using three adaptive
   learning models: 1) Cournot, 2) Fictitious Play, and 3) Payoff
   Reinforcement, in increasing order of required cognitive effort. The
   Fictitious Play model, which tracks only cumulative frequencies of
   opponents' past behaviors fits the data best.
RI Ho, Teck-Hua/D-1630-2013
OI Ho, Teck-Hua/0000-0001-5210-4977
ZB 1
ZA 0
TC 38
Z8 0
ZS 0
ZR 0
Z9 38
SN 0025-1909
EI 1526-5501
UT WOS:A1996WG41900003
ER

PT J
AU Mazzola, JB
   McCardle, KF
TI A Bayesian approach to managing learning-curve uncertainty
SO MANAGEMENT SCIENCE
VL 42
IS 5
BP 680
EP 692
DI 10.1287/mnsc.42.5.680
PD MAY 1996
PY 1996
AB This paper introduces a Bayesian decision theoretic model of optimal
   production in the presence of learning-curve uncertainty. The well-known
   learning-curve model is extended to allow for random variation in the
   learning process with uncertainty regarding some parameter of the
   variation. A production run generates excess value (above its current
   revenue) for a Bayesian manager in two ways: it pushes the firm further
   along the learning curve, increasing the likelihood of lower costs for
   future runs; and it provides information, through the observed costs,
   that reduces the uncertainty regarding the rate at which costs are
   decreasing. We provide conditions under which one of the classical
   deterministic learning-curve results-namely, that optimal production
   exceeds the myopic level-carries over to the extended framework. We
   demonstrate that another classical deterministic learning-curve
   result-namely, that optimal production increases with cumulative
   production-does not hold in the Bayesian setting.
ZA 0
ZS 1
TC 41
ZR 0
Z8 0
ZB 1
Z9 42
SN 0025-1909
UT WOS:A1996WG41900004
ER

PT J
AU Damanpour, F
TI Organizational complexity and innovation: Developing and testing
   multiple contingency models
SO MANAGEMENT SCIENCE
VL 42
IS 5
BP 693
EP 716
DI 10.1287/mnsc.42.5.693
PD MAY 1996
PY 1996
AB Current research in organizational innovation is extensive, yet, because
   of limitations in scope, most studies are not adequately encompassing.
   These studies typically relate organizational variables to innovation
   and control at most for the effect of one contingency factor. Because
   innovation depends upon a complex host of factors, such theories have
   limited predictive application. This study intends to develop and test
   theories that explain the variation in the organizational
   complexity-innovation relationship in greater detail. The study
   considers two major indicators of organizational complexity-structural
   complexity and organizational size. Hypotheses are proposed on the
   effects of 14 contingency factors on the relationships between
   structural complexity and innovation and organizational size and
   innovation. The contingency factors include environmental uncertainty,
   organizational size, industrial sectors, types of innovation, and stages
   of innovation adoption. Using a meta-analytic procedure for multivariate
   analysis, the hypotheses are then tested with data from published
   studies in organizational innovation during the last three decades. The
   effects of four methods variables-operational definitions of innovation,
   structural complexity and size, and similarity of data sources-are
   controlled for in testing the hypotheses. This process results in two
   powerful and encompassing models: (1) the association between structural
   complexity and innovation depends upon operational definition of
   complexity, environmental. uncertainty, use of manufacturing
   organizations, use of service organizations, focus on technical
   innovations, focus on product innovations, and focus on implementation
   of innovation; and (2) the association between organizational size and
   innovation depends upon operational definition of size, environmental
   uncertainty, use of service organizations, use of for-profit
   organizations, focus on technical innovations, and focus on product
   innovations. These models suggest avenues for further theory development
   and research, which we discuss.
RI Greiver, Michelle/N-8764-2015; Holman, B.J./E-8868-2010
TC 566
ZR 1
ZB 8
ZS 14
ZA 1
Z8 12
Z9 588
SN 0025-1909
EI 1526-5501
UT WOS:A1996WG41900005
ER

PT J
AU Andradottir, S
TI Optimization of the transient and steady-state behavior of discrete
   event systems
SO MANAGEMENT SCIENCE
VL 42
IS 5
BP 717
EP 737
DI 10.1287/mnsc.42.5.717
PD MAY 1996
PY 1996
AB We present a general framework for applying simulation to optimize the
   behavior of discrete event systems. Our approach involves modeling the
   discrete event system under study as a general state space Markov chain
   whose distribution depends on the decision parameters. We then show how
   simulation and the likelihood ratio method can be used to evaluate the
   performance measure of interest and its gradient, and we present
   conditions that guarantee that the Robbins-Monro stochastic
   approximation algorithm will converge almost surely to the optimal
   values of the decision parameters. Both transient and steady-state
   performance measures are considered. For steady-state performance
   measures, we consider both the case when the Markov chain of interest is
   regenerative in the standard sense, as well as the case when this Markov
   chain is Harris recurrent, and thereby regenerative in a wider sense.
Z8 1
ZS 0
TC 10
ZR 0
ZB 0
Z9 11
SN 0025-1909
EI 1526-5501
UT WOS:A1996WG41900006
ER

PT J
AU Tempelmeier, H
   Derstroff, M
TI A Lagrangean-based heuristic for dynamic multilevel multiitem
   constrained lotsizing with setup times
SO MANAGEMENT SCIENCE
VL 42
IS 5
BP 738
EP 757
DI 10.1287/mnsc.42.5.738
PD MAY 1996
PY 1996
AB In this paper a heuristic approach for the dynamic multilevel multiitem
   lotsizing problem in general product structures with multiple
   constrained resources and setup times is proposed. With the help of
   Lagrangean relaxation the capacitated multilevel multiitem lotsizing
   problem is decomposed into several uncapacitated single-item lotsizing
   problems. From the solutions of these single-item problems lower bounds
   on the minimum objective function value are derived. Upper bounds are
   generated by means of a heuristic finite scheduling procedure. The
   quality of the approach is tested with reference to various problem
   groups of differing sizes.
TC 141
ZA 0
ZS 2
ZB 0
ZR 0
Z8 8
Z9 150
SN 0025-1909
UT WOS:A1996WG41900007
ER

PT J
AU Collopy, F
TI Biases in retrospective self-reports of time use: An empirical study of
   computer users
SO MANAGEMENT SCIENCE
VL 42
IS 5
BP 758
EP 767
DI 10.1287/mnsc.42.5.758
PD MAY 1996
PY 1996
AB Research on information systems (IS) use has often relied upon
   retrospective self-reports. One example is when the amount of time spent
   using a system is reported, often as an indication of user acceptance.
   In this study, self-assessments of computer usage are compared with
   computer-monitored interactive use and conned time for 401 managers and
   professionals. When self-assessed use was compared with logged
   interactive use, there was a 32% difference in the average amount of use
   (3.9 vs. 2.7 hours/day). When the self-assessment was compared with
   total conned time, the averages were similar to each other (3.9 vs. 4.0
   hours). In both comparisons, though, there were considerable differences
   between individual self-assessments and logged time (with a median
   absolute percentage difference of 47% when compared with logged connect
   time). Individual estimates of use tended to regress toward the
   population's mean use. Those whose use of the system was relatively
   light overestimated their use, while heavy users underestimated theirs.
   When a test of the relationship between user satisfaction and amount of
   use was conducted using self-assessments, the relationship was not
   statistically significant. When the same test was conducted using logged
   connect time, the relationship was significant. These results suggest
   that fare should be exercised in operationalizing the user acceptance
   construct through self-reports of time use.
ZA 0
ZR 0
ZS 0
ZB 2
Z8 0
TC 53
Z9 53
SN 0025-1909
UT WOS:A1996WG41900008
ER

PT J
AU Buzacott, JA
TI Commonalities in reengineered business processes: Models and issues
SO MANAGEMENT SCIENCE
VL 42
IS 5
BP 768
EP 782
DI 10.1287/mnsc.42.5.768
PD MAY 1996
PY 1996
AB Process reengineering advocates making radical changes in how processing
   systems are structured, such as moving away from systems that use the
   principles of division of labor and division of management. Using formal
   system models from queueing theory, this paper explores the conditions
   under which such radical changes in system structure are likely to be
   appropriate. In general, a fairly high degree of variability in task
   times seems to be necessary.
RI Buzacott, John A/A-5274-2008
ZB 0
Z8 0
TC 85
ZA 0
ZR 0
ZS 0
Z9 85
SN 0025-1909
UT WOS:A1996WG41900009
ER

PT J
AU Federgruen, A
   Katalan, Z
TI The stochastic Economic Lot Scheduling Problem: Cyclical base-stock
   policies with idle times
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 783
EP 796
DI 10.1287/mnsc.42.6.783
PD JUN 1996
PY 1996
AB In this paper we discuss stochastic Economic Lot Scheduling Problems
   (ELSP), i.e., settings where several items need to be produced in a
   common facility with limited capacity, under significant uncertainty
   regarding demands, production times, setup times, or combinations
   thereof. We propose a class of production/inventory strategies for
   stochastic ELSPs and describe how a strategy which minimizes holding,
   backlogging, and setup costs within this class can be effectively
   determined and evaluated. The proposed class of strategies is simple but
   rich and effective: when the facility is assigned to a given item,
   production continues until either a specific target inventory level is
   reached or a specific production batch has been completed; the different
   items are produced in a given sequence or rotation cycle, possibly with
   idle times inserted between the completion of an item's production batch
   and the setup for the next item. An optimal strategy within the class
   can be determined, and all relevant performance measures can be
   evaluated in just a few CPU seconds, using a 486-based PC. We also
   derive a number of easily computable lower bounds for the optimal cost
   value and establish a comparison with deterministic ELSPs.
ZA 0
ZB 0
Z8 0
ZS 0
ZR 0
TC 52
Z9 52
SN 0025-1909
EI 1526-5501
UT WOS:A1996WG42000001
ER

PT J
AU Nowicki, E
   Smutnicki, C
TI A fast taboo search algorithm for the job shop problem
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 797
EP 813
DI 10.1287/mnsc.42.6.797
PD JUN 1996
PY 1996
AB A fast and easily implementable approximation algorithm for the problem
   of finding a minimum makespan in a job shop is presented. The algorithm
   is based on a taboo search technique with a specific neighborhood
   definition which employs a critical path and blocks of operations
   notions. Computational experiments (up to 2,000 operations) show that
   the algorithm not only finds shorter makespans than the best
   approximation approaches but also runs in shorter time. It solves the
   well-known 10 x 10 hard benchmark problem within 30 seconds on a
   personal computer.
ZR 0
ZB 7
ZA 0
Z8 58
TC 552
ZS 2
Z9 608
SN 0025-1909
UT WOS:A1996WG42000002
ER

PT J
AU Duenyas, I
   VanOyen, MP
TI Heuristic scheduling of parallel heterogeneous queues with set-ups
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 814
EP 829
DI 10.1287/mnsc.42.6.814
PD JUN 1996
PY 1996
AB We consider the problem of allocating a single server to a system of
   queues with Poisson arrivals. Each queue represents a class of jobs and
   possesses a holding cost rate, general service distribution, and general
   set-up time distribution. The objective is to minimize the expected
   holding cost due to the waiting of jobs. A set-up time is required to
   switch from one queue to another. We provide a limited characterization
   of the optimal policy and a simple heuristic scheduling policy for this
   problem. Simulation results demonstrate the effectiveness of our
   heuristic over a wide range of problem instances.
Z8 0
ZR 1
ZB 0
ZA 0
ZS 0
TC 28
Z9 29
SN 0025-1909
UT WOS:A1996WG42000003
ER

PT J
AU Axsater, S
TI Using the deterministic EOQ formula in stochastic inventory control
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 830
EP 834
DI 10.1287/mnsc.42.6.830
PD JUN 1996
PY 1996
AB This note gives an improved bound (root 5-2)/2 approximate to 0.1180 for
   the relative cost increase when using the deterministic EOQ formula as a
   heuristic solution when demands are stochastic. We also discuss under
   what circumstances this bound is tight.
ZA 0
ZS 0
ZB 0
TC 63
ZR 0
Z8 11
Z9 74
SN 0025-1909
UT WOS:A1996WG42000004
ER

PT J
AU Sun, MH
   Stam, A
   Steuer, RE
TI Solving multiple objective programming problems using feed-forward
   artificial neural networks: The Interactive FFANN Procedure
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 835
EP 849
DI 10.1287/mnsc.42.6.835
PD JUN 1996
PY 1996
AB In this paper, we propose a new interactive procedure for solving
   multiple objective programming problems. Based upon feed-forward
   artificial neural networks (FFANNs), the method is called the
   Interactive FFANN Procedure. In the procedure, the decision maker
   articulates preference information over representative samples from the
   nondominated set either by assigning preference ''values'' to the sample
   solutions or by making pairwise comparisons in a fashion similar to that
   in the Analytic Hierarchy Process. With this information, a FFANN is
   trained to represent the decision maker's preference structure. Then,
   using the FFANN, an optimization problem is solved to search for
   improved solutions. An example is given to illustrate the Interactive
   FFANN Procedure. Also, the procedure is compared computationally with
   the Tchebycheff Method (Steuer and Choo 1983). The computational results
   indicate that the Interactive FFANN Procedure produces good solutions
   and is robust with regard to the neural network architecture.
RI Sun, Minghe/J-1310-2014; Vukomanovic, Mladen/B-7268-2008
OI Sun, Minghe/0000-0001-8503-9761; 
ZR 0
ZS 0
ZA 0
ZB 1
TC 37
Z8 1
Z9 38
SN 0025-1909
UT WOS:A1996WG42000005
ER

PT J
AU Green, PE
   Krieger, AM
TI Individualized hybrid models for conjoint analysis
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 850
EP 867
DI 10.1287/mnsc.42.6.850
PD JUN 1996
PY 1996
AB Increasingly, conjoint analysts are being asked to design and analyze
   studies involving large numbers of attributes and/or attribute levels.
   Various types of approaches, including attribute bridging, Adaptive
   Conjoint Analysis, and hybrid models have been proposed to deal with the
   problem. This paper describes recent developments in hybrid modeling.
   Four hybrid models are described and compared in terms of their
   performance in an industry-based study entailing 15 product attributes.
   Comparisons are made in terms of internal cross-validation, market share
   estimates, attribute importances clustering, and its relationship to
   exogenous background variables. The proposed models are also compared to
   selected models from the transportation science literature. The authors
   emphasize the point that comparative model performance may strongly
   depend on the ways in which the models are to be used.
ZA 0
Z8 3
TC 67
ZB 1
ZR 0
ZS 1
Z9 71
SN 0025-1909
UT WOS:A1996WG42000006
ER

PT J
AU Umanath, NS
   Ray, MR
   Campbell, TL
TI The effect of uncertainty and information asymmetry on the structure of
   compensation contracts: A test of competing models
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 868
EP 874
DI 10.1287/mnsc.42.6.868
PD JUN 1996
PY 1996
AB This research note reports results of a laboratory experiment conducted
   as st follow-up investigation of an earlier study by Umanath, Ray and
   Campbell (1993). Here, we focus on a specific unexpected result of
   Umanath et al. who found evidence contradicting the theoretical
   prediction with respect to the impact of environmental uncertainty on
   the composition of compensation contracts. Umanath et al., in
   retrospect, offered an explanation for their unexpected finding based on
   an alternative theory under the saute agency framework. Our results not
   only ratify the alternative explanation offered by Umanath et al., but
   also identify information symmetry/asymmetry as the contingent factor
   capable of reconciling the apparently contradicting predictions of the
   two agency-based theories used in this research.
ZR 0
Z8 0
ZS 0
ZB 0
TC 8
ZA 0
Z9 8
SN 0025-1909
UT WOS:A1996WG42000007
ER

PT J
AU Park, SH
   Russo, MV
TI When competition eclipses cooperation: An event history analysis of
   joint venture failure
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 875
EP 890
DI 10.1287/mnsc.42.6.875
PD JUN 1996
PY 1996
AB Why do so many joint ventures fail? Despite the fact that their success
   is the exception rather than the rule, the literature on why joint
   venture performance has been so poor remains fragmentary. We address
   this issue, adopting a transaction-cost economics perspective and
   modeling joint ventures as governance structures that blend the
   advantages and drawbacks of both markets and hierarchies. Using a data
   base on electronics industry ventures and event history analysis, we
   identify several predictors of joint venture failure and test for their
   influences. A key finding is that the presence of competition between
   joint venture partners outside of the agreement significantly impairs
   chances for the operation's chance of survival. We also find clear
   evidence that the failure rate of joint ventures is nonmonotonic, rising
   to a peak in the middle term and then declining. Finally, we compare and
   contrast predictors of terminations due to failure to those due to
   acquisition of the joint venture by one of its partners. Our overall
   conclusions highlight implications for strategic choice theory-building
   and the management of joint ventures.
ZS 3
ZR 0
ZB 2
TC 422
ZA 0
Z8 5
Z9 430
SN 0025-1909
UT WOS:A1996WG42000008
ER

PT J
AU Dittus, RS
   Klein, RW
   DeBrota, DJ
   Dame, MA
   Fitzgerald, JF
TI Medical resident work schedules: Design and evaluation by simulation
   modeling
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 891
EP 906
DI 10.1287/mnsc.42.6.891
PD JUN 1996
PY 1996
AB Society has demanded reform in medical resident work scheduling;
   consequently, hospitals are implementing changes having organizational,
   clinical, financial, social, emotional, and educational consequences for
   physician training and patient care. We report the use of simulation
   modeling as an approach to evaluate the outcomes of alternative designs
   prior to implementation. Mobile resources such as physicians with
   complex job descriptions and patients with time-varying arrival
   processes complicated the modeling task. A flexible, powerful simulation
   language helped to model resource decision rules and the frequent
   preemptions of less urgent activities as more urgent requests arise. A
   distribution fitting package enhanced the synthesis of data from diverse
   sources into distributions that adequately modeled input processes. The
   resulting simulation model was used to examine alternatives in the
   design of a new housestaff work schedule. We were able to predict
   accurately the effects on the sleep and activity profile of interns when
   their schedules were modified. Furthermore, this model has remained an
   asset for investigating consequences of many types of variation within
   the system, including changes in patient demand as well as numbers or
   job descriptions of the housestaff.
ZA 0
ZB 0
ZS 0
TC 17
Z8 0
ZR 0
Z9 17
SN 0025-1909
UT WOS:A1996WG42000009
ER

PT J
AU Harhoff, D
TI Strategic spillovers and incentives for research and development
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 907
EP 925
DI 10.1287/mnsc.42.6.907
PD JUN 1996
PY 1996
AB This paper develops a model in which a monopolist supplier can
   contribute to downstream product improvements by creating knowledge
   spillovers which downstream firms use as a substitute for their own R&D
   efforts. Although a market for R&D information does not exist, the
   supplier may appropriate an indirect return on R&D for two reasons.
   Sufficiently high levels of spillover information lead to greater
   downstream product quality, and spillover information reduces the
   equilibrium sunk cost of R&D for downstream firms and thus facilitates
   entry. Both effects cause an expansion of downstream output and enhance
   the demand for the supplier's intermediate good. Given sufficiently
   strong incentives for supplier R&D, the locus of R&D shifts partially
   from the downstream to the upstream industry. R&D expenditures,
   technological opportunities, and downstream industry structure are
   determined endogenously. Weak appropriability conditions in the
   downstream industry enhance innovation incentives in the supply sector.
ZR 0
Z8 10
ZA 0
TC 64
ZS 0
ZB 4
Z9 75
SN 0025-1909
UT WOS:A1996WG42000010
ER

PT J
AU Joy, C
   Boyle, PP
   Tan, KS
TI Quasi-Monte Carlo methods in numerical finance
SO MANAGEMENT SCIENCE
VL 42
IS 6
BP 926
EP 938
DI 10.1287/mnsc.42.6.926
PD JUN 1996
PY 1996
AB This paper introduces and illustrates a new version of the Monte Carlo
   method that has attractive properties for the numerical valuation of
   derivatives. The traditional Monte Carlo method has proven to be a
   powerful and flexible tool for many types of derivatives calculations.
   Under the conventional approach pseudo-random numbers are used to
   evaluate the expression of interest. Unfortunately, the use of
   pseudo-random numbers yields an error bound that is probabilistic which
   can be a disadvantage. Another drawback of the standard approach is that
   many simulations may be required to obtain a high level of accuracy.
   There are several ways to improve the convergence of the standard
   method. This paper suggests a new approach which promises to be very
   useful for applications in finance. Quasi-Monte Carlo methods use
   sequences that are deterministic instead of random. These sequences
   improve convergence and give rise to deterministic error bounds. The
   method is explained and illustrated with several examples. These
   examples include complex derivatives such as basket options, Asian
   options, and energy swaps.
ZR 1
Z8 2
TC 96
ZS 1
ZA 0
ZB 0
Z9 100
SN 0025-1909
UT WOS:A1996WG42000011
ER

PT J
AU Tushman, ML
   Rosenkopf, L
TI Executive succession, strategic reorientation and performance growth: A
   longitudinal study in the US cement industry
SO MANAGEMENT SCIENCE
VL 42
IS 7
BP 939
EP 953
DI 10.1287/mnsc.42.7.939
PD JUL 1996
PY 1996
AB This research explores the performance consequences of CEO succession,
   executive team change, and strategic reorientation in different
   contexts. Based on team demography and organization learning ideas, we
   argue that CEO succession or executive team change enhances incremental
   organization change, while either strategic reorientation or the
   combination of CEO succession with executive team change triggers
   discontinuous organization change. We hypothesize that these contrasting
   intervention modes are appropriate in different contexts. A longitudinal
   study of the U.S. cement industry from 1918-1986 demonstrates that
   simple CEO succession is positively associated with subsequent
   performance when context is stable, but significantly more negatively
   associated with subsequent performance in turbulent contexts. Executive
   team change has significant effects on organization adaptation in both
   stable and turbulent contexts. Strategic reorientations are negatively
   associated with subsequent performance in stable contexts, but
   significantly more positively associated with subsequent performance in
   turbulent contexts. As a set, these results reinforce a demographic
   approach to succession research and indicate that CEO succession,
   executive team change, and reorientation are each distinct and important
   levers shaping organization adaptation. The impacts of these levers are
   contingent on organization context.
ZS 0
TC 132
ZB 2
ZA 0
Z8 2
ZR 0
Z9 134
SN 0025-1909
UT WOS:A1996VU20100001
ER

PT J
AU Barton, RR
   Ivey, JS
TI Nelder-Mead simplex modifications for simulation optimization
SO MANAGEMENT SCIENCE
VL 42
IS 7
BP 954
EP 973
DI 10.1287/mnsc.42.7.954
PD JUL 1996
PY 1996
AB When the Nelder-Mead method is used to optimize the expected response of
   a stochastic system (e.g., an output of a discrete-event simulation
   model), the simplex-resizing steps of the method introduce risks of
   inappropriate termination. We give analytical and empirical results
   describing the performance of Nelder-Mead when it is applied to a
   response function that incorporates an additive white-noise error, and
   we use these results to develop new modifications of Nelder-Mead that
   yield improved estimates of the optimal expected response. Compared to
   Nelder-Mead, the best performance was obtained by a modified method, RS
   + S9, in which (a) the best point in the simplex is reevaluated at each
   shrink, step and (b) the simplex is reduced by 10% (rather than 50%) at
   each shrink step. In a suite of 18 test problems that were adapted from
   the MINPACK collection of NETLIB, the expected response at the estimated
   optimal Feint obtained by RS + S9 had errors that averaged 15% less than
   at the original method's estimated optimal point, at an average cost of
   three times as many function evaluations. Two well-known existing
   modifications for stochastic responses, the (n + 3)-rule and the
   next-to-worst rule, were found to be inferior to the new modification RS
   + S9.
ZB 7
ZA 0
TC 114
Z8 3
ZR 0
ZS 0
Z9 116
SN 0025-1909
UT WOS:A1996VU20100002
ER

PT J
AU Chang, CW
   Chang, JSK
TI Option pricing with stochastic volatility: Information-time vs
   calendar-time
SO MANAGEMENT SCIENCE
VL 42
IS 7
BP 974
EP 991
DI 10.1287/mnsc.42.7.974
PD JUL 1996
PY 1996
AB Empirical evidence has shown that subordinated processes represent well
   the price changes of stocks and futures. Using either transaction counts
   or trading volume as a proxy for information arrival, it supports the
   contention that volatility is stochastic in calendar-time because of
   random information arrival, and thus becomes stationary in
   information-time. This contention has also been supported later in
   theoretical models. In this paper we investigate the implication of this
   contention to option pricing.
   First we price the option in calendar-time where the return of the
   underlying asset follows a jump subordinated process. We extend
   Rubinstein's (1976) and Ross's (1989a) martingale valuation methodology
   to incorporate the pricing of volatility risk. The resulting equilibrium
   formula requires estimating seven parameters upon implementation. We
   then make a stochastic time change, from calendar-time to
   information-time, in order to obtain a stationary underlying asset
   return process to price the option. We find that the isomorphic option
   has random maturity because the number of information arrivals prior to
   the option's calendar-time expiration date is random. We value the
   option using Dynkin's (1965) version of the Feynman-Kac formula that
   allows for a random terminal date. The resulting information-time
   formula requires estimating only one additional parameter compared to
   the Black-Scholes's in practical application. In this regard, the time
   change has reduced the computational complexity of the option pricing
   problem. Simulations show that the formula may outperform the
   Black-Scholes (1973) and Merton (1976a) models in pricing currency
   options. As a first attempt to derive valuation relationships in the
   information-time economy, this investigation may suggest that the
   information-time approach is a functional alternative to the current
   calendar-time norm. It is especially suitable for deriving
   ''volatility-free'' portfolio insurance strategies.
ZR 0
ZB 0
ZA 0
TC 1
Z8 0
ZS 0
Z9 1
SN 0025-1909
UT WOS:A1996VU20100003
ER

PT J
AU Hanson, W
   Martin, K
TI Optimizing multinomial logit profit functions
SO MANAGEMENT SCIENCE
VL 42
IS 7
BP 992
EP 1003
DI 10.1287/mnsc.42.7.992
PD JUL 1996
PY 1996
AB The multinomial logit model is a standard approach for determining the
   probability of purchase in product line problems. When the purchase
   probabilities are multiplied by product contribution margins, the
   resulting profit function is generally nonconcave. Because of this,
   standard nonlinear search procedures may terminate at a local optimum
   which is far from the global optimum. We present a simple procedure
   designed to alleviate this problem. The key idea of this procedure is to
   find a ''path'' of prices from the global optimum of a related, but
   concave logit profit function, to the global optimum of the true (but
   nonconcave) logit profit function.
ZS 0
Z8 1
ZA 0
ZR 0
TC 84
ZB 0
Z9 85
SN 0025-1909
UT WOS:A1996VU20100004
ER

PT J
AU Walls, MR
   Dyer, JS
TI Risk propensity and firm performance: A study of the petroleum
   exploration industry
SO MANAGEMENT SCIENCE
VL 42
IS 7
BP 1004
EP 1021
DI 10.1287/mnsc.42.7.1004
PD JUL 1996
PY 1996
AB This paper explores the differences in observed risk propensity among
   petroleum firms and their impact on firm performance. In this work, we
   (1) develop a decision theoretic model which measures a firm's risk
   propensity in the form of an ''implied'' utility function; (2)
   investigate changes in corporate risk propensity with respect to changes
   in firm size; and (3) examine the relationships between firms' risk
   propensities and alternative dimensions of economic performance,
   including ex post risk and return measures. We also develop a new risk
   propensity measure, the Risk Tolerance Ratio (RTR), which controls for
   firm size and allows firms to be differentiated in terms of relative
   risk propensity. The motivation for this work is managerial concerns
   regarding appropriate risk-laking behavior and the effect of risky
   choice on firm performance. This methodology has importance business
   strategy implications in that we are able to make strong inferences
   about causal relationships between ex ante risk-taking and performance.
   Our findings are compelling in that corporate risk propensity seems to
   matter, and that decisions about corporate risk policy have a
   significant impact on the petroleum firm's economic performance.
ZR 0
ZB 0
TC 62
ZA 0
ZS 2
Z8 1
Z9 63
SN 0025-1909
UT WOS:A1996VU20100005
ER

PT J
AU Hansen, JV
   McDonald, JB
   Messier, WF
   Bell, TB
TI A generalized qualitative-response model and the analysis of management
   fraud
SO MANAGEMENT SCIENCE
VL 42
IS 7
BP 1022
EP 1032
DI 10.1287/mnsc.42.7.1022
PD JUL 1996
PY 1996
AB Management fraud has become a topic of increasing interest to the public
   accounting profession. Prior research indicates that management fraud is
   seldom experienced by audiGtors. As a result, it is doubtful that
   auditors have a well-developed cognitive model for making fraud risk
   assessments as part of the audit planning process. Early research
   studies attempted to identify factors that could be linked to the
   occurrence of management fraud, while more recent work has attempted to
   build models to predict the presence of management fraud. In this paper,
   we report on a study that uses a powerful generalized
   qualitative-response model, EGB2 to model and predict management fraud
   based on a set of data developed by an international public accounting
   firm. The EGB2 specification includes the probit and logit models and
   others as special cases. Moreover, EGB2 easily accommodates asymmetric
   costs of type I and type II errors. This is important for public
   accounting firms since failure to predict fraud when it is present (a
   type II error) is usually very costly to the firm in terms of
   litigation. The results demonstrate good predictive capability for both
   symmetric and asymmetric cost assumptions.
TC 47
ZR 0
ZB 1
Z8 1
ZA 0
ZS 0
Z9 48
SN 0025-1909
UT WOS:A1996VU20100006
ER

PT J
AU Corner, JL
   Kirkwood, CW
TI The magnitude of errors in proximal multiattribute decision analysis
   with probabilistically dependent attributes
SO MANAGEMENT SCIENCE
VL 42
IS 7
BP 1033
EP 1042
DI 10.1287/mnsc.42.7.1033
PD JUL 1996
PY 1996
AB This paper investigates the accuracy of an approximation procedure for
   evaluating alternatives under uncertainty with multiple evaluation
   attributes. This approximation uses only the first two moments of the
   probability distributions for the alternatives, and hence it can
   substantially reduce the amount of information which must be collected
   in order to evaluate alternatives when evaluation attributes are
   probabilistically dependent. The accuracy of the approximation is
   investigated by comparing results from using it with exact calculations
   for a variety of situations representative of those found in decision
   analysis practice. This investigation shows that the approximation is
   accurate for situations representative of many decision analysis
   applications, However, caution is needed in applying the approximation
   in some situations where it may give inaccurate results. Characteristics
   of cases where the approximation is less accurate are presented.
ZR 0
TC 7
ZB 0
ZA 0
Z8 0
ZS 0
Z9 7
SN 0025-1909
UT WOS:A1996VU20100007
ER

PT J
AU Hann, J
   Weber, R
TI Information systems planning: A model and empirical tests
SO MANAGEMENT SCIENCE
VL 42
IS 7
BP 1043
EP 1064
DI 10.1287/mnsc.42.7.1043
PD JUL 1996
PY 1996
AB Empirical studies of information systems planning practices in
   organizations indicate that wide variations exist. We propose and test a
   model based on agency theory and transaction-costs economics to account
   for these variations. As senior management's uncertainty with respect to
   the information systems function increases, we argue they will delegate
   more decision rights to the information systems manager. As a result of
   increased agency costs, senior management will demand more information
   systems planning to provide the basis for monitoring and bonding of the
   manager. In addition, because information systems plans may be used to
   resolve the distribution of gains and losses between senior management
   and the information systems manager in the event of unforeseen
   circumstances, both senior management and the information systems
   manager will seek to exercise control over the planning process and the
   form of the final plan. We argue that the relative specialization of
   human capital of senior management versus the information systems
   manager will dictate whose views dominate in the preparation of and form
   of the information systems plan. Our empirical results show moderate
   support for our model.
ZS 0
ZA 0
ZB 0
ZR 0
TC 28
Z8 2
Z9 30
SN 0025-1909
EI 1526-5501
UT WOS:A1996VU20100008
ER

PT J
AU Brush, T
   Karnani, A
TI Impact of plant size and focus on productivity: An empirical study
SO MANAGEMENT SCIENCE
VL 42
IS 7
BP 1065
EP 1081
DI 10.1287/mnsc.42.7.1065
PD JUL 1996
PY 1996
AB Recent popular business literature has suggested that there is a
   significant trend in the United States for firms to decrease the size
   and increase the focus of manufacturing plants they operate, and that
   this leads to higher productivity. This paper tests empirically the
   validity of these claims. We analyze data on virtually the entire
   population of manufacturing plants in the United States and find that,
   contrary to the popular business literature, the average size of plants
   increased during the period 1972-1984. However, consistent with the
   popular notion, the rate of growth in plant size slowed considerably,
   and even turned negative for a category of large plants. Plant focus did
   increase during this period. We then investigate the relationship
   between productivity and plant characteristics including plant size and
   plant focus. Overall, our results do not support the popular argument
   that reduction in plant size results in productivity gains. However, we
   do find support for this argument in some two-digit SIC industries;
   also, scale economies in the entire population decreased over the period
   1972-1982. We also find only limited support for the popular argument
   that plant focus increases productivity.
ZB 0
ZR 0
TC 34
ZA 0
Z8 0
ZS 1
Z9 35
SN 0025-1909
UT WOS:A1996VU20100009
ER

PT J
AU Hill, T
   OConnor, M
   Remus, W
TI Neural network models for time series forecasts
SO MANAGEMENT SCIENCE
VL 42
IS 7
BP 1082
EP 1092
DI 10.1287/mnsc.42.7.1082
PD JUL 1996
PY 1996
AB Neural networks have been advocated as an alternative to traditional
   statistical forecasting methods. In the present experiment, time series
   forecasts produced by neural networks are compared with forecasts from
   six statistical time series methods generated in a major forecasting
   competition (Makridakis et al. 1982); the traditional method forecasts
   were estimated by experts in the particular technique. The neural
   networks were estimated using the same ground rules as the competition.
   Across monthly and quarterly time series, the neural networks did
   significantly better than traditional methods. As suggested by theory,
   the neural networks were particularly effective for discontinuous time
   series.
ZA 0
TC 225
ZS 2
ZB 6
Z8 5
ZR 0
Z9 232
SN 0025-1909
UT WOS:A1996VU20100010
ER

PT J
AU Abad, PL
TI Optimal pricing and lot-sizing under conditions of perishability and
   partial backordering
SO MANAGEMENT SCIENCE
VL 42
IS 8
BP 1093
EP 1104
DI 10.1287/mnsc.42.8.1093
PD AUG 1996
PY 1996
AB We formulate a generalized model of dynamic pricing and lot-sizing by a
   reseller who sells a perishable good. We assume that when it is economic
   to backlog demand, the reseller can plan for periods of shortage during
   which demand can be partially backordered. When the good is highly
   perishable, the reseller may need to backlog demand in order to market
   the good at a reasonable price. We present a simple solution procedure
   for solving the optimization problem. The procedure entails solving
   first a single nonlinear equation and then, if required, two nonlinear
   equations.
ZB 0
TC 247
ZA 0
ZS 0
Z8 20
ZR 0
Z9 266
SN 0025-1909
UT WOS:A1996VU20200001
ER

PT J
AU Balakrishnan, PV
   Jacob, VS
TI Genetic algorithms for product design
SO MANAGEMENT SCIENCE
VL 42
IS 8
BP 1105
EP 1117
DI 10.1287/mnsc.42.8.1105
PD AUG 1996
PY 1996
AB Product design is increasingly recognized as a critical activity that
   has a significant impact on the performance of firms. Consequently, when
   firms undertake a new (existing) product design (redesign) activity, it
   is important to employ techniques that will generate optimal solutions.
   As optimal product design using conjoint analysis data is an NP-hard
   problem, heuristic techniques for its solution have been proposed. This
   research proposes the use of and evaluates the performance of Genetic
   Algorithms (GA), which is based on the principles of natural selection,
   as an alternative procedure for generating ''good'' (i.e., close to
   optimal) solutions for the product design problem. The paper focuses on
   (1) how GA can be applied to the product design problems, (2)
   determining the comparative performance of GA vis-g-vis the dynamic
   programming (DP) heuristic (Kohli and Krishnamurti 1987, 1989) in
   generating solutions to the product design problems, (3) the sensitivity
   of the GA solutions to variations in parameter choices, and (4)
   generalizing the results of the dynamic programming heuristic to product
   designs involving attributes with varying number of levels and studying
   the impact of alternate attribute sequencing rules.
OI Balakrishnan, P.V./0000-0002-2856-5543
TC 93
ZS 0
ZR 0
ZA 0
Z8 1
ZB 1
Z9 94
SN 0025-1909
UT WOS:A1996VU20200002
ER

PT J
AU Magat, WA
   Viscusi, WK
   Huber, J
TI A reference lottery metric for valuing health
SO MANAGEMENT SCIENCE
VL 42
IS 8
BP 1118
EP 1130
DI 10.1287/mnsc.42.8.1118
PD AUG 1996
PY 1996
AB This study utilizes reference lotteries on life and death to establish a
   death-equivalent metric for valuing long-term health effects. We use a
   computer-based survey approach to elicit choices among residential
   locations that pose different risks of chronic disease and dying in an
   automobile accident. From paired choices between different locations, we
   infer their rates of trade-off between reducing the risks of chronic
   diseases and the automobile death risk. The values of reducing the risks
   from two diseases, a nerve disease (peripheral neuropathy) and lymphoma
   (cancer of the lymph system), are measured in terms of both trade-off
   rates with the risk of an automobile death and with dollars.
   While the use of reference lotteries for monetary outcomes to establish
   a utility metric is well established for monetary outcomes, our results
   suggest that reference lotteries on life and death can also be applied
   with decision-makers facing realistic choices to construct a utility
   metric for valuing health status. The results were corroborated by a
   strong positive correlation between the risk-risk trade-off values and
   relative aversion scores for the different health outcomes, as well as
   by the relative values of avoiding the three diseases in our study.
Z8 0
TC 48
ZR 0
ZA 0
ZB 4
ZS 0
Z9 48
SN 0025-1909
UT WOS:A1996VU20200003
ER

PT J
AU Wakker, P
   Deneffe, D
TI Eliciting von Neumann-Morgenstern utilities when probabilities are
   distorted or unknown
SO MANAGEMENT SCIENCE
VL 42
IS 8
BP 1131
EP 1150
DI 10.1287/mnsc.42.8.1131
PD AUG 1996
PY 1996
AB This paper proposes a new method, the (gamble-)tradeoff method, for
   eliciting utilities in decision under risk or uncertainty. The
   elicitation of utilities, to be used in the expected utility criterion,
   turns out to be possible even if probabilities are ambiguous or unknown.
   A disadvantage of the tradeoff method is that a few more questions
   usually must be asked to clients. Also, the lotteries that are needed
   are somewhat more complex than in the certainty-equivalent method or in
   the probability-equivalent method. The major advantage of the tradeoff
   method is its robustness against probability distortions and
   misconceptions, which constitute a major cause of violations of expected
   utility and generate inconsistencies in utility elicitation. Thus the
   tradeoff method retains full validity under prospect theory,
   rank-dependent utility, and the combination of the two, i.e., cumulative
   prospect theory.
   The tradeoff method is tested for monetary outcomes and for outcomes
   describing life-duration. We find higher risk aversion for life
   duration, but the tradeoff method elicits similar curvature of utility.
   Apparently the higher risk aversion for Life duration is due to more
   pronounced deviations from expected utility.
ZA 0
ZR 0
TC 222
Z8 2
ZS 0
ZB 7
Z9 224
SN 0025-1909
UT WOS:A1996VU20200004
ER

PT J
AU Zavadlav, E
   McClain, JO
   Thomas, LJ
TI Self-buffering, self-balancing, self-flushing production lines
SO MANAGEMENT SCIENCE
VL 42
IS 8
BP 1151
EP 1164
DI 10.1287/mnsc.42.8.1151
PD AUG 1996
PY 1996
AB This research addresses a system of flexible worker assignments in a
   setting where there are more workers than machines. When organized using
   this system, a production line balances itself by shifting the workloads
   continuously and automatically in response to changes in the state of
   the system. The system is, in effect, buffering itself against variation
   by altering the work assignments on the fly. This allows the system to
   operate with very low levels of work-in-process inventory (WIP).
   In this paper, the workers (rather than machines) are the factor that
   limits the rate of output. We also assume that the line has a ''U''
   shape, but many of the results do not depend on this topology. An
   industrial example is described.
   The system has some interesting and counter-intuitive properties which
   we demonstrate under a variety of circumstances through an exploratory
   approach that uses both Markovian and simulation models. Several
   different policies are compared under conditions of processing time
   uncertainty. We demonstrate that a flexible assignment system can
   outperform fixed assignments in a variety of circumstances. Of
   particular interest is the near absence of balance delay, even when the
   tasks cannot be divided equally among the workers.
ZA 0
Z8 1
ZS 1
ZR 0
TC 66
ZB 0
Z9 68
SN 0025-1909
UT WOS:A1996VU20200005
ER

PT J
AU Schutten, JMJ
   vandeVelde, SL
   Zijm, WHM
TI Single-machine scheduling with release dates, due dates and family setup
   times
SO MANAGEMENT SCIENCE
VL 42
IS 8
BP 1165
EP 1174
DI 10.1287/mnsc.42.8.1165
PD AUG 1996
PY 1996
AB We address the NP-hard problem of scheduling n independent jobs with
   release dates, due dates, and family setup times on a single machine to
   minimize the maximum lateness. This problem arises from the constant
   tug-of-war going on in manufacturing between efficient production and
   delivery performance, between maximizing machine utilization by batching
   similar jobs and maximizing customers' satisfaction by completing jobs
   before their due dates. We develop a branch-and-bound algorithm, and our
   computational results show that it solves almost all instances with up
   to about 40 jobs to optimality. The main algorithmic contribution is our
   lower bounding strategy to deal with family setup times. The key idea is
   to see a setup time as a setup job with a specific processing time,
   release date, due date, and precedence relations. We develop several
   sufficient conditions to derive setup jobs. We specify their parameters
   and precedence relations such that the optimal solution value of the
   modified problem obtained by ignoring the setup times, not the setup
   jobs, is no larger than the optimal solution value of the original
   problem. One lower bound for the modified problem proceeds by allowing
   preemption. Due to the agreeable precedence structure, the preemptive
   problem is solvable in O(n log n) time.
RI Schutten, Marco/B-9119-2009; Zijm, Henk/; Schutten, Marco/
OI Zijm, Henk/0000-0002-4227-2624; Schutten, Marco/0000-0001-5924-223X
Z8 3
ZS 1
ZA 0
TC 32
ZB 0
ZR 0
Z9 35
SN 0025-1909
UT WOS:A1996VU20200006
ER

PT J
AU Gable, GG
TI A multidimensional model of client success when engaging external
   consultants
SO MANAGEMENT SCIENCE
VL 42
IS 8
BP 1175
EP 1198
DI 10.1287/mnsc.42.8.1175
PD AUG 1996
PY 1996
AB Too often the relationship between clients and external consultants is
   perceived as one of protagonist versus antagonist. Stories on dramatic,
   failed consultancies abound, as do related anecdotal quips. A
   contributing factor to many ''apparently'' failed consultancies is a
   poor appreciation by both the client and consultant of the client's hue
   goals for the project and how to assess progress toward these goals.
   This paper presents and analyses a measurement model for assessing
   client success when engaging an external consultant. Three main areas of
   assessment are identified: (1) the consultant's recommendations, (2)
   client learning, and (3) consultant performance. Engagement success is
   empirically measured along these dimensions through a series of case
   studies and a subsequent survey of clients and consultants involved in
   85 computer-based information system selection projects. Validation of
   the model constructs suggests the existence of six distinct and
   individually important dimensions of engagement success. Both clients
   and consultants are encouraged to attend to these dimensions in
   pre-engagement proposal and selection processes, and post-engagement
   evaluation of outcomes.
RI /B-1761-2010; Gable, Guy/I-9717-2012; Graham, Ann-Maree/E-7178-2014; Gable, Guy/
OI Graham, Ann-Maree/0000-0003-1389-3859; Gable, Guy/0000-0003-0828-1268
ZA 0
ZR 0
ZB 0
ZS 0
TC 50
Z8 0
Z9 50
SN 0025-1909
UT WOS:A1996VU20200007
ER

PT J
AU Klassen, RD
   McLaughlin, CP
TI The impact of environmental management on firm performance
SO MANAGEMENT SCIENCE
VL 42
IS 8
BP 1199
EP 1214
DI 10.1287/mnsc.42.8.1199
PD AUG 1996
PY 1996
AB Environmental management has the potential to play a pivotal role in the
   financial performance of the firm. Many individuals suggest that
   profitability is hurt by the higher production costs of environmental
   management initiatives, while others cite anecdotal evidence of
   increased profitability. A theoretical model is proposed that links
   strong environmental management to improved perceived future financial
   performance, as measured by stock market performance. The linkage to
   firm performance is tested empirically using financial event methodology
   and archival data of firm-level environmental and financial performance.
   Significant positive returns were measured for strong environmental
   management as indicated by environmental performance awards, and
   significant negative returns were measured for weak environmental
   management as indicated by environmental crises. The implicit financial
   market valuation of these events also was estimated. Cross-sectional
   analysis of the environmental award events revealed differences for
   first-time awards and between industries. First-time award announcements
   were associated with greater increases in market valuation, although
   smaller increases were observed for firms in environmentally dirty
   industries, possibly indicative of market skepticism. This linkage
   between environmental management and financial performance can be used
   by both researchers and practitioners as one measure of the benefits
   experienced by industry leaders, and as one criterion against which to
   measure investment alternatives.
RI Klassen, Robert D/I-2178-2012; Klassen, Robert/
OI Klassen, Robert/0000-0002-8650-137X
ZR 0
TC 1175
ZB 50
ZS 15
Z8 11
ZA 1
Z9 1204
SN 0025-1909
UT WOS:A1996VU20200008
ER

PT J
AU Weber, Y
   Shenkar, O
   Raveh, A
TI National and corporate cultural fit in mergers/acquisitions: An
   exploratory study
SO MANAGEMENT SCIENCE
VL 42
IS 8
BP 1215
EP 1227
DI 10.1287/mnsc.42.8.1215
PD AUG 1996
PY 1996
AB While cultural fit has been acknowledged to be a potentially important
   factor in mergers and acquisitions, the concept has been ill-defined,
   with no distinction drawn between the national and corporate levels of
   culture. By examining both international and domestic mergers, the
   present study assesses the relative role of national and corporate
   cultural fit in predicting effective integration between merger
   partners. The innovative, nonparametric co-plot method is introduced,
   and its main advantage - the simultaneous consideration of both
   variables and observations-is utilized to explore cultural fit in the
   two groups of mergers,The findings confirm that national and corporate
   culture are separate constructs with variable attitudinal and behavioral
   correlates.
ZB 3
ZR 0
Z8 4
TC 304
ZA 0
ZS 2
Z9 309
SN 0025-1909
UT WOS:A1996VU20200009
ER

PT J
AU Balas, E
   Ceria, S
   Cornuejols, G
TI Mixed 0-1 programming by lift-and-project in a branch-and-cut framework
SO MANAGEMENT SCIENCE
VL 42
IS 9
BP 1229
EP 1246
DI 10.1287/mnsc.42.9.1229
PD SEP 1996
PY 1996
AB We investigate the computational issues that need to be addressed when
   incorporating general cutting planes for mixed 0-1 programs into a
   branch-and-cut framework. The cuts we use are of the lift-and-project
   variety. Some of the issues addressed have a theoretical answer, but
   others are of an experimental nature and are settled by comparing
   alternatives on a set of test problems. The resulting code is a robust
   solver for mixed 0-1 programs. We compare it with several existing
   codes. On a wide range of test problems it performs as well as, or
   better than, some of the best currently available mixed integer
   programming codes.
ZA 0
ZR 0
Z8 0
TC 126
ZS 0
ZB 1
Z9 126
SN 0025-1909
EI 1526-5501
UT WOS:A1996VU20300001
ER

PT J
AU Jacobs, LW
   Brusco, MJ
TI Overlapping start-time bands in implicit tour scheduling
SO MANAGEMENT SCIENCE
VL 42
IS 9
BP 1247
EP 1259
DI 10.1287/mnsc.42.9.1247
PD SEP 1996
PY 1996
AB Many organizations face personnel scheduling decisions under conditions
   of variable demand for service across a seven-day planning horizon.
   These organizations must assign employees to daily shifts that
   efficiently satisfy the demand for labor, yet allow adequate time for
   rest between subsequent shifts of an employee's weekly tour schedule. To
   meet these diverse objectives, managers may permit shifts to begin (and
   end) in any planning period of the day, but place bands on shift-start
   times to which individuals may be assigned on each day of their tour
   schedule.
   We present a compact integer programming model that implicitly
   represents start-time band scheduling flexibility. We demonstrate the
   new model by applying it to requirements for toll collectors on the
   Illinois Tollway. Problems requiring up to two million variables using a
   general set covering formulation were represented using the new implicit
   programming model and often solved to optimality in just a few minutes
   on a Pentium-based microcomputer. The results indicate that start-time
   bands can provide an important improvement in scheduling efficiency when
   compared to the exclusive use of schedules that require workers to begin
   work on the same hour of the day on each day of their tour.
ZA 0
ZS 0
TC 26
ZB 0
ZR 0
Z8 0
Z9 26
SN 0025-1909
UT WOS:A1996VU20300002
ER

PT J
AU Daniels, RL
   Hoopes, BJ
   Mazzola, JB
TI Scheduling parallel manufacturing cells with resource flexibility
SO MANAGEMENT SCIENCE
VL 42
IS 9
BP 1260
EP 1276
DI 10.1287/mnsc.42.9.1260
PD SEP 1996
PY 1996
AB This paper investigates the improvements in manufacturing performance
   that can be realized by broadening, the scope of the production
   scheduling function to include both job sequencing and processing-time
   control through the deployment of a flexible resource. We consider an
   environment in which a set of jobs must be scheduled over a set of
   parallel manufacturing cells, each consisting of a single machine, where
   the processing time of each job depends on the amount of resource
   allocated to the associated cell. Two versions of the problem are
   introduced: a static problem in which a single resource-allocation
   decision Is made and maintained throughout the production horizon, and a
   dynamic problem in which resource Can be reassigned among the production
   cells as local bottlenecks shift. We provide mathematical formulations
   for each version of the problem, establish problem complexity, identify
   important characteristics of optimal solutions, develop optimal and
   heuristic solution approaches, and report the results of a set of
   computational experiments. The computational results demonstrate that
   substantial improvements in operational performance can be achieved
   through effective utilization of resource flexibility.
ZR 0
TC 58
Z8 1
ZA 0
ZS 0
ZB 0
Z9 59
SN 0025-1909
UT WOS:A1996VU20300003
ER

PT J
AU Park, K
   Kang, S
   Park, S
TI An integer programming approach to the bandwidth packing problem
SO MANAGEMENT SCIENCE
VL 42
IS 9
BP 1277
EP 1291
DI 10.1287/mnsc.42.9.1277
PD SEP 1996
PY 1996
AB We consider the bandwidth packing problem arising from telecommunication
   networks. The problem is to determine the set of calls and an assignment
   of them to the paths in an are-capacitated network to maximize profit.
   We propose an algorithm to solve the integer programming formulation of
   the problem. An efficient column generation technique to solve the
   linear programming relaxation is proposed, and a modified cover
   inequality is used to strengthen the IP formulation. The algorithm
   incorporates the column generation technique and the strong cutting
   plane approach into a branch-and-bound scheme. We test the proposed
   algorithm on some random problems. The results show that the algorithm
   can be used to solve the problems within reasonably small time limits.
RI Park, Sungsoo/C-2007-2011
OI Park, Sungsoo/0000-0001-8226-4955
ZA 0
ZR 0
Z8 0
ZB 0
ZS 0
TC 36
Z9 36
SN 0025-1909
UT WOS:A1996VU20300004
ER

PT J
AU Glasserman, P
   Liu, TW
TI Rare-event simulation for multistage production-inventory systems
SO MANAGEMENT SCIENCE
VL 42
IS 9
BP 1292
EP 1307
DI 10.1287/mnsc.42.9.1292
PD SEP 1996
PY 1996
AB We consider the problem of precise estimation of service-level measures
   in multistage production-inventory systems when the system is managed
   for high levels of service. Precisely because the service level is high,
   stockouts, large backorders, and unfilled demands are rare and thus
   difficult to estimate by straightforward simulation. We propose and
   analyze alternative estimators, based on changing the demand
   distribution to make these rare events less rare. Whereas
   straightforward simulation for a fixed relative error results in
   computational requirements that grow exponentially in certain
   stock-level parameters, the requirements for our importance sampling
   estimators remain bounded for all parameter values. We provide bounds
   making it possible to determine the maximum number of replications
   required before any are generated. Numerical examples illustrate the
   effectiveness of our method.
Z8 0
ZA 0
ZB 0
TC 7
ZR 0
ZS 0
Z9 7
SN 0025-1909
UT WOS:A1996VU20300005
ER

PT J
AU Ofir, C
   Reddy, SK
TI Measurement errors in probability judgments
SO MANAGEMENT SCIENCE
VL 42
IS 9
BP 1308
EP 1325
DI 10.1287/mnsc.42.9.1308
PD SEP 1996
PY 1996
AB This paper investigates the psychometric properties of three measures of
   subjective uncertainty-a zero-to-hundred subjective probability scale
   and two seven point rating scales. Individual level analysis applied to
   data obtained from two separate studies suggests that the scales produce
   fairly similar results: The inter-response mode correlations were high,
   and individual plots comparing various methods were quite similar.
   Covariance structure models based on multitrait-multimethod matrices are
   utilized to assess the reliability and method variance of the scales.
   The cumulative evidence suggests that rating scales are consistently
   just as reliable as the subjective probability scale. The probability
   scale contained significant method error. In fact, the two rating scales
   were found to have lower systematic method variance and lower random
   error variance than the subjective probability scale, The payer
   concludes with a discussion regarding possible explanations of these
   results and directions for future research.
RI REDDY, Srinivas/D-2244-2010
ZB 0
Z8 0
TC 8
ZS 0
ZR 0
ZA 0
Z9 8
SN 0025-1909
EI 1526-5501
UT WOS:A1996VU20300006
ER

PT J
AU Sueyoshi, T
TI Divestiture of Nippon Telegraph and Telephone
SO MANAGEMENT SCIENCE
VL 42
IS 9
BP 1326
EP 1351
DI 10.1287/mnsc.42.9.1326
PD SEP 1996
PY 1996
AB This article discusses whether the Japanese government should break up
   NTT (Nippon Telegraph & Telephone) in 1995, as the U.S. federal
   government compelled AT&T (American Telephone & Telegram) to break
   itself into toll and local telephone companies in 1984. The divestiture
   of NTT has long been a major industrial policy issue in japan since the
   common carrier was privatized in 1985. The governmental decision to
   divest it may influence not only the Japanese telecommunications
   infrastructure, but also the global telecommunications and information
   industries in the world, where many common carriers are now facing an
   environmental change from regulation to competition. A unique feature of
   this study is that it employs eight different estimation techniques to
   obtain a cost function of NTT, so that this research avoids a
   methodological bias occurring in many empirical studies, This study
   confirms that NTT has maintained cost subadditivity, but it has failed
   to establish the status of a natural monopoly in the observed time
   period. However, it also finds that the NTT divestiture will not produce
   a price-reducing benefit to Japanese telecommunications consumers, This
   research result will. serve as empirical evidence for guiding the
   governmental review of this large-scale industrial policy issue in
   Japan.
ZA 0
ZR 0
ZS 0
Z8 0
TC 50
ZB 0
Z9 50
SN 0025-1909
UT WOS:A1996VU20300007
ER

PT J
AU Song, JS
   Zipkin, PH
TI The joint effect of leadtime variance and lot size in a parallel
   processing environment
SO MANAGEMENT SCIENCE
VL 42
IS 9
BP 1352
EP 1363
DI 10.1287/mnsc.42.9.1352
PD SEP 1996
PY 1996
AB We study a basic (r, q) system, in which the demand is a Poisson process
   and the leadtimes are independent, identically-distributed random
   variables. The key issue is the joint effect of the leadtime variance
   and the lot she q on performance. We know that, under a simple
   base-stock policy (with q = 1), the leadtime variance has no effect at
   all. We find here that, for larger q, the leadtime variance can have a
   significant adverse impact on performance.
   To explore this effect, we test two simple approximations. The simplest
   ignores the leadtime variance. The second approach is only a bit more
   complex; it captures the variance effect through a hybrid of two
   limiting approximations. Both methods provide useful information, but
   the second is more robust.
TC 24
ZA 0
Z8 0
ZS 0
ZB 0
ZR 0
Z9 24
SN 0025-1909
UT WOS:A1996VU20300008
ER

PT J
AU Bitran, GR
   Mondschein, SV
TI Mailing decisions in the catalog sales industry
SO MANAGEMENT SCIENCE
VL 42
IS 9
BP 1364
EP 1381
DI 10.1287/mnsc.42.9.1364
PD SEP 1996
PY 1996
AB Catalog sales are among the fastest growing businesses in the U.S. The
   most important asset a company in this industry has is its list of
   customers, called the house list. Building a house List is expensive,
   since the response rate of names from rental lists is low. Cash
   management therefore plays a central role in this capital intensive
   business,
   This paper studies optimal mailing policies in the catalog sales
   industry when there is limited access to capital, We consider a
   stochastic environment given by the random responses of customers and a
   dynamic evolution of the house list. Given the size of real problems, it
   is impossible to compute the optimal solutions. We therefore develop a
   heuristic based on the optimal solutions of simplified versions of the
   problem. The performance of this heuristic is evaluated by comparing its
   outcome with an upper bound derived for the original problem.
   Computational experiments show that it bt haves satisfactorily.
   The methodology presented permits the evaluation of potential catalog
   Ventures thus proving useful to entrepreneurs in this industry.
RI Mondschein, Susana/AAO-5816-2020
TC 87
ZA 0
Z8 3
ZS 0
ZR 0
ZB 0
Z9 90
SN 0025-1909
UT WOS:A1996VU20300009
ER

PT J
AU Jennings, OB
   Mandelbaum, A
   Massey, WA
   Whitt, W
TI Server staffing to meet time-varying demand
SO MANAGEMENT SCIENCE
VL 42
IS 10
BP 1383
EP 1394
DI 10.1287/mnsc.42.10.1383
PD OCT 1996
PY 1996
AB We consider a multiserver service system with general nonstationary
   arrival and service-time processes in which s(t), the number of servers
   as a function of time, needs to be selected to meet projected loads. We
   try to choose s(t) so that the probability of a delay (before beginning
   service) hits or falls just below a target probability at all times. We
   develop an approximate procedure based on a time-dependent normal
   distribution, where the mean and variance are determined by
   infinite-sewer approximations. We demonstrate that this approximation is
   effective by making comparisons with the exact numerical solution of the
   Markovian M(t)/M/S-t model.
RI Whitt, Ward/D-5337-2013
OI Whitt, Ward/0000-0003-4298-9964
ZR 0
ZB 1
ZA 0
ZS 1
Z8 1
TC 135
Z9 137
SN 0025-1909
UT WOS:A1996WM55900001
ER

PT J
AU Icmeli, O
   Erenguc, SS
TI A branch and bound procedure for the resource constrained project
   scheduling problem with discounted cash flows
SO MANAGEMENT SCIENCE
VL 42
IS 10
BP 1395
EP 1408
DI 10.1287/mnsc.42.10.1395
PD OCT 1996
PY 1996
AB Management of projects is complicated by the scarcity of resources
   required to execute them. Limited resources usually extend the project
   completion times beyond those determined by CPM/PERT. Several solution
   procedures have been developed for solving the resource constrained
   project scheduling problem. One objective commonly used for these
   problems is to complete the project as early as possible (minimize
   makespan). The problem considered in this paper is a resource
   constrained project scheduling problem, with the added features that
   there are cash flows associated with the project activities, and the
   objective is to schedule the project activities in such a way that the
   net present value of cash flows is maximized. With these features the
   problem becomes financially motivated and more realistic.
   We introduce a branch and bound procedure to solve the resource
   constrained project scheduling problem with discounted cash flows. Our
   procedure exploits the known fact that potential resource violations can
   be eliminated by introducing additional precedence relations between
   certain project activities. Specifically, we use the ''minimal delaying
   alternatives'' concept to resolve resource conflicts. The bounds in the
   branch and bound procedure are computed by solving Payment Scheduling
   Problems, which can be formulated as linear programs and by that are
   well-solvable.
   We test our procedure computationally on a set of 90 test problems from
   the literature and compare it with the only other exact procedure we
   know of.
ZB 1
TC 61
ZR 2
Z8 8
ZA 0
ZS 0
Z9 70
SN 0025-1909
UT WOS:A1996WM55900002
ER

PT J
AU Song, JS
   Zipkin, PH
TI Inventory control with information about supply conditions
SO MANAGEMENT SCIENCE
VL 42
IS 10
BP 1409
EP 1419
DI 10.1287/mnsc.42.10.1409
PD OCT 1996
PY 1996
AB This paper presents an inventory-control model which includes a
   Markovian model of the supply system. As that system evolves over time,
   so do the replenishment leadtimes. The optimal policy has the same
   structure as in standard models, but its parameters change dynamically
   to reflect current supply conditions. In this setting, contrary to
   conventional wisdom, a longer leadtime does not necessarily imply more
   inventory. The leadtime is important, but so is a concept we call order
   coverage.
Z8 2
ZR 0
ZA 0
TC 133
ZS 0
ZB 1
Z9 135
SN 0025-1909
UT WOS:A1996WM55900003
ER

PT J
AU Myung, IJ
   Ramamoorti, S
   Bailey, AD
TI Maximum entropy aggregation of expert predictions
SO MANAGEMENT SCIENCE
VL 42
IS 10
BP 1420
EP 1436
DI 10.1287/mnsc.42.10.1420
PD OCT 1996
PY 1996
AB This paper presents a maximum entropy framework for the aggregation of
   expert opinions where the expert opinions concern the prediction of the
   outcome of an uncertain event. The event to be predicted and individual
   predictions rendered are assumed to be discrete random variables. A
   measure of expert competence is defined using a distance metric between
   the actual outcome of the event and each expert's predicted outcome.
   Following Levy and Delic (1994), we use Shannon's information measure
   (Shannon 1948, Jaynes 1957) to derive aggregation rules for combining
   two or more expert predictions into a single aggregated prediction that
   appropriately calibrates different degrees of expert competence and
   reflects any dependence that may exist among the expert predictions. The
   resulting maximum entropy aggregated prediction is least prejudiced in
   the sense that it utilizes all information available but remains
   maximally noncommittal with regard to information not available.
   Numerical examples to illuminate the implications of maximum entropy
   aggregation are also presented.
CT 6th Behavioral Decision Research in Management Conference
CY MAY 20-22, 1994
CL MASSACHUSETTS INST TECHNOL, BOSTON, MA
HO MASSACHUSETTS INST TECHNOL
ZR 0
Z8 2
ZB 0
ZA 0
TC 22
ZS 0
Z9 24
SN 0025-1909
EI 1526-5501
UT WOS:A1996WM55900004
ER

PT J
AU Parsons, J
TI An information model based on classification theory
SO MANAGEMENT SCIENCE
VL 42
IS 10
BP 1437
EP 1453
DI 10.1287/mnsc.42.10.1437
PD OCT 1996
PY 1996
AB This paper develops a formal information structuring model based on the
   premise that an information system represents knowledge about things in
   an organization. Since humans organize knowledge about things via
   categories or classes, the model is motivated by a theory of
   classification. The theory suggests several critical elements of
   classification based on the importance of classifying things to human
   survival. These elements are reflected by constructs in the model.
   Formal implications of the model for systems development are derived and
   strategies proposed for empirically evaluating these implications with
   respect to current modeling approaches. Necessary conditions are
   identified for a collection of classes to be considered a ''good'' model
   of some domain. The conditions permit different users to classify the
   same objects in different ways, depending on need. This suggests a new
   approach to data or object modeling which emphasizes instances and
   properties, rather than fixed categories of data or schemas. The model
   also offers insights into the role of classification in object-oriented
   analysis and design methodologies. Finally, a program of research is
   outlined in which the model is being used to develop and experimentally
   evaluate an information modeling methodology, and as a source of
   implementation primitives for ''instance-based'' data modeling.
RI Parsons, Jeffrey/AAF-3380-2020
Z8 2
ZS 0
ZA 0
ZR 0
ZB 0
TC 36
Z9 38
SN 0025-1909
UT WOS:A1996WM55900005
ER

PT J
AU Raju, JS
   Srinivasan, V
TI Quota-based compensation plans for multiterritory heterogeneous
   salesforces
SO MANAGEMENT SCIENCE
VL 42
IS 10
BP 1454
EP 1462
DI 10.1287/mnsc.42.10.1454
PD OCT 1996
PY 1996
AB We compare quota-based salesforce compensation plans with the BLSS plan,
   i.e., the optimal curvilinear agency-theory-based compensation plans
   proposed in Basu, Lal, Srinivasan and Staelin (1985). A quota plan pays
   a fixed salary which is supplemented by commission income that is a
   prespecified fraction of the dollar sales that exceed the quota. For a
   salesforce comprised of multiple salespersons/territories, we consider a
   basic quota plan where the commission rate and salary remain the same
   across salespersons; however, quotas vary across
   salespersons/territories. Compared to the BLSS plan that is individually
   tailored to each salesperson/territory, the basic quota plan's total
   nonoptimality in profit has two components: (i) a shape-induced
   nonoptimality arising from the fact that the quota-based plan does not
   have the same optimal shape as the curvilinear BLSS plan, and (ii) a
   heterogeneity-induced nonoptimality arising from the fact that the
   salary and commission rate in the basic quota plan are constrained to be
   the same across the salesforce. Our numerical experiments indicate that
   the total nonoptimality is merely about 1% for the parametric scenarios
   studied. The basic quota plan is simpler to implement than the BLSS
   plan. Furthermore, changes in business conditions in a territory, or the
   transfer of a salesperson from one territory to another, can be
   accommodated by changing only the quota, without having to change the
   salary and the commission rate structure. Such advantages, together with
   our result that the nonoptimality is slight, suggest that quota-based
   plans offer considerable potential as a salesforce compensation scheme.
ZS 0
TC 82
Z8 4
ZA 0
ZB 0
ZR 0
Z9 85
SN 0025-1909
UT WOS:A1996WM55900006
ER

PT J
AU Dyer, D
   Kagel, JH
TI Bidding in common value auctions: How the commercial construction
   industry corrects for the winner's curse
SO MANAGEMENT SCIENCE
VL 42
IS 10
BP 1463
EP 1475
DI 10.1287/mnsc.42.10.1463
PD OCT 1996
PY 1996
AB Experienced construction industry executives suffer from a winner's
   curse in laboratory common value auction markets (Dyer et al. 1989).
   This paper identifies essential differences between field environments
   and the economic theory underlying the laboratory markets that account
   for the executives' success in the field and a winner's curse in the
   lab. These are (1) industry-specific mechanisms which enable contractors
   to escape the winner's curse even when they bid too low, (2) learned,
   industry-specific evaluative processes which enable experienced
   contractors to avoid the winner's curse in the first place, and (3)
   important private value elements that underlie bidding. Also identified
   are a number of industry-specific bidding characteristics whose
   evolution can be explained using modern auction theory. Lessons are
   drawn regarding the use of experimental methods in economics.
Z8 0
ZR 0
ZB 1
ZS 0
TC 60
ZA 0
Z9 60
SN 0025-1909
UT WOS:A1996WM55900007
ER

PT J
AU Peterson, MD
TI Two models for assessing a federal environmental health policy: The case
   of radon in US homes
SO MANAGEMENT SCIENCE
VL 42
IS 10
BP 1476
EP 1492
DI 10.1287/mnsc.42.10.1476
PD OCT 1996
PY 1996
AB The U.S. Environmental Protection Agency's (EPA's) strategy for reducing
   the public health risks of radon exposure depends largely on convincing
   the public to undertake testing and mitigation. In this context,
   important questions arise as to whether public response is likely to be
   high and thus whether changes in mortality are likely to be substantial.
   To explore these questions, we develop two models of the
   ''demographics'' of radon exposure in the United States. The first of
   these explores the sensitivity of projected mortality over the next 100
   years to important policy variables such as testing and mitigation
   rates. The second model takes the analysis down to the level of the
   individual and estimates the distribution of risk across the population
   and the costs and benefits of mitigation accruing to a person who may
   change residence several times during his or her life. Our results show
   that realistic policy scenarios lead to moderate changes in mortality
   and that the cost-benefit calculation of the individual is unlikely to
   lead to high levels of public response. The results support the idea of
   a more focused public policy.
ZR 0
Z8 0
TC 4
ZS 0
ZA 0
ZB 2
Z9 4
SN 0025-1909
UT WOS:A1996WM55900008
ER

PT J
AU Gugat, M
TI A fast algorithm for a class of generalized fractional programs
SO MANAGEMENT SCIENCE
VL 42
IS 10
BP 1493
EP 1499
DI 10.1287/mnsc.42.10.1493
PD OCT 1996
PY 1996
AB In many decision problems, criteria occur that can be expressed as
   ratios. The corresponding optimization problems are nonconvex programs
   of fractional type.
   In this paper, an algorithm for the numerical solution of these problems
   is introduced that converges always at superlinear speed. Numerical
   examples are presented.
RI Gugat, Martin/A-2093-2009; Gugat, Martin/I-3046-2019
OI Gugat, Martin/0000-0002-5281-110X
ZB 1
TC 16
ZA 0
ZR 0
ZS 0
Z8 0
Z9 16
SN 0025-1909
UT WOS:A1996WM55900009
ER

PT J
AU Chintagunta, PK
   Rao, VR
TI Pricing strategies in a dynamic duopoly: A differential game model
SO MANAGEMENT SCIENCE
VL 42
IS 11
BP 1501
EP 1514
DI 10.1287/mnsc.42.11.1501
PD NOV 1996
PY 1996
AB We formulate a differential game model for dynamic pricing in a
   duopolistic market. Firms' demand functions are derived from utility
   maximizing behavior of consumers with the demand for a brand given by
   the legit model. Preferences for brands are assumed to evolve over time
   in the market in a manner akin to learning models postulated in the
   marketing literature. We derive the differential equations governing the
   equilibrium open-loop price paths over time and show that in steady
   state, the brand with the higher preference level charges the higher
   price. The formulation is extended to include the effects of consumer
   heterogeneity, and equilibrium steady-state prices are compared with
   those obtained when heterogeneity is ignored. A comparison of
   steady-state dynamic prices with myopic prices is provided. An empirical
   example is discussed to show how steady-state model predictions may be
   obtained from actual longitudinal purchase data.
RI Chintagunta, Pradeep K/A-4764-2017; Chintagunta, Pradeep/
OI Chintagunta, Pradeep/0000-0003-2854-5216
ZA 0
Z8 4
TC 42
ZS 0
ZB 0
ZR 0
Z9 45
SN 0025-1909
UT WOS:A1996VY09700001
ER

PT J
AU Barron, FH
   Barrett, BE
TI Decision quality using ranked attribute weights
SO MANAGEMENT SCIENCE
VL 42
IS 11
BP 1515
EP 1523
DI 10.1287/mnsc.42.11.1515
PD NOV 1996
PY 1996
AB Three published approximation formulae for selecting the best
   multiattribute alternative based on rank-ordered weights are evaluated.
   All formulae are surprisingly efficacious in determining the best
   multiattribute alternative. Rank order centroid (ROC) weights are more
   accurate than the other rank-based formulae; furthermore, the ROC
   formula generalizes to incorporate both other forms of partial
   information about attribute weights and partial rank order information
   as well. Because a ROC-based analysis is so straightforward and
   efficacious, it provides an appropriate implementation tool.
ZS 5
ZR 1
Z8 18
ZA 0
ZB 16
TC 337
Z9 361
SN 0025-1909
UT WOS:A1996VY09700002
ER

PT J
AU Gollier, C
TI Repeated optional gambles and risk aversion
SO MANAGEMENT SCIENCE
VL 42
IS 11
BP 1524
EP 1530
DI 10.1287/mnsc.42.11.1524
PD NOV 1996
PY 1996
AB We analyze in this paper the effect of age on the optimal dynamic
   strategy toward repeated independent gambles. When deciding to accept or
   to reject a lottery that is offered today, the gambler knows how many
   lotteries can yet be played in the future. We first characterize the
   optimal dynamic strategy when future lotteries are identically
   distributed. We show that the existence of future lotteries always
   increases the willingness to gamble today. When the sequence of
   lotteries is independent but not identically distributed, we show that
   this does not need to be true. This analysis can be applied to the
   problem of investing in indivisible risky investment projects, or to the
   problem of dynamic optimal insurance demand.
RI Gollier, Christian/G-4476-2012
Z8 0
ZS 0
ZB 0
ZA 0
ZR 0
TC 9
Z9 9
SN 0025-1909
UT WOS:A1996VY09700003
ER

PT J
AU Tagaras, G
   Lee, HL
TI Economic models for vendor evaluation with quality cost analysis
SO MANAGEMENT SCIENCE
VL 42
IS 11
BP 1531
EP 1543
DI 10.1287/mnsc.42.11.1531
PD NOV 1996
PY 1996
AB Successful vendor-vendee relationship is viewed as an important
   ingredient for maintaining competitiveness in the current marketplace.
   This calls for a careful and comprehensive approach in selecting
   vendors. The cost of quality (or better phrased as the cost of
   ''unquality'') resulted from imperfections of a vendor's incoming input
   materials is one component of the total costs in the evaluation of
   vendors. The purpose of this paper is to show that looking at only one
   dimension of the quality cost is not sufficient and to highlight the
   importance of having a high quality internal process. We explore the
   relationship between the vendor's quality cost, the vendor's input
   quality, and the imperfections of the manufacturing process. We analyze
   the properties of the resulting quality cost model, and draw managerial
   implications in the selection of vendors.
ZA 0
ZR 0
ZS 2
TC 55
Z8 2
ZB 0
Z9 57
SN 0025-1909
UT WOS:A1996VY09700004
ER

PT J
AU Federgruen, A
   Mosheiov, G
TI Heuristics for multimachine scheduling problems with earliness and
   tardiness costs
SO MANAGEMENT SCIENCE
VL 42
IS 11
BP 1544
EP 1555
DI 10.1287/mnsc.42.11.1544
PD NOV 1996
PY 1996
AB We consider multimachine scheduling problems with earliness and
   tardiness costs. We first analyze problems in which the cost of a job is
   given by a general nondecreasing, convex function F of the absolute
   deviation of its completion time from a (common) unrestrictive due-date,
   and the objective is to minimize the sum of the costs incurred for all N
   jobs. (A special case to which considerable attention is given is the
   completion time variance problem.)
   We derive an easily computable lower bound for the minimum cost value
   and a simple ''Alternating Schedule'' heuristic, both of which are
   computable in O(N log N) time. Under mild technical conditions with
   respect to F, we show that the worst case optimality (accuracy) gap of
   the heuristic (lower bound) is bounded by a constant as well. as by a
   simple function of a single measure of the dispersion among the
   processing times. We also show that the heuristic (bound) is
   asymptotically optimal (accurate) and characterize the convergence rate
   as O(N-2) under very general conditions with respect to the function F.
   In addition, we report on a numerical study showing that the average gap
   is less than 1% even for problems with 30 jobs, and that it falls below
   0.1% for problems with 90 or more jobs. This study also establishes that
   the empirical gap is almost perfectly proportional with N-2, as verified
   by a regression analysis.
   Finally, we generalize the heuristic to settings with a possibly
   restrictive due date and general asymmetric, and possibly nonconvex,
   earliness and tardiness cost functions and demonstrate its excellent
   performance via a second numerical study.
ZB 0
TC 30
Z8 0
ZS 0
ZA 0
ZR 0
Z9 30
SN 0025-1909
UT WOS:A1996VY09700005
ER

PT J
AU Robinson, EP
   Gao, LL
TI A dual ascent procedure for multiproduct dynamic demand coordinated
   replenishment with backlogging
SO MANAGEMENT SCIENCE
VL 42
IS 11
BP 1556
EP 1564
DI 10.1287/mnsc.42.11.1556
PD NOV 1996
PY 1996
AB This paper describes a mixed-integer programming formulation and dual
   ascent based branch-and-bound algorithm for the multiproduct dynamic
   demand coordinated replenishment problem with backlogging. The single
   sourcing properties of the formulation and the hierarchical structure of
   the fixed-charge and continuous variables yield an extremely tight
   linear programming relaxation for the problem. A branch-and-bound
   algorithm based on Erlenkotter's dual ascent, dual adjustment, and
   primal construction concepts exploits these properties to obtain an
   efficient solution procedure. Computational results indicate that the
   new procedures find optimal solutions in less than five percent of the
   computational time of the most efficient previous algorithm. The
   heuristic performance of the procedures also demonstrate their
   superiority over existing approaches. We solved problems with 12 time
   periods and 20 products in 0.41 CPU seconds, and heuristic solutions
   with a worst-case three-percent optimality gap are found in 0.068 CPU
   seconds. The efficiency and large-scale capability of the procedures
   make their potential application in inventory requirements planning
   systems promising.
Z8 1
ZS 0
ZB 0
TC 24
ZA 0
ZR 0
Z9 25
SN 0025-1909
UT WOS:A1996VY09700006
ER

PT J
AU EbenChaime, M
TI Parametric solution for linear bicriteria knapsack models
SO MANAGEMENT SCIENCE
VL 42
IS 11
BP 1565
EP 1575
DI 10.1287/mnsc.42.11.1565
PD NOV 1996
PY 1996
AB Linear weighing is a common approach to handle multiple criteria and the
   ''knapsack'' is a well-known combinatorial optimization problem. A
   knapsack problem with two linearly weighted, objective criteria is
   considered in this paper For better support, it is important to provide
   the decision maker with information that covers the whole range of
   alternatives. Toward this goal, an algorithm for the construction of a
   parametric solution to the problem, i.e., for any combination of
   weights, is developed, which is based on finding a longest path in a
   network which compactly represents all feasible solutions to the
   knapsack problem. Exploiting the special structure of the knapsack
   model, the algorithm efficiently constructs the parametric solution in
   time that is linear in the product of the number of variables, the
   resource Limit (right-hand side of the constraint), and the (finite)
   number of vectors which constitute the solution. The amount of memory
   required is linear in the product of the number of variables and the
   resource Limit. Results of computational study are reported. The results
   are used to assess the efficiency of the algorithm and characterize its
   behavior with respect to the parameter values.
RI Eben-Chaime, Moshe/F-1871-2012
OI Eben-Chaime, Moshe/0000-0001-8759-0549
ZR 0
ZS 0
ZA 0
TC 19
Z8 0
ZB 0
Z9 19
SN 0025-1909
UT WOS:A1996VY09700007
ER

PT J
AU Safizadeh, MH
   Ritzman, LP
   Sharma, D
   Wood, C
TI An empirical analysis of the product-process matrix
SO MANAGEMENT SCIENCE
VL 42
IS 11
BP 1576
EP 1591
DI 10.1287/mnsc.42.11.1576
PD NOV 1996
PY 1996
AB Process choice, a major part of operations strategy, is a key decision
   that links operations to business strategy. Hayes and Wheelwright, among
   others, argue that the emphasis given to product customization and other
   competitive priorities should agree with process choice. Our empirical
   study investigates whether firms actually link their process choice to
   product customization and other competitive priorities as hypothesized,
   and whether compatible decision patterns lead to better performance.
   Analysis of data collected from managers at 144 U.S. manufacturing
   plants shows a strong correlation between process choice, product
   customization, and competitive priorities. Process choice is highly
   related with the degree of product customization, and also with the
   emphasis placed on the quality and cost competitive priorities. Job
   shops and batch shops tend to have more product customization, higher
   costs, and higher quality. Some continuous flow shops use part
   commonality and flexible automation to achieve more customization than
   would otherwise be expected. Without these initiatives, customization in
   continuous flow shops results in weak performance.
ZR 0
ZS 2
ZB 0
TC 176
Z8 1
ZA 1
Z9 180
SN 0025-1909
UT WOS:A1996VY09700008
ER

PT J
AU Moenaert, RK
   Souder, WE
TI Context and antecedents of information utility at the R&D/marketing
   interface
SO MANAGEMENT SCIENCE
VL 42
IS 11
BP 1592
EP 1610
DI 10.1287/mnsc.42.11.1592
PD NOV 1996
PY 1996
AB The objective of the present study was to develop a comprehensive
   empirically-based model of the communication interface between R&D and
   marketing. Following Moenaert and Souder (1990), a causal model of the
   antecedents of information utility at the R&D/marketing-interface was
   postulated. A non-experimental critical incident method was used to test
   the model. The field survey involved 386 team members of 80 new product
   innovation teams in 40 companies. Path analysis was used to test the
   causal model. Support for several aspects of the model were found.
   First, the relevance and the credibility of the message had strong
   effects on the perception of information utility. The comprehensibility
   of the message had a moderate effect on the perception of information
   utility, whereas novelty had a small effect. Second, the quality of the
   relationship, the seniority and the prior experience of the message
   source, and the type of communication channel used had significant
   effects on the perception of the message. The implications of the
   research results for managers and researchers are detailed.
CT Conference of the Dutch-Flemish-Academy-of-Management
CY JAN, 1993
CL AMSTERDAM, NETHERLANDS
ZB 1
Z8 3
ZR 0
TC 96
ZS 0
ZA 0
Z9 99
SN 0025-1909
UT WOS:A1996VY09700009
ER

PT J
AU Balakrishnan, A
   Francis, RL
   Grotzinger, SJ
TI Bottleneck resource allocation in manufacturing
SO MANAGEMENT SCIENCE
VL 42
IS 11
BP 1611
EP 1625
DI 10.1287/mnsc.42.11.1611
PD NOV 1996
PY 1996
AB Many resource-allocation problems in manufacturing and service
   operations require selecting integer-valued levels for various
   activities that consume ''nondecreasing amounts'' of limited resources.
   System productivity, to be maximized, is limited by the least productive
   (bottleneck) activity. We first review a basic bisection method that can
   solve this discrete, monotonic resource-allocation problem even with a
   nonlinear objective and constraints. We then generalize the basic
   algorithm to solve an enhanced version of the problem containing
   additional coupling constraints on the allocation decisions. This
   generalization applies to assembly-release planning (ARP) in a
   multiproduct assemble-to-forecast environment with part commonality. The
   ARP problem requires deciding the number of kits for each product to
   release for assembly in every time period, using the;available parts, to
   achieve if possible the target service levels for all products and time
   periods or minimize the maximum deviation of the actual service levels
   from the targets. We also consider extensions of the ARP model
   incorporating precedence constraints and part substitutability, and show
   how to modify the bisection method to solve these problems.
ZR 0
ZA 0
Z8 0
ZS 0
ZB 0
TC 10
Z9 10
SN 0025-1909
UT WOS:A1996VY09700010
ER

PT J
AU Brynjolfsson, E
   Kemerer, CF
TI Network externalities in microcomputer software: An econometric analysis
   of the spreadsheet market
SO MANAGEMENT SCIENCE
VL 42
IS 12
BP 1627
EP 1647
DI 10.1287/mnsc.42.12.1627
PD DEC 1996
PY 1996
AB Because of network externalities, the success of a software product may
   depend in part on stalled base and its conformance to industry
   standards. This research builds a hedonic model to determine the effects
   of network externalities, standards, intrinsic features and a time trend
   on microcomputer spreadsheet software prices. When data for a sample of
   products during the 1987-1992 time period were analyzed using this
   model, four main results emerged: 1) Network externalities, as measured
   by the size of a product's installed base, significantly increased the
   price of spreadsheet products: a one percent increase in a product's
   installed base was associated with a 0.75% increase in its price. 2)
   Products which adhered to the dominant standard, the Lotus menu tree
   interface, commanded prices which were higher by an average of 46%. 3)
   Although nominal prices increased slightly during this time period,
   quality-adjusted prices declined by an average of 16% per year. 4) The
   hedonic model was found to be a good predictor of actual market prices,
   despite the fact that it was originally estimated using list prices.
   Several variations of the model were examined, and, while the
   qualitative findings were robust, the precise estimates of the
   coefficients varied somewhat depending on the sample of products
   examined, the weighting of the observations and the functional form used
   in estimation, suggesting that the use of hedonic methods in this domain
   is subject to a number of limitations due, inter alia, to the potential
   for strategic pricing by vendors.
RI Brynjolfsson, Erik/H-2412-2012
ZB 0
TC 311
Z8 5
ZA 0
ZR 5
ZS 1
Z9 319
SN 0025-1909
UT WOS:A1996WA59100001
ER

PT J
AU Baligh, HH
   Burton, RM
   Obel, B
TI Organizational consultant: Creating a usable theory for organizational
   design
SO MANAGEMENT SCIENCE
VL 42
IS 12
BP 1648
EP 1662
DI 10.1287/mnsc.42.12.1648
PD DEC 1996
PY 1996
AB Organization theory is a positive science; organizational design is a
   normative science ''concerned with how things ought to be, with devising
   structures to attain goals.'' The Organizational Consultant is a
   knowledge base expert system to help design organizations. That is, it
   takes facts about the environment, size, strategy, technology,
   ownership, and management preferences and applies the knowledge base to
   recommend the design structure and properties such as complexity,
   formalization, centralization, and span of control, among others.
   Organization theory is comprised of numerous positive contingency
   theories, which are not integrated. The main issue is to create a
   comprehensive and consistent knowledge base from what we know, i.e.,
   create a useful synthesis. We utilize four fit criteria as a guide:
   contingency fit, design parameter fit, situation fit, and total
   parameter fit. Contingency fit demands that the knowledge base of
   ''if-then'' rules follow what we know from the literature. Design
   parameter fit requires a balance, or weighting, among the supporting and
   opposing design recommendations. Situation fit assures us that the
   situation itself is not inconsistent. Finally, total design fit requires
   that it is useable and helpful to recommend structure and properties to
   attain goals.
   The development of the Organizational Consultant is a continuing
   validation exercise. The size of an organization is an important design
   contingency. Yet, an operational definition of size for design purposes
   has been wanting. We discuss how a useful definition of size was
   developed for the Organizational Consultant.
   We describe the development of the Organizational Consultant--a
   knowledge-based expert system that utilizes a synthesis of the elements
   of organizational contingency theory through a validation process. The
   four fit criteria were applied to guide the development process.
OI Obel, Borge/0000-0003-1283-5489
ZA 0
TC 34
ZB 0
ZS 0
ZR 0
Z8 0
Z9 34
SN 0025-1909
UT WOS:A1996WA59100002
ER

PT J
AU OLeary, DE
TI Verification of uncertain knowledge-based systems: An empirical
   verification approach
SO MANAGEMENT SCIENCE
VL 42
IS 12
BP 1663
EP 1675
DI 10.1287/mnsc.42.12.1663
PD DEC 1996
PY 1996
AB A number of different tests and approaches are developed to determine
   the existence of potential anomalies in rule-based systems that employ
   MYCIN uncertainty factors (weights). First, the distribution of weights
   is compared to other systems' distributions and weights are investigated
   as to their individual meanings, to determine whether any weights are
   unusual. Second, there is increasing evidence that people are not
   ''good'' at developing weights on rules, building in symmetries and
   redundancies that signal ''usual'' assumptions about the underlying
   probabilities. Accordingly, weight symmetries generated from rule pairs
   are analyzed to determine the existence of anomalies. Third, typically
   rule-based tools have been developed for application in specific
   domains, such as medicine. Unique aspects of those domains may limit
   application of the tools to other domains. Finally, ad hoc, rule-based
   approaches are suboptimal, and alternative formal probability
   approaches, such as Bayes' nets, more fully specify the probabilistic
   nature of knowledge.
   The paper is part of the empirical verification literature, where
   verification is done on an actual system and the system provides data
   that indicates the kinds of anomalies that can be expected. A case study
   is used to illustrate each of the verification tests and concerns.
RI O'Leary, Daniel E/B-6469-2008
TC 3
Z8 0
ZR 0
ZB 0
ZS 1
ZA 0
Z9 3
SN 0025-1909
UT WOS:A1996WA59100003
ER

PT J
AU Wu, G
   Gonzalez, R
TI Curvature of the probability weighting function
SO MANAGEMENT SCIENCE
VL 42
IS 12
BP 1676
EP 1690
DI 10.1287/mnsc.42.12.1676
PD DEC 1996
PY 1996
AB When individuals choose among risky alternatives, the psychological
   weight attached to an outcome may not correspond to the probability of
   that outcome. In rank-dependent utility theories, including prospect
   theory, the probability weighting function permits probabilities to be
   weighted nonlinearly. Previous empirical studies of the weighting
   function have suggested an inverse S-shaped function, first concave and
   then convex. However, these studies suffer from a methodological
   shortcoming: estimation procedures have required assumptions about the
   functional form of the value and/or weighting functions. We propose two
   preference conditions that are necessary and sufficient for concavity
   and convexity of the weighting function. Empirical tests of these
   conditions are independent of the form of the value function. We test
   these conditions using preference ''ladders'' (a series of questions
   that differ only by a common consequence). The concavity-convexity
   ladders validate previous findings of an S-shaped weighting function,
   concave up to p < 0.40, and convex beyond that probability. The tests
   also show significant nonlinearity away from the boundaries, 0 and 1.
   Finally, we fit the ladder data with weighting functions proposed by
   Tversky and Kahneman (1992) and Prelec (1995).
RI Wu, George/B-2820-2008; Gonzalez, Richard/B-6449-2008
OI Gonzalez, Richard/0000-0001-6334-0430
ZA 0
TC 456
ZB 31
Z8 22
ZR 0
ZS 1
Z9 477
SN 0025-1909
UT WOS:A1996WA59100004
ER

PT J
AU Jia, JM
   Dyer, JS
TI A standard measure of risk and risk-value models
SO MANAGEMENT SCIENCE
VL 42
IS 12
BP 1691
EP 1705
DI 10.1287/mnsc.42.12.1691
PD DEC 1996
PY 1996
AB In this paper we propose a standard measure of risk that is based on the
   converted expected utility of normalized lotteries with zero-expected
   values. This measure of risk has many desirable properties that
   characterize the notion of risk. It is very general and includes many
   previously proposed measures of risk as special cases. Moreover, our
   standard measure of risk provides a preference-based and unified method
   for risk studies. Since the standard measure of risk is compatible with
   the measure of expected utility, it can be used explicitly or implicitly
   in an expected utility model. Under a condition called risk
   independence, a decision could be made by explicitly trading off between
   risk and value, which offers an alternative representation of the
   expected utility model, named the standard risk-value model. Finally, we
   discuss some other applications of the standard measure of risk and
   extensions of our risk-value tradeoff framework for descriptive decision
   making.
CT ORSA/TIMS Joint National Meeting
CY NOV, 1993
CL PHOENIX, AZ
SP ORSA; TIMS
TC 63
ZA 0
ZR 0
ZB 0
ZS 0
Z8 19
Z9 81
SN 0025-1909
UT WOS:A1996WA59100005
ER

PT J
AU Papastavrou, JD
   Rajagopalan, S
   Kleywegt, AJ
TI The dynamic and stochastic knapsack problem with deadlines
SO MANAGEMENT SCIENCE
VL 42
IS 12
BP 1706
EP 1718
DI 10.1287/mnsc.42.12.1706
PD DEC 1996
PY 1996
AB In this paper a dynamic and stochastic model of the well-known knapsack
   problem is motivated by a wide variety of real-world applications.
   Objects of random weight and reward arrive according to a stochastic
   process in time. The weights and rewards associated with the objects are
   distributed according to a known probability distribution. Each object
   can either be accepted to be loaded into the knapsack, of known weight
   capacity, or be rejected. The objective is to determine the optimal
   policy for loading the knapsack within a fixed time horizon so as to
   maximize the expected accumulated reward. The optimal decision rules are
   derived and are shown to exhibit surprising behavior in some cases. it
   is also shown that if the distribution of the weights is concave, then
   the decision rules behave according to intuition.
ZB 0
Z8 1
ZS 0
ZR 0
ZA 0
TC 79
Z9 80
SN 0025-1909
UT WOS:A1996WA59100006
ER

PT J
AU Andersen, ED
   Ye, YY
TI Combining interior-point and pivoting algorithms for linear programming
SO MANAGEMENT SCIENCE
VL 42
IS 12
BP 1719
EP 1731
DI 10.1287/mnsc.42.12.1719
PD DEC 1996
PY 1996
AB We propose a new approach to combine linear programming (LP)
   interior-point and simplex pivoting algorithms. In any iteration of an
   interior-point algorithm we construct a related LP problem, which
   approximates the original problem, with a known (strictly) complementary
   primal-dual solution pair. Thus, we can apply Megiddo's (1991) pivoting
   procedure to compute an optimal basis for the approximate problem in
   strongly polynomial time. We show that, if the approximate problem is
   constructed from an interior-point iterate sufficiently close to the
   optimal face, then any optimal basis of the approximate problem is an
   optimal basis for the original problem. If the LP data are rational, the
   total number of interior-point iterations to create such a sufficient
   approximate problem is bounded by a polynomial in the data size. We
   develop a modification of Megiddo's procedure and discuss several
   implementation issues in solving the approximate problem. We also report
   encouraging computational results for this combined approach.
OI Andersen, Erling Dalgaard/0000-0001-6351-8761
TC 17
ZA 0
ZR 0
Z8 0
ZS 1
ZB 0
Z9 17
SN 0025-1909
UT WOS:A1996WA59100007
ER

PT J
AU Tzur, M
TI Learning in setups: Analysis, minimal forecast horizons, and algorithms
SO MANAGEMENT SCIENCE
VL 42
IS 12
BP 1732
EP 1743
DI 10.1287/mnsc.42.12.1732
PD DEC 1996
PY 1996
AB We analyze the dynamic lot-sizing model in which the cost of a setup
   depends on the number of setups that have occurred prior to it. This
   arises, for example, when there exist learning effects in setups. Our
   model is more general than most learning models in the literature since
   it allows the total setup cost to be a general nondecreasing (but not
   necessarily concave) function of the number of setups.
   We explore tight relationships between our model and special cases of
   the classical dynamic lot-sizing model. On the basis of these we find
   minimal forecast and planning horizons for our model, which determine
   the first decision when the model is solved on a rolling horizon basis.
   When a forecast horizon cannot be found, we provide guidelines regarding
   the optimal first decision. We also provide an algorithm to solve the
   finite horizon problem, which uses as subproblems variations of the
   classical dynamic lot-sizing problem. The advantage of this approach is
   the ability to use the extensive literature available on the latter, to
   generalize the results of this paper. As many of our results are
   qualitative in nature, they provide insights which can be useful for
   other models with a similar setup cost behavior.
RI Tzur, Michal/L-1474-2019
TC 9
ZS 0
ZA 0
ZR 0
Z8 0
ZB 0
Z9 9
SN 0025-1909
UT WOS:A1996WA59100008
ER

PT J
AU Johnson, ME
   Jackman, J
TI Interval coverage in multiclass queues using batch mean estimates
SO MANAGEMENT SCIENCE
VL 42
IS 12
BP 1744
EP 1752
DI 10.1287/mnsc.42.12.1744
PD DEC 1996
PY 1996
AB We investigate the fixed, sample-size, batch-mean procedure for creating
   confidence intervals from simulated data obtained from a stochastic
   queueing system with multiple customer classes. We show that, for a
   multiclass M/M/1 queue, serial correlation between customers of the same
   class decreases to zero as the number of customer classes increases. We
   also derive a closed-form expression for the asymptotic variance of
   waiting time by customer type. We then empirically examine batch-mean
   estimator coverage for a simple queue with multiple customer classes. We
   find that batch-mean estimators perform better in terms of coverage and
   interval half width in multiclass queues, with a fixed number of
   observations per class, than in the traditionally studied single-class
   systems. We also examine the effect of multiple classes where the total
   computational effort remains fixed.
ZA 0
ZS 0
Z8 0
TC 1
ZR 0
ZB 0
Z9 1
SN 0025-1909
UT WOS:A1996WA59100009
ER

PT J
AU Cohen, MA
   Eliashberg, J
   Ho, TH
TI New product development: The performance and time-to-market tradeoff
   (vol 42, pg 174, 1996)
SO MANAGEMENT SCIENCE
VL 42
IS 12
BP 1753
EP 1755
PD DEC 1996
PY 1996
RI Ho, Teck-Hua/D-1630-2013
OI Ho, Teck-Hua/0000-0001-5210-4977
ZB 0
Z8 0
ZA 0
ZR 0
ZS 0
TC 5
Z9 5
SN 0025-1909
UT WOS:A1996WA59100010
ER

PT J
AU Browne, GJ
   Curley, SP
   Benson, PG
TI Evoking information in probability assessment: Knowledge maps and
   reasoning-based directed questions
SO MANAGEMENT SCIENCE
VL 43
IS 1
BP 1
EP 14
DI 10.1287/mnsc.43.1.1
PD JAN 1997
PY 1997
AB To assess probabilities in decision analysis, and for decision making in
   general, decision variety of structuring tools to aid decision makers in
   these tasks, including influence diagrams and knowledge maps. However,
   despite their pervasive use in practice, there have been no reported
   empirical tests of these tools. One goal of the present research was to
   provide an empirical test of the evocative knowledge map methodology.
   Second, a theoretical analysis of probability assessment was used to
   develop a new prescriptive elicitation technique. This technique uses a
   theoretically-grounded set of directed questions to help decision makers
   evoke information for probability assessment. Experimental results
   showed that both the knowledge map and the new directed questions
   methodology elicited a higher quantity and quality of information from
   decision makers engaged in probability assessment tasks than did a
   control condition. Further, the information elicited by the two
   techniques was qualitatively different, suggesting that the two methods
   might profitably be used as complementary elicitation techniques.
ZA 0
ZS 0
Z8 0
ZB 13
TC 47
ZR 0
Z9 48
SN 0025-1909
UT WOS:A1997WG42100001
ER

PT J
AU Fishburn, PC
   Sarin, RK
TI Fairness and social risk .2. Aggregated analyses
SO MANAGEMENT SCIENCE
VL 43
IS 1
BP 15
EP 26
DI 10.1287/mnsc.43.1.15
PD JAN 1997
PY 1997
AB This paper is the second of a two-paper study of fairness issues for
   decisions that affect the benefits received and the risks encountered by
   a population. The study examines fairness for individuals and for
   homogeneous groups within the population. It considers fairness both for
   population benefit-risk profiles and for probability distributions over
   profiles.
   Our study bases fairness on notions of envy among individuals and
   groups. The first paper focused on fairness in profiles and profile
   distributions when benefits and risks are not aggregated. The present
   paper uses individual preferences to assess fairness when benefits and
   risks are aggregated within groups or over the population. It
   concentrates on intergroup envy measures and fairness indices that
   account for ways that aggregated benefits and risks might be allocated
   to members of groups or to groups within the population.
TC 6
ZB 0
ZS 0
ZA 0
Z8 0
ZR 0
Z9 6
SN 0025-1909
UT WOS:A1997WG42100002
ER

PT J
AU Karmarkar, US
   Pitbladdo, RC
TI Quality, class, and competition
SO MANAGEMENT SCIENCE
VL 43
IS 1
BP 27
EP 39
DI 10.1287/mnsc.43.1.27
PD JAN 1997
PY 1997
AB This paper integrates the process oriented view of quality in
   manufacturing with the multiattribute product positioning and customer
   preference models of marketing, within the context of traditional
   economic models of markets and competition. In manufacturing
   applications, ''quality'' is often defined as conformance to
   specifications or as meeting standards on the performance of the
   product. In the marketing and economics literature, ''quality''
   typically refers to the performance level or ''class'' of the product.
   To capture both perspectives, a product is described by a vector of
   performance attributes, and the population of produced units is assumed
   to display a distribution on these attributes. The distribution
   perceived by customers may differ from the actual. The attribute levels
   (means) may be taken to define the class, or performance of the product.
   Quality in the sense of conformance is then conceptually identified with
   the absence of variation of the population. Consumer preferences are
   modelled by a cardinal utility function defined on the vector of
   attributes and price, and customers maximize expected utility. Product
   manufacturers are assumed to face a cost of producing a given population
   distribution. Under specific assumptions regarding costs and utility
   functions, models of monopoly, oligopoly and perfect competition are
   formulated. The model clarifies the distinction between product class
   (performance) and conformance quality, identifies the sources of quality
   improvement, and provides an economic framework relating issues like
   product positioning, process improvement, quality function deployment
   (QFD) and customer preference estimation. This framework is used to
   address issues such as quality costs and benefits and the economics of
   investments in quality.
Z8 2
ZS 0
ZR 0
ZA 1
ZB 0
TC 45
Z9 48
SN 0025-1909
UT WOS:A1997WG42100003
ER

PT J
AU Lee, HL
   Tang, CS
TI Modelling the costs and benefits of delayed product differentiation
SO MANAGEMENT SCIENCE
VL 43
IS 1
BP 40
EP 53
DI 10.1287/mnsc.43.1.40
PD JAN 1997
PY 1997
AB Expanding product variety and high customer service provision are both
   major challenges for manufacturers to compete in the global market. in
   addition to many ongoing programs, such as lead-time reduction,
   redesigning products and processes so as to delay the point of product
   differentiation is becoming an emerging means to address these
   challenges. Such a strategy calls for redesigning products and processes
   so that the stages of the production process in which a common process
   is used are prolonged. This product/process redesign will defer the
   point of differentiation (i.e., defer the stage after which the products
   assume their unique identities). In this paper, we develop a simple
   model that captures the costs and benefits associated with this redesign
   strategy. We apply this simple model to analyze some special cases that
   are motivated by real examples. These special cases enable us to
   formalize three different product/process redesign approaches
   (standardization, modular design, and process restructuring) for
   delaying product differentiation that some companies are beginning to
   pursue. Finally, we analyze some special theoretical cases that enable
   us to characterize the optimal point of product differentiation and
   derive managerial insights.
OI tang, christopher/0000-0001-9597-7620
ZR 0
TC 370
ZA 1
ZB 2
ZS 1
Z8 16
Z9 388
SN 0025-1909
UT WOS:A1997WG42100004
ER

PT J
AU Fruchter, GE
   Kalish, S
TI Closed-loop advertising strategies in a duopoly
SO MANAGEMENT SCIENCE
VL 43
IS 1
BP 54
EP 63
DI 10.1287/mnsc.43.1.54
PD JAN 1997
PY 1997
AB Using the Lanchester model to describe the dynamics of the market where
   two firms compete fur customers by advertising, we solve the problem of
   determining an optimal advertising strategy for maximum discounted
   profits. We develop both open- and closed-loop strategies and explain
   the relationship between them. Using a new mathematical approach, we
   prove that our closed-loop solution is a global Nash equilibrium. The
   closed-loop strategy is time-variant and depends linearly on the actual
   market share. The time-variant coefficient incorporates the discount
   factor; its computation requires the solution of a backward differential
   equation and a set of two nonlinear differential equations for an
   initial value problem. The closed-loop advertising expenditures are
   proportional to the open-loop advertising expenditures and to the square
   of the competitor's actual market share. This provides a very practical
   adaptive control rule that allows the manager to adjust the actual
   advertising expenditure and tit deviate from budget. We illustrate the
   use of our control rule, using data fur the period 1968-1984 of the Cola
   War. Marketing implications of the results are provided.
TC 67
Z8 14
ZR 0
ZB 0
ZA 0
ZS 0
Z9 81
SN 0025-1909
UT WOS:A1997WG42100005
ER

PT J
AU Bitran, GR
   Mondschein, SV
TI Periodic pricing of seasonal products in retailing
SO MANAGEMENT SCIENCE
VL 43
IS 1
BP 64
EP 79
DI 10.1287/mnsc.43.1.64
PD JAN 1997
PY 1997
AB This paper studies intertemporal pricing policies when selling seasonal
   products in retail stores. We first present a continuous time model
   where a seller laces a stochastic arrival of customers with different
   valuations of the product. For this model, we characterize the optimal
   pricing policies as functions of time and inventory. We use this model
   as a benchmark against which we compare more realistic models that
   consider periodic pricing reviews. We show that the structure of the
   optimal pricing policies in this case is consistent with the procedures
   observed in practice; retail stores successively discount the product
   during the season and promote a liquidation sale at the end of the
   planning horizon. We also show that the loss experienced when
   implementing periodic pricing reviews instead of continuous policies is
   small when the appropriate number of reviews is chosen. Several
   interesting economic insights emerge from our analysis. For example,
   uncertainty in the demand for new products leads to higher prices,
   larger discounts, and more unsold inventory. Finally, we study the
   effect of announced discount policies on prices and profits. We show
   that stores that have adopted this type of strategy usually set prices
   such that with high probability the merchandise is sold during the first
   periods and the largest discounts rarely take place.
RI Mondschein, Susana/AAO-5816-2020
ZA 0
ZS 0
TC 195
ZB 0
Z8 7
ZR 0
Z9 202
SN 0025-1909
UT WOS:A1997WG42100006
ER

PT J
AU Green, LV
   Kolesar, PJ
TI The lagged PSA for estimating peak congestion in multiserver Markovian
   queues with periodic arrival rates
SO MANAGEMENT SCIENCE
VL 43
IS 1
BP 80
EP 87
DI 10.1287/mnsc.43.1.80
PD JAN 1997
PY 1997
AB We propose using a modification of the simple peak hour approximation
   (SPHA) for estimating peak congestion in multiserver queueing systems
   with exponential service times and time-varying periodic Poisson
   arrivals. This lagged pointwise stationary approximation (lagged PSA) is
   obtained by first estimating the time of the actual peak congestion by
   the time of peak congestion in an infinite server model and then
   substituting the arrival rate at this time in the corresponding
   stationary finite server model. We show that the lagged PSA is always
   more accurate than the SPHA and results in dramatically smaller errors
   when average service times are greater than a half an hour (based on a
   24 hour period). More importantly, the lagged PSA reliably identifies
   proper staffing levels to meet targeted performance levels to keep
   congestion low.
ZS 0
ZR 0
ZA 0
ZB 0
TC 22
Z8 0
Z9 22
SN 0025-1909
UT WOS:A1997WG42100007
ER

PT J
AU Meyer, MH
   Tertzakian, P
   Utterback, JM
TI Metrics for managing research and development in the context of the
   product family
SO MANAGEMENT SCIENCE
VL 43
IS 1
BP 88
EP 111
DI 10.1287/mnsc.43.1.88
PD JAN 1997
PY 1997
AB The paper proposes methods to measure the performance of research and
   development in new product development. We frame these measures in the
   context of evolving product families in the technology-based firm. Our
   goal is to more clearly understand the dynamics of platform renewal and
   derivative product generation and their consequences fur long-term
   success.
   We explore the utility of the proposed methods with data gathered from a
   large measurement systems manufacturer. We find that the methods and
   measures can help management assess the technological and market
   leverage achieved from the firm's present and past product platforms.
   This provides a foundation for transforming single-product,
   single-period planning processes into a multi-product, multi-period form
   that embraces the product family and the renewal of product
   architecture. The research also shows the need to integrate data from
   engineering, manufacturing, and sales organizations to produce
   information for managing the growth of the firm's product families.
TC 156
ZS 2
ZA 1
ZR 0
ZB 1
Z8 4
Z9 163
SN 0025-1909
UT WOS:A1997WG42100008
ER

PT J
AU Wohl, A
TI The feasibility of an index-contingent trading mechanism
SO MANAGEMENT SCIENCE
VL 43
IS 1
BP 112
EP 121
DI 10.1287/mnsc.43.1.112
PD JAN 1997
PY 1997
AB ''Auction'' or ''call'' trading systems are used in many stock
   exchanges. An essential problem in the application of these systems is
   that orders in one security cannot be conditioned on prices of other
   securities. This payer proposes and analyzes the feasibility of an
   index-contingent trading system. in this system, limit orders may be
   conditioned on an index (any weighted average of the security prices
   that is determined simultaneously with the prices) in addition to the
   asset price. Without any assumptions about traders' behavior it is shown
   that under a reasonable restriction on the structure of the limit
   orders, there is a unique solution (vector of prices) to any set of
   orders in all securities. Moreover, the paper presents a quick and
   simple algorithm that converges to the solution. This algorithm is based
   on an extension of the current mechanisms; therefore it can be
   implemented easily in any computerized auction system.
ZS 0
ZB 0
ZA 0
TC 5
Z8 1
ZR 0
Z9 6
SN 0025-1909
UT WOS:A1997WG42100009
ER

PT J
AU Bruggemann, W
   Jahnke, H
TI Remarks on: ''Some extensions of the discrete lotsizing and scheduling
   problem''
SO MANAGEMENT SCIENCE
VL 43
IS 1
BP 122
EP 122
DI 10.1287/mnsc.43.1.122
PD JAN 1997
PY 1997
ZB 0
ZA 0
ZS 0
ZR 0
TC 6
Z8 0
Z9 6
SN 0025-1909
UT WOS:A1997WG42100010
ER

PT J
AU Weber, EU
   Milliman, RA
TI Perceived risk attitudes: Relating risk perception to risky choice
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 123
EP 144
DI 10.1287/mnsc.43.2.123
PD FEB 1997
PY 1997
AB This paper provides empirical evidence that distinguishes between
   alternative conceptualizations of the risky decision making process. Two
   studies investigate whether cross-situational differences in choice
   behavior should be interpreted in the expected utility framework as
   differences in risk attitude (as measured by risk-averse vs.
   risk-seeking utility functions) or as differences in the perception of
   the relative riskiness of choice alternatives as permitted by
   risk-return interpretations of utility functions, leaving open the
   possibility of stable cross-situational risk preference as a personality
   trait. To this end, we propose a way of assessing a person's inherent
   risk preference that factors out individual and situational differences
   in risk perception. We document that a definition of risk aversion and
   risk seeking as the preference for options perceived to be more risky or
   less risky, respectively, provides the cross-situational stability to a
   person's risk preference that has eluded more traditional definitions.
   In Experiment 1, commuters changed their preferences for trains with
   risky arrival times when the alternatives involved gains in commuting
   time rather than losses. However, changes in preference coincided with
   changes in the perception of the riskiness of the choice alternatives,
   leaving the perceived risk attitudes of a majority of commuters
   unchanged. Experiment 2, a stockmarket investment task, investigated
   changes in risk perception, information acquisition, and stock selection
   as a function of outcome feedback. Investors' stock selections and their
   perception of the risk of the same stocks were different in a series of
   decisions in which they lost money than in a series in which they made
   money. As in Experiment 1, differences in choice and in risk perception
   were systematically related, such that the majority of investors had the
   same preference for perceived risk in both series of decisions. Our
   results provide empirical support for the usefulness of recent
   risk-return conceptualizations of risky choice (Bell 1995, Jia and Dyer
   1994, M. Weber and Sarin 1993).
ZA 0
ZB 26
Z8 6
ZS 3
ZR 0
TC 300
Z9 309
SN 0025-1909
UT WOS:A1997WM79600001
ER

PT J
AU Du, YF
   Hall, R
TI Fleet sizing and empty equipment redistribution for center-terminal
   transportation networks
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 145
EP 157
DI 10.1287/mnsc.43.2.145
PD FEB 1997
PY 1997
AB Fleet sizing and empty equipment redistribution are important issues in
   managing transportation systems. Most of the mathematical models that
   have been developed for these problems are complex and computationally
   demanding, including dynamic linear programming and stochastic/dynamic
   mathematical programs. Our research takes an alternate approach by
   building from inventory theory and developing decentralized stock
   control policies for empty equipment. This approach is applied to
   hub-and-spoke networks (i.e., center-terminal networks), by first
   analytically modeling the stochastic processes representing various
   stock-control variables, and then comparing the analytical results to
   monte-carlo simulations. A decomposition approach is also developed to
   determine stock-out probabilities as a function of the fleet size as a
   whole, and as a function of localized control parameters.
RI Hall, Randolph/AAS-8616-2020
OI Hall, Randolph/0000-0001-7060-1272
ZB 0
ZS 1
ZA 0
TC 92
ZR 0
Z8 2
Z9 94
SN 0025-1909
UT WOS:A1997WM79600002
ER

PT J
AU Berman, O
   Larson, RC
   Pinker, E
TI Scheduling workforce and workflow in a high volume factory
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 158
EP 172
DI 10.1287/mnsc.43.2.158
PD FEB 1997
PY 1997
AB We define a high volume factory to be a connected network of
   workstations, at which assigned workers process work-in-progress that
   flows at high rates through the workstations. A high rate usually
   implies that each worker processes many pieces per hour, enough so that
   work can be described as a deterministic hourly flow rate rather than,
   say, a stochastic number of discrete entities. Examples include mail
   processing and sorting, check processing, telephoned order processing,
   and inspecting and packaging of certain foods. Exogenous work may enter
   the factory at any workstation according to any time-of-day profile.
   Work-in-progress flows through the factory in discrete time according to
   Markovian routings. Workers, who in general are cross-trained, may work
   part time or full time shifts, may start work only at designated shift
   starting times, and may change job assignments at mid shift. In order to
   smooth the flow of work-in-progress through the service factory,
   work-in-progress may be temporarily inventoried (in buffers) at work
   stations. The objective is to schedule the workers (and correspondingly,
   the workflow) in a manner that minimizes labor costs subject to a
   variety of service-level, contractual and physical constraints.
   Motivated in part by analysis techniques of discrete time linear
   time-invariant (LTI) systems, an object-oriented linear programming
   (OOLP) model is developed. Using exogenous input work profiles typical
   of large U.S. mail processing facilities, illustrative computational
   results are included.
RI Pinker, Edieal/A-9253-2008
TC 40
Z8 1
ZS 0
ZR 0
ZA 0
ZB 0
Z9 41
SN 0025-1909
UT WOS:A1997WM79600003
ER

PT J
AU Archibald, TW
   Sassen, SAE
   Thomas, LC
TI An optimal policy for a two depot inventory problem with stock transfer
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 173
EP 183
DI 10.1287/mnsc.43.2.173
PD FEB 1997
PY 1997
AB Multiple depot inventory systems with stock transfer are used by many
   companies especially when demand is high relative to storage capacity.
   The key issues in such systems are how many of each item to hold at each
   depot and what to do if there is a demand for an item at a depot that
   has none of that item in stock. This study was motivated by the
   inventory problem faced by a UK car part retailer that groups its depots
   into pairs. The company's policy for dealing with a demand at a depot
   that cannot be satisfied from local stock is to either transfer the item
   from the other depot in the group or to place an emergency order. The
   object of this paper is to characterise an optimal policy for this
   problem and to propose a method of calculating the parameters of such a
   policy.
RI Thomas, Lyn/B-3326-2014; Archibald, Thomas/
OI Thomas, Lyn/0000-0002-3727-4772; Archibald, Thomas/0000-0002-3132-7909
ZR 0
ZA 0
TC 95
Z8 2
ZB 0
ZS 0
Z9 97
SN 0025-1909
UT WOS:A1997WM79600004
ER

PT J
AU Henig, M
   Gerchak, Y
   Ernst, R
   Pyke, DF
TI An inventory model embedded in designing a supply contract
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 184
EP 189
DI 10.1287/mnsc.43.2.184
PD FEB 1997
PY 1997
AB To reduce lead-time and its variability, modern supply and
   transportation contracts often specify the frequency of, and volume
   available for, future deliveries in advance even when final demand is
   somewhat uncertain (Yano and Gerchak 1989). We explore the joint
   optimization of contract parameters and inventory control policy in such
   environments. We first. model and derive the optimal periodic review
   inventory policy corresponding to a given supply contract, which
   generates piecewise-linear convex ordering costs. The optimal policy has
   two critical levels, and there is a range of stock levels for which the
   quantity ordered equals the contract volume. To numerically compute the
   critical levels, we model consecutive inventory levels as a Markov
   Chain, whose steady-state distribution is used to compute the holding,
   shortage and transportation costs. We then use the resulting total costs
   to derive the optimal contract volume. Various examples are provided.
   The optimal contracted delivery frequency can also be computed.
Z8 1
TC 60
ZS 0
ZA 0
ZR 0
ZB 0
Z9 61
SN 0025-1909
UT WOS:A1997WM79600005
ER

PT J
AU DeWolf, D
   Smeers, Y
TI A stochastic version of a Stackelberg-Nash-Cournot equilibrium model
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 190
EP 197
DI 10.1287/mnsc.43.2.190
PD FEB 1997
PY 1997
AB We consider a stochastic version of the Stackelberg-Nash-Cournot model
   proposed by Murphy et al. (1983). Ln the first stage, the leader chooses
   and announces his production level taking into account the reaction of
   the followers. The decision of the leader is taken when market demand is
   uncertain. In the second stage, the followers, knowing the leader's
   output, react to this level according to the Cournot assumption. At this
   stage, demand is known. We study the extension of the Murphy et al.
   model and give a numerical illustration of this model using the European
   gas market.
ZB 0
ZS 0
ZR 0
ZA 0
Z8 1
TC 61
Z9 61
SN 0025-1909
UT WOS:A1997WM79600006
ER

PT J
AU Paroush, J
   Prisman, EZ
TI On the relative importance of duration constraints
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 198
EP 205
DI 10.1287/mnsc.43.2.198
PD FEB 1997
PY 1997
AB This paper uncovers an implicit assumption, and its implications, made
   in the process of maximizing yield (or minimizing costs) subject to the
   duration constraints. Using linear programming results, it is shown that
   this technique is sensible only if the yield of a bond is a linear
   function of its duration measures. Utilizing this result the paper
   analyzes the relative importance of the duration constraints. Former
   studies have hinted that the first order duration may be the most
   important. It is shown here there is no reason to satisfy the first
   duration constraint with priority over satisfaction of a higher order
   duration constraint. practitioners who use duration techniques for
   portfolio immunization must be aware of such an important
   counter-intuitive result.
ZB 0
ZS 0
ZR 0
TC 5
Z8 0
Z9 5
SN 0025-1909
UT WOS:A1997WM79600007
ER

PT J
AU Basso, A
   Pianca, P
TI Decreasing absolute risk aversion and option pricing bounds
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 206
EP 216
DI 10.1287/mnsc.43.2.206
PD FEB 1997
PY 1997
AB In this paper efficient bounds for the price of a call option are
   obtained using the decreasing absolute risk aversion (DARA) dominance
   rule. Such lower and upper bounds are obtained minimizing and
   maximizing, respectively, the objective function of a nonlinear
   optimization problem. An explicit formula (related to an exponential
   utility function) is given for the special case of three states of
   nature.
   A large number of experiments have been carried out and the numerical
   results support the conjecture that the same formula holds for problems
   with a number of states n > 3. Moreover, DARA bounds are more efficient
   than the bounds obtained using different criteria.
RI Basso, Antonella/E-8338-2013
OI Basso, Antonella/0000-0003-2021-616X
ZA 0
ZR 0
Z8 0
TC 13
ZS 0
ZB 0
Z9 13
SN 0025-1909
EI 1526-5501
UT WOS:A1997WM79600008
ER

PT J
AU Lin, Z
   Carley, KM
TI Organizational response: The cost performance tradeoff
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 217
EP 234
DI 10.1287/mnsc.43.2.217
PD FEB 1997
PY 1997
AB Organizations constantly face a dynamic environment where they must
   respond both quickly and accurately in order to survive. In this paper,
   we examine the issue: do organizations need to employ costly designs in
   order to exhibit high performance in a dynamic situation. In the context
   of a computational framework we derive a set of logically consistent
   propositions about the interrelationship among task, opportunities for
   review, training, and cost and their relative impact on organizational
   performance. Our analyses indicate that complex organizational designs
   have drawbacks and design is often not the dominant factor affecting
   performance. The relationship between organizational complexity (hence
   cost) and performance is complex and depends on the level of time
   pressure, training, and the task environment. Within the context of the
   computational framework, we find that the benefits of re-thinking
   decisions and of matching the organizational design to the task
   environment are questionable. Further, these results suggest that
   applying scarce resources to mitigate the adverse impact of time
   pressure may have more impact on performance than using those resources
   to support a more complex organizational design.
OI Carley, Kathleen M./0000-0002-6356-0238
TC 28
ZS 0
ZR 0
Z8 3
ZA 0
ZB 0
Z9 31
SN 0025-1909
UT WOS:A1997WM79600009
ER

PT J
AU Sherali, HD
   Tuncbilek, CH
TI Static and dynamic time-space strategic models and algorithms for
   multilevel rail-car meet management
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 235
EP 250
DI 10.1287/mnsc.43.2.235
PD FEB 1997
PY 1997
AB This paper deals with the design of dynamic time-space and calibrated
   static strategic planning models, along with solution algorithms, for
   the multilevel rail-car fleet management problem faced by RELOAD(R), a
   branch of the Association of American Railroads (AAR). We discuss a
   prevalent fleet sizing management model that is static in nature, and
   propose an alternative dynamic model based on a time-space network
   representation. This model accurately represents the problem, and also
   provides information regarding the issue of storing and retrieving empty
   cars. A suitable decomposition heuristic, that is based on solving
   subproblems defined for overlapping time segments, is developed to solve
   this model. This heuristic is shown to recover an optimal solution for
   all the test problems with a reasonable effort. We also investigate a
   procedure for calibrating the static model based on this improved
   time-space representation. Our results show that for the static model, a
   calibrated use of available data can yield near-optimal total fleet size
   requirements. This enables the use of such a simple, calibrated static
   model for accurately conducting fleet sizing, the determination of fleet
   size allocations among railroads, as well as for analyzing various
   ''what-if'' scenarios. The proposed methodology is being currently
   implemented at the AAR, and the status of this process as well as some
   test results are presented.
TC 35
ZS 0
ZR 0
ZB 0
Z8 1
ZA 0
Z9 36
SN 0025-1909
UT WOS:A1997WM79600010
ER

PT J
AU Simester, D
TI Note. Optimal promotion strategies: A demand-sided characterization
SO MANAGEMENT SCIENCE
VL 43
IS 2
BP 251
EP 256
DI 10.1287/mnsc.43.2.251
PD FEB 1997
PY 1997
AB We generalize Narasimhan's (1988) model of retail promotion to include
   multiple products and general demand functions. Doing so allows us to
   further characterize optimal promotion strategies. We find that firms
   prefer to offer deeper promotions on products for which switching
   customers have stronger demand than loyal customers and/or for which the
   price sensitivity of demand is high for both switching and loyal
   customers. We further show that firms will offer deeper promotions on
   products which enjoy complementary relationships with other products
   that they sell rather than on products for which the firm sells a
   substitute.
ZR 0
Z8 0
TC 15
ZB 0
ZS 0
ZA 0
Z9 15
SN 0025-1909
UT WOS:A1997WM79600011
ER

PT J
AU Midgley, DF
   Marks, RE
   Cooper, LG
TI Breeding competitive strategies
SO MANAGEMENT SCIENCE
VL 43
IS 3
BP 257
EP 275
DI 10.1287/mnsc.43.3.257
PD MAR 1997
PY 1997
AB We show how genetic algorithms can be used to evolve strategies in
   oligopolistic markets characterized by asymmetric competition. The
   approach is illustrated using scanner tracking data of brand actions in
   a real market. An asymmetric market-share model and a category-volume
   model are combined to represent market response to the actions of brand
   managers. The actions available to each artificial brand manager are
   constrained to four typical marketing actions of each from the
   historical data. Each brand's strategies evolve through simulations of
   repeated interactions in a virtual market, using the estimated weekly
   profits of each brand as measures of its fitness for the genetic
   algorithm. The artificial agents bred in this environment outperform the
   historical actions of brand managers in the real market. The
   implications of these findings for the study of marketing strategy are
   discussed.
CT 1994 Australasian Meeting of the Econometrics-Society
CY JUL, 1994
CL ARMIDALE, AUSTRALIA
SP Econometr Soc
RI Midgley, David F/B-3718-2010
ZB 0
ZR 0
TC 47
ZA 0
ZS 0
Z8 0
Z9 47
SN 0025-1909
UT WOS:A1997WQ99900001
ER

PT J
AU Smith, RP
   Eppinger, SD
TI Identifying controlling features of engineering design iteration
SO MANAGEMENT SCIENCE
VL 43
IS 3
BP 276
EP 293
DI 10.1287/mnsc.43.3.276
PD MAR 1997
PY 1997
AB Engineering design often involves a very complex set of relationships
   among a large number of coupled problems. It is this complex coupling
   that leads to iteration among the various engineering tasks in a large
   project. The design structure matrix (DSM) is useful in identifying
   where iteration is necessary. The work transformation matrix model
   developed in this paper is a powerful extension of the DSM method which
   can predict slow and rapid convergence of iteration within a project,
   and predict those coupled features of the design problem which will
   require many iterations to reach a technical solution. This model is
   applied to an automotive brake-system development process in order to
   illustrate the model's utility in describing the main features of an
   actual design process.
Z8 23
ZS 0
ZR 0
TC 304
ZA 0
ZB 0
Z9 326
SN 0025-1909
UT WOS:A1997WQ99900002
ER

PT J
AU Viswanathan, S
   Mathur, K
TI Integrating routing and inventory decisions in one-warehouse
   multiretailer multiproduct distribution systems
SO MANAGEMENT SCIENCE
VL 43
IS 3
BP 294
EP 312
DI 10.1287/mnsc.43.3.294
PD MAR 1997
PY 1997
AB We consider distribution systems with a central warehouse and many
   retailers that stock a number of different products. Deterministic
   demand occurs at the retailers for each product. The warehouse acts as a
   break-bulk center and does not keep any inventory. The products are
   delivered from the warehouse to the retailers by vehicles that combine
   the deliveries to several retailers into efficient vehicle routes. The
   objective is to determine replenishment policies that specify the
   delivery quantities and the vehicle routes used for the delivery, so as
   to minimize the long-run average inventory and transportation costs. A
   new heuristic that develops a stationary nested joint replenishment
   policy for the problem is presented in this paper. Unlike existing
   methods, the proposed heuristic is capable of solving problems involving
   distribution systems with multiple products. Results of a computational
   study on randomly generated single-product problems are also presented.
ZA 0
ZB 0
TC 127
ZS 0
Z8 9
ZR 0
Z9 135
SN 0025-1909
UT WOS:A1997WQ99900003
ER

PT J
AU Dasu, S
   delaTorre, J
TI Optimizing an international network of partially owned plants under
   conditions of trade liberalization
SO MANAGEMENT SCIENCE
VL 43
IS 3
BP 313
EP 333
DI 10.1287/mnsc.43.3.313
PD MAR 1997
PY 1997
AB For the last four decades the preferred economic philosophy in much of
   Latin America was that of import-substituting industrialization. As a
   result multinational corporations (MNCs) approached different countries
   with the expectation that each plant would primarily serve its domestic
   market. Each of these plants was partially owned by the MNC. Beginning
   in the late 1980s, Latin America countries began decreasing barriers to
   cross-border trade. This made competition between the units belonging to
   a common network possible for the first time. Operations which had
   subsisted side by side in spite of differences in costs and quality of
   output, and which were under the control of different owners now found
   themselves in competition with one another and having to rationalize
   their efforts. In this paper we analyze the problem of operating a
   network of plants under conditions of free trade and exchange rate
   fluctuations, when the firms that compose it are partially-owned
   subsidiaries of an MNC. A model of three subsidiaries and four countries
   is developed for one industry, based on actual corporate and economic
   data. We study the problem of coordinating the activities of the
   subsidiaries and allocating the gains arising from coordination.
ZR 0
ZS 1
ZA 0
Z8 0
ZB 0
TC 18
Z9 18
SN 0025-1909
UT WOS:A1997WQ99900004
ER

PT J
AU Moinzadeh, K
TI Replenishment and stocking policies for inventory systems with random
   deal offerings
SO MANAGEMENT SCIENCE
VL 43
IS 3
BP 334
EP 342
DI 10.1287/mnsc.43.3.334
PD MAR 1997
PY 1997
AB This paper considers the replenishment and stocking decision for
   inventory systems in which price discounts, referred to as deals, are
   offered by the supplier (or the market place) at random points in time.
   Assuming that the demand is constant over time, the times between deal
   offerings are exponentially distributed and that the order leadtimes are
   negligible, we derive expressions for evaluating the operating
   characteristics of the model. Moreover, we derive expressions for
   determining the optimal policy parameters for such systems and present
   results on the behavior of the optimal policy parameters. Our results
   are easy to implement, intuitive and provide managerial insights and a
   better understanding on the effect of random deal offerings on
   replenishment and stocking decisions. In addition, we suggest a back of
   envelope heuristic solution for deriving the policy parameters.
RI Yedidsion, Liron/M-9996-2014
ZR 0
ZB 0
Z8 0
TC 29
ZS 0
ZA 0
Z9 29
SN 0025-1909
UT WOS:A1997WQ99900005
ER

PT J
AU Dutta, S
   Weiss, AM
TI The relationship between a firm's level of technological innovativeness
   and its pattern of partnership agreements
SO MANAGEMENT SCIENCE
VL 43
IS 3
BP 343
EP 356
DI 10.1287/mnsc.43.3.343
PD MAR 1997
PY 1997
AB In this paper we investigate the relationship between the level of a
   firm's technological innovativeness and its pattern of partnership
   agreements (i.e., relative number of partnership agreements of one type
   versus another). We argue that the protection of tacit technological
   knowledge from potential opportunism is of importance to technologically
   innovative firms, and as a result they tend to have a relatively larger
   number of partnership agreements which generally minimize the transfer
   of tacit technological knowledge. Specifically, they tend to have a
   greater number of marketing agreements than joint ventures and a greater
   number of licensing agreements than joint ventures. This argument is
   tested using data from manufacturing firms in the electrical and
   electronics machinery sector who invest in R&D, and our results hold for
   our focal firm's agreements with both domestic and foreign partners. We
   discuss the strategic and policy implications from this research. In
   particular, the empirical results suggest that technologically
   innovative firms already have relatively more agreements which are
   likely to preempt transfer of their tacit technological knowledge to
   their foreign partners. Thus, recent suggestions of more active
   government regulation in the area of intellectual property may be
   unwarranted.
RI DUTTA, Shantanu/C-6457-2014
ZB 0
ZS 0
TC 107
ZR 0
Z8 5
ZA 1
Z9 113
SN 0025-1909
EI 1526-5501
UT WOS:A1997WQ99900006
ER

PT J
AU Smidts, A
TI The relationship between risk attitude and strength of preference: A
   test of intrinsic risk attitude
SO MANAGEMENT SCIENCE
VL 43
IS 3
BP 357
EP 370
DI 10.1287/mnsc.43.3.357
PD MAR 1997
PY 1997
AB In a field study, the concept of intrinsic risk attitude is
   investigated. Intrinsic risk attitude I concerns the relationship
   between risk attitude, measured by the utility function u(x), and
   strength of preference, measured by the value function v(x). We study
   farmers' decision-making vis-a-vis price risk and obtain assessments of
   risk attitude and strength of preference in two consecutive years in a
   sample of 253 respondents. This design enables us to investigate the
   temporal stability of intrinsic risk attitude. Our findings show that
   risk attitude and strength of preference are two distinctive constructs.
   More specifically, the hypothesis of a linear relationship between u(x)
   and v(x) is clearly rejected in favor of an exponential relationship.
   This exponential relationship implies that our respondents exhibit a
   constant absolute intrinsic risk attitude for different price levels,
   during a time period. Differences between respondents in direction and
   degree of intrinsic risk attitude are substantial and the majority of
   the respondents are intrinsically risk seeking. No statistically
   significant change in intrinsic risk attitude could be detected between
   the two years of measurement. However, the correlation between measures
   across time appears to be low. In the discussion, issues for further
   research are identified.
RI Smidts, Ale/B-8701-2008; Smidts, Ale/
OI Smidts, Ale/0000-0002-6699-1172
Z8 2
ZA 0
ZR 0
ZS 0
TC 54
ZB 2
Z9 56
SN 0025-1909
UT WOS:A1997WQ99900007
ER

PT J
AU Boudoukh, J
   Richardson, M
   Whitelaw, RF
TI Nonlinearities in the relation between the equity risk premium and the
   term structure
SO MANAGEMENT SCIENCE
VL 43
IS 3
BP 371
EP 385
DI 10.1287/mnsc.43.3.371
PD MAR 1997
PY 1997
AB This paper investigates the relation between the conditional expected
   equity risk premium and the slope of the term structure of interest
   rates. Theoretically, these variables are linked, the relation may be
   nonlinear, and negative risk premiums are consistent with equilibrium.
   Given these implications, we employ a nonparametric estimation technique
   to document the empirical relation between the risk premium and the
   slope of the term. structure using almost two hundred years of data. Of
   particular interest, the risk premium is increasing in the term
   structure slope; however, for either small or negative slopes, the risk
   premium is much more sensitive to changes in interest rates. In
   addition, the empirical results imply negative expected equity risk
   premiums for some inverted term structures. Finally, variations in the
   risk premium do not appear to be related to variations in the variance
   of equity returns. We illustrate these features in a stylized
   consumption-based model, and provide the economic intuition behind the
   results.
TC 22
ZR 0
Z8 0
ZB 0
ZS 0
ZA 0
Z9 22
SN 0025-1909
UT WOS:A1997WQ99900008
ER

PT J
AU Wilhelm, WE
   Srinivasa, AV
TI Prescribing tactical response for oil spill clean up operations
SO MANAGEMENT SCIENCE
VL 43
IS 3
BP 386
EP 402
DI 10.1287/mnsc.43.3.386
PD MAR 1997
PY 1997
AB The Tactical Decision Problem (TDP) associated with oil spill clean up
   operations prescribes the time-phased allocation of available components
   over the planning horizon so that the clean up requirement at each
   critical time point is met. The objective is to minimize response time
   to allow for the most effective clean up possible. In this paper, we
   formulate the TDP as a general integer program. We devise a method based
   on graph theory to efficiently generate response system types (RSTs),
   including constituent components, the locations from which each of the
   component types is obtained, and the staging area at which that RST is
   composed. We present several pre-processing methods and derive
   expressions for bounds on decision variables to facilitate solution. We
   then develop two heuristics to obtain approximate solutions to the TDP.
   The first heuristic is an LP-based method, while the second uses a
   combination of LP relaxation and branch and bound. The two heuristics
   are compared on problems that are based on realistic scenarios
   representing application in the Galveston Bay Area.
ZA 0
Z8 1
ZS 0
TC 21
ZB 6
ZR 0
Z9 22
SN 0025-1909
UT WOS:A1997WQ99900009
ER

PT J
AU Graves, SC
   Fisher, ML
TI Introduction to Special Issue on frontier research in manufacturing and
   logistics
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 403
EP 404
PD APR 1997
PY 1997
Z8 0
ZS 0
ZB 0
ZR 0
TC 3
Z9 3
SN 0025-1909
UT WOS:A1997WY85700002
ER

PT J
AU Khanna, T
   Iansiti, M
TI Firm asymmetries and sequential R&D: Theory and evidence from the
   mainframe computer industry
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 405
EP 421
DI 10.1287/mnsc.43.4.405
PD APR 1997
PY 1997
AB We incorporate strategic considerations into the analysis of a problem
   that has hitherto been treated in a decision theoretic fashion: the
   allocation of scarce R&D resources when R&D proceeds in stages. In doing
   so, we formalize a notion of ''system complexity'' and investigate its
   implications for the allocation of these scarce resources. Using
   detailed data from fieldwork at all mainframe manufacturers in the world
   to investigate our theoretical predictions, we provide evidence that
   larger market share firms set more aggressive stage targets, as do more
   resource-rich firms. Our results can be seen as a verification of the
   mechanism underlying Arrow's ''replacement'' effect.
ZS 0
Z8 1
ZB 0
TC 17
ZA 0
ZR 0
Z9 18
SN 0025-1909
UT WOS:A1997WY85700003
ER

PT J
AU Hendricks, KB
   Singhal, VR
TI Delays in new product introductions and the market value of the firm:
   The consequences of being late to the market
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 422
EP 436
DI 10.1287/mnsc.43.4.422
PD APR 1997
PY 1997
AB This paper empirically estimates the impact of not meeting promised new
   product introduction dates on the market value of the firm. We estimate
   the average ''abnormal'' change in the market value for a sample of 101
   firms around the date when information about delaying the introduction
   of new products is publicly announced. On average, delay announcements
   decrease the market value of the firm by 5.25%. The average dollar
   change in the market value in 1991 dollars is $-119.3 million. The
   evidence suggests that there are significant penalties for not
   introducing new products on time.
   To provide further insight, regression analyses are used to identify
   factors that influence the direction and magnitude of the change in
   market value. We find that the competitiveness of the industry in which
   the firm operates, the size of the firm, and the firm's degree of
   diversification are statistically significant predictors for the change
   in the market value of firms that announce delays in the introduction of
   new products.
ZS 0
TC 120
Z8 2
ZR 0
ZA 0
ZB 0
Z9 122
SN 0025-1909
UT WOS:A1997WY85700004
ER

PT J
AU Krishnan, V
   Eppinger, SD
   Whitney, DE
TI A model-based framework to overlap product development activities
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 437
EP 451
DI 10.1287/mnsc.43.4.437
PD APR 1997
PY 1997
AB Intense competition in many industries forces manufacturing firms to
   develop new, higher quality products at an increasingly rapid pace.
   Overlapping product development activities is an important component of
   concurrent product development that can help firms develop products
   faster. However, since product development activities may be coupled in
   complex ways, overlapping interrelated activities can present many
   difficulties. Without careful management of the overlapped product
   development process, the development effort and cost may increase, and
   product quality may worsen. This paper goes beyond the common
   recommendation to simply overlap activities as much as possible. We
   present a model-based framework to manage the overlapping of coupled
   product development activities. The model and framework identify
   conditions under which various types of overlapping are appropriate for
   a pair of coupled activities. We illustrate the model and framework with
   industrial applications involving the development of electronic pagers
   and automobile doors.
ZB 3
TC 354
ZS 1
ZR 0
ZA 0
Z8 29
Z9 383
SN 0025-1909
UT WOS:A1997WY85700005
ER

PT J
AU Datar, S
   Jordan, C
   Kekre, S
   Rajiv, S
   Srinivasan, K
TI New product development structures and time-to-market
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 452
EP 464
DI 10.1287/mnsc.43.4.452
PD APR 1997
PY 1997
AB In fast-cycle, high technology industries, the speed and rate at which
   companies can introduce products into the market are critical for
   sustaining competitive advantage and market share. The authors analyze
   new product development by three international manufacturers that
   dominate a segment of the electronic component industry. The objective
   is to examine the impact of two distinct product development strategies
   and structures on time-to-market.
   The analysis of more than 200 new product developments provides
   important findings. A concentrated new product development structure, in
   contrast to a distributed structure, affords rapid prototyping. However,
   volume production is reached faster in the distributed structure. Also,
   devoting more time to prototyping hastens volume production.
ZS 0
Z8 4
ZA 1
ZR 0
ZB 0
TC 71
Z9 76
SN 0025-1909
UT WOS:A1997WY85700006
ER

PT J
AU Burchill, G
   Fine, CH
TI Time versus market orientation in product concept development:
   Empirically-based theory generation
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 465
EP 478
DI 10.1287/mnsc.43.4.465
PD APR 1997
PY 1997
AB In collaboration with industry partners, a normative model of the
   product concept decision process was developed, supported with tools and
   techniques, and codified as a decision support process for product
   development teams. This process (Concept Engineering) was then
   introduced into a number of product development teams in different
   companies. A comparative analysis of actual product concept development
   activities, with and without the use of Concept Engineering, was
   conducted. All of the observed teams viewed time to market as a critical
   measure of their success. However, the development processes differed
   significantly depending on whether relatively more emphasis was placed
   on time or market considerations. Key variables associated with the
   product concept development decision process and time-to-market dynamics
   were identified and a theory of the concept development process was
   developed using the inductive system diagram technique, a research
   methodology developed in the course of this work.
   We believe this work contributes to the operations management literature
   in three ways. First, it introduces a very detailed, structured decision
   process for product concept development, enhancing the literature on
   Quality Function Deployment (QFD). Second, it presents a theory of
   product concept development that can improve understanding of success
   and failure in product concept development. Third, this work develops
   new methodology (Inductive Systems Diagrams) for field work in
   operations management. This methodology marries the grounded theory
   methods, familiar to sociologists with causal-loop modeling familiar to
   systems dynamicists, yielding a rigorous tool for systematically
   collecting, organizing, and distilling large amounts of field-based
   data.
ZA 1
TC 56
Z8 1
ZS 1
ZR 0
ZB 1
Z9 59
SN 0025-1909
UT WOS:A1997WY85700007
ER

PT J
AU MacDuffie, JP
TI The road to ''root cause'': Shop-floor problem-solving at three auto
   assembly plants
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 479
EP 502
DI 10.1287/mnsc.43.4.479
PD APR 1997
PY 1997
AB This paper uses case studies of shop-floor problem-solving at three
   automotive assembly plants to examine organizational influences on
   process quality improvement. Three complex quality problems-water leaks,
   paint defects, and electrical defects-were chosen because they are
   universally found in assembly plants, have multiple sources, and can
   only be resolved with high levels of interaction and coordination among
   individuals in multiple departments or functional groups. The case
   studies focus particularly on the early stages of the problem-solving
   process-problem definition, problem analysis, and the generation of
   solutions-emphasizing how each plant tries to identify the ''root
   cause'' of defects. The paper then explores consistencies and contrasts
   within and across the three cases to analyze the factors underlying
   effective shop-floor problem-solving. Central to this analysis is the
   idea that successful process quality improvement depends heavily on how
   the organization influences the cognitive processes of its members.
   Problem-solving processes benefit from rich data that capture multiple
   perspectives on a problem; problem categories that are ''fuzzy''; and
   organizational structures that facilitate the development of a common
   language for discussing problems. Also, when problems are framed as
   opportunities for learning, the combination of positive attributions
   that boost motivation and the suppression of threat effects can improve
   the effectiveness of improvement activities. Finally, when process
   standardization is understood as marking the beginning (and not the end)
   of further improvement efforts, the normal inertial tendencies of
   organizations with respect to adaptive learning can be partially
   overcome.
ZR 0
ZB 1
TC 141
ZS 0
Z8 0
ZA 0
Z9 141
SN 0025-1909
UT WOS:A1997WY85700008
ER

PT J
AU Sterman, JD
   Repenning, NP
   Kofman, F
TI Unanticipated side effects of successful quality programs: Exploring a
   paradox of organizational improvement
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 503
EP 521
DI 10.1287/mnsc.43.4.503
PD APR 1997
PY 1997
AB Recent evidence suggests the connection between quality improvement and
   financial results may be weak. Consider the case of Analog Devices,
   Inc., a leading manufacturer of integrated circuits. Analog's TQM
   program was a dramatic success. Yield doubled, cycle time was cut in
   half, and product defects fell by a factor of ten. However, financial
   performance worsened. To explore the apparent paradox we develop a
   detailed simulation model of Analog, including operations, financial and
   cost accounting, product development, human resources, the competitive
   environment, and the financial markets. We used econometric estimation,
   interviews, observation, and archival data to specify and estimate the
   model. We find that improvement programs like TQM can present firms with
   a tradeoff between short and long run effects. In the long run TQM can
   increase productivity, raise quality, and lower costs. In the short run,
   these improvements can interact with prevailing accounting systems and
   organizational routines to create excess capacity, financial stress, and
   pressure for layoffs that undercut commitment to continuous improvement.
   We explore policies to promote sustained improvement in financial as
   well as nonfinancial measures of performance.
TC 174
ZB 2
ZR 0
ZS 3
ZA 0
Z8 2
Z9 179
SN 0025-1909
UT WOS:A1997WY85700009
ER

PT J
AU Ittner, CD
   Larcker, DF
TI The performance effects of process management techniques
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 522
EP 534
DI 10.1287/mnsc.43.4.522
PD APR 1997
PY 1997
AB This paper provides exploratory evidence on the cross-sectional
   association between process management techniques and two profit
   measures: return on assets and return on sales. Using a sample of firms
   in two industries (automotive and computer) and four countries (Canada,
   Germany, Japan, and the United States), we find that certain process
   management techniques improve profitability while others have little
   effect on financial performance; In particular, long-term partnerships
   with suppliers and customers are associated with higher performance in
   both industries. The value of other techniques such as statistical
   process control, process capability studies, and cycle time analysis, on
   the other hand, appears to vary by industry, reflecting differences in
   the stages of the two industries' process management practices. Finally,
   computer organizations following an innovation-oriented strategy earned
   significantly higher accounting returns regardless of the process
   management techniques employed, suggesting that these techniques have
   only a second-order effect on performance in this industry.
RI van Lent, Laurence/G-5298-2010
ZA 0
ZB 0
TC 130
Z8 0
ZR 0
ZS 0
Z9 130
SN 0025-1909
UT WOS:A1997WY85700010
ER

PT J
AU Cohen, MA
   Whang, SJ
TI Competing in product and service: A product life-cycle model
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 535
EP 545
DI 10.1287/mnsc.43.4.535
PD APR 1997
PY 1997
AB In this paper we develop a product life-cycle model that studies a set
   of strategic choices facing manufacturers as they design the joint
   product/service bundle for a product which may require maintenance and
   repair support after its sale. The choice parameters of interest include
   the product price, the quality of after-sales service and the price to
   be charged for the after-sales service. We adopt a competitive,
   game-theoretic (as opposed to single-firm optimization) framework, where
   there is competition for the provision of after-sales service between
   the manufacturer and an independent service operator. The product price
   and the service quality/price are characterized by an equilibrium to a
   sequential game. The resulting outcome is applied to support the
   valuation of alternative product designs in explicit consideration of
   the tradeoff between profit from product sale and from the provision of
   after-sales service. The model can also be used to evaluate the asset
   value of a firm's customer base.
ZB 1
ZA 0
ZR 0
ZS 0
TC 104
Z8 17
Z9 120
SN 0025-1909
UT WOS:A1997WY85700011
ER

PT J
AU Lee, HL
   Padmanabhan, V
   Whang, SJ
TI Information distortion in a supply chain: The bullwhip effect
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 546
EP 558
DI 10.1287/mnsc.43.4.546
PD APR 1997
PY 1997
AB Consider a series of companies in a supply chain, each of whom orders
   from its immediate upstream member. In this setting, inbound orders from
   a downstream member serve as a valuable informational input to upstream
   production and inventory decisions. This paper claims that the
   information transferred in the form of ''orders'' tends to be distorted
   and can misguide upstream members in their inventory and production
   decisions. In particular, the variance of orders may be larger than that
   of sales, and the distortion tends to increase as one moves upstream-a
   phenomenon termed ''bullwhip effect.'' This paper analyzes four sources
   of the bullwhip effect: demand signal processing, rationing game, order
   batching, and price variations. Actions that can be taken to mitigate
   the detrimental impact of this distortion are also discussed.
RI Weller, Matt J/E-8421-2010; Padmanabhan, V./B-3659-2010; Padmanabhan, Vineet/
OI Padmanabhan, Vineet/0000-0002-5571-839X
TC 2069
Z8 188
ZR 2
ZB 19
ZA 2
ZS 17
Z9 2274
SN 0025-1909
UT WOS:A1997WY85700012
ER

PT J
AU Iyer, AV
   Bergen, ME
TI Quick response in manufacturer-retailer channels
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP 559
EP 570
DI 10.1287/mnsc.43.4.559
PD APR 1997
PY 1997
AB Quick Response (QR) is a movement in the apparel industry to shorten
   lead time. Under QR, the retailer has the ability to adjust orders based
   on better demand information. We study how a manufacturer-retailer
   channel impacts choices of production and marketing variables under QR
   in the apparel industry. Specifically, we build formal models of the
   inventory decisions of manufacturers and retailers both before and after
   QR. Our models allow us to address who wins and who loses under QR and
   suggest actions such as service level, wholesale price and volume
   commitments that can be used to make QR profitable for both members of
   the channel, i.e., Pareto improving. Detailed discussions with a major
   retailer, and information from industry sources provide supporting
   evidence for the structure and conclusions of the model.
ZA 0
TC 334
ZR 0
ZB 1
Z8 66
ZS 0
Z9 398
SN 0025-1909
EI 1526-5501
UT WOS:A1997WY85700013
ER

PT J
AU Tang, CS
TI Editorial objectives supply chain management
SO MANAGEMENT SCIENCE
VL 43
IS 4
BP U3
EP U3
PD APR 1997
PY 1997
ZR 0
Z8 0
TC 0
ZA 0
ZB 0
ZS 0
Z9 0
SN 0025-1909
UT WOS:A1997WY85700001
ER

PT J
AU Kouvelis, P
   Gutierrez, GJ
TI The Newsvendor problem in a global market: Optimal centralized and
   decentralized control policies for a two-market stochastic inventory
   system
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 571
EP 585
DI 10.1287/mnsc.43.5.571
PD MAY 1997
PY 1997
AB The global markets of today offer to the ''style goods'' producer more
   selling opportunities and pose new challenges in production planning and
   coordination. From a production management standpoint the opportunity to
   exploit the difference in timing of the selling season of geographically
   dispersed markets for ''style goods'' is important for improving the
   firm's profitability. In this paper we examine the above issue with an
   insightful model of a producer of ''style goods'' selling the goods to
   two markets (a primary and a secondary market) with nonoverlapping
   selling seasons. We refer to this problem as the ''global newsvendor''
   problem. For the above two market stochastic inventory systems we first
   develop optimal centralized control policies. Then we demonstrate the
   suboptimality of decentralized production control policies, with the
   production centers at each market treated as independent profit centers
   and a constant transfer price being used to coordinate their production.
   We propose as an effective alternative a decentralized production
   control structure with a nonlinear pricing scheme for production
   coordination among centers administered through an intermediate
   organizational unit. In our modeling, we explicitly consider the effects
   of exchange rate uncertainty on the production planning decisions.
RI Kouvelis, Panos/ABG-2350-2020
TC 76
ZS 0
ZA 0
ZR 0
ZB 1
Z8 3
Z9 79
SN 0025-1909
UT WOS:A1997XF21000001
ER

PT J
AU Bowden, RJ
TI Generalising interest rate duration with directional derivatives:
   Direction X and applications
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 586
EP 595
DI 10.1287/mnsc.43.5.586
PD MAY 1997
PY 1997
AB Conventional (or Fisher-Weil) duration is an ordinary derivative that
   measures the response of portfolio value to marginal parallel shifts in
   the term structure, while other proposed measures are generally specific
   to particular interest rate processes. In this paper, we show that
   portfolio responses to arbitrary shifts in the term structure may be
   handled by the use of Frechet or directional derivatives, presenting a
   simple algorithm for the directional derivative of a fixed interest
   portfolio, viewed as a set of cash flows. For a given portfolio, one can
   locate the most sensitive areas along the term structure by computing a
   function or profile (''Direction X'') that gives the term structure
   movement to which the portfolio is most exposed. Immunisation techniques
   can be based on choosing ancillary assets that ensure that the portfolio
   directional derivative is zero, or as close to zero as possible; this
   generalises approaches based on factor models of the term structure, The
   analysis is applied to both continuous and discrete time.
ZS 0
ZR 0
TC 5
Z8 0
ZB 0
ZA 0
Z9 5
SN 0025-1909
UT WOS:A1997XF21000002
ER

PT J
AU Larkey, P
   Kadane, JB
   Austin, R
   Zamir, S
TI Skill in games
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 596
EP 609
DI 10.1287/mnsc.43.5.596
PD MAY 1997
PY 1997
AB Differences in players' skill are important determinants of relative
   player success in most real games such as poker, chess, basketball,
   business, and politics. Yet conventional game theory has concentrated
   primarily on games with no skill differences among players. This paper
   uses a simplified version of stud poker to better understand the concept
   of differential player skill in games. Players with very different
   strategies for playing this game are modeled algorithmically and pitted
   against one another in simulation tournaments.
ZR 0
Z8 0
ZA 0
ZS 0
ZB 1
TC 16
Z9 16
SN 0025-1909
UT WOS:A1997XF21000003
ER

PT J
AU Ito, K
TI Domestic competitive position and export strategy of Japanese
   manufacturing firms: 1971-1985
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 610
EP 622
DI 10.1287/mnsc.43.5.610
PD MAY 1997
PY 1997
AB This paper analyzes Japanese manufacturing firms' export behavior and
   their performance. In a slow growth era, leading firms' and minor firms'
   export ratio tended to be less than that of follower (medium market
   share) firms in the same industry; there appears to be an inverted-U
   shape between export ratio and relative size of firms. An affiliation
   with a large industrial group has no positive relationship with export
   ratio, while other firm-specific factors do not show consistent
   relationships with ie in the years 1971 to 1985. Exports and firm
   performance do not have a positive relationship. Competitive environment
   in the domestic market is related to the export strategy of Japanese
   firms.
ZR 0
ZS 0
Z8 0
TC 36
ZB 0
ZA 0
Z9 36
SN 0025-1909
UT WOS:A1997XF21000004
ER

PT J
AU Basu, A
   Blanning, RW
   Shtub, A
TI Metagraphs in hierarchical modeling
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 623
EP 639
DI 10.1287/mnsc.43.5.623
PD MAY 1997
PY 1997
AB When using a decision support system (DSS) containing a large model
   base, a user has to decide which specific models are relevant for any
   particular task. When the model base is large and diverse, this task can
   be quite difficult. Furthermore, the number and variety of models
   available can be confusing. One way to simplify the user's interaction
   with the DSS, and facilitate more effective use of the system, is
   through the use of ''views'' of the model base. A view is an abstraction
   of a model base that limits attention to relationships between certain
   variables, and its purpose is to guide the development of DSS software
   that executes lower-level models in response to higher-level requests
   for information or analysis. Single views may be of use to individual
   decision makers who wish to abstract information from a model base, and
   multiple views may be of use to collections of decision makers who are
   using a model base to integrate their analyses to make a collective
   decision. In this paper, we show how representation of models using a
   graph theoretic structure called a metagraph can facilitate the
   construction and maintenance of model base views. In particular, we show
   how useful views can be constructed using a projection operation on a
   metagraph, and also present conditions under which views can be
   combined. The concepts developed in the paper are illustrated using an
   example from life cycle costing.
ZA 0
TC 19
Z8 1
ZR 0
ZS 0
ZB 0
Z9 20
SN 0025-1909
UT WOS:A1997XF21000005
ER

PT J
AU Delquie, P
TI ''Bi-matching'': A new preference assessment method to reduce
   compatibility effects
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 640
EP 658
DI 10.1287/mnsc.43.5.640
PD MAY 1997
PY 1997
AB Preference models and utility functions are often assessed by eliciting
   value trade-offs among attributes. Prior research has shown that
   trade-off judgments can be biased in systematic ways: for example, the
   attribute which is used as response receives more relative subjective
   weight, i.e. the so-called scale compatibility effects (Tversky et al.
   1988). This paper proposes a new procedure to elicit value trade-offs
   called bidimensional matching, of ''bi-matching'', designed to alleviate
   this effect. Bi-matching differs from traditional trade-off judgments in
   that both attributes are adjusted simultaneously to reach indifference
   judgments. Bi-matching is compared with simple matching and choice in
   four experimental studies, to measure preferences for lotteries and
   riskless multiattribute alternatives. The main results are: (I)
   bi-matching produces trade-offs intermediate between those derived from
   matching on the ''more important'' attribute and matching on the less
   important attribute, although closer to the former; (2) the trade-offs
   derived from choice reflect more relative weight on the more important
   dimension than those from bi-matching (3) bi-matching appears to reduce
   response error compared to standard matching. These results are
   generally consistent with theoretical predictions. We discuss the
   normative question of which preference assessment method is preferable.
   The current results as a whole and the built-in features of the
   bi-matching procedure already position this elicitation method as a
   worthwhile alternative to traditional methods for helping
   decision-makers introspect and construct their value trade-offs.
ZR 0
ZB 0
ZA 0
TC 24
ZS 0
Z8 0
Z9 24
SN 0025-1909
UT WOS:A1997XF21000006
ER

PT J
AU Pinsonneault, A
   Kraemer, KL
TI Middle management downsizing: An empirical investigation of the impact
   of information technology
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 659
EP 679
DI 10.1287/mnsc.43.5.659
PD MAY 1997
PY 1997
AB Nearly all Fortune 1000 firms claim to have downsized since the early
   eighties, and it is argued that information technology (IT) is
   responsible for this massive downsizing. However, earlier research has
   indicated that IT increases middle management. Even though the impact of
   IT on the middle management workforce has been studied for the last
   thirty years, research has failed to clearly explain this phenomenon.
   Quite the opposite, research has fueled controversy and has provided
   inconsistent findings. This article addresses the state of inconsistent
   findings across multiple studies by examining the impact of information
   technology on the number of middle managers using two additional
   variables: the degree of centralization of organizational decision
   authority and the degree of centralization of computing decision
   authority. One hundred and fifty-five city governments were surveyed.
   Information technology was found to be both positively and negatively
   associated with the size of the middle management workforce. The impact
   of information technology was fundamentally determined by who controlled
   computing decisions and what interests were being served, and by the
   roles of middle managers. Information technology was associated with a
   decrease in the size of the middle management workforce in organizations
   with centralized decision authority and with an increase in the number
   of middle managers in organizations where decision authority was
   decentralized.
RI Pinsonneault, Alain/N-4490-2017
ZS 1
ZA 0
TC 53
Z8 1
ZR 0
ZB 0
Z9 55
SN 0025-1909
UT WOS:A1997XF21000007
ER

PT J
AU Ross, WT
   Anderson, E
   Weitz, B
TI Performance in principal-agent dyads: The causes and consequences of
   perceived asymmetry of commitment to the relationship
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 680
EP 704
DI 10.1287/mnsc.43.5.680
PD MAY 1997
PY 1997
AB We focus on the principal-agent relationship in a distribution channel.
   In a services context (insurance), we examine how two facets of
   performance, from the point of view of both the principal and the agent,
   are influenced by the perceiver's belief that it. is more committed to
   the relationship than is the other party. Using primary data from 255
   insurance agent-insurance provider dyads, we show that each side's
   assessment of how much it benefits from the dyad is related in a
   potentially dysfunctional manner to its perception of asymmetric
   commitment. Perceivers rate their performance outcomes from the dyad
   (i.e., harmony and profit) highest when they believe they are less
   committed than their counterpart. Conversely, they rate their own
   performance outcomes lowest when they believe they are more committed
   than the other party. We explain this finding in terms of suspected
   opportunism and offer a partial! test of this explanation compared with
   explanations from theories of equity and power/dependence. Further, we
   demonstrate that each party's perception of asymmetric commitment
   partially reflects actual asymmetry, as measured by confidential data
   collected from both sides. Perceived asymmetric commitment is also shown
   to be related to levels of communication and dependence in the dyad.
   Managerial implications for reducing perceived asymmetric commitment and
   improving the performance outcomes of each dyad member are discussed.
ZB 0
TC 75
ZS 1
ZA 0
ZR 0
Z8 0
Z9 75
SN 0025-1909
UT WOS:A1997XF21000008
ER

PT J
AU Dasu, S
   Li, L
TI Optimal operating policies in the presence of exchange rate variability
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 705
EP 722
DI 10.1287/mnsc.43.5.705
PD MAY 1997
PY 1997
AB We study the structure of the optimal policies for a firm operating
   plants in different countries. The relative costs of production between
   the plants are assumed to vary over time due to economic and political
   factors such as exchange rates, inflation, taxes, and tariffs. Based on
   the costs, the firm can alter the quantity produced in each plant. We
   determine the structure of the optimal policies for deciding when and by
   how much to alter the production quantities. When the switch-over costs
   are linear or step functions, regardless of whether the variable
   production costs are concave or piece-wise linear convex, and regardless
   of whether the firm is supplying one or more markets, the optimal policy
   is always a barrier policy. The optimal barriers can be determined by
   using linear programming techniques, and the optimal costs can be
   computed by solving a system of linear equations. When the number of
   optimal barriers is two, the optimal expected costs and the condition
   that determines the optimal barriers are explicitly derived.
ZA 0
ZB 0
Z8 1
ZR 0
TC 74
ZS 0
Z9 75
SN 0025-1909
UT WOS:A1997XF21000009
ER

PT J
AU Prasad, SY
   Karwan, MH
   Zionts, S
TI Use of convex cones in interactive multiple objective decision making
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 723
EP 734
DI 10.1287/mnsc.43.5.723
PD MAY 1997
PY 1997
AB One approach for solving decision problems involving multiple objectives
   is interactive optimization. Methods based on this approach assess the
   decision maker's preference structure interactively, typically based on
   pairwise comparisons and tradeoffs, and guide the search process toward
   identifying improved solutions. A desirable feature of such approaches,
   that is based on minimizing the preference information requirements, is
   fast convergence. Toward this end, the use of convex cones as a
   preference structure representation has been proposed in the literature.
   In this work, new theory is developed that aids in further reducing
   preference information requirements and improving convergence. New cones
   termed p cones are developed. The efficiencies of solution alternatives
   are evaluated with respect to the p cones, and these are termed p cone
   efficiencies. Acceleration and Early Termination procedures that are
   based on these efficiencies are proposed. The procedures are presented
   within a solution framework for solving Multiple Objective Linear
   Programming (MOLP) problems along with computational results.
RI Karwan, Mark/H-5150-2016
OI Karwan, Mark/0000-0001-9478-6988
ZB 0
ZA 0
TC 15
ZS 0
Z8 0
ZR 0
Z9 15
SN 0025-1909
UT WOS:A1997XF21000010
ER

PT J
AU Federgruen, A
   Mosheiov, G
TI Heuristics for multimachine scheduling problems with earliness and
   tardiness costs (vol 42, pg 1544, 1996)
SO MANAGEMENT SCIENCE
VL 43
IS 5
BP 735
EP 735
PD MAY 1997
PY 1997
ZS 0
TC 1
ZB 0
Z8 0
ZA 0
ZR 0
Z9 1
SN 0025-1909
UT WOS:A1997XF21000011
ER

PT J
AU Zhang, GC
TI Moral hazard in corporate investment and the disciplinary role of
   voluntary capital rationing
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 737
EP 750
DI 10.1287/mnsc.43.6.737
PD JUN 1997
PY 1997
AB This paper compares three capital-budgeting rules, the NPV rule, a high
   hurdle rate and capital rationing, and explains why some firms may
   voluntarily impose capital rationing. Under both capital rationing and a
   high hurdle, a restrictive investment criterion is used to control
   managerial shirking. However, implementation of these budgeting rules
   requires a mechanism to prevent the firm from expanding the investment
   scale ex post. Capital rationing, in the form of a predetermined, fixed
   budget, differs from the high-hurdle-rate rule in that the former
   requires the firm to overcome the cost of raising additional capital
   before making further investment.
TC 13
ZB 0
ZS 0
ZA 0
Z8 1
ZR 0
Z9 14
SN 0025-1909
UT WOS:A1997XG07700001
ER

PT J
AU Duenyas, I
   Keblis, MF
   Pollock, SM
TI Dynamic type mating
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 751
EP 763
DI 10.1287/mnsc.43.6.751
PD JUN 1997
PY 1997
AB We address an assembly problem, motivated by flat panel display
   manufacturing, where the quality (or performance) of the final product
   depends upon characteristics of the components to be assembled, which
   are not constant from component to component. We analyze the tradeoff
   between the increase in the potential value of products gained by
   putting off the ''mating'' of components exhibiting various
   characteristic ''types,'' and the inventory costs caused by this delay
   in mating. We formulate this dynamic type mating problem as a Markov
   Decision Process and characterize the structure of the optimal policy
   for special cases. We then present a heuristic policy for a more general
   case and compare its performance against the optimal policy.
   Computational results indicate that the heuristic is effective for a
   wide variety of cases.
TC 4
ZB 0
ZS 0
ZA 0
ZR 0
Z8 0
Z9 4
SN 0025-1909
UT WOS:A1997XG07700002
ER

PT J
AU Sridhar, S
   Balachandran, BV
TI Incomplete information, task assignment, and managerial control systems
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 764
EP 778
DI 10.1287/mnsc.43.6.764
PD JUN 1997
PY 1997
AB A firm typically assigns multiple tasks it must perform to either
   internal employees or outside vendors. This paper demonstrates the need
   to integrate a task assignment decision with the design of a managerial
   control system as each affects the other. An internal employee is
   distinguished from an outside supplier on four different informational
   dimensions: (i) at the time of contracting, the outside supplier has
   less information about the task environment more often than the internal
   employee; (ii) the principal observes the employee's information set
   more frequently than that of the supplier; (iii) the principal can
   exercise a greater control over information flow to the internal
   employee than to the outside supplier; and (iv) the principal may share
   the details of the outside supplier's contract with the internal
   employee but not vice versa. Under each of these lour distinguishing
   dimensions, the principal is shown to outsource the upstream task and
   assign the downstream task to the internal employee more often than vice
   versa. Further, under the last two dimensions of the firm's boundary,
   the principal can eliminate inefficiencies arising from the agents'
   contracting with incomplete information by assigning the downstream task
   to the employee and not providing predecision information to him while
   assigning the upstream task to the supplier.
Z8 0
ZS 0
ZB 0
ZA 0
ZR 0
TC 18
Z9 18
SN 0025-1909
UT WOS:A1997XG07700003
ER

PT J
AU Sueyoshi, T
TI Measuring efficiencies and returns to scale of Nippon Telegraph &
   Telephone in production and cost analyses
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 779
EP 796
DI 10.1287/mnsc.43.6.779
PD JUN 1997
PY 1997
AB This article provides a theoretical framework related to Data
   Envelopment Analysis (DEA) in which an analytical relationship among
   eight different efficiency concepts is defined and explored in terms of
   production and cost analyses. This article extends the theoretical basis
   into the measurement of Scale Economies (SE) and Returns to Scale (RTS).
   A unique feature of the SE/RTS measurement is that the proposed approach
   is based upon the measurement regarding not only production activity but
   also cost performance. As an important case study, this article applies
   the DEA-based approach to measure the eight efficiency concepts and
   SE/RTS of Nippon Telegraph & Telephone (NTT). This study finds that NTT
   has maintained high SE and increasing RTS in the operations of 39 annual
   periods from 1953 through 1992.
ZB 1
ZS 0
Z8 0
ZA 0
TC 61
ZR 0
Z9 62
SN 0025-1909
UT WOS:A1997XG07700004
ER

PT J
AU Hunton, JE
   Price, KH
TI Effects of the user participation process and task meaningfulness on key
   information system outcomes
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 797
EP 812
DI 10.1287/mnsc.43.6.797
PD JUN 1997
PY 1997
AB In this study, 144 professional accounting data entry clerks took part
   in a fully randomized field experiment using a 4 (mode of participation)
   X 2 (task meaningfulness) design. Participants were full-time, mandatory
   users of payroll applications. The nature of the experiment engaged
   these users in hands-on activity (Hartwick and Barki 1994) regarding the
   development of a payroll input screen. User mode of participation was
   manipulated by varying the extent of decision input used to execute
   hands-on activity in accordance with procedural justice theory.
   Perceptions of decision control, procedural justice, and outcome
   satisfaction, as well as objective levels of task performance escalated
   with corresponding increases in decision input. Task meaningfulness was
   manipulated by creating either high or low expectations of using the
   payroll input screen in the near future. As the development task became
   more meaningful, procedural justice, decision control, task commitment,
   and task performance responses also increased. An underlying theoretical
   model of treatment effects was tested using path analysis which
   supported the control-oriented theory of procedural justice. The strong
   attitudinal and behavioral results observed in this experiment enhance
   understanding of the user participation and involvement model proposed
   by Hartwick and Barki (1994) by incorporating process considerations
   from procedural justice theory into their framework. Implications of
   this research are discussed.
ZS 0
ZA 0
ZB 0
TC 39
ZR 0
Z8 0
Z9 39
SN 0025-1909
EI 1526-5501
UT WOS:A1997XG07700005
ER

PT J
AU Ahlbrecht, M
   Weber, M
TI An empirical study on intertemporal decision making under risk
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 813
EP 826
DI 10.1287/mnsc.43.6.813
PD JUN 1997
PY 1997
AB This study compares time preference in the cases of certainty and risk.
   We analyze both matching and choice behavior. We find that violations of
   the stationarity axiom are restricted to matching behavior, both for
   certainty and risk. We also compare the discounting of certain and risky
   outcomes as well as the discounting of gains and losses. In matching
   tasks, certain outcomes are discounted more than risky ones. We could
   not confirm these results in a choice task. Gains and losses are not
   found to be discounted at different rates.
ZA 0
Z8 3
ZB 10
ZR 0
ZS 0
TC 79
Z9 82
SN 0025-1909
UT WOS:A1997XG07700006
ER

PT J
AU Gopalakrishnan, M
   Ahire, SL
   Miller, DM
TI Maximizing the effectiveness of a preventive maintenance system: An
   adaptive modeling approach
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 827
EP 840
DI 10.1287/mnsc.43.6.827
PD JUN 1997
PY 1997
AB The dynamic nature of an operating environment, such as machine
   utilization and breakdown frequency results in changing preventive
   maintenance (PM) needs for manufacturing equipment. In this paper, we
   present an approach to generate an adaptive PM schedule which maximizes
   the net savings from PM subject to workforce constraints. The approach
   consists of two components: (a) task prioritization based on a
   multi-legit regression model for each type of PM task, and (b) task
   rescheduling based on a binary integer programming (BIP) model with
   constraints on single-skilled and multi-skilled workforce availability.
   The task prioritization component develops a multi-legit regression for
   machine failure probability associated with each type of PM task at the
   beginning of the year, using historical data on machine utilization, PM,
   and machine breakdowns. At the start of each PM time-bucket (e.g., a
   month), we use the updated machine failure probability for each
   candidate PM task to compute its current contribution to net PM savings,
   which indicates its current priority. The task rescheduling BIP model
   incorporates the priorities in selecting tasks for the current bucket to
   maximize PM effectiveness subject to workforce availability, yielding an
   adaptive and effective PM schedule for each time-bucket of the master PM
   schedule. We examine the effect of using multi-skilled workforce on the
   overall PM effectiveness, and also provide an illustration from a
   newspaper publishing environment to explain the use of the approach. We
   have developed four heuristic algorithms to yield good solutions to
   large scale versions of this scheduling problem. The heuristics perform
   extremely well, and the best heuristic solution is within 1.4% of
   optimality on an average.
ZA 0
ZS 1
ZR 0
Z8 0
ZB 0
TC 26
Z9 27
SN 0025-1909
UT WOS:A1997XG07700007
ER

PT J
AU Desaulniers, G
   Desrosiers, J
   Dumas, Y
   Solomon, MM
   Soumis, F
TI Daily aircraft routing and scheduling
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 841
EP 855
DI 10.1287/mnsc.43.6.841
PD JUN 1997
PY 1997
AB In this paper we consider the daily aircraft routing and scheduling
   problem (DARSP). It consists of determining daily schedules which
   maximize the anticipated profits derived from the aircraft of a
   heterogeneous fleet. This fleet must cover a set of operational flight
   legs with known departure time windows, durations and profits according
   to the aircraft type. We present two models for this problem: a Set
   Partitioning type formulation and a time constrained multicommodity
   network flow formulation. We describe the network structure of the
   subproblem when a column generation technique is applied to solve the
   linear relaxation of the first model and when a Dantzig-Wolfe
   decomposition approach is used to solve the linear relaxation of the
   second model. The linear relaxation of the first model provides upper
   bounds. Integer solutions to the overall problem are derived through
   branch-and-bound. By exploiting the equivalence between the two
   formulations, we propose various optimal branching strategies compatible
   with the column generation technique. Finally we report computational
   results obtained an data provided by two different airlines. These
   results show that significant profit improvement can be generated by
   solving the DARSP using our approach and that this can be obtained in a
   reasonable amount of CPU time.
OI Desaulniers, Guy/0000-0003-4469-9813
TC 107
ZS 0
ZA 0
ZB 0
Z8 2
ZR 0
Z9 108
SN 0025-1909
UT WOS:A1997XG07700008
ER

PT J
AU Lefebvre, LA
   Mason, R
   Lefebvre, E
TI The influence prism in SMEs: The power of CEOs' perceptions on
   technology policy and its organizational impacts
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 856
EP 878
DI 10.1287/mnsc.43.6.856
PD JUN 1997
PY 1997
AB The research proposes a model, which relates the following variables:
   (a) the CEO's perceptions of the environment, (b) the strategic business
   orientation, scanning, and structural characteristics, (c) technology
   policy, (d) realized innovative efforts of the firm, and (e) measures of
   firm performance. The empirical data from small manufacturing
   enterprises (SMEs) that share a common economic and industrial
   environment show that CEOs' perceptions of external environment-and riot
   objective measures-are key significant issues with respect to technology
   policy formulation and enactment in SMEs and its subsequent
   organizational impacts. In particular, perceived environmental hostility
   and dynamism are shown to have specific and differing moderating roles
   on the form and strength of the relationships between technology policy
   and its determinants and between technology policy and realized
   innovative efforts, Furthermore, a more aggressive technology policy
   leads to greater realized innovative efforts, which in turn are
   positively related to export performance and, to a lesser extent, to
   financial performance.
ZR 0
ZA 0
Z8 2
ZB 0
ZS 0
TC 76
Z9 78
SN 0025-1909
UT WOS:A1997XG07700009
ER

PT J
AU Guerrero, VM
   Elizondo, JA
TI Forecasting a cumulative variable using its partially accumulated data
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 879
EP 889
DI 10.1287/mnsc.43.6.879
PD JUN 1997
PY 1997
AB Several forecasting algorithms have been proposed to forecast a
   cumulative variable using its partially accumulated data. Some
   particular cases of this problem are known in the literature as the
   ''style goods inventory problem'' or as ''forecasting shipments using
   firm orders-to-date'', among other names. Here we summarize some of the
   most popular techniques and propose a statistical approach to
   discriminate among them in an objective (data-based) way. Our basic idea
   is to use statistical models to produce minimum mean square error
   forecasts and let the data lead us to select an appropriate model to
   represent their behavior. We apply our proposal to some published data
   showing total accumulated values with constant level and then to two
   actual sets of data pertaining to the Mexican economy, showing a
   nonconstant level. The forecasting performance of the statistical models
   was evaluated by comparing their results against those obtained with
   algorithmic solutions. In general the models produced better forecasts
   for all lead times, as indicated by the most common measures of
   forecasting accuracy and precision.
RI Guerrero, Victor M./G-1986-2019
OI Guerrero, Victor M./0000-0003-2184-5216
TC 18
ZS 0
ZB 0
ZA 0
Z8 0
ZR 0
Z9 18
SN 0025-1909
UT WOS:A1997XG07700010
ER

PT J
AU Leschke, JP
   Weiss, EN
TI The multi-item setup-reduction investment-allocation problem with
   continuous investment-cost functions
SO MANAGEMENT SCIENCE
VL 43
IS 6
BP 890
EP 894
DI 10.1287/mnsc.43.6.890
PD JUN 1997
PY 1997
AB In this note, we analyze investment priorities for setup-reduction
   programs in a multi-product system. We provide an objective function
   transformation for the model developed by Porteus multi-product (1985)
   that permits the use of marginal analysis in both the single- and
   multiple-item problems. For the multiple-item problem, we show that
   managers should not reduce the setup for each product to its optimum in
   sequential order. This is in contrast to recommendations found in the
   existing literature.
ZA 0
ZB 0
TC 16
ZS 0
Z8 0
ZR 0
Z9 16
SN 0025-1909
UT WOS:A1997XG07700011
ER

PT J
AU Bai, DW
   Carpenter, T
   Mulvey, J
TI Making a case for robust optimization models
SO MANAGEMENT SCIENCE
VL 43
IS 7
BP 895
EP 907
DI 10.1287/mnsc.43.7.895
PD JUL 1997
PY 1997
AB Robust optimization searches for recommendations that are relatively
   immune to anticipated uncertainty in the problem parameters.
   Stochasticities are addressed via a set of discrete scenarios. This
   paper presents applications in which the traditional stochastic linear
   program fails to identify a robust solution-despite the presence of a
   cheap robust point. Limitations of piecewise linearization are
   discussed. We argue that a concave utility function should be
   incorporated in a model whenever the decision maker is risk averse.
   Examples are taken from telecommunications and financial planning.
ZR 0
ZA 0
TC 82
ZS 0
ZB 5
Z8 9
Z9 91
SN 0025-1909
UT WOS:A1997XL35200001
ER

PT J
AU Cao, BY
   Glover, F
TI Tabu search and ejection chains - Application to a node weighted version
   of the cardinality-constrained TSP
SO MANAGEMENT SCIENCE
VL 43
IS 7
BP 908
EP 921
DI 10.1287/mnsc.43.7.908
PD JUL 1997
PY 1997
AB A cardinality-constrained TSP (CC-TSP) problem requires the salesman to
   visit at. least L and at most U cities, represented toy nodes of a
   graph. The objective of this problem is to maximize the sum of weights
   of nodes visited. In this paper we propose a tabu search method based on
   ejection chain procedures, which have proved effective for many kinds of
   combinatorial optimization problems. Computational results on a set of
   randomly generated test problems with various implementations of the
   algorithm are reported.
ZB 0
ZA 0
TC 13
ZR 0
ZS 0
Z8 1
Z9 14
SN 0025-1909
EI 1526-5501
UT WOS:A1997XL35200002
ER

PT J
AU Eisenstein, DD
   Iyer, AV
TI Garbage collection in Chicago: A dynamic scheduling model
SO MANAGEMENT SCIENCE
VL 43
IS 7
BP 922
EP 933
DI 10.1287/mnsc.43.7.922
PD JUL 1997
PY 1997
AB We investigate the scheduling of garbage trucks in the city of Chicago,
   Analysis of data collected from the system shows that city blocks differ
   in the rate at which garbage is collected. However, in the current
   system, each truck visits the dumpsite two times each day. Our approach
   is to devise a flexible routing scheme in which some routes visit the
   dumpsite only once per day, while others visit the dumpsite twice per
   day depending on the blocks assigned to the route. We use a Markov
   decision process to model the impact on capacity of using flexible
   routes, This provides a dynamic scheduling algorithm that adjusts the
   number of dumpsite visits throughout the week to maximize service level.
   Results of the model suggest a potential reduction in truck capacity of
   12-16% for a set of five pilot wards. This paper shows that flexible
   schedules can significantly reduce the capacity required to operate a
   system in the presence of variability.
ZS 1
ZB 6
ZR 0
Z8 1
TC 29
ZA 0
Z9 31
SN 0025-1909
UT WOS:A1997XL35200003
ER

PT J
AU Levinthal, DA
TI Adaptation on rugged landscapes
SO MANAGEMENT SCIENCE
VL 43
IS 7
BP 934
EP 950
DI 10.1287/mnsc.43.7.934
PD JUL 1997
PY 1997
AB A simple model is developed to explore the interrelationship between
   processes of organizational level change and population selection
   forces. A critical property of the model is that the effect on
   organizational fitness of the various attributes that constitute an
   organization's form is interactive. As a result of these interaction
   effects, the fitness landscape is ''rugged.'' An organization's form at
   founding has a persistent effect on its future form when there are
   multiple peaks in the fitness landscape, since the particular peak that
   an organization discovers is influenced by its starting position in the
   space of alternative organizational forms. Selection pressures influence
   the distribution of the organizational forms that emerge from the
   process of local adaptation. The ability of established organizations to
   respond to changing environments is importantly conditioned by the
   extent to which elements of organizational form interact in their effect
   on organizational fitness. Tightly coupled organizations are subject to
   high rates of failure in changing environments. Furthermore, successful
   ''reorientations'' are strongly associated with survival for tightly
   coupled organizations, but not for more loosely coupled organizations
   that are able to engage in effective local adaptation.
RI Levinthal, Daniel/D-1073-2010
OI Levinthal, Daniel/0000-0002-8740-6091
ZS 5
ZR 2
ZA 0
TC 916
Z8 20
ZB 24
Z9 944
SN 0025-1909
EI 1526-5501
UT WOS:A1997XL35200004
ER

PT J
AU Platt, DE
   Robinson, LW
   Freund, RB
TI Tractable (Q,R) heuristic models for constrained service levels
SO MANAGEMENT SCIENCE
VL 43
IS 7
BP 951
EP 965
DI 10.1287/mnsc.43.7.951
PD JUL 1997
PY 1997
AB The fill rate (the proportion of demand that is satisfied from stock) is
   a viable alternative in inventory models to the hard-to-quantify penalty
   cost. However, a number of difficulties have impeded its implementation,
   among them that the existing cycle-based approximate solutions do not
   reflect the possibility of multiple outstanding orders and that the
   optimal policy cannot be found directly, but must be iteratively
   calculated. We show that for a large family of leadtime demand
   distributions, the optimal policy depends on only two parameters: the
   fill rate and the economic order quantity (EOQ) scaled by the standard
   deviation of demand over the constant leadtime. If we then assume that
   the leadtime demand is normally distributed, we can use the asymptotic
   results as the EOQ goes to zero and to positive infinity to fit
   atheoretic curves for the order quantity Q and the reorder point R.
   These fitted curves yield a good (Q, R) policy without iteration. We
   also find that, among the set of simple heuristics, the limit form as
   EOQ goes to positive infinity provides a better alternative to simply
   setting Q equal to the EOQ.
ZB 0
TC 40
ZS 1
Z8 1
ZA 0
ZR 0
Z9 42
SN 0025-1909
UT WOS:A1997XL35200005
ER

PT J
AU Eliashberg, J
   Singpurwalla, ND
   Wilson, SP
TI Calculating the reserve for a time and usage indexed warranty
SO MANAGEMENT SCIENCE
VL 43
IS 7
BP 966
EP 975
DI 10.1287/mnsc.43.7.966
PD JUL 1997
PY 1997
AB Many products carry a warranty that offers protection for the consumer
   against low quality. warranties are often two dimensional, such as an
   automobile warranty that guarantees repair up to a certain time and
   mileage after sale. This paper considers the problem of assessing the
   size of a reserve needed by the manufacturer to meet future claims for
   such a two-dimensional warranty. To do this, a class of failure models
   that describe failure by two scales-time and mileage, for example-must
   be developed. The first half of the paper is devoted to this
   development. Then the warranty reserve problem is considered in more
   detail. The problem is described and a decision-theoretic solution,
   making use of the newly developed reliability model, is proposed.
OI Wilson, Simon/0000-0003-0312-3586; SINGPURWALLA, Nozer
   Darabsha/0000-0003-3578-2308
TC 39
ZA 0
ZR 0
ZB 2
ZS 0
Z8 0
Z9 39
SN 0025-1909
UT WOS:A1997XL35200006
ER

PT J
AU Carley, KM
   Lin, ZA
TI A theoretical study of organizational performance under information
   distortion
SO MANAGEMENT SCIENCE
VL 43
IS 7
BP 976
EP 997
DI 10.1287/mnsc.43.7.976
PD JUL 1997
PY 1997
AB How should organizations of intelligent agents be designed so that they
   exhibit high performance despite information distortion? We present a
   formal information-based network model of organizational performance
   given a distributed decision making environment in which agents
   encounter a radar detection task. Using this model, we examine rite
   performance of organizations with, various designs in different task
   environments subject to various types of information distortion, We
   distinguish five sources of information distortion-missing information,
   incorrect information, agent unavailability, communication channel
   breakdowns, and agent turnover. This formal analysis suggests that: (1)
   regardless of information, distortion, performance is enhanced if there
   is a match between the complexity of organizational design and task
   environment; (2) task environment characteristics have more effect on
   performance than information distortion and the organizational design;
   (3) the effects of information distortion can be combated by training,
   but only to a limited extent; and (4) technology based information
   distortion typically is more debilitating than personnel induced
   information distortion.
OI Carley, Kathleen M./0000-0002-6356-0238
ZA 0
ZR 0
ZB 0
Z8 1
ZS 0
TC 69
Z9 70
SN 0025-1909
UT WOS:A1997XL35200007
ER

PT J
AU Novomestky, F
TI A dynamic, globally diversified, index neutral synthetic asset
   allocation strategy
SO MANAGEMENT SCIENCE
VL 43
IS 7
BP 998
EP 1016
DI 10.1287/mnsc.43.7.998
PD JUL 1997
PY 1997
AB An investor with the ability to assess the prospective return and risk
   structure of the global capital markets can construct portfolios that,
   over time, will not only outperform actively or passively managed
   domestic asset portfolios but will also outperform passively managed
   global portfolios. A Bayesian approach to dynamic seemingly unrelated
   regression (DSUR) is a robust and effective means to forecast the
   one-step ahead, conditional distribution of asset returns. This approach
   recognizes the time-varying nature of the global capital markets. The
   predictive moments are used to derive a single-factor return model once
   an index portfolio is specified. The index portfolio represents an
   investor's underlying portfolio. Given the factor model that assesses
   the relative attractiveness and risk of the assets in relation to the
   index, an index neutral portfolio is constructed as an overlay to
   enhance the returns of the index portfolio. This portfolio is
   mean-variance optimal, is notional neutral (i.e., the sum of the asset
   exposures is zero), and has returns that are designed to be uncorrelated
   with the returns of the index portfolio. The implementation of such an
   index neutral portfolio using derivative securities is simulated over
   the period January 1988 to December 1993.
ZA 0
ZB 0
ZR 0
ZS 1
Z8 0
TC 6
Z9 6
SN 0025-1909
EI 1526-5501
UT WOS:A1997XL35200008
ER

PT J
AU Gong, LG
   Jwo, WS
   Tang, K
TI Using on-line sensors in statistical process control
SO MANAGEMENT SCIENCE
VL 43
IS 7
BP 1017
EP 1028
DI 10.1287/mnsc.43.7.1017
PD JUL 1997
PY 1997
AB As manufacturing technology moves toward more computerized automation,
   statistical process control (SPC) techniques must adapt to keep pace
   with the new environment and take advantage of the development in
   automated on-line sensors. In this paper, a two-phase procedure is
   proposed for combining an on-line sensor and a control chart to improve
   statistical process control decisions. In phase 1 of this procedure, a
   production process is monitored continually by a sensor. When a sensor
   warning signal is observed, phase 2 takes place: A sample of items is
   drawn from the process and inspected. If the sample mean is outside the
   predetermined control limits, the process is stopped, and a search is
   initiated to determine the actual process status for possible necessary
   adjustment. If the sample mean is within the control limits, the process
   continues. A mathematical model is formulated for jointly determining
   the sample size and the control limit of the control chart and a
   decision rule for sending out sensor warning signals. The model is based
   on the assumption that there is only a weak relationship between the
   sensor measurement and the process condition. A solution algorithm based
   on a numerical search is developed. A numerical example is used to show
   the advantage of the proposed model over the models based separately on
   the sensor and the control chart, and a sensitivity analysis is used to
   show the effects of several important model parameters on the optimal
   solution.
OI TANG, KWEI/0000-0002-1777-6476
ZA 0
ZS 0
ZB 0
Z8 1
TC 16
ZR 0
Z9 17
SN 0025-1909
UT WOS:A1997XL35200009
ER

PT J
AU Connolly, T
   Dean, D
TI Decomposed versus holistic estimates of effort required for software
   writing tasks
SO MANAGEMENT SCIENCE
VL 43
IS 7
BP 1029
EP 1045
DI 10.1287/mnsc.43.7.1029
PD JUL 1997
PY 1997
AB We examine decision analysis' central ''decomposition principle'' in the
   context of work-time estimates of software writers. Two experiments
   examined the abilities of advanced programming students to estimate how
   long they would take to complete specific software projects. They
   estimated their own work times both for entire projects and for their
   constituent subtasks. Estimates showed varying degrees of overoptimism
   and overpessimism but all were much too tight, with almost half of
   actual outcomes falling in the 1% tails of estimated distributions. This
   overtightness was unaffected by task decomposition, question wording,
   question order, or training in estimation. It was, however,
   significantly reduced by a procedure aimed at inducing generous upper
   and lower plausible limits. An underlying model of incomplete search is
   used to connect these findings to existing themes in cognition and
   judgment research, as well as to practical application. The findings
   suggest that the best level of decomposition at which to elicit
   work-time estimates may depend on task, judge, and elicitation method.
ZR 0
ZB 2
TC 73
ZA 0
Z8 1
ZS 0
Z9 74
SN 0025-1909
UT WOS:A1997XL35200010
ER

PT J
AU Lotfi, V
   Yoon, YS
   Zionts, S
TI Aspiration-based search algorithm (ABSALG) for multiple objective linear
   programming problems: Theory and comparative tests
SO MANAGEMENT SCIENCE
VL 43
IS 8
BP 1047
EP 1059
DI 10.1287/mnsc.43.8.1047
PD AUG 1997
PY 1997
AB We develop an interactive method for multiple objective linear
   programming based on aspiration levels of a decision maker. The method
   assumes an unknown pseudoconcave preference structure of a decision
   maker throughout the decision process, and the decision maker's ability
   to select a preferred solution from p + 1 alternatives, where p is the
   number of objectives. In addition to presenting the supporting theory
   and algorithm, we perform a comparative study using a fictitious
   decision maker, comparing our approach to those of Steuer and Choo
   (1983) and Reeves and Franz (1985). All three methods are interactive.
   During an iteration, each method presents several solution alternatives
   to the decision maker simultaneously. Our approach utilizes a
   Tchebycheff function that facilitates attainment of an optimum at a
   nonextreme point solution. The statistics collected in the comparative
   study provide insights into the nature of the algorithms and the
   behavior of the solution techniques with different categories of problem
   structure and different underlying utility functions.
ZR 0
ZA 0
TC 11
ZB 0
Z8 0
ZS 0
Z9 11
SN 0025-1909
UT WOS:A1997XR72700001
ER

PT J
AU Federgruen, A
   vanRyzin, G
TI Probabilistic analysis of a combined aggregation and math programming
   heuristic for a general class of vehicle routing and scheduling problems
SO MANAGEMENT SCIENCE
VL 43
IS 8
BP 1060
EP 1078
DI 10.1287/mnsc.43.8.1060
PD AUG 1997
PY 1997
AB We propose and analyze a heuristic that uses region partitioning and an
   aggregation scheme for customer attributes (load size, time windows,
   etc.) to create a finite number of customer types. A math program is
   solved based on these aggregated customer types to generate a feasible
   solution to the original problem. The problem class we address is quite
   general and defined by a number of general consistency properties.
   Problems in this class include VRPs with general distance norms,
   capacitated problems, time window VRPs, pick-up and delivery problems,
   combined inventory control and routing problems and are routing.
   We provide a probabilistic analysis of this heuristic under very general
   probabilistic assumptions. In particular, we do not require independence
   between customer locations and their various attributes. The heuristic
   is (a.s.) epsilon-optimal as the number of customers n tends to
   infinity. Further, it runs in O(n log n) time for a fixed relative
   error, and can be designed to be asymptotically optimal while still
   running in polynomial time. We characterize the asymptotic average value
   of the heuristic and the optimal solution as the limit of a sequence of
   linear program values. We also provide bounds on the rate of convergence
   to the asymptotic value and bounds on tail probabilities. Finally, we
   discuss numerical issues involved in implementing our heuristic.
ZS 0
TC 1
Z8 0
ZB 0
ZR 0
ZA 0
Z9 1
SN 0025-1909
UT WOS:A1997XR72700002
ER

PT J
AU Upton, DM
TI Process range in manufacturing: An empirical study of flexibility
SO MANAGEMENT SCIENCE
VL 43
IS 8
BP 1079
EP 1092
DI 10.1287/mnsc.43.8.1079
PD AUG 1997
PY 1997
AB This paper examines the relationship between one form of manufacturing
   flexibility-process range-and structure, infrastructure, and managerial
   policy at the plant level. The paper provides evidence of the strength
   of the links between manufacturing flexibility and such factors as
   scale, technology vintage, computer integration, and workforce
   management. Data from 54 plants in the fine-paper industry are
   presented, and a model of the determinants of short-term flexibility is
   developed. The plants examined differed by a factor of 20 in their
   ability to accommodate large process variation. The evidence suggests
   that flexibility is strongly negatively related to scale and degree of
   computer integration, yet positively related to newer vintages of
   mechanical technology and workforce experience. Some results differ
   significantly from the prevailing view of the industry, in particular,
   that newer plants are less flexible. The paper shows that newer machine
   technology is more flexible once other factors are controlled for. In
   the longer term, the results show that management has a significant
   impact on the improvement of flexibility in operations, regardless of
   the technology and infrastructure in place. Plant network managers'
   views of flexibility are important. The data suggest that inflexible
   plants may be inflexible partly as a result of their being considered
   inflexible by network managers, and never being assigned the product
   range needed to improve the capability.
TC 93
ZB 0
ZA 0
ZR 0
ZS 3
Z8 0
Z9 96
SN 0025-1909
UT WOS:A1997XR72700003
ER

PT J
AU Ha, AY
TI Inventory rationing in a make-to-stock production system with several
   demand classes and lost sales
SO MANAGEMENT SCIENCE
VL 43
IS 8
BP 1093
EP 1103
DI 10.1287/mnsc.43.8.1093
PD AUG 1997
PY 1997
AB This paper considers the stock rationing problem of a single-item,
   make-to-stock production system with several demand classes and lost
   sales. For the case of Poisson demands and exponential production times,
   we show that the optimal policy can be characterized by a sequence of
   monotone stock rationing levels. For each demand class, there exists a
   stock rationing level at or below which it is optimal to start rejecting
   the demand of this class in anticipation of future arrival of higher
   priority demands. A simple queueing model is analyzed to compute the
   operating cost of a rationing policy. In a numerical study, we compare
   the optimal rationing policy with a first-come first-served policy to
   investigate the benefit of stock rationing under different operating
   conditions of the system.
Z8 13
ZR 0
ZA 0
TC 221
ZS 0
ZB 1
Z9 234
SN 0025-1909
UT WOS:A1997XR72700004
ER

PT J
AU Smith, RP
   Eppinger, SD
TI A predictive model of sequential iteration in engineering design
SO MANAGEMENT SCIENCE
VL 43
IS 8
BP 1104
EP 1120
DI 10.1287/mnsc.43.8.1104
PD AUG 1997
PY 1997
AB This paper presents a model describing sequential iteration, one of the
   fundamental solution processes experienced in complex engineering design
   projects. The model is based upon the design structure matrix
   representation and assumes that each individual design activity is of
   deterministic duration with probabilistic repetition, where the repeat
   probabilities are defined by the strength of the task coupling. Using
   the model, we are able to compute rite expected duration of the
   iterative solution process, and to suggest an initial ordering of the
   coupled design tasks to minimize the expected duration. We conclude the
   paper with a discussion of limitations and several extensions to the
   sequential iteration model.
ZA 0
ZS 0
ZR 0
Z8 40
TC 242
ZB 1
Z9 280
SN 0025-1909
UT WOS:A1997XR72700005
ER

PT J
AU Munoz, DF
   Glynn, PW
TI A batch means methodology for estimation of a nonlinear function of a
   steady-state mean
SO MANAGEMENT SCIENCE
VL 43
IS 8
BP 1121
EP 1135
DI 10.1287/mnsc.43.8.1121
PD AUG 1997
PY 1997
AB We study the estimation of steady-state performance measures from an
   R-d-valued stochastic process Y = {Y(t) : t greater than or equal to 0}
   representing the output of a simulation. In many applications, we may be
   interested in the estimation of a steady-state performance measure that
   cannot be expressed as a steady-state mean r, e.g., the variance of the
   steady-state distribution, the ratio of steady-state means, and
   steady-state conditional expectations. These examples are particular
   cases of a more general problem-the estimation of a (nonlinear) function
   f(r) of r. We propose a batch-means-based methodology that allows us to
   use jackknifing to reduce the bias of the point estimator.
   Asymptotically valid confidence intervals for f(r) are obtained by
   combining three different point estimators (classical, batch means, and
   jackknife) with two different variability estimators (classical and
   jackknife). The performances of the point estimators are discussed by
   considering asymptotic expansions for their biases and mean squared
   errors. Our results show that, if the run length is large enough, the
   jackknife point estimator provides the smallest bias, with no
   significant increase in the mean squared error.
RI Munoz, David F/R-2033-2017
OI Munoz, David F/0000-0003-1241-0704
ZR 0
Z8 0
ZS 1
TC 18
ZB 0
ZA 0
Z9 19
SN 0025-1909
UT WOS:A1997XR72700006
ER

PT J
AU Marakas, GM
   Elam, JJ
TI Creativity enhancement in problem solving: Through software or process?
SO MANAGEMENT SCIENCE
VL 43
IS 8
BP 1136
EP 1146
DI 10.1287/mnsc.43.8.1136
PD AUG 1997
PY 1997
AB This paper reports the results of a controlled laboratory experiment in
   which the work of Elam and Mead (1990) was both replicated and extended
   to explore how knowledge and use of a creativity-enhancing process
   employed both manually and delivered via computer software affect the
   level of creativity in response to a problem-solving ask. The results
   suggest the enhancement of creativity in response to open-ended problems
   is significantly affected by the process employed by the decision maker
   rather than the vehicle by which the process is delivered. Further, the
   results indicate that the capability of a decision support system (DSS)
   to provide directed guidance in the application of a process combined
   with user knowledge of the underlying process model improves creativity
   enhancement over use of either the DSS or the process alone.
RI Marakas, George M/D-7032-2018; Marakas, George/
OI Marakas, George/0000-0003-4112-2322
ZS 0
ZA 0
TC 36
ZR 0
Z8 1
ZB 0
Z9 37
SN 0025-1909
UT WOS:A1997XR72700007
ER

PT J
AU Rangaswamy, A
   Shell, GR
TI Using computers to realize joint gains in negotiations: Toward an
   ''electronic bargaining table''
SO MANAGEMENT SCIENCE
VL 43
IS 8
BP 1147
EP 1163
DI 10.1287/mnsc.43.8.1147
PD AUG 1997
PY 1997
AB Multiissue negotiations present opportunities for tradeoffs that create
   gains for one or more parties without causing any party to be worse off.
   The literature suggests that parties are often unable to identify and
   capitalize on such trades. We present a Negotiation Support System,
   called NEGOTIATION ASSISTANT, that enables negotiators to analyze their
   own preferences and provides a structured negotiation process to help
   parties move toward optimal trades. The underlying model is based on a
   multiattribute representation of preferences and communications over a
   computer network where offers and counteroffers are evaluated according
   to one's own preferences. The parties can send and receive both formal
   offers and informal messages. If and when agreement is reached, the
   computer evaluates the agreement and suggests improvements based on the
   criteria of Pareto-superiority. In this paper, we motivate the system,
   present its analytical foundations, discuss its design and development,
   and provide an experimental assessment of its ''value-in-use.'' Our
   results strongly suggest that parties using the system in structured
   negotiation settings would achieve better outcomes than parties
   negotiating face to face or over an e-mail messaging facility, other
   things being equal. For example, only 4 of the 34 dyads (11.1%)
   negotiating a simulated sales transaction face to face or over e-mail
   reached an ''integrative'' settlement, as compared with 29 of the 68
   dyads (42.6%) using NEGOTIATION ASSISTANT. Systems such as NEGOTIATION
   ASSISTANT have the potential to be used in emerging ''electronic
   markets.''
ZR 0
ZA 0
Z8 1
ZB 0
TC 90
ZS 0
Z9 91
SN 0025-1909
UT WOS:A1997XR72700008
ER

PT J
AU Gavish, B
   Kalvenes, J
TI LEOS - Optimal satellite launch policies: The static case
SO MANAGEMENT SCIENCE
VL 43
IS 8
BP 1164
EP 1176
DI 10.1287/mnsc.43.8.1164
PD AUG 1997
PY 1997
AB Low earth orbit satellite (LEOS) systems promise to provide global
   communication. A LEOS system consists of a large number of satellites in
   low orbits. A satellite has a limited Life of approximately five to
   eight years. Therefore, frequent satellite replenishments are required,
   and the LEOS systems will be facing annual replenishment costs in the
   range of several hundred million dollars. This paper considers static
   satellite launch policies for LEGS systems. The satellite launch problem
   is formulated and a solution method based on dynamic programming is
   proposed Lexicographic ordering is used to reduce the search space of
   the dynamic program to a moderate size. An algorithm for calculating
   optimal static policies is used to demonstrate the potentially
   significant economic impact of satellite launch policies on system
   maintenance costs.
ZR 0
Z8 0
ZS 0
TC 5
ZB 0
Z9 5
SN 0025-1909
UT WOS:A1997XR72700009
ER

PT J
AU Booth, GG
   Broussard, JP
   Martikainen, T
   Puttonen, V
TI Prudent margin levels in the Finnish stock index futures market
SO MANAGEMENT SCIENCE
VL 43
IS 8
BP 1177
EP 1188
DI 10.1287/mnsc.43.8.1177
PD AUG 1997
PY 1997
AB Futures market officials are confronted with the difficult task of
   setting appropriate margin levels that must balance the costs of trader
   default and the benefits of increased market liquidity. One way to guard
   against default is prudent margin setting practices designed to protect
   futures positions from extreme price movements. The objective of this
   research is to extrapolate the probabilities of encountering extreme
   price movements by applying statistical extreme value theory to the
   Finnish stock index futures market. The extreme value technique is found
   to be appropriate since it generates theoretical margin violation
   probabilities that closely follow the empirical probability
   distribution. The extrapolated results provide decision makers
   information on extreme events that have not yet occurred.
RI Broussard, John/AAQ-8380-2020; Puttonen, Vesa/
OI Broussard, John/0000-0002-5090-9947; Puttonen, Vesa/0000-0001-8353-1410
ZB 0
ZA 0
Z8 4
ZR 0
ZS 0
TC 26
Z9 30
SN 0025-1909
UT WOS:A1997XR72700010
ER

PT J
AU Sox, CR
   Thomas, LJ
   McClain, JO
TI Coordinating production and inventory to improve service
SO MANAGEMENT SCIENCE
VL 43
IS 9
BP 1189
EP 1197
DI 10.1287/mnsc.43.9.1189
PD SEP 1997
PY 1997
AB Customer service has assumed strategic importance in most manufacturing
   environments. Corporate reputations often depend on how reliably
   promised lead times are met. A goal of filling orders within a service
   window of T time units is often encountered in practice. This goal
   ignores the differences among types of units, treating all customers as
   equally important. Keeping finished goods inventory of all items is only
   one, and often not the best, way to achieve this objective. High-demand
   items naturally have safety stock assigned to them, but in many
   organizations there are so many very-low-demand items that keeping any
   stock in these items is prohibitively expensive. Customer service can be
   maintained for these low-demand items by giving them higher production
   priority when a demand occurs. In this paper, stochastic analysis and
   simulation are employed to test the merit of this idea. Changes in
   management structure to allow this type of system are discussed.
ZS 0
TC 36
ZB 0
ZR 0
Z8 1
ZA 0
Z9 37
SN 0025-1909
UT WOS:A1997XX48700001
ER

PT J
AU Chevalier, PB
   Wein, LM
TI Inspection for circuit board assembly
SO MANAGEMENT SCIENCE
VL 43
IS 9
BP 1198
EP 1213
DI 10.1287/mnsc.43.9.1198
PD SEP 1997
PY 1997
AB Several stages of tests are typically performed in circuit board
   assembly, and each test consists of one or more noisy measurements. We
   consider the problem of jointly optimizing the allocation of inspection
   and the testing policy in a system with a predefined. inspection
   configuration; that is, at which stages should a board be inspected, and
   at these stages, whether to accept or reject a board based on noisy test
   measurements. The objective is to minimize the expected costs for
   testing, repair, and defective items shipped to customers. We analyze
   the problem and document an application of the model to an industrial
   facility. Since we were unable to gather all the necessary data, the
   model was applied in a limited and piecemeal fashion. Nevertheless, the
   proposed policy significantly improves upon the facility's historical
   policy.
OI Chevalier, Philippe/0000-0001-6443-624X
ZA 0
ZB 0
Z8 0
ZS 0
TC 14
ZR 0
Z9 14
SN 0025-1909
UT WOS:A1997XX48700002
ER

PT J
AU Porteus, EL
   Angelus, A
TI Opportunities for improved statistical process control
SO MANAGEMENT SCIENCE
VL 43
IS 9
BP 1214
EP 1228
DI 10.1287/mnsc.43.9.1214
PD SEP 1997
PY 1997
AB Our Bayesian dynamic programming model builds on existing models to
   account for inspection delay, choice of keeping production going during
   inspection and/or restoration, and lot sizing. We focus on describing
   how dynamic statistical process control (DSPC) rules can improve on
   traditional, static ones. We explore numerical examples and identify
   nine opportunities for improvement. Some of these ideas are well known
   and strongly supported in the literature, Other ideas may be less well,
   understood. Our list includes the following: Cancel some of the
   inspections called for by an (economically) optimal static rule when
   starting in control (such as at the beginning of a production run and
   following a restoration). Inspect more frequently than called for by an
   optimal static rule once inspections begin, and inspect even more
   frequently than that when negative evidence is accumulated. Utilize
   evidence from previous inspections to justify either restoration or
   another inspection. Cancel inspections and hesitate to restore the
   process at the end of a production run. Consider using scheduled
   restoration, in which restoration is carried out regardless of the
   results of any inspections. implementation, limitations, and extensions
   are addressed.
RI ANGELUS, Alexandar/D-2215-2010
ZB 0
Z8 1
TC 34
ZR 0
ZS 1
ZA 0
Z9 36
SN 0025-1909
UT WOS:A1997XX48700003
ER

PT J
AU Kamps, J
   Masuch, M
TI Partial deductive closure: Logical simulation and management science
SO MANAGEMENT SCIENCE
VL 43
IS 9
BP 1229
EP 1245
DI 10.1287/mnsc.43.9.1229
PD SEP 1997
PY 1997
AB This research is part of a larger effort to build machine-based tools
   for developing scientific theories. In analogy with the research process
   in empirical research, we describe a logical cycle of theory
   development: (1) starting with an informal version of a theory, (2) then
   moving to its formal representation, (3) applying formal logic to
   investigate this representation, and (4) using the results as feedback
   for the update/revision of the original theory. A central aspect of the
   logical cycle is the detection of the (hidden) implications of a theory
   (called ''partial deductive closure''). In this paper, we present an
   algorithm that performs the partial deductive closure for a relevant
   class of theorems, while filtering out trivial results. The algorithm is
   applied to an important organization theory, Organizational Ecology, and
   is shown to generate new theorems of interest.
ZR 0
ZB 0
Z8 0
TC 4
ZS 0
ZA 0
Z9 4
SN 0025-1909
UT WOS:A1997XX48700004
ER

PT J
AU Sakakibara, S
   Flynn, BB
   Schroeder, RG
   Morris, WT
TI The impact of just-in-time manufacturing and its infrastructure on
   manufacturing performance
SO MANAGEMENT SCIENCE
VL 43
IS 9
BP 1246
EP 1257
DI 10.1287/mnsc.43.9.1246
PD SEP 1997
PY 1997
AB We consider Just-in-Time (JIT) to be an overall organizational
   phenomenon. Accordingly, we developed and tested a model that includes
   both JIT practices and the infrastructure practices hypothesized to
   provide an environment in which JIT practices perform more effectively.
   Canonical correlation analysis was used to test five hypotheses. The
   results indicated that: (1) there was not a significant relationship
   between the use of JIT practices, alone, and manufacturing performance;
   (2) there was a very strong relationship between FT practices and
   infrastructure practices; (3) the combination of JIT management and
   infrastructure practice was related to manufacturing performance; (4)
   infrastructure, by itself, is sufficient to explain manufacturing
   performance; and (5) manufacturing performance was related to
   competitive advantage. These findings provide support for the notion
   that JIT is an overall organizational phenomenon, rather than limited to
   strictly shop floor practices, and that at least part of its effect on
   manufacturing performance may bet through providing a set of improvement
   targets and discipline for the entire organization. in addition, the
   analysis highlights the areas of infrastructure practice most relevant
   for future research.
Z8 0
ZR 0
ZB 3
ZS 2
TC 236
ZA 4
Z9 242
SN 0025-1909
UT WOS:A1997XX48700005
ER

PT J
AU Hendricks, KB
   Singhal, VR
TI Does implementing an effective TQM program actually improve operating
   performance? Empirical evidence from firms that have won quality awards
SO MANAGEMENT SCIENCE
VL 43
IS 9
BP 1258
EP 1274
DI 10.1287/mnsc.43.9.1258
PD SEP 1997
PY 1997
AB This study explores the hypotheses that implementing effective total
   quality management (TQM) programs improves the operating performance of
   firms. The winning of quality awards is used as a proxy for the
   effective implementation of TQM programs. Changes in various performance
   measures for a test sample of quality-award winners are compared against
   a sample of control firms. Our statistical tests provide strong evidence
   that firms that have won quality awards outperform the control firms on
   operating income-based measures Over a 10-year period, from 6 years
   before to 3 years after the year of winning the first quality award, the
   mean (median) change in the operating income for the test sample is 107%
   (48%) higher than that of the control sample. There is reasonably strong
   evidence that firms that have won quality awards do better on sales
   growth than the control firms. Over the 10-year period, the mean
   (median) Change in sales for the test sample is 64% (24%) higher than
   that of the control sample. We also find weak evidence that firms in our
   test sample are more successful in controlling costs when compared with
   the firms in the control sample. in addition, the results indicate that
   firms in our test sample increased their capital expenditures more than
   the control sample over the time period prior to winning quality awards.
   Compared with the control sample, the test sample shows higher growth in
   both employment and total assets.
ZS 10
TC 400
ZA 0
ZR 0
Z8 1
ZB 4
Z9 408
SN 0025-1909
EI 1526-5501
UT WOS:A1997XX48700006
ER

PT J
AU Gerwin, D
   Moffat, L
TI Withdrawal of team autonomy during concurrent engineering
SO MANAGEMENT SCIENCE
VL 43
IS 9
BP 1275
EP 1287
DI 10.1287/mnsc.43.9.1275
PD SEP 1997
PY 1997
AB Team autonomy is an essential characteristic of cross-functional teams
   engaged in concurrent engineering. At the same time it is a
   characteristic that North American firms have considerable difficulty in
   successfully implementing. Delegating a good deal of decision making to
   teams is often counteracted by processes that during a new product
   program withdraw some of a team's autonomy or discretion. Data from 53
   cross-functional product development teams in 14 firms indicated that
   withdrawing autonomy is negatively correlated with both task and process
   aspects of team performance. The determinants of withdrawing discretion
   include lack of a shared understanding of the development process,
   environmental change, and lack of managerial ''buy-in'' to team
   autonomy. Consequently, successful implementation of team autonomy,
   through mitigating withdrawal of discretion, requires a clear
   well-communicated model of the development process, a freezing of design
   revisions, and policies that encourage managers to support the team
   rather than interfere in its decision making.
ZS 1
ZB 1
TC 59
Z8 1
ZR 0
ZA 0
Z9 61
SN 0025-1909
UT WOS:A1997XX48700007
ER

PT J
AU Chien, C
   Goldsman, D
   Melamed, B
TI Large-sample results for batch means
SO MANAGEMENT SCIENCE
VL 43
IS 9
BP 1288
EP 1295
DI 10.1287/mnsc.43.9.1288
PD SEP 1997
PY 1997
AB In analyzing the output process generated by a steady-state simulation,
   we often seek to estimate the expected value of the output. The sample
   mean based on a finite sample of size n is usually the estimator of
   choice for the steady-state mean; and a measure of the sample mean's
   precision is the variance parameter, i.e., the limiting value of the
   sample size multiplied by the variance of the sample mean as n becomes
   large. This paper establishes asymptotic properties of the conventional
   batch-means (BM) estimator of the variance parameter as both the batch
   size and the number of batches become large, In particular, we show that
   the BM variance estimator is asymtotically unbiased and convergent in
   mean square. We also provide asymptotic expressions for the variance of
   the BM variance estimator. Exact and empirical examples illustrate our
   findings.
OI Melamed, Benjamin/0000-0002-2568-2293
Z8 1
ZS 0
ZA 0
ZR 0
TC 48
ZB 0
Z9 49
SN 0025-1909
UT WOS:A1997XX48700008
ER

PT J
AU Denardo, EV
   Tang, CS
TI Control of a stochastic production system with estimated parameters
SO MANAGEMENT SCIENCE
VL 43
IS 9
BP 1296
EP 1307
DI 10.1287/mnsc.43.9.1296
PD SEP 1997
PY 1997
AB For an uncertain production system, the rule that controls the flow of
   material relies on parameters, such as the yield rates and the demand
   rate. These parameters are estimates, and they are usually inaccurate.
   In this paper, we analyze a type of ''pull'' rule called a proportional
   restoration rule. We show that these rules are stable; they do not lead
   to erratic behavior even when the estimation error is significant. We
   also show that these rules localize the effect of mis-estimates; e.g.,
   underestimating the demand rate lowers the level of finished goods
   inventory, but has scant effect-within the line. We show that these
   rules exhibit other desirable attributes-that they are efficient, that
   they are easy to interpret, and that they recover from disruptions
   quickly.
OI tang, christopher/0000-0001-9597-7620
TC 12
ZS 0
Z8 1
ZB 0
ZA 0
ZR 0
Z9 13
SN 0025-1909
UT WOS:A1997XX48700009
ER

PT J
AU Gaimon, C
TI Planning information technology-knowledge worker systems
SO MANAGEMENT SCIENCE
VL 43
IS 9
BP 1308
EP 1328
DI 10.1287/mnsc.43.9.1308
PD SEP 1997
PY 1997
AB A model is introduced to examine the long-term planning associated with
   the purchase and implementation of information technologies (IT) that
   indirectly contribute to output through enhancement of an organization's
   knowledge workers. For example, architectural firms in the service
   industry and manufacturers developing new or modified products invest in
   computer-aided design systems (CAD) to increase the volume of output
   generated by the engineering specialist.
   A critical element of the IT-knowledge worker model introduced is the
   inclusion of implementation-related dynamics. In particular we model
   bath the short-term disruption to output that typically occurs at the
   start of the implementation period and the effect of worker learning
   during implementation The ability of the organization to generate output
   is examined in relation to the levels of workforce, information
   technology, worker skill, and a variety of features of the IT. Seven
   production function attributes are introduced to quantify the manner in
   which output is generated for the IT-knowledge worker system.
   The production function is embedded into an optimization model in which
   profit is maximized. The formulation is dynamic in order to capture
   important elements of the decision-making environment, including the
   learning process, technological change, increasing wages, and changes in
   the labor supply. Optimal policies are obtained depicting the manner in
   which an organization should hire and fire its workforce and acquire
   information technology over time.
   A fundamental result is obtained establishing the existence of a
   complementary relationship between IT and knowledge workers. It is shown
   that a greater level of effective IT increases the desirability of
   hiring additional workers. In addition, as the ability of the IT to
   enhance knowledge worker productivity improves (reflecting IT features
   such as ease of use, functionality, connectivity, etc.), the
   desirability of hiring additional workers increases. Similarly, due to a
   high volume of workforce or a high level of worker skill, the
   desirability of acquiring IT increases.
   It is also shown that if an organization ignores the nature of the
   lagged effect of workforce learning, or if the impact of workforce
   learning on output is underestimated, then the projected volume of
   output over time is largely exaggerated. These results have important
   implications to management decision making with respect to effective
   implementation practices, technology choice issues, and workforce
   selection.
   Numerical results are generated to explore the effect of organizational
   size. It is shown that a smaller organization (as measured by the size
   of its workforce) relies more heavily on information technology to
   enhance worker productivity and generate output. Lastly, in response to
   higher wages, analytic results are derived demonstrating that an
   organization should reduce its level of hiring and its purchase of IT.
   Furthermore, numerical results show that an organization paying higher
   wages should allocate a. greater amount of IT per worker to enhance
   productivity.
ZS 1
Z8 0
ZR 0
TC 42
ZA 0
ZB 0
Z9 43
SN 0025-1909
UT WOS:A1997XX48700010
ER

PT J
AU Parlar, M
   Weng, ZK
TI Designing a firm's coordinated manufacturing and supply decisions with
   short product life cycles
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1329
EP 1344
DI 10.1287/mnsc.43.10.1329
PD OCT 1997
PY 1997
AB In this paper we consider a problem of joint coordination between a
   firm's manufacturing and supply departments. The manufacturing
   department is responsible for meeting random demand of a product with a
   short life cycle. The supply department's responsibility is to provide
   the sufficient amount of raw materials so that the required production
   level can be achieved. When coordination prevails, both departments'
   decisions are jointly made; otherwise, decisions are made independently
   without an exchange of information. If the random demand exceeds the
   amount produced, a second production nm can be expedited at a
   substantially higher cost. Our analysis yields insightful results to
   such a coordination problem between the two departments. We provide
   conditions under which it is desirable to coordinate, resulting in a
   significant increase in expected profit. If coordination is optimal,
   then the supply department would purchase additional reserved material
   for the second run. Under this scenario, we analyze the effects of joint
   coordination on the expected profit. We also find explicit conditions
   for which joint coordination is not beneficial, i.e., the supply
   department should only order sufficient material to meet the first
   production nm requirements. We provide a detailed set of numerical
   examples and generate response surfaces indicating the desirability of
   coordination for different pairs of parameter combinations.
ZA 0
ZR 0
Z8 5
ZS 0
TC 42
ZB 0
Z9 47
SN 0025-1909
UT WOS:A1997YC76700001
ER

PT J
AU Fichman, RG
   Kemerer, CF
TI The assimilation of software process innovations: An organizational
   learning perspective
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1345
EP 1363
DI 10.1287/mnsc.43.10.1345
PD OCT 1997
PY 1997
AB The burden of organizational learning surrounding software process
   innovations (SPIs)-and complex organizational technologies in
   general-creates a ''knowledge barrier'' that inhibits diffusion.
   Attewell (1992) has suggested that many organizations will defer
   adoption until knowledge barriers have been sufficiently lowered;
   however, this leaves open the question of which organizations should be
   more likely to innovate, even in face of high knowledge barriers. It is
   proposed here that organizations will innovate in the presence of
   knowledge barriers when the burden of organizational learning is
   effectively lower, either because much of the required know-how already
   exists within the organization, or because such knowledge can be
   acquired more easily or more economically. Specifically, it is
   hypothesized that organizations will have a greater propensity to
   initiate and sustain the assimilation of SPIs when they have a greater
   scale of activities over which learning costs can be spread
   (learning-related scale), more extensive existing knowledge related to
   the focal innovation (related knowledge), and a greater diversity of
   technical knowledge and activities (diversity). An empirical study using
   data on the assimilation of object-oriented programming languages
   (OOPLs) by 608 information technology organizations strongly confirmed
   the importance of the three hypothesized factors in explaining the
   assimilation of OOPLs.
Z8 4
ZA 0
ZB 1
TC 370
ZR 0
ZS 4
Z9 378
SN 0025-1909
UT WOS:A1997YC76700002
ER

PT J
AU Caulkins, JP
TI Modeling the domestic distribution network for illicit drugs
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1364
EP 1371
DI 10.1287/mnsc.43.10.1364
PD OCT 1997
PY 1997
AB This paper presents a simple economic model of a drug dealer's decision
   about how many customers to supply. The model relates the number of
   customers (i.e., the branching factor of the distribution network) to a
   quantity discount factor describing the extent to which prices are
   marked up from one distribution level to the next and the ratio of
   selling costs to product costs. Solving the model allows one to infer
   characteristics of the domestic distribution network from more readily
   observable characteristics of the markets and, thereby, to gain insight
   into how drug control interventions might work.
ZR 0
Z8 0
ZS 1
ZB 1
TC 11
Z9 12
SN 0025-1909
UT WOS:A1997YC76700003
ER

PT J
AU Duenyas, I
   Hopp, WJ
   Bassok, Y
TI Production quotas as bounds on interplant JIT contracts
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1372
EP 1386
DI 10.1287/mnsc.43.10.1372
PD OCT 1997
PY 1997
AB We consider the situation of a supplier plant whose customer plants
   desire just-in-time (JIT) deliveries. Randomness in both the production
   and demand processes make satisfying every demand that might occur in
   true JIT fashion impossible. Therefore, supplier plants typically
   negotiate bounds on JIT contracts with their customers. In this paper,
   we focus on the use Of ''quotas'' or ''target inventory levels'' as a
   mechanism for establishing such bounds. That is, the supplier firm is
   responsible for meeting periodic demands up to the quota, but not
   beyond. In this paper, we consider the problem of setting an appropriate
   quota from the perspective of the supplier plant and interpret our
   results in the context of the negotiation process between the supplier
   and its customers. Under the assumption that ''safety capacity'' (i.e.,
   overtime or a vendoring option) is available, we develop two models that
   address this problem. The first model assumes that quota shortfalls
   cannot be carried over to the next regular time production period and
   are made up with overtime/vendoring, which incurs fixed plus variable
   costs. The second model assumes that shortages can be backlogged to the
   next regular time production period at a cost. We use numerical examples
   to demonstrate how the models we developed were used by a clutch
   supplier to a large auto manufacturer to negotiate its JIT contracts.
TC 18
ZR 0
Z8 1
ZS 0
ZA 0
ZB 0
Z9 19
SN 0025-1909
UT WOS:A1997YC76700004
ER

PT J
AU Gorn, GJ
   Chattopadhyay, A
   Yi, T
   Dahl, DW
TI Effects of color as an executional cue in advertising: They're in the
   shade
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1387
EP 1400
DI 10.1287/mnsc.43.10.1387
PD OCT 1997
PY 1997
AB In designing print ads, one of the decisions the advertiser must make is
   which color(s) to use as executional cues in the ad. Typically, color
   decisions are based on intuition and anecdotal evidence. To provide
   guidelines for these decisions, this research proposes and tests a
   conceptual framework linking the hue, chroma, and value of the color(s)
   in an ad to consumers' feelings and attitudes. In an experimental study,
   the three dimensions of color used in an ad are manipulated using a
   between-subjects design. The results support the hypotheses that ads
   containing colors with a higher level of value lead to greater liking
   for the ad, and this effect is mediated by the greater feelings of
   relaxation elicited by the higher value color. Feelings play an equally
   important role in the effect of chroma. Consistent with the hypotheses,
   higher levels of chroma elicit greater feelings of excitement, which in
   turn increase ad likeability. A follow-up study found that although
   managers often select higher value and higher chroma colors, in a large
   number of cases they do not. The findings of both studies are integrated
   in our discussion of the importance of value and chroma in increasing
   the range of options available to a manager faced with the selection of
   colors in an ad.
RI Chattopadhyay, Amitava/B-3795-2010
OI Chattopadhyay, Amitava/0000-0001-5150-4995
ZS 1
ZA 0
TC 169
Z8 1
ZB 4
ZR 1
Z9 171
SN 0025-1909
EI 1526-5501
UT WOS:A1997YC76700005
ER

PT J
AU Desai, PS
TI Advertising fee in business-format franchising
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1401
EP 1419
DI 10.1287/mnsc.43.10.1401
PD OCT 1997
PY 1997
AB Most franchisors charge an advertising fee in addition to the better
   known royalty and franchise fee. We study the role of the advertising
   fee in improving channel coordination. We begin our analysis with a
   simple case of one franchisor dealing with two identical franchisees and
   find that the advertising fee allows the franchisor to commit to a
   specific level of advertising spending at the time of contract
   acceptance. We also find that the lump-sum advertising fee is better
   than the sales-based advertising fee. These results are intriguing
   because most franchisors use the sales-based advertising fee. We show
   that when franchisees' markets differ in how advertising affects sales,
   the franchisor may prefer the sales-based advertising fee. There are two
   reasons for the higher profitability of the sales-based advertising fee.
   First, the sales-based advertising fee conditions the franchisor's
   advertising decision on the franchisees' price and service decisions,
   and induces them to make better price and service decisions. The second
   reason is that with heterogeneous franchisees, using the sales-based
   advertising fee does not increase the total sales-based component in the
   fee structure. These results also hold when the franchisor pledges to
   contribute a matching fraction of the advertising fee to the advertising
   fund.
TC 61
ZA 0
ZS 0
ZR 0
Z8 4
ZB 1
Z9 65
SN 0025-1909
UT WOS:A1997YC76700006
ER

PT J
AU Stafira, S
   Parnell, GS
   Moore, JT
TI A methodology for evaluating military systems in a counterproliferation
   role
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1420
EP 1430
DI 10.1287/mnsc.43.10.1420
PD OCT 1997
PY 1997
AB This paper illustrates a methodology to evaluate how dissimilar military
   systems support the accomplishment of the United States'
   counterproliferation objectives. The key questions in evaluating
   counterproliferation systems are identified. By using decision analysis,
   an influence diagram model is developed that represents military
   activities in the counterproliferation process. A value model is
   developed that enables systems to be evaluated against common criteria.
   An analysis of intelligence, defensive, and offensive
   counterproliferation systems suggests that intelligence system
   improvements may provide the greatest potential to meet the United
   States' counterproliferation objectives. Sensitivity analysis is
   conducted to determine which factors in the model are most important. To
   demonstrate the model, nine systems from the Air Force Vulcan's Forge
   1995 wargame are evaluated. This paper illustrates the value of decision
   analysis, and influence diagrams in particular, by involving decision
   makers and subject matter experts in structuring complex problems for
   analysis.
ZB 0
ZS 0
ZR 0
ZA 0
Z8 0
TC 5
Z9 5
SN 0025-1909
UT WOS:A1997YC76700007
ER

PT J
AU Lamar, BW
   Wallace, CA
TI Revised-modified penalties for fixed charge transportation problems
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1431
EP 1436
DI 10.1287/mnsc.43.10.1431
PD OCT 1997
PY 1997
AB Conditional penalties are used to obtain lower bounds to subproblems in
   a branch-and-bound procedure that can be tighter than the LP relaxation
   of the subproblems. For the fixed charge transportation problem (FCTP),
   branch-and-bound algorithms have been implemented using conditional
   penalties proposed by Driebeek (1966), Cabot and Erenguc (1984), and
   Palekar et al. (1990). The last conditional penalties are referred to as
   the ''modified'' penalties. In this paper, we show that the modified
   penalties are not valid conditional penalties. In fact, in nearly a
   quarter of the test problems examined, the modified penalties prevented
   the branch-and-bound algorithm from properly identifying the optimal
   solution to the FCTP. A simple change, which corrects a subcase in the
   penalty calculation, restores the validity of the modified penalties
   while retaining their efficiency. Computational tests indicate that the
   ''revised-modified'' penalties continue to dominate the Driebeek and the
   Cabot and Erenguc penalties.
TC 19
ZR 0
Z8 0
ZS 0
ZA 0
ZB 0
Z9 19
SN 0025-1909
UT WOS:A1997YC76700008
ER

PT J
AU Simaan, Y
TI Estimation risk in portfolio selection: The mean variance model versus
   the mean absolute deviation model
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1437
EP 1446
DI 10.1287/mnsc.43.10.1437
PD OCT 1997
PY 1997
AB Konno and Yamazaki (1992) propose the mean absolute deviation (MAD)
   model as an alternative to the mean variance (MV) model. They claim it
   retains all the positive features of the MV model, saves the investor
   computing time, and does not require the covariance matrix. This paper
   shows that ignoring the covariance matrix results in greater estimation
   risk that outweighs the benefits. In both models, estimation error is
   more;severe in small samples (small. observations relative to the number
   of assets) and for investors with high risk tolerance. The MV model's
   lower estimation risk is most striking in small samples and for
   investors with a low risk tolerance.
ZS 0
ZB 0
ZA 0
TC 105
Z8 6
ZR 0
Z9 110
SN 0025-1909
UT WOS:A1997YC76700009
ER

PT J
AU Viswanathan, S
TI Periodic review (s, S) policies for joint replenishment inventory
   systems
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1447
EP 1454
DI 10.1287/mnsc.43.10.1447
PD OCT 1997
PY 1997
AB This note deals with the joint replenishment problem with stochastic
   demands. A new class of policies called P(s, S) policy is proposed for
   this problem. The proposed policy uses independent, periodic review (s,
   S) policies for each item. Results on test problems show that the
   proposed policy is superior to other classes of policies for the
   problem.
Z8 3
TC 49
ZR 0
ZS 0
ZA 0
ZB 0
Z9 52
SN 0025-1909
UT WOS:A1997YC76700010
ER

PT J
AU Joglekar, P
   Bohl, AH
   Hamburg, M
TI Fortune favors the prepared firm - Comments
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1455
EP 1462
DI 10.1287/mnsc.43.10.1455
PD OCT 1997
PY 1997
AB A recent paper in Management Science titled ''Fortune Favors the
   Prepared Firm'' (Cohen and Levinthal 1994) is a pioneering work insofar
   as it introduces the concept of a firm's absorptive capacity-the ability
   to evaluate, assimilate, and exploit extramural technological
   developments. We appreciate the paper's extensive qualitative discussion
   of the nature and role of absorptive capacity. We also commend the
   authors' idea of constructing a mathematical model to analyze a rational
   firm's incentives for an investment in absorptive capacity. However, we
   find that the authors' model overlooks one key element of a firm's
   absorptive capacity, namely, the firm's ability to defend itself against
   the threat of an external technology. In the absence of that element,
   the authors' model may be able to explain a firm's incentives for an
   innovation rather than incentives for the development of an absorptive
   capacity. We also identify several internal inconsistencies in the
   authors' mathematical model. For example, the assumed profit
   maximization function seems inconsistent with the assumed degree of
   sophistication of the firm's probability assessment behavior. We believe
   that the inconsistencies and shortcomings noted here raise serious
   questions about the validity of the authors' findings. However, we hope
   that this note does not detract from the pioneering nature of the
   authors' work, but instead increases its value by stimulating further
   work on the important topic of absorptive capacity.
ZB 0
Z8 0
TC 8
ZR 0
ZA 0
ZS 1
Z9 8
SN 0025-1909
UT WOS:A1997YC76700011
ER

PT J
AU Cohen, WM
   Levinthal, DA
TI Fortune favors the prepared firm - Reply
SO MANAGEMENT SCIENCE
VL 43
IS 10
BP 1463
EP 1468
DI 10.1287/mnsc.43.10.1463
PD OCT 1997
PY 1997
AB Joglekar, Bohl, and Hamburg (JBH) make two basic sets of criticisms of
   our paper (Cohen and Levinthal 1994) in their comment. First, they
   object to two key elements of the model structure: relevance of the
   monopoly analysis and the appropriateness of modeling competition via an
   entry model. Second, JBH express concern over the manner in which we
   have modeled the updating process. With regard to the basic model
   structure, we argue that the initial monopoly analysis allows us to
   capture some important notions regarding the path dependent nature of
   investment in technical capabilities. Further, the analysis of
   competition by an entry model does not presume that an established firm
   takes the initiative which is one of JBH's key objections. The structure
   merely implies that some firm, possibly a start-up enterprise, moves
   first. With regard to the concerns over the modeling of updating, we
   acknowledge that our notation could have been clearer in some instances
   but that does not negate the correctness of the analysis. Furthermore,
   JBH's recommendations regarding the updating process have the same
   qualitative properties as our own specification. Indeed, at no point in
   their critique do JBH ever indicate how their proposed specification
   would change the results of our analysis.
ZB 1
ZR 0
Z8 0
ZA 0
TC 5
ZS 0
Z9 5
SN 0025-1909
UT WOS:A1997YC76700012
ER

PT J
AU Eppen, GD
   Iyer, AV
TI Backup agreements in fashion buying - The value of upstream flexibility
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1469
EP 1484
DI 10.1287/mnsc.43.11.1469
PD NOV 1997
PY 1997
AB We focus on backup agreements between a catalog company and
   manufacturers-a scheme to provide upstream sourcing flexibility for
   fashion merchandise. A backup agreement states that if the catalog
   company commits to a number of units for the season, the manufacturer
   holds back a constant fraction of the commitment and delivers the
   remaining units before the start of the fashion season. After observing
   early demand, the catalog company can order up to this backup quantity
   for the original purchase cost and receive quick delivery but will pay a
   penalty cost for any of the backup units it does not buy. In
   representative contracts with five companies, the fraction held as
   backup varies from 20% to 33% and the penalty ranges from 0 to 20% of
   cost. We model this inventory problem and derive the optimal solution.
   We provide results from a retrospective parallel test of the model
   against buyer decisions in 1993 based on a data set from the women's
   fashion department at a catalog company (Catco). The results indicate
   that backup arrangements can have a substantial impact on expected
   profits and may result in an increase in the committed quantity. Also,
   these arrangements may maintain the manufacturer's expected profit for a
   wide range of parameters.
Z8 24
ZB 3
TC 267
ZR 0
ZA 0
ZS 1
Z9 291
SN 0025-1909
UT WOS:A1997YG98600001
ER

PT J
AU Demeulemeester, EL
   Herroelen, WS
TI New benchmark results for the resource - Constrained project scheduling
   problem
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1485
EP 1492
DI 10.1287/mnsc.43.11.1485
PD NOV 1997
PY 1997
AB This paper reports on new insights derived from computational results
   obtained with an updated version of the branch-and-bound procedure
   previously developed by Demeulemeester and Herroelen (1992) for solving
   the resource-constrained project scheduling problem (RCPSP). The new
   code fully exploits the advantages of 32-bit programming provided by
   recent compilers running on platforms such as Windows NT(R) and OS/2(R):
   flat memory, increased addressable memory, and fast program execution.
   We study the impact of three important variables on the computation time
   for the RCPSP: addressable computer memory, the search strategy
   (depth-first, best-first, or hybrid), and the introduction of a stronger
   lower bound. We compare the results obtained by a truncated
   branch-and-bound procedure with the results generated by the minimum
   slack time heuristic and report on the dependency of its solution
   quality on the allotted CPU time.
ZB 1
Z8 5
TC 140
ZS 2
ZR 0
ZA 0
Z9 146
SN 0025-1909
UT WOS:A1997YG98600002
ER

PT J
AU Zaheer, A
   Zaheer, S
TI Catching the wave: Alertness, responsiveness, and market influence in
   global electronic networks
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1493
EP 1509
DI 10.1287/mnsc.43.11.1493
PD NOV 1997
PY 1997
AB This paper introduces the concepts of alertness and responsiveness as
   key capabilities for firms in fast-moving, information-intensive
   environments such as global currency trading. Hypotheses drawn from the
   resource-based view of the firm, from network theory, and from Austrian
   economics are tested on objective cross-section and time-series data for
   the population of 4,088 banks engaged in foreign-exchange trading on the
   Reuters dealing system. Results strongly support the hypotheses that
   banks that are alert, i.e., use their information networks in ways that
   expand the range of information they are exposed to, and
   responsive-those that act quickly in volatile markets-tend to exercise
   greater market influence in this industry.
TC 129
ZS 1
Z8 4
ZR 0
ZB 0
ZA 0
Z9 134
SN 0025-1909
UT WOS:A1997YG98600003
ER

PT J
AU VanderWerf, PA
   Mahon, JF
TI Meta-analysis of the impact of research methods on findings of
   first-mover advantage
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1510
EP 1519
DI 10.1287/mnsc.43.11.1510
PD NOV 1997
PY 1997
AB A long-standing hypothesis is that firms that enter a market early
   (''first movers'') tend to have higher performance than their followers
   (''first-mover advantage''). Recently, researchers have begun to argue
   that the statistical tests that support this relationship are limited in
   their applicability. That is, it is suggested that because of the
   methods used, these tests show the relationship only for certain subsets
   of firms, markets, and types of performance.
   We performed a meta-analysis to determine whether the findings are in
   fact sensitive to the methods used. We discovered that tests using
   market share as their performance measure were sharply and significantly
   more likely to find a first-mover advantage than tests using other
   measures (such as profitability or survival). Also significantly more
   likely to find an advantage were tests that sample from individually
   selected industries and those that include no measures of the entrants'
   competitive strength. Conversely, we found little evidence that
   ''survivor bias'' (the exclusion of nonsurviving entrants from the
   sample) affects a test's findings.
   The data further suggest that tests that use none of the questioned
   research practices will find a first-mover advantage no more often than
   can be accounted for by random statistical error alone.
RI mahon, john f./ABG-4727-2020; Burlibasa, Liliana/S-7557-2017
OI Burlibasa, Liliana/0000-0003-0596-9331
TC 114
Z8 2
ZA 0
ZS 0
ZB 0
ZR 0
Z9 116
SN 0025-1909
UT WOS:A1997YG98600004
ER

PT J
AU Fischetti, M
   Toth, P
TI A polyhedral approach to the asymmetric traveling salesman problem
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1520
EP 1536
DI 10.1287/mnsc.43.11.1520
PD NOV 1997
PY 1997
AB Several branch-and-bound algorithms for the exact solution of the
   asymmetric traveling salesman problem (ATSP), based on the assignment
   problem (AP) relaxation, have been proposed in the literature. These
   algorithms perform very well for some instances (e.g., those with
   uniformly random integer costs), but very poorly for others. The aim of
   this paper is to evaluate the effectiveness of a branch-and-cut
   algorithm exploiting ATSP-specific facet-defining cuts, to be used to
   attack hard instances that cannot be solved by the AP-based procedures
   from the literature. We present new separation algorithms for some
   classes of facet-defining cuts, and a new variable-pricing technique for
   dealing with highly degenerate primal LP problems. A branch-and-cut
   algorithm based on these new results is designed and evaluated through
   computational analysis on several classes of both random and real-world
   instances. The outcome of the research is that, on hard instances, the
   branch-and-cut algorithm clearly outperforms the best AP-based
   algorithms from the literature.
ZR 0
ZB 1
Z8 1
ZA 0
ZS 0
TC 52
Z9 53
SN 0025-1909
UT WOS:A1997YG98600005
ER

PT J
AU Balvers, RJ
   Mitchell, DW
TI Autocorrelated returns and optimal intertemporal portfolio choice
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1537
EP 1551
DI 10.1287/mnsc.43.11.1537
PD NOV 1997
PY 1997
AB In recent years it has been shown empirically that stock returns exhibit
   positive or negative autocorrelation, depending on observation
   frequency. In this context of autocorrelated returns the present paper
   is the first to derive an explicit analytical solution to the dynamic
   portfolio problem of an individual agent saving for retirement (or other
   change of status, like the purchase of a house or starting college).
   Using a normal ARMA(1, 1) process, dynamic programming techniques
   combined with the use of Stein's Lemma are employed to examine
   ''dollar-cost-averaging'' and ''age effects'' in intertemporal portfolio
   choice with CARA preferences. We show that with a positive moving
   average parameter and positive risk free rates, if first-order serial
   correlation is nonnegative, then the expected value of the optimal risky
   investment is increasing over time, while if first-order serial
   correlation is negative this path can be increasing or decreasing over
   time. Thus a necessary but not sufficient condition to obtain the
   conventional age effect of increasing conservatism over time is that
   first-order serial correlation be negative. Further, dollar-cost
   averaging in the general sense of gradual entry into the risky asset
   does not emerge as an optimal policy. Simulation results for U.S. data
   are used to illustrate optimal portfolio paths.
OI Balvers, Ronald/0000-0002-5285-6084
Z8 4
ZS 0
ZB 0
TC 13
ZA 0
ZR 0
Z9 16
SN 0025-1909
UT WOS:A1997YG98600006
ER

PT J
AU Wathieu, L
TI Habits and the anomalies in intertemporal choice
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1552
EP 1563
DI 10.1287/mnsc.43.11.1552
PD NOV 1997
PY 1997
AB This paper analyzes a model of discounted utility under habit formation.
   Habit formation means that utility in each period is determined by the
   difference between the received outcome and the customary outcome at
   that point in time. Preferences are rational, in the sense that the
   decision maker correctly anticipates the habit formation process and
   behaves in a dynamically consistent manner, i.e., plans are truly
   carried out. The purpose is to demonstrate that this generalization of
   the discounted utility model accounts, jointly and in a meaningful way,
   for the most striking anomalies with respect to classical discounted
   utility theory. The common difference effect is explained first. This
   effect, also called decreasing impatience effect, has usually been
   viewed as evidence against exponential discounting. Then, the frequently
   observed preference for increasing sequences of outcomes is examined.
   Such preference, under the traditional discounted utility model, would
   be regarded as a paradoxical case of negative discounting. A discussion
   of the descriptive, prescriptive, and normative values of the model is
   included.
ZB 0
ZA 0
TC 23
ZS 0
ZR 0
Z8 0
Z9 23
SN 0025-1909
UT WOS:A1997YG98600007
ER

PT J
AU Booth, GG
   Chowdhury, M
   Martikainen, T
   Tse, Y
TI Intraday volatility in international stock index futures markets: Meteor
   showers or heat waves?
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1564
EP 1576
DI 10.1287/mnsc.43.11.1564
PD NOV 1997
PY 1997
AB The international transmission of intraday price volatility among the
   United States, United Kingdom, and Japanese stock index futures markets
   in the period 1988-1994 is investigated in this paper. The empirical
   results based on extreme-value estimators and vector autoregression
   indicate the rapid transmission of information between markets. The
   volatilities of the U.S. and U.K. futures markets appear to follow a
   meteor shower rather than a heat wave type of process. This means that
   these volatilities react to shocks from other markets, i.e., they cannot
   be described only by their past values. However, the heat wave
   hypothesis is not rejected for the Japanese market, meaning that the
   shocks to Japanese volatility are mostly country-specific. A
   multivariate GARCH model supports the U.K. and Japanese but not the U.S.
   results.
Z8 0
ZB 0
ZR 0
TC 20
ZS 0
ZA 0
Z9 20
SN 0025-1909
UT WOS:A1997YG98600008
ER

PT J
AU Moinzadeh, K
   Aggarwal, P
TI Analysis of a production/inventory system subject to random disruptions
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1577
EP 1588
DI 10.1287/mnsc.43.11.1577
PD NOV 1997
PY 1997
AB In this paper we study an unreliable bottleneck production/inventory
   system with a constant production and demand rate that is subject to
   random disruptions. We assume that the restoration times are constant,
   the time between breakdowns is exponential, the production setup cost
   and/or setup time is positive, and excess demand is backordered. We
   propose an (s, S) production policy for such systems and develop
   expressions for the operating characteristics of the system. The
   properties of the policy parameters that minimize the expected total
   cost rate are investigated and a procedure for finding their optimal
   values is developed. In addition, we devise and test a simple heuristic
   procedure for finding near optimal production policies. The results of a
   numerical experiment suggest that: (i) setup cost reduction is more
   effective in reducing total operating cost when the production system is
   more reliable, (ii) setup cost reduction in unreliable production
   systems results in higher optimal safety stock level, and (iii) proper
   determination of the safety stock levels is extremely important in
   Just-in-Time systems, which are susceptible to disruptions.
Z8 6
ZS 0
ZB 1
TC 96
ZA 0
ZR 0
Z9 102
SN 0025-1909
UT WOS:A1997YG98600009
ER

PT J
AU Grant, D
   Vora, G
   Weeks, D
TI Path-dependent options: Extending the Monte Carlo simulation approach
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1589
EP 1602
DI 10.1287/mnsc.43.11.1589
PD NOV 1997
PY 1997
AB Monte Carlo simulation has been used to value options since Boyle's
   seminal paper. Monte Carlo simulation, however, has not been used to its
   fullest extent for option valuation because of the belief that the
   method is not feasible for American-style options. This paper
   demonstrates how to incorporate optimal early exercise in the Monte
   Carlo method of valuing options by linking forward-moving simulation and
   the backward-moving recursion of dynamic programming through an
   iterative search process. To demonstrate the potential of this method,
   we use it to value American-style options on the average price (or Asian
   options). The computational experience reveals a flexible valuation
   technique with potential for application to a range of securities and
   financial decision problems.
TC 44
Z8 3
ZR 0
ZS 1
ZB 0
ZA 0
Z9 48
SN 0025-1909
UT WOS:A1997YG98600010
ER

PT J
AU Erickson, GM
TI Note. Dynamic conjectural variations in a Lanchester oligopoly
SO MANAGEMENT SCIENCE
VL 43
IS 11
BP 1603
EP 1608
DI 10.1287/mnsc.43.11.1603
PD NOV 1997
PY 1997
AB An approach based on dynamic conjectural variations is advanced for
   developing dynamic advertising strategies in a Lanchester oligopoly
   differential game. The approach allows competitors to anticipate rival
   reactions to market-share state variables, and maintains the
   computational advantage of open-loop Nash equilibrium strategies. In an
   empirical application to the ready-to-eat cereal industry, it is shown
   that advertising strategies based on dynamic conjectural variations can
   better explain the advertising of the cereal competitors than can
   open-loop advertising strategies.
ZS 0
TC 18
Z8 2
ZB 0
ZR 0
ZA 0
Z9 20
SN 0025-1909
UT WOS:A1997YG98600011
ER

PT J
AU Brynjolfsson, E
   Seidmann, A
TI A call for exploration: Introduction to special issue on frontier
   research on information systems and economics
SO MANAGEMENT SCIENCE
VL 43
IS 12
BP 1605
EP 1607
PD DEC 1997
PY 1997
RI Brynjolfsson, Erik/H-2412-2012
ZB 0
ZS 0
TC 4
Z8 0
ZA 0
ZR 0
Z9 4
SN 0025-1909
UT WOS:000071534100001
ER

PT J
AU Anand, KS
   Mendelson, H
TI Information and organization for horizontal multimarket coordination
SO MANAGEMENT SCIENCE
VL 43
IS 12
BP 1609
EP 1627
DI 10.1287/mnsc.43.12.1609
PD DEC 1997
PY 1997
AB We model the effects of alternative coordination structures on the
   performance of a firm that faces uncertain demand in multiple horizontal
   markets. The firm's coordination structure is jointly determined by its
   decision-rights structure and by its information structure. We compare
   the performance of decentralized, centralized and distributed structures
   and study factors that affect the value of coordination. The results
   quantify and illustrate the value of co-locating decision rights with
   specific knowledge.
Z8 13
ZA 0
ZR 0
TC 83
ZS 1
ZB 1
Z9 96
SN 0025-1909
UT WOS:000071534100002
ER

PT J
AU Desiraju, R
   Moorthy, S
TI Managing a distribution channel under asymmetric information with
   performance requirements
SO MANAGEMENT SCIENCE
VL 43
IS 12
BP 1628
EP 1644
DI 10.1287/mnsc.43.12.1628
PD DEC 1997
PY 1997
AB In this paper we study how performance requirements may improve the
   working of a distribution channel when the retailer is better informed
   about demand conditions than the manufacturer. Performance requirements
   means that the manufacturer and retailer agree to (1) have the
   manufacturer set requirements on retail price or service or both, and
   (2) jointly invest in the information systems required to monitor the
   retailer's compliance with the requirements. We show that performance
   requirements on price and service will improve channel performance. But
   if requirements cannot be set on both performance dimensions, the choice
   among the remaining options is not straightforward Price requirements
   may be worse than no requirements, and service requirements no better.
   The central problem with setting requirements on only one dimension is
   that the retailer then behaves suboptimally on the other. Between the
   two partial options, service requirements are better than price
   requirements in aligning the interests of the manufacturer and the
   retailer, whereas price requirements are better at inducing the retailer
   to reveal his demand.
RI Moorthy, Sridhar/N-5219-2019; Desiraju, Ramarao/H-1912-2011; Moorthy, Sridhar/E-7447-2012
ZS 0
TC 108
Z8 19
ZB 0
ZR 0
ZA 0
Z9 125
SN 0025-1909
UT WOS:000071534100003
ER

PT J
AU Mukhopadhyay, T
   Rajiv, S
   Srinivasan, K
TI Information technology impact on process output and quality
SO MANAGEMENT SCIENCE
VL 43
IS 12
BP 1645
EP 1659
DI 10.1287/mnsc.43.12.1645
PD DEC 1997
PY 1997
AB Our work represents one of the first attempts to assess the impact of IT
   (information technology) on both process output and quality. We examine
   the optical character recognition and barcode sorting technologies in
   the mail sorting process at the United States Postal Service. Our
   analysis is at the application level, and thus does not involve the
   aggregation of IT impact over multiple processes. We use data from 46
   mail processing centers over 3 years to study the IT impact. We also use
   a set of factors in our model to account for differences in input
   characteristics. Our results show that mail sorting output significantly
   increases with higher use of IT. In addition, IT improves quality which
   in turn enhances output. We also find that input characteristics exert
   considerable influence in determining the output and quality of the mail
   sorting operation. For example, while absenteeism tends to decrease
   output and quality due to its disruptive consequences, a higher fraction
   of barcoded mail seems to enhance both performance measures.
OI Mukhopadhyay, Tridas/0000-0001-6691-9595
ZS 1
ZB 0
Z8 3
TC 122
ZR 0
ZA 0
Z9 126
SN 0025-1909
UT WOS:000071534100004
ER

PT J
AU Dewan, S
   Min, CK
TI The substitution of information technology for other factors of
   production: A firm level analysis
SO MANAGEMENT SCIENCE
VL 43
IS 12
BP 1660
EP 1675
DI 10.1287/mnsc.43.12.1660
PD DEC 1997
PY 1997
AB Fueled by its constant technological and price improvements, information
   technology (IT) is displacing other inputs in the production of goods
   and services. By 1994, IT accounts for over 15% of fixed investments by
   the U.S. private sector, and the ratio of new IT investments to labor
   costs is approaching 5% (1990 dollar basis). The ability to take
   advantage of improvements in IT is determined in part by the
   substitutability of IT for other factors of production.
   This paper builds on the empirical framework of Brynjolfsson and Hitt
   (1995) and extends it to jointly estimate output and substitution
   elasticities using the CES-translog production function. Our primary
   source of IT-related data is the IDG/Computerworld annual survey data on
   IS spending by large U.S. firms, for the period 1988 to 1992, previously
   analyzed by Brynjolfsson and Hitt (1995, 1996) and Lichtenberg (1995).
   A key result is that IT capital is a net substitute for both ordinary
   capital and labor, suggesting that the factor share of IT in production
   will grow to more significant levels over time. We confirm earlier
   findings of positive returns to IT investment for this data set.
   Further, we find excess returns on IT investment relative to labor input
   and some evidence of excess returns relative to ordinary capital. Taken
   together, these results shed new light on the productivity paradox of IT
   and on the growth of information intensity across the economy as firms
   take advantage of the continuing improvements in IT.
Z8 3
ZB 0
ZS 2
ZR 0
TC 214
ZA 0
Z9 219
SN 0025-1909
UT WOS:000071534100005
ER

PT J
AU Bakos, JY
TI Reducing buyer search costs: Implications for electronic marketplaces
SO MANAGEMENT SCIENCE
VL 43
IS 12
BP 1676
EP 1692
DI 10.1287/mnsc.43.12.1676
PD DEC 1997
PY 1997
AB Information systems can serve as intermediaries between the buyers and
   the sellers in a market, creating an "electronic marketplace" that
   lowers the buyers' cost to acquire information about seller prices and
   product offerings. As a result, electronic marketplaces reduce the
   inefficiencies caused by buyer search costs, in the process reducing the
   ability of sellers to extract monopolistic profits while increasing the
   ability of markets to optimally allocate productive resources. This
   article models the role of buyer search costs in markets with
   differentiated product offerings. The impact of reducing these search
   costs is analyzed in the context of an electronic marketplace, and the
   allocational efficiencies such a reduction can bring to a differentiated
   market are formalized. The resulting implications for the incentives of
   buyers, sellers, and independent intermediaries to invest in electronic
   marketplaces are explored. Finally, the possibility to separate price
   information from product attribute information is introduced, and the
   implications of designing markets promoting competition along each of
   these dimensions are discussed.
RI Bakos, Yannis/P-8841-2019
ZB 5
Z8 23
ZS 6
ZR 0
ZA 0
TC 796
Z9 824
SN 0025-1909
UT WOS:000071534100006
ER

PT J
AU Clemons, EK
   Weber, BW
TI Information technology and screen-based securities trading: Pricing the
   stock and pricing the trade
SO MANAGEMENT SCIENCE
VL 43
IS 12
BP 1693
EP 1708
DI 10.1287/mnsc.43.12.1693
PD DEC 1997
PY 1997
AB Many major stock exchanges rely on their member firms to act as dealer
   intermediaries, risking their own capital to trade as dealers with
   investor customers. A confluence of forces will dramatically alter the
   role of these intermediaries and the strategies available to-them.
   Information technology is increasing the diversity of trading strategies
   used by investors; these impose different costs and risks upon
   intermediaries. Alternative electronic trading venues-off-exchange
   trading systems-are increasing the competition faced by established
   exchanges, and have been especially effective in targeting investors who
   impose low risks upon intermediaries. Finally, many of the automated
   systems developed by existing exchanges have stripped of many of the
   cues that have in the past been used by intermediaries to assess the
   riskiness of an investor's trade and to price accordingly. We believe
   that competitive pressure from alternative trading venues will drive
   exchanges to develop mechanisms to support risk-based pricing. We
   explore, through a stylized model of trading, how the use of risk-based
   pricing can preserve the established central market. This enables
   intermediaries to separate pricing the shares traded from pricing the
   services for dealing these shares, and provides low-cost execution while
   preserving the benefits of intermediation. Our model uses a detailed
   computer simulation, in which dealers interact with order flow to
   produce a sequence of trades, which determine market prices, which in
   turn influence order flow; the model enables us to calculate trading
   costs for different classes of investor, various other standard measures
   of market quality, and market maker profitability.
TC 16
Z8 0
ZB 0
ZR 0
ZS 0
ZA 0
Z9 16
SN 0025-1909
UT WOS:000071534100007
ER

PT J
AU Banker, RD
   Slaughter, SA
TI A field study of scale economies in software maintenance
SO MANAGEMENT SCIENCE
VL 43
IS 12
BP 1709
EP 1725
DI 10.1287/mnsc.43.12.1709
PD DEC 1997
PY 1997
AB Software maintenance is a major concern for organizations. Productivity
   gains in software maintenance can enable redeployment of Information
   Systems resources to other activities. Thus, it is important to
   understand how software maintenance productivity can be improved. In
   this study, we investigate the relationship between project size and
   software maintenance productivity. We explore scale economies in
   software maintenance by examining a number of software enhancement
   projects at a large financial services organization. We use Data
   Envelopment Analysis (DEA) to estimate the functional relationship
   between maintenance inputs and outputs and employ DEA-based statistical
   tests to evaluate returns to scale for the projects. Our results
   indicate the presence of significant scale economies in software
   maintenance, and are robust to a number of sensitivity checks. For our
   sample of projects, there is the potential to reduce software
   maintenance costs 36% by batching smaller modification projects into
   larger planned releases. We conclude by rationalizing why the software
   managers at our research site do not take advantage of scale economies
   in software maintenance. Our analysis considers the opportunity costs of
   delaying projects to batch them into larger size projects as a potential
   explanation for the managers' behavior.
ZR 0
TC 90
ZA 0
ZB 0
Z8 0
ZS 0
Z9 90
SN 0025-1909
UT WOS:000071534100008
ER

PT J
AU Wang, ETG
   Barron, T
   Seidmann, A
TI Contracting structures for custom software development: The impacts of
   informational rents and uncertainty on internal development and
   outsourcing
SO MANAGEMENT SCIENCE
VL 43
IS 12
BP 1726
EP 1744
DI 10.1287/mnsc.43.12.1726
PD DEC 1997
PY 1997
AB Custom software development projects have special informational
   attributes that have challenged managers for many years: they are
   associated with information asymmetries regarding user valuation and
   developer costs, relationship-specific investments, and a resulting
   likelihood of positive externalities for the user or the developer from
   the other party's investment. Furthermore, in a custom project, market
   prices for software are not helpful in solving either the valuation or
   the cost problems. In this paper we analyze the unique nature of the
   software development agreements that can be reached between the user and
   the developer in such a setting. We compare the value of using internal
   and external developers, with the goal of better understanding the
   factors relevant to the outsourcing decision. For internal development,
   we derive a new mechanism that achieves the first-best system whenever
   the project has positive expected net value, while achieving ex ante
   budget balance. In contrast, the optimal mechanism for an external
   developer will not in general yield the first-best system. This implies
   that when internal and external developers have identical cost
   functions, internal development definitely yields the larger net value.
   More generally, this implies that an external developer must have
   considerable cost advantages over an internal developer in order to have
   the larger net value. Numerical results indicate that this difference in
   net values can be very large, as much as a 100% increase for internal
   development over external development. This is consistent with the
   strong bias in favor of internal custom development found in recent
   empirical studies. We also explain why the efficient levels of
   investment can be achieved only when there are no externalities, and we
   show that the presence of positive externalities results in
   underinvestment. Since using an external developer will typically yield
   a system that is not first-best, inefficient investments result with or
   without externalities. We present examples showing that uncertainty
   about system value is not a significant factor in choosing between
   internal and external development. However, uncertainty about the
   development costs is highly significant, with greater uncertainty making
   outsourcing less attractive.
ZR 0
ZB 0
ZA 0
Z8 1
ZS 0
TC 40
Z9 41
SN 0025-1909
UT WOS:000071534100009
ER

PT J
AU Gurbaxani, V
   Kraemer, K
   Vitalari, N
TI Note: An economic analysis of IS budgets
SO MANAGEMENT SCIENCE
VL 43
IS 12
BP 1745
EP 1755
DI 10.1287/mnsc.43.12.1745
PD DEC 1997
PY 1997
AB This paper conducts an empirical analysis of information systems budget
   data focusing on the implications for the efficient production of
   information services. We use a model of the production of information
   services based on the economic theory of production to develop testable
   hypotheses for budget behavior. In particular, we focus on two important
   issues: (1) the allocation of the information systems budget to its two
   largest components-personnel and hardware, and (2) the existence of
   scale economies in the provision of information services. These issues
   are examined using budget data collected through a survey of information
   systems managers in Fortune 500 corporations. We find that the optimal
   ratio of personnel to hardware expenditures is independent of the scale
   of the information systems organization for a given set of prices, and
   that there are no measurable economies of scale in the provision of
   information services. The implications of the analysis for the
   management of information services are discussed.
ZB 0
ZA 0
TC 9
Z8 0
ZS 0
ZR 0
Z9 9
SN 0025-1909
UT WOS:000071534100010
ER

PT J
AU Ettlie, JE
TI R&D and global manufacturing performance
SO MANAGEMENT SCIENCE
VL 44
IS 1
BP 1
EP 11
DI 10.1287/mnsc.44.1.1
PD JAN 1998
PY 1998
AB R&D intensity and manufacturing performance were evaluated in this study
   of 600 durable goods firms in 20 countries. In a path-analytic model,
   R&D intensity was significantly associated with improvements in market
   share (R-2 = 34%), controlling for firm size, previous market share, and
   regardless of industry or region of the world. Market share increases
   were also significantly correlated with improvements in manufacturing
   agility (R-2 = 4%). Agility improvement was significantly correlated
   with R&D intensity, and computerization in manufacturing, controlling
   for firm size and region, and did exhibit industry effects, with
   electronic equipment firms elevated on this measure. Computerization
   exhibited regional (not industry) differences, with South American firms
   depressed on this measure. The role of computerization in manufacturing
   and agility in firm innovativeness are discussed.
ZA 0
ZR 0
Z8 0
ZS 2
TC 99
ZB 0
Z9 101
SN 0025-1909
UT WOS:000072627200001
ER

PT J
AU Rajagopalan, S
   Singh, MR
   Morton, TE
TI Capacity expansion and replacement in growing markets with uncertain
   technological breakthroughs
SO MANAGEMENT SCIENCE
VL 44
IS 1
BP 12
EP 30
DI 10.1287/mnsc.44.1.12
PD JAN 1998
PY 1998
AB The accelerated pace of technological change has led to rapid
   obsolescence of productive capacity in electronics and other industries.
   Managers must consider the impact of future technologies while making
   acquisition and replacement decisions in such environments. We consider
   a problem where a sequence of technological breakthroughs are
   anticipated but their magnitude and timing are uncertain. A firm,
   operating in such an environment, must decide how much capacity of the
   current technology to acquire to meet future demand growth. It must also
   determine whether to upgrade any of the older vintages. We formulate
   this problem and present some structural results. Using these results,
   we then develop a highly efficient regeneration point-based dynamic
   programming algorithm. The effectiveness of the proposed algorithm is
   illustrated through a computational study. The sensitivity of the first
   period decision to various parameters is also explored.
ZA 0
ZS 0
TC 82
ZB 1
Z8 2
ZR 0
Z9 84
SN 0025-1909
UT WOS:000072627200002
ER

PT J
AU KLaassen, P
TI Financial asset-pricing theory and stochastic programming models for
   asset/liability management: A synthesis
SO MANAGEMENT SCIENCE
VL 44
IS 1
BP 31
EP 48
DI 10.1287/mnsc.44.1.31
PD JAN 1998
PY 1998
AB Practical portfolio investment problems under uncertainty can be modeled
   well as multiperiod stochastic programs. However, the numerical
   optimization methods that need to be used to solve such models seriously
   limit the level of detail in the uncertainty about future asset prices
   and returns that can be incorporated. Somewhat surprisingly, the
   question how this necessarily approximate description of the uncertainty
   should be constructed has received relatively little attention in the
   stochastic programming literature. Moreover, many of the descriptions
   that have been used are not arbitrage-free, and therefore inconsistent
   with modern financial asset-pricing theory. In this paper we will
   present aggregation methods that tan be used in combination with
   financial asset-pricing models to obtain a description of the
   uncertainty that is arbitrage-free, consistent with observed market
   prices as well as concise enough for a stochastic programming model.
   Furthermore, we will discuss how these aggregation methods can form the
   basis of an iterative solution approach.
ZB 0
ZS 1
ZR 1
TC 42
ZA 0
Z8 5
Z9 48
SN 0025-1909
UT WOS:000072627200003
ER

PT J
AU Simar, L
   Wilson, PW
TI Sensitivity analysis of efficiency scores: How to bootstrap in
   nonparametric frontier models
SO MANAGEMENT SCIENCE
VL 44
IS 1
BP 49
EP 61
DI 10.1287/mnsc.44.1.49
PD JAN 1998
PY 1998
AB Efficiency scores of production units are generally measured relative to
   an estimated production frontier. Nonparametric estimators (DEA,
   FDH,...) are based on a finite sample of observed production units. The
   bootstrap is one easy way to analyze the sensitivity of efficiency
   scores relative to the sampling variations of the estimated frontier.
   The main point in order to validate the bootstrap is to define a
   reasonable data-generating process in this complex framework and to
   propose a reasonable estimator of it. This paper provides a general
   methodology of bootstrapping in nonparametric frontier models. Some
   adapted methods are illustrated in analyzing the bootstrap sampling
   variations of input efficiency measures of electricity plants.
RI Figueiredo, Otavio H S/K-4777-2015; Wilson, Paul W/
OI Wilson, Paul W/0000-0002-9865-033X
ZA 0
ZR 2
ZS 20
ZB 57
TC 1004
Z8 26
Z9 1048
SN 0025-1909
UT WOS:000072627200004
ER

PT J
AU Clark, BH
   Montgomery, DB
TI Deterrence, reputations, and competitive cognition
SO MANAGEMENT SCIENCE
VL 44
IS 1
BP 62
EP 82
DI 10.1287/mnsc.44.1.62
PD JAN 1998
PY 1998
AB This study examines an aspect of competitive interactions that has
   attracted increasing research attention: the relationship between
   deterrence and competitive reputations. We build a conceptual model of
   the antecedents and consequences of a firm's reputation for being a
   credible defender of its markets. Theory and limited empirical evidence
   suggests a firm with this reputation should deter competitive attacks
   against it. We explore how a manager's competitive cognition about her
   opponents' (1) patterns of activity in the marketplace and (2) previous
   success can lead her to perceive a competitor as a credible defender. We
   test the framework using MBA students in a quasi-field setting, the
   Markstrat2 simulation game. The results of this study suggest that
   reputation deters attack only when the potential attacker considers the
   target firm a minor competitor. Managers consider defenders that have
   previously been successful as credible defenders of their markets. They
   also weigh consistency of activity relative to industry average in
   making inferences about credibility. The study indicates that the
   deterrence-reputation link is more complex than previous theory and
   evidence might imply, and suggests considerable promise for a
   psychological approach to examining competitive interactions.
RI Montgomery, David/AAG-5357-2019; MONTGOMERY, David/D-2179-2010
ZB 0
Z8 0
TC 85
ZA 0
ZS 1
ZR 0
Z9 85
SN 0025-1909
UT WOS:000072627200005
ER

PT J
AU Reddy, SK
   Aronson, JE
   Stam, A
TI SPOT: Scheduling programs optimally for television
SO MANAGEMENT SCIENCE
VL 44
IS 1
BP 83
EP 102
DI 10.1287/mnsc.44.1.83
PD JAN 1998
PY 1998
AB This paper introduces SPOT (Scheduling Programs Optimally for
   Television), an analytical model for optimal prime-time TV program
   scheduling. Due in part to the advent of new cable TV channels, the
   competition for viewer ratings has intensified substantially in recent
   years, and the revenues of the major networks have not kept pace with
   the costs of the programs. As profit margins decrease, the networks seek
   to improve their viewer ratings with innovative scheduling strategies.
   Our SPOT models for scheduling network programs combine predicted
   ratings for different combinations of prime-time schedules with a novel,
   mixed-integer, generalized network-based flow, mathematical programming
   model which when solved provides an optimal schedule. In addition to
   historical performance, subjective inputs from actual network managers
   were used as input to the network flow optimization model. The
   optimization model is flexible. It can utilize the managers' input and
   maximize profit (instead of ratings) by considering not only the revenue
   potential but also the costs of the shows. Moreover, SPOT can describe
   the scheduling problem over any time period (e.g., day, week, month,
   season), and designate certain shows to, and restrict them from, given
   time slots. The methodology of SPOT is illustrated using data for the
   first quarter of 1990, obtained from a cable network. The optimization
   model produces solutions that would have generated an increase of
   approximately 2% in overall profitability, representing over $6 million
   annually for the cable network. SPOT not only produces more profitable
   TV schedules for this network, but also provides valuable general
   insights into the development of mixed programming strategies for
   improving future schedules.
RI REDDY, Srinivas/D-2244-2010
TC 35
ZR 0
ZB 0
ZA 0
Z8 1
ZS 0
Z9 35
SN 0025-1909
UT WOS:000072627200006
ER

PT J
AU Pinnoi, A
   Wilhelm, WE
TI Assembly system design: A branch and cut approach
SO MANAGEMENT SCIENCE
VL 44
IS 1
BP 103
EP 118
DI 10.1287/mnsc.44.1.103
PD JAN 1998
PY 1998
AB This paper addresses the single-product assembly system design problem
   (ASDP), which seeks to minimize total cost by optimally integrating
   design (selecting the machine type to locate at each activated station)
   and operating issues (assigning tasks to observe precedence
   relationships and cycle time restrictions). We propose an effective
   branch-and-cut approach for solving single-product ASDPs, adapting
   inequalities known to be valid for embedded line balancing structures to
   form inequalities that are valid for the ASDP. The implementation also
   involves a specialized preprocessor, a heuristic, separation procedures,
   and an enumeration scheme. Computational tests establish benchmark
   results for this first implementation of cutting planes for solving the
   ASDP.
Z8 0
ZB 0
ZS 1
ZA 0
TC 34
ZR 0
Z9 35
SN 0025-1909
UT WOS:000072627200007
ER

PT J
AU Rapoport, A
   Seale, DA
   Erev, I
   Sundali, JA
TI Equilibrium play in large group market entry games
SO MANAGEMENT SCIENCE
VL 44
IS 1
BP 119
EP 141
DI 10.1287/mnsc.44.1.119
PD JAN 1998
PY 1998
AB Coordination behavior is studied experimentally in a class of
   noncooperative market entry games featuring symmetric players, complete
   information, zero entry costs, and several randomly presented values of
   the market capacity. Once the market capacity becomes publicly known,
   each player must decide privately whether to enter the market and
   receive a payoff, which increases linearly in the difference between the
   market capacity and the number of entrants, or stay out. Payoffs for
   staying out are either positive, giving rise to the domain of gains, or
   negative, giving rise to the domain of losses. The major findings are
   substantial individual differences that do not diminish with practice,
   aggregate behavior that is organized extremely well in both the domains
   of gains and losses by the Nash equilibrium solution, and variations in
   the population action strategies with repeated play of the stage game
   that are accounted for by a variant of an adaptive learning model due to
   Roth and Erev (1995).
OI Erev, Ido/0000-0001-9889-4070
ZB 4
ZS 0
TC 49
Z8 0
ZR 0
ZA 0
Z9 49
SN 0025-1909
UT WOS:000072627200008
ER

PT J
AU Thonemann, UW
   Brandeau, ML
TI Note. Optimal storage assignment policies for automated storage and
   retrieval systems with stochastic demands
SO MANAGEMENT SCIENCE
VL 44
IS 1
BP 142
EP 148
DI 10.1287/mnsc.44.1.142
PD JAN 1998
PY 1998
AB In existing AS/RS research, storage assignment policies are evaluated
   based on the probability that item type j will be stored (and
   subsequently retrieved). This note applies the turnover-based and
   class-based assignment policies of Hausman et al. (1976) to a stochastic
   environment by identifying the kth pallet of item type j: Frequently
   demanded pallets are stored close to the input/output point and rarely
   demanded pallets are stored at the end of the storage rack. We consider
   a discrete storage rack and a continuous storage rack. For the
   continuous rack case, we develop an expression for expected one-way
   travel time given uniform and exponentially distributed demand. We show
   that the turnover-based policy applied to the stochastic environment is
   optimal(it minimizes one-way travel time) and that both the
   turnover-based and class-based assignment policies applied in the
   stochastic environment reduce expected storage/retrieval time compared
   with random assignment. These savings can be directly translated into
   increased throughput capacity for existing systems and can be used to
   improve the design of proposed systems.
RI Thonemann, Ulrich W/C-4344-2008
OI Thonemann, Ulrich W/0000-0002-3507-9498
Z8 8
ZB 0
ZS 0
ZA 0
TC 36
ZR 0
Z9 44
SN 0025-1909
UT WOS:000072627200009
ER

PT J
AU Lipscomb, J
   Parmigiani, G
   Hasselblad, V
TI Combining expert judgment by hierarchical modeling: An application to
   physician staffing
SO MANAGEMENT SCIENCE
VL 44
IS 2
BP 149
EP 161
DI 10.1287/mnsc.44.2.149
PD FEB 1998
PY 1998
AB Expert panels are playing an increasingly important role in U.S. health
   policy decision making. A fundamental issue in these applications is how
   to synthesize the judgments of individual experts into a group judgment.
   In this paper we propose an approach to synthesis based on Bayesian
   hierarchical models, and apply it to the problem of determining
   physician staffing at medical centers operated by the U.S. Department of
   Veteran Affairs (VA).
   Our starting point is the supra-Bayesian approach to synthesis, whose
   principal motivation in the present context is to generate an estimate
   of the uncertainty associated with a panel's evaluation of the number of
   physicians required under specified conditions. Hierarchical models are
   particularly natural in this context since variability in the experts'
   judgments results in part from heterogeneity in their baseline
   experiences at different VA medical centers.
   We derive alternative hierarchical Bayes synthesis distributions for the
   number of physicians required to handle the (service-mix specific) daily
   workload in internal medicine at a given VA medical center (VAMC). The
   analysis appears to be the first to provide a statistical treatment of
   expert judgment processes for evaluating the appropriate use of
   resources in health care. Also, while hierarchical models are well
   established, their application to the synthesis of expert judgment is
   novel.
ZR 0
ZS 0
ZB 1
Z8 0
TC 23
ZA 0
Z9 23
SN 0025-1909
UT WOS:000072627300001
ER

PT J
AU Lee, HL
   Tang, CS
TI Variability reduction through operations reversal
SO MANAGEMENT SCIENCE
VL 44
IS 2
BP 162
EP 172
DI 10.1287/mnsc.44.2.162
PD FEB 1998
PY 1998
AB Products with high product variety are often made in a manufacturing
   process (or a supply chain) consisting of multiple stages, with products
   taking certain features or "personalities" at each stage. The product
   may start as a common single engine. As the product moves along
   manufacturing process, more features are added, and the product assumes
   more identities of the final end product. When demands of the end
   products are variable from period to period, the production volumes of
   the intermediate stages in the manufacturing process are also variable.
   It is widely recognized that variabilities of production volumes may add
   cost to the process. This paper is motivated by our observations in
   industry, where some companies have reengineered the manufacturing
   process by reversing two consecutive stages of the process. Such changes
   could lead to variance reduction, thereby improving the performance of
   the process. We develop formalized models that characterize the impact
   of such changes: operations reversal. These models are used to derive
   insights on when such reversal would be advisable.
OI tang, christopher/0000-0001-9597-7620
ZR 0
ZS 1
ZA 0
ZB 0
Z8 3
TC 75
Z9 79
SN 0025-1909
UT WOS:000072627300002
ER

PT J
AU Athanassopoulos, AD
TI Decision support for target-based resource allocation of public services
   in multiunit and multilevel systems
SO MANAGEMENT SCIENCE
VL 44
IS 2
BP 173
EP 187
DI 10.1287/mnsc.44.2.173
PD FEB 1998
PY 1998
AB This paper is concerned with the problem of resource allocation and
   target setting in the provision of public services. The paper develops a
   network-based representation of multilevel resource management With
   equity, efficiency, and effectiveness being recognised as the
   fundamental objectives of the system. On the modelling side, the
   proposed method combines data envelopment analysis and goal programming
   formulations integrated within an interactive planning framework. An
   illustrative application on fire departments is used to show the
   applicability of the method developed to assist the resource allocation
   process.
ZR 0
Z8 8
ZB 2
ZA 0
ZS 3
TC 76
Z9 85
SN 0025-1909
EI 1526-5501
UT WOS:000072627300003
ER

PT J
AU Young, MR
   DeSarbo, WS
   Morwitz, VG
TI The stochastic modeling of purchase intentions and behavior
SO MANAGEMENT SCIENCE
VL 44
IS 2
BP 188
EP 202
DI 10.1287/mnsc.44.2.188
PD FEB 1998
PY 1998
AB A common objective of social science and business research is the
   modeling of the relationship between demographic/psychographic
   characteristics of individuals and the likelihood of certain behaviors
   for these same individuals. Frequently, data on actual behavior are
   unavailable; rather, one has available only the self-reported intentions
   of the individual. If the reported intentions imperfectly predict actual
   behavior, then any model of behavior based on the intention data should
   account for the associated measurement error, or else the resulting
   predictions will be biased. In this paper, we provide a method for
   analyzing intentions data that explicitly models the discrepancy between
   reported intention and behavior, thus facilitating a less biased
   assessment of the impact of designated covariates on actual behavior.
   The application examined here relates to modeling relationships between
   demographic characteristics and actual purchase behavior among
   consumers. A new Bayesian approach employing the Gibbs sampler is
   developed and compared to alternative models. We show, through simulated
   and real data, that, relative to methods that implicitly equate
   intentions and behavior, the proposed method can increase the accuracy
   with which purchase response models are estimated.
ZA 0
ZS 1
TC 56
Z8 1
ZR 0
ZB 1
Z9 57
SN 0025-1909
UT WOS:000072627300004
ER

PT J
AU Lurie, PM
   Goldberg, MS
TI An approximate method for sampling correlated random variables from
   partially-specified distributions
SO MANAGEMENT SCIENCE
VL 44
IS 2
BP 203
EP 218
DI 10.1287/mnsc.44.2.203
PD FEB 1998
PY 1998
AB This paper presents an algorithm for generating correlated vectors of
   random numbers. The user need not fully specify the joint distribution
   function; instead, the user "partially specifies" only the marginal
   distributions and the correlation matrix. The algorithm may be applied
   to any set of continuous, strictly increasing distribution functions;
   the marginal distributions need not all be of the same functional form.
   The correlation matrix is first checked for mathematical consistency
   (positive semi-definiteness), and adjusted if necessary. Then the
   correlated random vectors are generated using a combination of Cholesky
   decomposition and Gauss-Newton iteration. Applications are made to cost
   analysis, where correlations are often present between cost elements in
   a work breakdown structure.
ZS 0
Z8 0
ZR 0
ZA 0
TC 69
ZB 4
Z9 69
SN 0025-1909
UT WOS:000072627300005
ER

PT J
AU Gallego, G
TI New bounds and heuristics for (Q, r) policies
SO MANAGEMENT SCIENCE
VL 44
IS 2
BP 219
EP 233
DI 10.1287/mnsc.44.2.219
PD FEB 1998
PY 1998
AB To clarify the impact of demand variability on single item stochastic
   inventory systems with setup costs, we subsume the distributional
   information of the lead time demand into its mean and variance and solve
   the resulting problem against the worst possible distribution in this
   class. For (Q, r) policies we obtain in closed form a distribution-free
   solution for Q and r, and upper bounds on the optimal long run average
   cost and on the optimal batch size. As a byproduct we develop a robust,
   distribution-free, batch size heuristic that causes a relative cost
   increase of no more than 6.07%. In addition, when the newsvendor cost is
   known, we obtain sharper lower and upper bounds on the long run average
   cost. These bounds clarify, in an exceedingly simple way, the cost
   impact of fixed setup costs, demand variability, and constraints on the
   batch size. We illustrate our bounds and heuristics on problems with
   Poisson and Compound Poisson demands.
RI Gallego, Guillermo/AAK-1549-2020
OI Gallego, Guillermo/0000-0002-9664-3750
Z8 2
ZR 0
TC 63
ZB 0
ZA 0
ZS 0
Z9 64
SN 0025-1909
EI 1526-5501
UT WOS:000072627300006
ER

PT J
AU Tokol, G
   Goldsman, D
   Ockerman, DH
   Swain, JJ
TI Standardized time series L-p-norm variance estimators for simulations
SO MANAGEMENT SCIENCE
VL 44
IS 2
BP 234
EP 245
DI 10.1287/mnsc.44.2.234
PD FEB 1998
PY 1998
AB This paper studies a class of estimators for the variance parameter of a
   stationary stochastic process. The estimators are based on L-p norms of
   standardized time series, and they generalize previously studied
   estimators due to Schruben. We show that the new estimators have some
   desirable properties: they are asymptotically unbiased and have low
   asymptotic variance. We also illustrate empirically the performance of
   the L-p-norm estimators on various stochastic processes.
ZR 0
ZS 0
Z8 0
TC 7
ZA 0
ZB 0
Z9 7
SN 0025-1909
UT WOS:000072627300007
ER

PT J
AU Rump, CM
   Stidham, S
TI Stability and chaos in input pricing for a service facility with
   adaptive customer response to congestion
SO MANAGEMENT SCIENCE
VL 44
IS 2
BP 246
EP 261
DI 10.1287/mnsc.44.2.246
PD FEB 1998
PY 1998
AB We consider the stability of the equilibrium arrival rate and
   equilibrium admission price at a service facility, using a
   generalization of an input-pricing model introduced by Dewan and
   Mendelson and further examined by Stidham. At the equilibrium, the
   marginal value of service equals the admission price, that is, the sum
   of the admission fee and the expected delay cost. Stability means
   (roughly) that the system returns to the equilibrium after a
   perturbation, assuming the customers base their join/balk decisions on
   previous prices. We extend the discrete-time, dynamic-system pricing
   model of Stidham to allow adaptive expectations in which customers
   predict the future price based on a convex combination of the current
   price and the previous prediction. We show that this can lead to chaotic
   behavior when the equilibrium is unstable. That is, the price and
   arrival rate can follow aperiodic orbits, which appear to be completely
   random. Our results suggest an alternative explanation for observed
   variations in the mean arrival rate to a queueing system, which are
   often modeled by means of a random exogenous (e.g., Markovian)
   environment process.
ZA 0
Z8 0
TC 34
ZB 0
ZS 0
ZR 0
Z9 34
SN 0025-1909
UT WOS:000072627300008
ER

PT J
AU Balas, E
   Vazacopoulos, A
TI Guided local search with shifting bottleneck for job shop scheduling
SO MANAGEMENT SCIENCE
VL 44
IS 2
BP 262
EP 275
DI 10.1287/mnsc.44.2.262
PD FEB 1998
PY 1998
AB Many recently developed local search procedures for job shop scheduling
   use interchange of operations, embedded in a simulated annealing or tabu
   search framework. We develop a new variable depth search procedure, GLS
   (Guided Local Search), based on an interchange scheme and using the new
   concept of neighborhood trees. Structural properties of the neighborhood
   are used to guide the search in promising directions. While this
   procedure competes successfully with others even as a stand-alone, a
   hybrid procedure that embeds GLS into a Shifting Bottleneck framework
   and takes advantage of the differences between the two neighborhood
   structures proves to be particularly efficient. We report extensive
   computational testing on all the problems available from the literature.
TC 201
ZB 5
ZR 0
Z8 30
ZS 0
ZA 0
Z9 229
SN 0025-1909
UT WOS:000072627300009
ER

PT J
AU Emmons, H
   Gilbert, SM
TI Note. The role of returns policies in pricing and inventory decisions
   for catalogue goods
SO MANAGEMENT SCIENCE
VL 44
IS 2
BP 276
EP 283
DI 10.1287/mnsc.44.2.276
PD FEB 1998
PY 1998
AB Manufacturers often use returns policies to encourage retailers to stock
   and price items more aggressively. We focus on the effect that such
   policies have on both a retailer's and a manufacturer's profits when the
   retailer must commit prior to the selling season to both a stocking
   quantity and a price at which to sell an item. Such a commitment is
   often necessary for retailers who sell primarily through catalogues.
TC 404
ZS 1
Z8 91
ZR 0
ZB 3
ZA 0
Z9 493
SN 0025-1909
UT WOS:000072627300010
ER

PT J
AU Smith, SA
   Achabal, DD
TI Clearance pricing and inventory policies for retail chains
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 285
EP 300
DI 10.1287/mnsc.44.3.285
PD MAR 1998
PY 1998
AB Clearance pricing and end of season inventory management are challenging
   and important problems in retailing. Sales rates depend upon price,
   seasonal effects, and the remaining assortment of items available to
   customers. There is little time to react to observed sales, and pricing
   errors result in either loss of potential revenue or excess inventory to
   be liquidated. This paper develops optimal clearance prices and
   inventory management policies that take into account the impact of
   reduced assortment and seasonal changes on sales rates. Versions of
   these policies have been tested and implemented at three major retail
   chains and these applications are summarized and discussed.
RI Achabal, Dale D/A-8004-2009
ZR 0
Z8 6
ZA 0
ZB 1
TC 126
ZS 0
Z9 132
SN 0025-1909
UT WOS:000072930000001
ER

PT J
AU Degraeve, Z
   Vandebroek, M
TI A mixed integer programming model for solving a layout problem in the
   fashion industry
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 301
EP 310
DI 10.1287/mnsc.44.3.301
PD MAR 1998
PY 1998
AB The cutting operation in the high fashion clothing industry essentially
   involves putting several layers of cloth on a long cutting table and
   fixing templates of the parts of several articles on top of the stack
   before the actual cutting can be initiated. This is a very
   time-consuming task giving raise to high setup costs in addition to
   waste production resulting from the cutting process. Total production
   costs can then be optimized by minimizing the number of these setups
   while at the same time producing little or no waste. In this paper a
   mixed integer programming model is proposed that searches for an optimal
   set of cutting patterns, each giving a combination of articles to be cut
   in one operation, and corresponding stack heights.
RI Vandebroek, Martina L./J-9103-2015
OI Vandebroek, Martina L./0000-0002-0317-1986
ZR 0
ZS 0
TC 26
Z8 2
ZB 0
ZA 0
Z9 27
SN 0025-1909
UT WOS:000072930000002
ER

PT J
AU Carrizosa, E
   Conde, E
   Munoz-Marquez, M
TI Admission policies in loss queueing models with heterogeneous arrivals
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 311
EP 320
DI 10.1287/mnsc.44.3.311
PD MAR 1998
PY 1998
AB In this paper we consider a loss system where the arrivals can be
   classified into different groups according to their arrival rate and
   expected service time. While the standard admission policy consists of
   rejecting only those customers who arrive when all servers are busy, we
   address the problem of finding the optimal static admission policy (with
   respect to a given reward structure) when customers can be discriminated
   according to the group they belong to, thus customers of some groups
   might be automatically rejected (even if some servers remain idle) in
   order to enhance the global efficiency of the system. The optimality of
   a c mu-rule is shown, from which finite-time algorithms for the one-and
   two-server cases are derived.
RI Conde, Eduardo/I-3111-2018; Munoz-Marquez, Manuel/K-7206-2012; Carrizosa, Emilio/K-6788-2014
OI Conde, Eduardo/0000-0001-5369-8463; Munoz-Marquez,
   Manuel/0000-0003-4157-8784; Carrizosa, Emilio/0000-0002-0832-8700
ZR 0
ZB 0
Z8 1
ZS 0
TC 14
ZA 0
Z9 15
SN 0025-1909
UT WOS:000072930000003
ER

PT J
AU Shumsky, RA
TI Optimal updating of forecasts for the timing of future events
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 321
EP 335
DI 10.1287/mnsc.44.3.321
PD MAR 1998
PY 1998
AB A major problem in forecasting is estimating the time of some future
   event. Traditionally, forecasts are designed to minimize an error cost
   function that is evaluated once, possibly when the event occurs and
   forecast accuracy can be determined. However, in many applications
   forecast error costs accumulate over time, and the forecasts themselves
   may be updated with information that is collected as the expected time
   of the event approaches. This paper examines one such application in
   which flow control managers in the U.S. air traffic system depend on
   forecasts of aircraft departure times to predict and alleviate potential
   congestion. These forecasts are periodically updated until take-off
   occurs, although the number of updates may be limited by the cost of
   collecting, processing, and distributing information. The procedures
   developed in this paper balance the costs of accumulated forecast errors
   and the costs of forecast updates. The procedures are applied to the
   aircraft departure forecasting problem and are compared with methods
   currently used by the air traffic management system. Numerical examples
   demonstrate that the procedures increase forecast accuracy while
   reducing the costs associated with frequent forecast updates.
ZB 0
ZR 0
ZS 0
TC 3
ZA 0
Z8 0
Z9 3
SN 0025-1909
UT WOS:000072930000004
ER

PT J
AU Glover, F
   Kochenberger, GA
   Alidaee, B
TI Adaptive memory tabu search for binary quadratic programs
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 336
EP 345
DI 10.1287/mnsc.44.3.336
PD MAR 1998
PY 1998
AB Recent studies have demonstrated the effectiveness of applying adaptive
   memory tabu search procedures to combinatorial optimization problems. in
   this paper we describe the development and use of such an approach to
   solve binary quadratic programs. Computational experience is reported,
   showing that the approach optimally solves the most difficult problems
   reported in the literature. For challenging problems of limited size,
   which are capable of being approached by exact procedures, we find
   optimal solutions considerably faster than the best reported exact
   method. Moreover, we demonstrate that our approach is significantly more
   efficient and yields better solutions than the best heuristic method
   reported to date. Finally, we give outcomes for larger problems that are
   considerably more challenging than any currently reported in the
   literature.
ZB 3
ZA 0
ZS 2
Z8 0
TC 108
ZR 0
Z9 110
SN 0025-1909
UT WOS:000072930000005
ER

PT J
AU Lau, HS
   Lau, AHL
   Ho, CJ
TI Improved moment-estimation formulas using more than three subjective
   fractiles
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 346
EP 351
DI 10.1287/mnsc.44.3.346
PD MAR 1998
PY 1998
AB PERT-type subjective estimations are used in many stochastic decision
   models to estimate the random variables' mean and standard deviation
   (s.d.). The approach is based on the beta-distribution assumption; also,
   mast PERT-type formulas use only three estimated fractiles. We point out
   that: (if it is desirable to consider a substantially richer set of
   distributions than the beta in developing PERT-type formulas; (ii) it
   may be beneficial to use more than three fractile-estimates in PERT-type
   formulas. We then develop formulas for estimating the mean and s.d. that
   are based on a substantially richer set of distributions than the beta
   and that use more than three estimated fractiles. These formulas perform
   better than the best currently-available formulas when the subjective
   distribution is not restricted to be beta.
TC 18
ZB 3
Z8 0
ZS 0
ZR 0
ZA 0
Z9 18
SN 0025-1909
UT WOS:000072930000006
ER

PT J
AU Ulrich, KT
   Pearson, S
TI Assessing the importance of design through product archaeology
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 352
EP 369
DI 10.1287/mnsc.44.3.352
PD MAR 1998
PY 1998
AB This paper assesses the importance-of design in determining product
   costs by measuring the variation in design performance among a set of
   competing design efforts. This assessment is completed for a set of
   functionally similar products in a single product category: automatic
   drip coffee makers, The approach of this study is to measure the
   manufacturing content-the attributes of the design that drive
   cost-through analysis of the physical products themselves, and to
   estimate how variation in manufacturing content relates to variation in
   cost in a hypothetical manufacturing setting. We call this approach
   product archaeology. For the domain of coffee makers, we find
   significant variation in manufacturing content. This variation in
   manufacturing content corresponds to a range of estimated manufacturing
   casts, for a hypothetical manufacturing system, of approximately 50
   percent of the average manufacturing cost of the products, We also find
   that differences in capabilities among product-development efforts are
   the most plausible explanation for the differences in manufacturing
   content.
ZS 0
Z8 1
ZA 0
ZB 0
ZR 0
TC 82
Z9 83
SN 0025-1909
UT WOS:000072930000007
ER

PT J
AU Epstein, GS
TI Network competition and the timing of commercials
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 370
EP 387
DI 10.1287/mnsc.44.3.370
PD MAR 1998
PY 1998
AB In a market with a small number of networks, the timing of the
   commercial breaks is a very import-ant factor in determining the number
   of Viewers facing a channel. Using a theoretical model and statistical
   analysis with empirical data from the four networks in the United
   States, we analyze the equilibrium achieved in this network monopolistic
   competition. Among other things, it is shown theoretically and
   empirically that in equilibrium all networks broadcast commercial breaks
   at the same time. As the ability to coordinate is not always possible,
   it is shown that, as the program progresses, the level of coordination
   decreases.
ZS 0
ZB 0
Z8 0
ZR 0
TC 5
Z9 5
SN 0025-1909
UT WOS:000072930000008
ER

PT J
AU Martello, S
   Vigo, D
TI Exact solution of the Two-Dimensional Finite Bin Packing Problem
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 388
EP 399
DI 10.1287/mnsc.44.3.388
PD MAR 1998
PY 1998
AB Given a set of rectangular pieces to be cut from an unlimited number of
   standardized stock pieces (bins), the Two-Dimensional Finite Bin Packing
   Problem is to determine the minimum number of stock pieces that provide
   all the pieces. The problem is NP-hard in the strong sense and finds
   many practical applications in the cutting and packing area. We analyze
   a well-known lower bound and determine its worst-case performance. We
   propose new lower bounds which are used within a branch-and-bound
   algorithm for the exact solution of the problem. Extensive computational
   testing on problem instances from the literature involving up to 120
   pieces shows the effectiveness of the proposed approach.
RI Martello, Silvano/D-3117-2011; Vigo, Daniele/K-3979-2013
OI Martello, Silvano/0000-0001-6515-1406; Vigo, Daniele/0000-0002-1499-8452
Z8 8
ZS 1
ZB 1
ZR 7
TC 208
ZA 0
Z9 224
SN 0025-1909
UT WOS:000072930000009
ER

PT J
AU Berk, E
   Moinzadeh, K
TI The impact of discharge decisions on health care quality
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 400
EP 415
DI 10.1287/mnsc.44.3.400
PD MAR 1998
PY 1998
AB In this paper, we present a normative study that describes the impact of
   discharging decisions in the face of resource shortages. We develop a
   model that represents the dynamics of a health cafe unit. Then, to
   capture the essence of discharge decisions, we consider discharge
   policies that incorporate both the occupancy level of the unit and the
   status of patients measured by their stage of recovery and the time they
   have spent in that stage. We believe that our model tan be used as an
   aid to physicians and administrators to better assess discharge and/or
   capacity decisions. in addition, we investigate the impact of discharge
   decisions on the measures that represent the duality of care at a
   facility such as average hospital stays, system accessibility, and
   average complication risk of discharged patients. Our findings
   illustrate that inclusion of early discharge option improves system
   accessibility significantly and does not jeopardize care equity among
   patients. Furthermore, introduction of early discharge option has more
   pronounced effects on increasing care unit capacity than addition of
   open beds with no early discharges.
RI Embrett, Mark G./H-4466-2014
OI Embrett, Mark G./0000-0002-3969-0219
Z8 1
ZA 0
ZR 0
ZS 0
ZB 0
TC 11
Z9 12
SN 0025-1909
UT WOS:000072930000010
ER

PT J
AU Piramuthu, S
   Ragavan, H
   Shaw, MJ
TI Using feature construction to improve the performance of neural networks
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 416
EP 430
DI 10.1287/mnsc.44.3.416
PD MAR 1998
PY 1998
AB Recent years have seen the growth in popularity of neural networks for
   business decision support because of their capabilities' for modeling,
   estimating, and classifying. Compared to other AI methods for problem
   solving such as expert systems, neural network approaches are especially
   useful far their ability to learn adaptively from observations. However,
   neural network learning performed by algorithms such as back-propagation
   (BP) are known to be slow due to the size of the search space involved
   and also the iterative manner in which the algorithm works. In this
   paper, we show that the degree of difficulty in neural network learning
   is inherent in the given set of training examples. We propose a
   technique for measuring such learning difficulty, and then develop a
   feature construction methodology that helps transform the training data
   so that both. the learning speed and classification accuracy of neural
   network algorithms are improved, We show the efficacy of the proposed
   method for financial risk classification, a domain characterized by
   frequent data noise, lack of functional structure, and high attribute
   interactions. Moreover, the empirical studies also provide insights into
   the structural characteristics of neural networks with respect to the
   input data used as well as possible mechanisms to improve the learning
   performance.
TC 58
ZB 2
ZA 0
ZS 1
ZR 0
Z8 0
Z9 58
SN 0025-1909
UT WOS:000072930000011
ER

PT J
AU Zhang, HT
TI A note on the convexity of service-level measures of the (r, q) system
SO MANAGEMENT SCIENCE
VL 44
IS 3
BP 431
EP 432
DI 10.1287/mnsc.44.3.431
PD MAR 1998
PY 1998
AB This note gives a simple proof that in a (r, q) system the average
   outstanding backorders and the average stockouts per unit time are
   jointly convex in the two control variables q and r.
TC 9
ZR 0
ZS 0
Z8 0
ZB 0
ZA 0
Z9 9
SN 0025-1909
UT WOS:000072930000012
ER

PT J
AU Banker, RD
   Davis, GB
   Slaughter, SA
TI Software development practices, software complexity, and software
   maintenance performance: A field study
SO MANAGEMENT SCIENCE
VL 44
IS 4
BP 433
EP 450
DI 10.1287/mnsc.44.4.433
PD APR 1998
PY 1998
AB Software maintenance claims a large proportion of organizational
   resources. It is thought that many maintenance problems derive from
   inadequate software design and development practices. Poor design
   choices can result in complex software that is costly to support and
   difficult to change. However, it is difficult to assess the actual
   maintenance performance effects of software development practices
   because their impact is realized over the software life cycle. To
   estimate the impact of development activities in a more practical time
   frame, this research develops a two-stage model in which software
   complexity is a key intermediate variable that links design and
   development decisions to their downstream effects on software
   maintenance. The research analyzes data collected from a national mass
   merchandising retailer on 29 software enhancement projects and 23
   software applications in a large IBM COBOL environment. Results indicate
   that the use of a code generator in development is associated with
   increased software complexity and software enhancement project effort.
   The use of packaged software is associated with decreased software
   complexity and software enhancement effort. These results suggest an
   important link between software development practices and maintenance
   performance.
ZS 0
TC 127
ZB 0
Z8 0
ZR 0
ZA 0
Z9 127
SN 0025-1909
UT WOS:000073674500001
ER

PT J
AU Alles, M
   Datar, S
TI Strategic transfer pricing
SO MANAGEMENT SCIENCE
VL 44
IS 4
BP 451
EP 461
DI 10.1287/mnsc.44.4.451
PD APR 1998
PY 1998
AB Most research into cost systems has focused on their motivational
   implications. This paper takes a different approach, by developing a
   model where two oligopolistic firms strategically select their
   cost-based transfer prices. Duopoly models frequently assume that firms
   game on their choice of prices. Product prices, however, are ultimately
   based on the firms' transfer prices that communicate manufacturing costs
   to marketing departments. It is for this reason that transfer prices
   will have a strategic component to them. We derive implications for cost
   system choice and transfer pricing, including showing that firms may
   cross subsidize their products-a result consistent with the empirical
   evidence.
ZR 0
ZB 0
ZA 0
ZS 0
Z8 10
TC 75
Z9 85
SN 0025-1909
UT WOS:000073674500002
ER

PT J
AU Ballou, D
   Wang, R
   Pazer, H
   Tayi, GK
TI Modeling information manufacturing systems to determine information
   product quality
SO MANAGEMENT SCIENCE
VL 44
IS 4
BP 462
EP 484
DI 10.1287/mnsc.44.4.462
PD APR 1998
PY 1998
AB Many of the concepts and procedures of product quality control can be
   applied to the problem of producing better quality information outputs.
   From this perspective, information outputs can be viewed as information
   products, and many information systems can be modeled as information
   manufacturing systems. The use of information products is becoming
   increasingly prevalent both within and across organizational boundaries.
   This paper presents a set of ideas, concepts, models, and procedures
   appropriate to information manufacturing systems that can be used to
   determine the quality of Information products delivered, or transferred,
   to information customers. These systems produce information products on
   a regular or as-requested basis. The model systematically tracks
   relevant attributes of the information product such as timeliness,
   accuracy and cost. This is facilitated through an information
   manufacturing analysis matrix that relates data units and various system
   components. Measures of these attributes can then be used to analyze
   potential improvements to the information manufacturing system under
   consideration.
   An illustrative example is given to demonstrate the various features of
   the information manufacturing system and show how it can be used to
   analyze and improve the system. Following that is an actual application,
   which, although not as involved as the illustrative example, does
   demonstrate the applicability of the model and its associated concepts
   and procedures.
Z8 6
TC 159
ZR 0
ZB 3
ZA 0
ZS 4
Z9 169
SN 0025-1909
UT WOS:000073674500003
ER

PT J
AU Ferson, WE
   Locke, DH
TI Estimating the cost of capital through time: An analysis of the sources
   of error
SO MANAGEMENT SCIENCE
VL 44
IS 4
BP 485
EP 500
DI 10.1287/mnsc.44.4.485
PD APR 1998
PY 1998
AB Practitioners needing estimates of a firm's equity cost of capital have
   long relied on the Capital Asset Pricing Model (CAPM). Recent evidence
   casts renewed doubt on the validity of the CAPM and beta. However, there
   is not much evidence to gauge the importance of the rejections of the
   CAPM in a practical decision-making context. This paper presents
   evidence on the sources of error in estimating required returns over
   time. We use a number of proxies for the true mean variance efficient
   portfolio, allowing that the CAPM is the "wrong" model. The analyst is
   assumed to rely on a standard market index. We find that the great
   majority of the error in estimating the cost of equity capital is found
   in the risk premium estimate, and relatively small errors are due to the
   risk measure, or beta. This suggests that analysts should improve
   estimation procedures for market risk premiums, which are commonly based
   on historical averages. This can be done by using regression models,
   such as:have appeared in the recent finance literature, or by purchasing
   forecasts from firms that specialize in producing them.
ZB 0
ZA 0
Z8 0
TC 16
ZS 3
ZR 0
Z9 19
SN 0025-1909
UT WOS:000073674500004
ER

PT J
AU van Witteloostuijn, A
TI Bridging behavioral and economic theories of decline: Organizational
   inertia, strategic competition, and chronic failure
SO MANAGEMENT SCIENCE
VL 44
IS 4
BP 501
EP 519
DI 10.1287/mnsc.44.4.501
PD APR 1998
PY 1998
AB This paper is another plea for bridging behavioral and economic
   approaches to the study of competition in markets and strategy making by
   firms. The arguments focus on a specific case in point: the behavioral
   theory of organizational decline and the economic modeling of immediate
   exit. The arguments come in three steps. First, the literature on
   organizational decline is reviewed by organizing a framework that
   summarizes arguments from varying economic and organizational
   perspectives that have, for the most part, developed independently.
   Observations from empirical and theoretical studies are combined in
   order to investigate the causes, conditions, courses, and consequences
   of organizational downturn. Second, a theoretical argument is developed
   that explains voluntary exit and chronic failure by introducing a proxy
   of organizational inertia in a model of strategic Cournot duopoly. The
   key assumptions, which have a behavioral flavour that seemingly
   contradicts orthodox economics, are grounded in the theoretical and
   empirical literatures. The results of the model support the claim that
   "pure profit maximizing behavior may be at the expense of organizational
   survival" (D'Aveni 1990, p. 135). Third, by formulating two hypotheses
   and presenting tentative evidence from the chemical industry, the paper
   hopes to convincingly argue that such integrative models lead to
   empirical testing of interesting hypotheses. A key finding here is that
   inefficient firms may outlast their efficient rivals (cf. D'Aveni
   1989a).
OI van Witteloostuijn, A./0000-0002-0287-5965
TC 72
ZB 1
ZA 0
Z8 0
ZS 2
ZR 0
Z9 73
SN 0025-1909
EI 1526-5501
UT WOS:000073674500005
ER

PT J
AU Regenwetter, M
   Grofman, B
TI Approval voting, borda winners, and condorcet winners: Evidence from
   seven elections
SO MANAGEMENT SCIENCE
VL 44
IS 4
BP 520
EP 533
DI 10.1287/mnsc.44.4.520
PD APR 1998
PY 1998
AB We analyze 10 three-candidate elections (and mock elections) conducted
   under approval voting (AV) using a method developed by Falmagne and
   Regenwetter (1996) that allows us to construct a distribution of rank
   orders from subset choice data. The elections were held by the Institute
   of Management Science, the Mathematical Association of America, several
   professional organizations in Britain, and the Institute of Electrical
   and Electronics Engineers. Seven of the 10 elections satisfy the
   conditions under which the Falmagne-Regenwetter method is suitable. For
   these elections we recreate possible underlying preferences of the
   electorate. On the basis of these distributions of preferences we find
   strong evidence that AV would have selected Condorcet winners when they
   exist and would have always selected the Borda winner, Thus, we find
   that AV is not just simple to use, but also gives rise to outcomes that
   well reflect voter preferences.
   Our results also have an important implication fur the general study of
   social choice processes, They suggest that transitive majority orderings
   may be expected in real-world settings more often then the formal social
   choice literature suggests. In six out of seven data sets we find social
   welfare orders; only one data set generates cycles anywhere in the
   solution space.
OI Regenwetter, Michel/0000-0002-5607-9016
ZS 0
ZR 1
Z8 0
ZB 2
ZA 0
TC 40
Z9 41
SN 0025-1909
UT WOS:000073674500006
ER

PT J
AU Brusco, MJ
   Jacobs, LW
TI Personnel tour scheduling when starting-time restrictions are present
SO MANAGEMENT SCIENCE
VL 44
IS 4
BP 534
EP 547
DI 10.1287/mnsc.44.4.534
PD APR 1998
PY 1998
AB This payer presents an effective solution strategy for an important
   category of personnel scheduling problems. Specifically, we address the
   restricted starting-time tour-scheduling problem (RSTP), which involves
   the determination of the hours of the day (shifts) and days of the week
   (days on) that employees are assigned to work. RSTP is characterized by
   restrictions on the number of daily time periods in which employees may
   begin their shifts. Moreover, the RSTP we consider contains constraints
   that require separation of starting times. Such restrictions are widely
   encountered in practice and are based on a number of factors including
   managerial concerns for control of employee movements, union contractual
   obligations, and employee preferences for common shift starting times.
   A two-stage heuristic solution strategy is proposed for RSTP. We
   developed eight heuristic procedures based on this strategy and applied
   them to four sets of labor requirements, for each of 27 United Airlines
   (UA) airport ground stations. One of the best of these procedures
   yielded solution costs that averaged only 1.36 full-time-equivalent
   employees above very conservative LP-based lower bounds. Moreover, the
   solution costs obtained using this procedure were, on average, 28
   percent closer to the lower bounds than solution costs obtained using
   UA's current scheduling system. We conclude that the two-stage heuristic
   solution strategy is a valuable platform from which to develop
   procedures for generating near-optimal solutions to this difficult class
   of personnel scheduling problems.
ZS 0
Z8 0
ZB 0
ZR 0
TC 48
ZA 0
Z9 48
SN 0025-1909
UT WOS:000073674500007
ER

PT J
AU Lewis, GH
   Srinivasan, A
   Subrahmanian, E
TI Staffing and allocation of workers in an administrative office
SO MANAGEMENT SCIENCE
VL 44
IS 4
BP 548
EP 570
DI 10.1287/mnsc.44.4.548
PD APR 1998
PY 1998
AB The world of work is increasingly characterized by processing of
   records, forms, or cases. This processing is usually organized as a set
   of interdependent tasks within an administrative office. A major issue
   facing such administrative offices is how they should be organized to
   maximize productivity when short-term reassignment of workers is
   difficult; costly, or severely restricted. The present work grew out of
   a study conducted at a Count-Jr Assistance Office in Western
   Pennsylvania and addresses three important productivity questions in
   organizational productivity: (1) How should a given number of workers be
   allocated across related tasks, (2) will the arrangement that seems best
   for productivity increase or decrease equity within the office, and (3)
   what is the optimal size of an office?
   To answer question 1, we model the administrative office as a closed
   queueing network. Thus modeled, the problem has an optimal allocation of
   workers, and we propose an efficient method for finding it. in response
   to question 2, we show (1) that for offices of a fixed size, the
   allocation of workers that maximizes throughput also maximizes equity,
   and (2) that across offices of different sizes, throughput per worker is
   not monotonicly related to equity. Changes in the size of the office
   that improve productivity may have lower equity; conversely, changes in
   the size of the office that improve equity may have lower productivity.
   Finally, in response to question 3, we show that the previous results
   can be used to determine the optimal office size in terms of throughput,
   This result has relevance for situations in which there are multiple
   offices of the same type.
   To the extent that worker satisfaction is related to equity, these
   results imply that managers may have to choose between worker
   satisfaction and output in setting the size of the office, but for
   offices of a fixed size, the allocation that maximizes output will also
   maximize worker satisfaction.
OI Subrahmanian, Eswaran/0000-0002-4639-627X
Z8 0
ZR 0
ZA 0
ZB 0
ZS 0
TC 5
Z9 5
SN 0025-1909
UT WOS:000073674500008
ER

PT J
AU Shaver, JM
TI Accounting for endogeneity when assessing strategy performance: Does
   entry mode choice affect FDI survival?
SO MANAGEMENT SCIENCE
VL 44
IS 4
BP 571
EP 585
DI 10.1287/mnsc.44.4.571
PD APR 1998
PY 1998
AB Firms choose strategies based on their attributes and industry
   conditions; therefore, strategy choice is endogenous and self-selected.
   Empirical models that do not account for this and regress performance
   measures on strategy choice variables are potentially misspecified and
   their conclusions incorrect. I highlight how self-selection on
   hard-to-measure or unobservable characteristics can bias strategy
   performance estimates and recommend an econometric technique that has
   been developed to account for this effect. Although this concern applies
   to a wide range of strategy questions, to demonstrate its effect I
   empirically examine if entry mode choice (acquisition versus greenfield)
   influences foreign direct investment survival. In specifications that do
   not account for self-selection, I find that greenfield entries have
   survival advantages compared to acquisitions. This confirms previous
   findings. However, the significance of this effect disappears once I
   account for self-selection of entry mode in the empirical estimates. The
   results confirm that estimates from models that do not account for
   self-selection of strategy choice can lead to incorrect or misleading
   conclusions.
RI Shaver, J Myles/AAI-4171-2020; Shaver, James/
OI Shaver, James/0000-0003-3742-2816
ZS 2
TC 552
Z8 3
ZB 1
ZA 0
ZR 0
Z9 556
SN 0025-1909
UT WOS:000073674500009
ER

PT J
AU Thanassoulis, E
   Allen, R
TI Simulating weights restrictions in data envelopment analysis by means of
   unobserved DMUs
SO MANAGEMENT SCIENCE
VL 44
IS 4
BP 586
EP 594
DI 10.1287/mnsc.44.4.586
PD APR 1998
PY 1998
AB Data envelopment analysis (DEA) is a method for assessing the
   comparative efficiencies of decision making units (e.g., banks and
   schools) by relating their output to their input levels, Restrictions
   are often imposed in these assessments to reflect prior judgments on the
   values of input and/or output variables. This paper introduces a new
   approach to capturing and using value judgments in DEA, based on
   unobserved Decision Making Units. In so doing, it opens up a whole new
   approach for reflecting value judgments in DEA assessments, which can
   offer advantages in certain situations.
OI Thanassoulis, Emmanuel/0000-0002-3769-5374
ZB 1
Z8 1
ZR 0
TC 82
ZA 0
ZS 1
Z9 84
SN 0025-1909
UT WOS:000073674500010
ER

PT J
AU Dewan, S
   Mendelson, H
TI Information technology and time-based competition in financial markets
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 595
EP 609
DI 10.1287/mnsc.44.5.595
PD MAY 1998
PY 1998
AB This paper studies time-based competition in imperfect securities
   markets, linking IT investment decisions, information processing delays,
   and trading strategies. At the IT investment stage, traders trade off
   the cost of IT against their anticipated trading profits. At the trading
   stage, each trader devises a trading strategy based on his new
   information while taking into account the impact of both his own trades
   and those of other traders in the market. Our results illustrate how
   traders react to market imperfections due to trading costs and
   information processing delays, and how superior traders convert a
   timeliness advantage into higher trading profits. They also shed light
   on the relationship between the price adjustment process and traders'
   information processing delays. Timeliness imposes an interesting
   structure on trader competition: traders with longer information
   processing delays trade less frequently, submit smaller orders and enjoy
   lower profits per trade. Our analysis of traders' IT investment
   decisions demonstrates how factors such as IT costs, number of traders,
   and the frequency and nature of new information affect the level of IT
   investments. We further illustrate how improved IT infrastructure
   translates into competitive advantage.
ZB 0
ZS 1
Z8 1
ZR 0
ZA 0
TC 26
Z9 28
SN 0025-1909
UT WOS:000074264100001
ER

PT J
AU Morwitz, VG
   Schmittlein, DC
TI Testing new direct marketing offerings: The interplay of management
   judgment and statistical models
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 610
EP 628
DI 10.1287/mnsc.44.5.610
PD MAY 1998
PY 1998
AB The launch of a new product or service via direct marketing is nearly
   always preceded by a test of that offering. Such a "live" test,
   conducted with a subset of the entire list of customer prospects, can
   sometimes be useful in a "go/no-go" decision regarding a full-scale
   launch of the offering. More commonly, the test is used to direct the
   offering more effectively toward the market segments that appear most
   promising. Specifically, test results are used and useful to determine
   whether a particular rental list of customer prospects should indeed be
   rented, and (for both rental and in-house lists) which specific customer
   segments should be contacted with the offering.
   This paper examines the effectiveness of managers' decisions related to
   designing a test and interpreting test results both conceptually-based
   on the literature of heuristics and biases in expert judgments-and
   empirically, for two new direct marketing offers. The paper describes
   how an interplay of management judgment and statistical models can lead
   to increased profits for new direct marketing offerings.
Z8 1
ZA 0
ZS 0
ZB 0
ZR 0
TC 12
Z9 13
SN 0025-1909
UT WOS:000074264100002
ER

PT J
AU von Hippel, E
TI Economics of product development by users: The impact of "sticky" local
   information
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 629
EP 644
DI 10.1287/mnsc.44.5.629
PD MAY 1998
PY 1998
AB Those who solve more of a given type of problem tend to get better at
   it-which suggests that problems of any given type should be brought to
   specialists for a solution. However, in this paper we argue that
   agency-related costs and information transfer costs ("sticky" local
   information) will tend drive the locus of problem-solving in the
   opposite direction-away from problem-solving by specialist suppliers,
   and towards those who directly benefit from a solution and who have
   difficult-to-transfer local information about a particular application
   being solved, such as the direct users of a product or service. We
   examine the actual location of design activities in two fields in which
   custom products are produced by "mass-customization'' methods:
   application-specific integrated circuits (ASICs) and computer telephony
   integration (CTI) systems. In both, we find that users rather than
   suppliers are the actual designers of the application-specific portion
   of the product types examined. We offer anecdotal evidence that the
   pattern of user-based customization we have documented in these two
   fields is in fact quite general, and we discuss implications for
   research and practice.
ZR 0
TC 399
ZA 0
Z8 1
ZS 1
ZB 4
Z9 401
SN 0025-1909
UT WOS:000074264100003
ER

PT J
AU van Bruggen, GH
   Smidts, A
   Wierenga, B
TI Improving decision making by means of a marketing decision support
   system
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 645
EP 658
DI 10.1287/mnsc.44.5.645
PD MAY 1998
PY 1998
AB Marketing decision makers are confronted with an increasing amount of
   information. This leads to a complex decision environment that may cause
   decision makers to lapse into using mental-effort-reducing heuristics
   such as anchoring and adjustment, in an experimental study, we find that
   the use of a marketing decision support system (MDSS) increases the
   effectiveness of marketing decision makers. An MDSS is effective because
   it assists its users in identifying the important decision variables
   and, subsequently, making better decisions based on those variables.
   Decision makers using an MDSS are also less susceptible to applying the
   anchoring and adjustment heuristic and, therefore show more variation in
   their decisions in a dynamic environment. Low-analytical decision makers
   and decision makers operating under low time pressure especially benefit
   from using an MDSS.
RI Smidts, Ale/B-8701-2008; Smidts, Ale/
OI Smidts, Ale/0000-0002-6699-1172
ZS 0
ZB 0
ZA 0
ZR 0
TC 55
Z8 0
Z9 55
SN 0025-1909
UT WOS:000074264100004
ER

PT J
AU Leland, JW
TI Similarity judgments in choice under uncertainty: A reinterpretation of
   the predictions of regret theory
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 659
EP 672
DI 10.1287/mnsc.44.5.659
PD MAY 1998
PY 1998
AB The Regret theory of Loomes and Sugden (1982) predicts choice anomalies
   implied by other alternatives to expected utility (e.g., violations of
   the independence axiom). It also makes unique and controversial
   predictions regarding the rational violation of stochastic dominance and
   invariance. All these predictions depend critically on assumptions
   regarding the statistical independence or dependence of the available
   alternatives. None of the predictions depend on the framing or
   representation of the alternatives. Leland (1994) shows that a model of
   choice based on similarity judgments predicts choices implied by Regret
   theory. In contrast to Regret theory, however, these predictions depend
   critically on the way the choices are framed and not on the dependence
   or independence of the alternatives. This paper presents experimental
   results indicating that the frequencies with which violations of
   independence, dominance, and invariance occur are, in most cases,
   insensitive to the statistical dependence or independence of the
   alternatives but sensitive to the way the choices are presented. These
   findings support the hypothesis that such behaviors arise as a
   consequence of reliance upon similarity judgments.
ZB 2
TC 30
ZR 0
ZA 0
ZS 0
Z8 1
Z9 31
SN 0025-1909
UT WOS:000074264100005
ER

PT J
AU Young, MR
TI A minimax portfolio selection rule with linear programming solution
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 673
EP 683
DI 10.1287/mnsc.44.5.673
PD MAY 1998
PY 1998
AB A new principle for choosing portfolios based on historical returns data
   is introduced; the optimal portfolio based on this principle is the
   solution to a simple linear programming problem. This principle uses
   minimum return rather than variance as a measure of risk. In particular,
   the portfolio is chosen that minimizes the maximum loss over all past
   observation periods, for a given level of return. This objective
   function avoids the logical problems of a quadratic (nonmonotone)
   utility function implied by mean-variance portfolio selection rules. The
   resulting minimax portfolios are diversified; for normal returns data,
   the portfolios are nearly equivalent to those chosen by a mean-variance
   rule. Framing the portfolio selection process as a linear optimization
   problem also makes it feasible to constrain certain decision variables
   to be integer, or 0-1, valued; this feature facilitates the use of more
   complex decision-making models, including models with fixed transaction
   charges and models with Boolean-type constraints on allocations.
ZA 1
ZB 0
ZR 0
TC 193
Z8 21
ZS 2
Z9 216
SN 0025-1909
UT WOS:000074264100006
ER

PT J
AU Berg, M
   Schouten, FV
   Jansen, J
TI Optimal batch provisioning to customers subject to a delay-limit
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 684
EP 697
DI 10.1287/mnsc.44.5.684
PD MAY 1998
PY 1998
AB This work deals with batch provisioning and order aggregation. Two
   examples are: (i) a manufacturer that has to deliver items to customers
   in a remote destination, and (ii) a company that provides repair and
   replacement service to its clients. In both cases the remoteness of
   customers suggests order aggregation-a batch delivery in the first
   example, and a batch-visits journey in the other; the alternative is to
   provide individual services to customers. A key element is a contractual
   obligation of the company to provide service within an agreed
   delay-limit, and in that view the main decision problem is to determine
   the moments at which a batch service should be executed. That decision
   would depend on: (random) demand-arrival patterns, the costs associated
   with the two service modes (batch and individual), as well as the model
   used to describe operating conditions.
   This paper proposes and investigates several service-provision policies,
   with a simple enough structure to make them appealing for real-life
   implementation. Optimal service-provision procedures are obtained for
   these policies, minimizing the long-run expected cost per unit of time.
   The optimal costs of the proposed policies are compared and their
   relative performance is evaluated with respect to the global minimal
   cost (of the optimal policy) on one hand, and basic policies that employ
   either only batch or only individual services on the other hand.
   Finally, a range of model generalizations of interest is presented and
   the relationship of the problem here to broader issues is discussed.
TC 2
ZB 0
ZS 0
Z8 0
ZA 0
ZR 0
Z9 2
SN 0025-1909
UT WOS:000074264100007
ER

PT J
AU Jordan, C
   Drexl, A
TI Discrete lotsizing and scheduling by batch sequencing
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 698
EP 713
DI 10.1287/mnsc.44.5.698
PD MAY 1998
PY 1998
AB The discrete lotsizing and scheduling problem for one machine with
   sequence-dependent setup times and setup costs is solved as a single
   machine scheduling problem, which we term the batch sequencing problem.
   The relationship between the lotsizing problem and the batch sequencing
   problem is analyzed. The batch sequencing problem is solved with a
   branch & bound algorithm which is accelerated by bounding and dominance
   rules. The algorithm is compared with recently published procedures for
   solving variants of the DLSP and is found to be more efficient if the
   number of items is not large.
TC 31
ZR 0
Z8 0
ZB 0
ZS 1
ZA 0
Z9 32
SN 0025-1909
UT WOS:000074264100008
ER

PT J
AU Mingozzi, A
   Maniezzo, V
   Ricciardelli, S
   Bianco, L
TI An exact algorithm for the resource-constrained project scheduling
   problem based on a new mathematical formulation
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 714
EP 729
DI 10.1287/mnsc.44.5.714
PD MAY 1998
PY 1998
AB In this paper we consider the Project Scheduling Problem with resource
   constraints, where the objective is to minimize the project makespan. We
   present a new 0-1 linear programming formulation of the problem that
   requires an exponential number of variables, corresponding to all
   feasible subsets of activities that can be simultaneously executed
   without violating resource or precedence constraints. Different
   relaxations of the above formulation are used to derive new lower
   bounds, which dominate the value of the longest path on the precedence
   graph and are tighter than the bound proposed by Stinson et al. (1978).
   A tree search algorithm, based on the above formulation, that uses new
   lower bounds and dominance criteria is also presented. Computational
   results indicate that the exact algorithm can solve hard instances that
   cannot be solved by the best algorithms reported in the literature.
OI maniezzo, vittorio/0000-0002-1220-1235
ZB 1
TC 205
Z8 8
ZA 0
ZS 4
ZR 2
Z9 217
SN 0025-1909
UT WOS:000074264100009
ER

PT J
AU Gersbach, H
TI On the equivalence of general and specific control in organizations
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 730
EP 737
DI 10.1287/mnsc.44.5.730
PD MAY 1998
PY 1998
AB Most principal-agent relationships in firms are multidimensional. In the
   presence of multiple tasks and multiple performance signals, the
   contract between principal and agent not only has to motivate the agent,
   but also has to direct the agent to allocate effort among different
   tasks. The value of efforts for a specific task accrues not only through
   the principal's expected returns, but also through its contribution to
   overall risk, and therefore to the risk diversification of the task
   portfolio. Hence, if the agent is risk-averse, multitask relationships
   can be considered as a portfolio problem coupled with incentive
   constraints.
   We examine the relationship between specific control (SC) and general
   control (GC) for multitask principal-agent problems. Under SC, the
   principal observes the outcome of each individual task and uses this set
   of information for compensation. Under GC, contracts are based only on
   the aggregate signal, such as cumulative profits of all tasks. We
   describe two sets of multitask problems for which GC and SC are
   equivalent. That is, contracts based only on aggregate performance
   signals impose the same incentives for the agent as a contract that is
   based on the outcome of each task. The first multitask problem is
   characterized by homogeneous tasks. In the second multitask problem, all
   activities are perfect substitutes in the cost function of the agent.
   The equivalence of SC and GC arises since GC provides insurance to the
   agent and yields the same overall risk premium as specific control.
   Moreover, GC allows the principal to set the same incentives as SC,
   since the marginal returns from GC are equal to the sum of the marginal
   returns for each task under SC.
   The results described in this paper can serve as benchmarks where GC and
   SC are equivalent. We show how the equivalence can be relevant for a
   variety of business situations, such as the compensation of sales
   persons or managers at all hierarchy levels. We also discuss the reasons
   when GC and SC differ. Suppose, for instance, that tasks are
   technologically separable and the precision of the performance of one
   task is low. Then, the principal is forced under GC to adopt an
   incentive scheme that implements only a low effort across all tasks
   since the average precision matters. Under SC, however, the principal
   can tailor the optimal efforts to each task.
RI van Lent, Laurence/G-5298-2010
ZA 0
ZR 0
ZB 0
ZS 0
TC 9
Z8 0
Z9 9
SN 0025-1909
UT WOS:000074264100010
ER

PT J
AU Urban, TL
TI Note. Optimal balancing of U-shaped assembly lines
SO MANAGEMENT SCIENCE
VL 44
IS 5
BP 738
EP 741
DI 10.1287/mnsc.44.5.738
PD MAY 1998
PY 1998
AB This note presents an integer programming formulation for determining
   the optimal balance for the U-line line balancing problem. It is shown
   that this model can optimally solve larger problems than previously
   reported.
ZA 0
ZB 0
ZS 1
ZR 0
TC 96
Z8 8
Z9 105
SN 0025-1909
UT WOS:000074264100011
ER

PT J
AU Thomke, SH
TI Managing experimentation in the design of new products
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 743
EP 762
DI 10.1287/mnsc.44.6.743
PD JUN 1998
PY 1998
AB Experimentation, a form of problem-solving, is a fundamental innovation
   activity and accounts for a significant part of total innovation cost
   and time. In many fields, the economics of experimentation are being
   radically affected by the use of new and greatly improved versions of
   methods such as computer simulation, mass screening, and rapid
   prototyping. This paper shows that a given experiment (and the related
   trial and error learning) can be conducted in different "modes" (e.g.,
   computer simulation and rapid prototyping) and that users Will find it
   economical to optimize the switching between these modes as to reduce
   total product development cost and time. The findings are confirmed by a
   large-scale empirical study of the experimentation process in the design
   of integrated circuits containing either (1) electrically programmable
   logic devices (EPLDs); or (2) application-specific integrated circuits
   (ASICs). In comparing their different experimentation strategies for
   analogous design projects, I found that the former (EPLD)-an approach
   that utilizes many prototype iterations-outperformed the latter (ASIC)
   by factor of 2.2 (in person-months) and over 43 percent of that
   difference can be attributed to differences in experimentation
   strategies. The implications for managerial practice and theory are
   discussed and suggestions for further research undertakings are
   provided.
ZR 0
TC 242
ZS 1
Z8 1
ZB 3
ZA 0
Z9 244
SN 0025-1909
UT WOS:000074877000001
ER

PT J
AU Bayus, BL
TI An analysis of product lifetimes in a technologically dynamic industry
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 763
EP 775
DI 10.1287/mnsc.44.6.763
PD JUN 1998
PY 1998
AB The conventional wisdom that product lifetimes are shrinking has
   important implications for technology management and product planning.
   However, very limited empirical information on this topic is available.
   Ln this paper, product lifetimes are directly measured as the time
   between product introduction and withdrawal. Statistical analyses of
   desktop personal computer models introduced between 1974 and 1992 are
   conducted at various product market levels. Results indicate that (1)
   product technology and product model lifetimes have not accelerated, and
   (2) manufacturers have not systematically reduced the life-cycles of
   products within their lines. Instead, the products of firms that have
   entered this industry in the more recent years tend to be based on
   previously existing technology, and, not surprisingly, these products
   have lifetimes that are shorter than those of established firms.
   Implications of these findings are discussed.
Z8 0
ZA 0
ZS 3
TC 88
ZB 6
ZR 0
Z9 91
SN 0025-1909
UT WOS:000074877000002
ER

PT J
AU Balachander, S
   Srinivasan, K
TI Modifying customer expectations of price decreases for a durable product
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 776
EP 786
DI 10.1287/mnsc.44.6.776
PD JUN 1998
PY 1998
AB We study the introductory signalling strategy for a durable product that
   faces optimistic expectations among customers about price declines over
   time. The firm introducing the product knows that experiential learning
   is low for the product. However, customers, being uncertain about the
   extent of experiential learning, assign a nonzero probability that the
   firm's new product will enjoy a high cost reduction with cumulative
   experience. The optimistic expectations of customers reduce their
   willingness to pay a high price at the product's introduction while
   predisposing them to buying later. The challenge facing the
   low-experience firm is to choose an introductory strategy that will
   credibly convey the low experience-curve effect to customers. We use the
   sequential equilibrium concept in a game-theoretic framework to identify
   the firm's signalling strategy. We identify the unique separating
   equilibrium of the game after refining the set of separating equilibria.
   We demonstrate that a high introductory price credibly signals the low
   experiential learning to customers. We also show that signalling causes
   an artificial learning-curve effect.
Z8 3
ZR 0
ZA 0
ZB 0
ZS 0
TC 21
Z9 24
SN 0025-1909
UT WOS:000074877000003
ER

PT J
AU Verheyen, P
TI The missing link in budget models of nonprofit institutions: Two
   practical Dutch applications
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 787
EP 800
DI 10.1287/mnsc.44.6.787
PD JUN 1998
PY 1998
AB The Dutch government, health insurance associations, and research boards
   allocate budgets to nonprofit institutions (hospitals, universities),
   based on general indicators (inhabitants, admissions, or students). With
   these budgets, the top management of each institution (the principal)
   allocates the funds, using general indicators to distribute the money
   further down to the base. At the base of the nonprofit institutions, the
   professionals (the agents) perform a spectrum of specific tasks. Tension
   around the budgetting process exists between top management and
   professionals. This paper resolves the tension along the research lines
   of Burton and Obel (1995) by measuring in money terms the specific tasks
   of the professionals of universities and hospitals at the base, and by
   reconsidering the theoretical background of the internal budget system.
   The study also develops the missing link in an integral external and
   internal budget system by integrating the managerial and professional
   decisions or the input-output decisions in one approach.
ZR 0
Z8 0
TC 7
ZS 0
ZB 2
ZA 0
Z9 7
SN 0025-1909
UT WOS:000074877000004
ER

PT J
AU Gaba, A
   Viscusi, WK
TI Differences in subjective risk thresholds: Worker groups as an example
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 801
EP 811
DI 10.1287/mnsc.44.6.801
PD JUN 1998
PY 1998
AB Subjective risk perceptions are often encoded as responses to 0-1
   questions in surveys or other qualitative risk scales. However,
   reference points for assessing an activity as risky are confounded by
   various characteristics of the respondents. This paper uses a sample of
   workers for whom quantitative risk assessments as well as dichotomous
   risk perception responses are available. It is shown that, given a
   quantitative risk measure, the thresholds for assessing an activity as
   "risky" vary systematically, particularly by education. The differences
   in such thresholds across worker groups are estimated. The resulting
   implications of using qualitative risk variables for assessing wage-risk
   tradeoffs are estimated, yielding results that are also relevant for
   many other areas involving similar qualitative variables.
TC 16
ZB 1
ZA 0
ZS 0
Z8 0
ZR 0
Z9 16
SN 0025-1909
UT WOS:000074877000005
ER

PT J
AU Kleijnen, JPC
   Bettonvil, B
   Van Groenendaal, W
TI Validation of trace-driven simulation models: A novel regression test
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 812
EP 819
DI 10.1287/mnsc.44.6.812
PD JUN 1998
PY 1998
AB This paper argues that it is wrong to require that regressing the
   outputs of a trace-driven simulation on the observed real outcomes
   should give a 45 degrees (unit slope) line through the origin (zero
   intercept). This note proposes instead an alternative requirement: the
   responses of the simulated and the real systems should have the same
   means and the same variances. To test statistically whether this
   requirement is satisfied, a novel procedure is derived: regress the
   differences between simulated and real responses on their associated
   sums, and test whether the resulting intercept and slope are both zero.
   This novel but simple test assumes identically, independently, and
   normally distributed outputs of the real system and the simulated
   system. The old and the new procedures are investigated in extensive
   Monte Carlo experiments that simulate M/M/1 queueing systems. The
   conclusions are: (i) the naive intuitive test rejects a valid simulation
   model substantially more often than the novel test does; (ii) the naive
   test shows "perverse" behavior within a certain domain: the worse the
   simulation model, the higher its estimated probability of acceptance;
   and (iii) the novel test does not reject a valid simulation model too
   often (its type I error probability is correct), provided the queueing
   response is transformed appropriately to obtain (nearly) normally
   distributed responses.
RI Kleijnen, Jack/AAL-6469-2020; Kleijnen, Jack/ABB-6455-2020; Kleijnen, jack/
OI Kleijnen, jack/0000-0001-8413-2366
ZS 0
Z8 0
ZA 0
TC 49
ZR 0
ZB 23
Z9 50
SN 0025-1909
UT WOS:000074877000006
ER

PT J
AU Miller, JH
TI Active nonlinear tests (ANTs) of complex simulation models
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 820
EP 830
DI 10.1287/mnsc.44.6.820
PD JUN 1998
PY 1998
AB Simulation models are becoming increasingly common in the analysis of
   critical scientific, policy, and management issues. Such models provide
   a way to analyze complex systems characterized by both large parameter
   spaces and nonlinear interactions. Unfortunately, these same
   characteristics make understanding such models using traditional testing
   techniques extremely difficult. Here we show how a model's structure and
   robustness can be validated via a simple, automatic, nonlinear search
   algorithm designed to actively "break" the model's implications. Using
   the active nonlinear tests (ANTs) developed here, one can easily probe
   for key weaknesses in a simulation's structure, and thereby begin to
   improve and refine its design. We demonstrate ANTs by testing a
   well-known model of global dynamics (World3), and show how this
   technique can be used to uncover small, but powerful, nonlinear effects
   that may highlight vulnerabilities in the original model.
ZS 0
Z8 1
ZA 0
ZR 0
ZB 7
TC 76
Z9 77
SN 0025-1909
UT WOS:000074877000007
ER

PT J
AU Shaw, DX
   Wagelmans, APM
TI An algorithm for single-item capacitated economic lot sizing with
   piecewise linear production costs and general holding costs
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 831
EP 838
DI 10.1287/mnsc.44.6.831
PD JUN 1998
PY 1998
AB We consider the Capacitated Economic Lot Size Problem with piecewise
   linear production costs and general holding costs, which is an NP-hard
   problem but solvable in pseudopolynomial time. A straightforward dynamic
   programming approach to this problem results in an O(n(2)(c) over bar
   (d) over bar) algorithm, where n is the number of periods, and (d) over
   bar and care the average demand and the average production capacity over
   the n periods, respectively. However, we present a dynamic programming
   procedure with complexity O(n(2)(q) over bar (d) over bar), where (q)
   over bar is the average number of pieces required to represent the
   production cost functions. In particular, this means that problems in
   which the production functions consist of a fixed set-up cost plus a
   linear variable cost are solved in O(n(2)(d) over bar) time. Hence, the
   running time of our algorithm is only linearly dependent on the
   magnitude of the data. This result also holds if extensions such as
   backlogging and startup costs are considered. Moreover, computational
   experiments indicate that the algorithm is capable of solving quite
   large problem instances within a reasonable amount of time. For example,
   the average time needed to solve test instances with 96 periods, 8
   pieces in every production cost function, and average demand of 100
   units is approximately 40 seconds on a SUN SPARC 5 workstation.
ZA 0
ZR 1
TC 58
Z8 2
ZS 0
ZB 0
Z9 60
SN 0025-1909
UT WOS:000074877000008
ER

PT J
AU Miyamoto, JM
   Wakker, PP
   Bleichrodt, H
   Peters, HJM
TI The zero-condition: A simplifying assumption in QALY measurement and
   multiattribute utility
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 839
EP 849
DI 10.1287/mnsc.44.6.839
PD JUN 1998
PY 1998
AB This paper studies the implications of the "zero-condition" for
   multiattribute utility theory. The zero-condition simplifies the
   measurement and derivation of the Quality Adjusted Life Year (QALY)
   measure commonly used in medical decision analysis. For general
   multiattribute utility theory, no simple condition has heretofore been
   found to characterize multiplicatively decomposable forms. When the
   zero-condition is satisfied, however, such a simple condition, "standard
   gamble invariance," becomes available.
Z8 0
ZB 1
TC 55
ZA 0
ZR 0
ZS 0
Z9 55
SN 0025-1909
UT WOS:000074877000009
ER

PT J
AU Haviv, M
   Ritov, Y
TI Externalities, tangible externalities, and queue disciplines
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 850
EP 858
DI 10.1287/mnsc.44.6.850
PD JUN 1998
PY 1998
AB Externalities are the (marginal) costs that a user of a common resource
   imposes on others. We introduce the efficient measure of tangible
   externalities that are the costs that a user imposes on others while
   being served. Then, for a single sen er queueing system under various
   service disciplines, we compute the expected externalities and the
   expected tangible externalities conditioning on the length of the
   service requirement.
Z8 0
ZB 0
TC 15
ZR 0
ZS 0
ZA 0
Z9 15
SN 0025-1909
UT WOS:000074877000010
ER

PT J
AU Katok, E
   Lewis, HS
   Harrison, TP
TI Lot sizing in general assembly systems with setup costs, setup times,
   and multiple constrained resources
SO MANAGEMENT SCIENCE
VL 44
IS 6
BP 859
EP 877
DI 10.1287/mnsc.44.6.859
PD JUN 1998
PY 1998
AB We introduce a heuristic method for finding good, feasible solutions for
   multiproduct lot sizing problems with general assembly structures,
   multiple constrained resources, and nonzero setup costs and setup times.
   We evaluate the performance of this heuristic by comparing its solutions
   to optimal solutions of small randomly generated problems and to
   time-truncated Optimization Subroutine Library (OSL) solutions of
   medium-sized randomly generated problems. In the first case, the
   heuristic locates solutions averaging 4 percent worse than optimal in
   less than 1 percent of time required by OSL. The heuristic solutions to
   medium-sized problems are approximately 26 percent better than solutions
   OSL finds after 10,000 CPU seconds, and the heuristic finds these
   solutions in approximately 10 percent of OSL time.
ZR 0
ZA 0
Z8 1
TC 40
ZB 0
ZS 0
Z9 41
SN 0025-1909
UT WOS:000074877000011
ER

PT J
AU Fox, CR
   Tversky, A
TI A belief-based account of decision under uncertainty
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 879
EP 895
DI 10.1287/mnsc.44.7.879
PD JUL 1998
PY 1998
AB We develop a belief-based account of decision under uncertainty. This
   model predicts decisions under uncertainty from (i)judgments of
   probability, which are assumed to satisfy support theory; and (ii)
   decisions under risk, which are assumed to satisfy prospect theory. In
   two experiments, subjects evaluated uncertain prospects and assessed the
   probability of the respective events. Study I involved the 1995
   professional basketball playoffs; Study 2 involved the movement of
   economic indicators in a simulated economy. The results of both studies
   are consistent with the belief-based account, but violate the partition
   inequality implied by the classical theory of decision under
   uncertainty.
RI Fox, Craig/A-2293-2014
ZB 19
ZA 0
ZR 1
Z8 6
TC 167
ZS 1
Z9 174
SN 0025-1909
EI 1526-5501
UT WOS:000075214900001
ER

PT J
AU Trivedi, M
TI Distribution channels: An extension of exclusive retailership
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 896
EP 909
DI 10.1287/mnsc.44.7.896
PD JUL 1998
PY 1998
AB The underlying channel structure in most studies to date has consisted
   either of exclusive dealers that sell only one manufacturer's brand or
   of a single retailer selling multiple brands. Little attention has been
   given to the larger segment of most consumer goods markets in which
   retailers compete to sell multiple brands at the same location. This
   research seeks to add to the growing Literature of channel competition
   by analyzing three channel structures, the least constrained of which
   deals with two competing manufacturers and two retailers, each of whom
   distributes both products in a noncooperative game with two Nash's and
   one Stackleberg equilibrium. Using differentiated products and a linear
   demand function, we introduce the concept of "store substitutability"-a
   measure corresponding to product substitutability representing
   competitiveness at the retail level-between the two retailers. We are
   able to obtain closed form solutions for all cases. We show that the
   presence of competitive effects at both retail and manufacturer levels
   of distribution has a significant impact on profits and prices. We also
   study the effects of various power relationships in the channel.
   Furthermore, we compare these results to those obtained by previous
   research. Finally, we propose some testable implications and suggest
   avenues for future research.
ZR 0
TC 124
Z8 20
ZA 0
ZS 0
ZB 0
Z9 142
SN 0025-1909
EI 1526-5501
UT WOS:000075214900002
ER

PT J
AU Zangwill, WI
   Kantor, PB
TI Toward a theory of continuous improvement and the learning curve
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 910
EP 920
DI 10.1287/mnsc.44.7.910
PD JUL 1998
PY 1998
AB Continuous improvement (CI) unceasingly strives to improve the
   performance of production and service firms. The learning curve (LC)
   provides a means to observe and track that improvement. At present,
   however, the concepts of CI are abstract and imprecise and the rationale
   underpinning the LC is obscure. For managers to improve processes
   effectively, they need a more scientific theory of CI and the LC. This
   paper begins to develop such a theory. Our approach is based on learning
   cycles, that is, in each period management takes an action to improve
   the process, observes the results, and thereby learns how to improve the
   process further over time. This analysis suggests a differential
   equation that not only characterizes continuous improvement but also
   reveals how learning might occur in the learning curve. This
   differential equation might help management to evaluate the
   effectiveness of various procedures and to improve and enhance
   industrial processes more quickly.
ZA 0
ZR 0
Z8 1
ZB 4
ZS 3
TC 125
Z9 128
SN 0025-1909
UT WOS:000075214900003
ER

PT J
AU Mello, AS
   Neuhaus, HJ
TI A portfolio approach to risk reduction in discretely rebalanced option
   hedges
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 921
EP 934
DI 10.1287/mnsc.44.7.921
PD JUL 1998
PY 1998
AB This paper analyses the accumulated hedging errors generated by
   discretely rebalanced option hedges. We show that simple generalizations
   of the prior research can underestimate the variance of the accumulated
   hedging errors and that even with daily rebalancing, these accumulated
   hedging errors can introduce substantial risk in arbitrage strategies
   suggested by the Black-Scholes option pricing model. We also show that
   the correlation between the accumulated hedging errors for different
   options can be quite high, so that the risk of arbitrage due to hedging
   errors can be substantially reduced by optimally combining options into
   portfolios. The results also suggest that tests of market pricing of
   traded options which are based on employing a portfolio approach are
   likely to be much better specified than the standard tests that focus on
   individual options.
ZS 0
ZB 0
Z8 1
ZR 0
TC 5
ZA 0
Z9 6
SN 0025-1909
UT WOS:000075214900004
ER

PT J
AU Lal, R
   Villas-Boas, JM
TI Price promotions and trade deals with multiproduct retailers
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 935
EP 949
DI 10.1287/mnsc.44.7.935
PD JUL 1998
PY 1998
AB In this paper we study retail price promotions and manufacturer trade
   deals in markets with multiproduct retailers. We find that in situations
   where retailers carry more than one competing brand, the promotions
   across brands can be positively or negatively correlated depending on
   the structure of the market: the relative sizes of the various market
   segments (In terms of loyalty to manufacturer, retailer, or the pair
   manufacturer-retailer). We show that sometimes retailers offer the same
   discount on different products, but at other times they offer a smaller
   discount on a brand supported by a bigger trade deal. We also present
   results on the effects of changes in the sizes of the different market
   segments on the depth of price promotions and trade deals and on pass
   through.
OI Villas-Boas, J. Miguel/0000-0003-1299-4324
TC 58
ZB 0
Z8 3
ZR 0
ZS 0
ZA 0
Z9 61
SN 0025-1909
UT WOS:000075214900005
ER

PT J
AU DeCroix, GA
   Arreola-Risa, A
TI Optimal production and inventory policy for multiple products under
   resource constraints
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 950
EP 961
DI 10.1287/mnsc.44.7.950
PD JUL 1998
PY 1998
AB We show that a modified base-stock policy is optimal for multiproduct,
   infinite-horizon production-inventory systems, where demand for the
   products is random and the products share a finite resource every
   period. We characterize the optimal policy for the case of homogeneous
   products. Because of the difficulty in computing the optimal base-stock
   levels for the heterogeneous case, we propose a heuristic that is simple
   enough for practical applications. We present numerical results that
   suggest that the heuristic yields near-optimal solutions.
ZA 0
ZB 0
ZS 0
ZR 0
Z8 2
TC 54
Z9 56
SN 0025-1909
UT WOS:000075214900006
ER

PT J
AU Joro, T
   Korhonen, P
   Wallenius, J
TI Structural comparison of data envelopment analysis and multiple
   objective linear programming
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 962
EP 970
DI 10.1287/mnsc.44.7.962
PD JUL 1998
PY 1998
AB The concept of efficiency as it applies to Decision Making Units (DMUs),
   solutions, alternatives plays an important role both in Data Envelopment
   Analysis (DEA) and Multiple Objective Linear Programming (MOLP). Despite
   this and other apparent similarities, DEA and MOLP research has
   developed separately. We show that structurally the DEA formulation to
   identify efficient units is quite similar to the MOLP model based on the
   reference point or the reference direction approach to generate
   efficient solutions. DEA and MOLP should not be seen as substitutes, but
   rather as complements. We show that they cross-fertilize each other.
   MOLP provides interesting extensions to DEA and DEA provides new areas
   of application to MOLP.
ZR 0
ZA 0
Z8 2
ZB 2
ZS 0
TC 132
Z9 134
SN 0025-1909
UT WOS:000075214900007
ER

PT J
AU Mandelbaum, A
   Reiman, MI
TI On pooling in queueing networks
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 971
EP 981
DI 10.1287/mnsc.44.7.971
PD JUL 1998
PY 1998
AB We view each station in a Jackson network as a queue of tasks, of a
   particular type, which are to be processed by the associated specialized
   server. A complete pooling of queues, into a single queue, and servers,
   into a single server, gives rise to an M/PH/1 queue, where the server is
   flexible in the sense that it processes all tasks. We assess the value
   of complete pooling by comparing the steady-state mean sojourn times of
   these two systems. The main insight from our analysis is that care must
   be used in pooling. Sometimes pooling helps, sometimes it hurts, and its
   effect (good or bad) can be unbounded. Also discussed briefly are
   alternative pooling scenarios, for example complete pooling of only
   queues which results in an M/PH/S system, or partial pooling which can
   be devastating enough to turn a stable Jackson network into an unstable
   Bramson network. We conclude with some possible future research
   directions.
ZS 0
ZB 0
ZA 0
ZR 0
TC 64
Z8 0
Z9 64
SN 0025-1909
EI 1526-5501
UT WOS:000075214900008
ER

PT J
AU Basu, A
   Blanning, RW
TI The analysis of assumptions in model bases using metagraphs
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 982
EP 995
DI 10.1287/mnsc.44.7.982
PD JUL 1998
PY 1998
AB Decision models are often based on certain assumptions as to their
   validity. Relevant assumptions may include value-based assumptions, such
   as limitations on the range or values of some input variables or
   exogenous factors, as well as assumptions about model structure (e.g.,
   Linearity). In a model base consisting of many models, there may be
   several models (or collections of models) that can be used to solve a
   particular problem. We may wish to know what the applicable models are,
   what assumptions are associated with these models, and whether a given
   set of assumptions is necessary and/or sufficient for solving the
   problem. We describe an analytical approach, based on a graph-theoretic
   construct called a metagraph, and show how it can be used to represent
   and analyze assumptions in model bases.
ZR 0
ZS 0
TC 17
ZA 0
ZB 0
Z8 4
Z9 21
SN 0025-1909
UT WOS:000075214900009
ER

PT J
AU Baum, JAC
   Ingram, P
TI Survival-enhancing learning in the Manhattan hotel industry, 1898-1980
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 996
EP 1016
DI 10.1287/mnsc.44.7.996
PD JUL 1998
PY 1998
AB In this study, we examine how experience at the level of the
   organization, the population, andthe related group affects the failure
   of Manhattan hotels. We find organizational experience has a U-shaped
   effect on failure; that organizations enjoy reduced failure as a
   function of population experience before their founding, but not after;
   and that related organizations provide experience that lowers failure,
   but it matters whether their experience is local or non-local, and if it
   was acquired before or after the relationship was established. These
   results indicate both the difficulty of applying different types of
   experience to reduce the risk of organizational failure, and the
   relevance of experience for the evolution of organizational populations.
RI Baum, Joel A. C./A-2904-2008
OI Baum, Joel A. C./0000-0002-0707-7938
Z8 16
ZA 0
TC 383
ZB 2
ZR 1
ZS 5
Z9 404
SN 0025-1909
UT WOS:000075214900010
ER

PT J
AU Gupta, D
   Srinivasan, MM
TI Note: How does product proliferation affect responsiveness?
SO MANAGEMENT SCIENCE
VL 44
IS 7
BP 1017
EP 1020
DI 10.1287/mnsc.44.7.1017
PD JUL 1998
PY 1998
AB In this note we consider some strategies that a manufacturing firm may
   use to deal with an increase in the variety of products it offers. We
   indicate how alternate strategies for dealing with product proliferation
   impact the firm's responsiveness, measured in terms of average
   production lead time and average work-in-process inventory. Focusing on
   the make-to-order environment and using queueing models, we derive
   conditions under which an increase in product variety can improve both
   individual product performance as well as system performance, thus
   contradicting a common belief that a greater degree of focus and greater
   responsiveness go hand in hand. These queueing models provide operations
   managers analytical tools for evaluating alternate strategies for coping
   with product proliferation.
Z8 0
ZS 1
TC 20
ZB 0
ZA 0
ZR 0
Z9 20
SN 0025-1909
UT WOS:000075214900011
ER

PT J
AU Kulatilaka, N
   Perotti, EC
TI Strategic growth options
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1021
EP 1031
DI 10.1287/mnsc.44.8.1021
PD AUG 1998
PY 1998
AB We provide a strategic rationale for growth options under uncertainty
   and imperfect competition. In a market with strategic competition,
   investment confers a greater capability to take advantage of future
   growth opportunities. This strategic advantage leads to the capture of a
   greater share of the market, either by dissuading entry or by inducing
   competitors to "make room" for the stronger competitor. As a result of
   this strategic effect, payoffs are in a rough sense more convex than in
   the case of no investment in a growth option. When the strategic
   advantage is strong, increased uncertainty encourages investment in
   growth options: higher uncertainty means more opportunity rather than
   simply larger risk. If the strategic effect is weak, the reverse is
   true. On the other hand, an increase in systematic risk discourages the
   acquisition of growth options. Our results contradict the view that
   volatility is a strong disincentive for investment.
RI perotti, enrico/A-6638-2010
TC 238
ZS 1
ZA 0
ZR 0
Z8 13
ZB 1
Z9 253
SN 0025-1909
EI 1526-5501
UT WOS:000075653800001
ER

PT J
AU Loch, CH
   Terwiesch, C
TI Communication and uncertainty in concurrent engineering
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1032
EP 1048
DI 10.1287/mnsc.44.8.1032
PD AUG 1998
PY 1998
AB We present an analytical model of concurrent engineering, where an
   upstream and a downstream task are overlapped to minimize
   time-to-market. The gain from overlapping activities must be weighed
   against the delay from rework that results from proceeding in parallel
   based on preliminary information. Communication reduces the negative
   effect of rework at the expense of communication time. We derive the
   optimal levels of concurrency combined with communication, and we
   analyze how these two decisions interact in the presence of uncertainty
   and dependence. Uncertainty is modeled via the average rate of
   engineering changes, and its reduction via the change of the
   modification rate over time. In addition, we model dependence by the
   impact the modifications impose on the downstream task. The model yields
   three main results. First, we present a dynamic decision rule for
   determining the optimal meeting schedule. The optimal meeting frequency
   follows the frequency of engineering changes over time, and it increases
   with the levels of uncertainty and dependence. Second, we derive the
   optimal concurrency between activities when communication follows the
   optimal pattern described by our decision rule. Uncertainty and
   dependence make concurrency less attractive, reducing the optimal
   overlap. However, the speed of uncertainty reduction may increase or
   decrease optimal overlap. Third, choosing communication and concurrency
   separately prevents achieving the optimal time-to-market, resulting in a
   need for coordination.
ZS 1
ZR 0
TC 217
ZA 0
Z8 21
ZB 3
Z9 238
SN 0025-1909
UT WOS:000075653800002
ER

PT J
AU O'Leary, DE
TI Knowledge acquisition from multiple experts: An empirical study
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1049
EP 1058
DI 10.1287/mnsc.44.8.1049
PD AUG 1998
PY 1998
AB Expert systems often employ a weight on rules to capture conditional
   probabilities. For example, in classic rule-based settings, Pr(h \ e) =
   x is used to mean "If e is known to be true then conclude h is true with
   probability x." Further, other probability-based approaches, such as
   influence diagrams and Bayes' Nets are increasingly being used to
   support decision making through decision support systems. Although
   algorithms for these systems have received substantial attention, less
   attention has been given to knowledge acquisition of probabilities used
   in these systems. However, the underlying probabilities are critical
   because they lead the user to particular solutions. Accordingly, the
   purpose of this paper is to investigate the quality of probability
   knowledge when it is acquired from groups or individuals.
   This paper summarizes the results of an empirical cognitive study on the
   ability of individuals and groups to provide consistent sets of
   probabilities Pr(A), Pr(B), Pr(A \ B) and Pr(B \ A). The analysis of
   these probabilities allowed the study of the ability of subjects to
   account for Bayes' theorem reversals, a basic assumption made by
   virtually all algorithms. It was found that knowledge acquisition from
   groups provided more correct orderings to the probabilities than
   knowledge acquisition from individuals. This suggests that knowledge
   acquisition from groups is more likely to obtain correct probability
   knowledge.
RI O'Leary, Daniel E/B-6469-2008
ZS 0
Z8 0
TC 20
ZA 0
ZR 0
ZB 0
Z9 20
SN 0025-1909
UT WOS:000075653800003
ER

PT J
AU Cortazar, G
   Schwartz, ES
   Salinas, M
TI Evaluating environmental investments: A real options approach
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1059
EP 1070
DI 10.1287/mnsc.44.8.1059
PD AUG 1998
PY 1998
AB The paper presents a model that determines when (at which output price
   level) it is optimum for a firm to invest in environmental technologies
   and which are the main parameters that affect this decision. Our
   analysis shows that firms require high output price levels to be induced
   to invest in environmental technologies, because they optimally would
   not want to commit to a heavy irreversible investment that could turn
   out to be unprofitable in the event of a price fall. A comparative
   static analysis predicts that firms in industries with high output price
   volatility would be more reluctant to invest in environmental protection
   technologies and would be more willing to operate at low output levels
   (thus attaining low emission levels). Increases in the interest rate
   would also reduce optimal environmental investment levels.
RI Cortazar, Gonzalo/I-3848-2013
ZR 0
Z8 4
ZA 0
ZS 0
ZB 8
TC 58
Z9 62
SN 0025-1909
UT WOS:000075653800004
ER

PT J
AU Van Mieghem, JA
TI Investment strategies for flexible resources
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1071
EP 1078
DI 10.1287/mnsc.44.8.1071
PD AUG 1998
PY 1998
AB This article studies optimal investment in flexible manufacturing
   capacity as a function of product prices (margins), investment costs and
   multivariate demand uncertainty. We consider a two-product firm that has
   the option to invest in product-dedicated resources and / or in a
   flexible resource that can produce either product, but has to make its
   investment decision before demands are observed. The flexible resource
   provides the firm with a hedge against demand uncertainty, but at a
   higher investment cost than the dedicated resources. Our analysis
   highlights the important role of price (margin) and cost mix
   differentials, which, in addition to the correlation between product
   demands, significantly affect the investment decision and the value of
   flexibility. Contrary to the intuition also prevalent in the academic
   literature, we show that it can be advantageous to invest in flexible
   resources even with perfectly positively correlated product demands.
ZA 0
ZR 0
ZS 0
Z8 1
TC 204
ZB 0
Z9 204
SN 0025-1909
UT WOS:000075653800005
ER

PT J
AU Cooper, RB
   Niu, SC
   Srinivasan, MM
TI When does forced idle time improve performance in polling models?
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1079
EP 1086
DI 10.1287/mnsc.44.8.1079
PD AUG 1998
PY 1998
AB Sarkar and Zangwill (1991) showed by numerical examples that reduction
   in setup times can, surprisingly, actually increase work in process in
   some cyclic production systems (that is, reduction in switchover times
   can increase waiting times in some polling models). We present, for
   polling models with exhaustive and gated service disciplines, some
   explicit formulas that provide additional insight and characterization
   of this anomaly. More specifically, we show that, for both of these
   models, there exist simple formulas that define for each queue a
   critical value z* of the mean total setup time z per cycle such that, if
   z < z*, then the expected waiting time at that queue will be minimized
   if the server is forced to idle for a constant length of time z* - z
   every cycle; also, for the symmetric polling model, we give a simple
   explicit formula for the expected waiting time and the critical value z*
   that minimizes it.
TC 15
ZR 1
ZB 0
ZS 0
ZA 0
Z8 0
Z9 16
SN 0025-1909
EI 1526-5501
UT WOS:000075653800006
ER

PT J
AU Kleindorfer, GB
   O'Neill, L
   Ganeshan, R
TI Validation in simulation: Various positions in the philosophy of science
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1087
EP 1099
DI 10.1287/mnsc.44.8.1087
PD AUG 1998
PY 1998
AB There is still considerable doubt and even anxiety among simulation
   modelers as to what the methodologically correct guidelines or
   procedures for validating simulation models should be. Epistemically,
   the approaches one finds in the simulation literature run the gamut from
   objectivist to relativist with shades in between. At present in the
   philosophy of science, there appears to be a convergence toward a
   nonalgorithmic but discursive and nonrelativistic view of the
   argumentation involved in warranting scientific theorizing. The present
   gaper attempts to give a description of the various philosophical
   positions as well as to summarize their problems and the kinds of
   evidentiary arguments they would each allow in arriving at defensible
   simulation models. From the debate, we attempt to set out a perspective
   that frees the practioner to pursue a varied set of approaches to
   validation with a diminished burden of methodological anxiety.
   Reciprocally this perspective does not let the modeler off of the hook
   but rather converts the validation problem into an ethical problem in
   which the practitioner must responsibly and professionally argue for the
   warrant of the model.
ZR 1
TC 96
ZB 12
Z8 2
ZA 0
ZS 1
Z9 102
SN 0025-1909
UT WOS:000075653800007
ER

PT J
AU Mehrotra, A
   Johnson, EL
   Nemhauser, GL
TI An optimization based heuristic for political districting
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1100
EP 1114
DI 10.1287/mnsc.44.8.1100
PD AUG 1998
PY 1998
AB Redistricting, the redrawing of congressional district boundaries within
   the states, may occur every 10 years on the basis of the population
   census. Many redistricting plans are designed with partisan politics in
   mind, resulting in disputes and forcing judges to intervene. We address
   this problem from a nonpolitical viewpoint and present an optimization
   based heuristic incorporating universally agreed upon characteristics.
   We model the problem as a constrained graph partitioning problem and
   develop a specialized branch-and-price based solution methodology. We
   demonstrate the feasibility of our methodology by showing how to satisfy
   the one-person, one-vote principle with compact and contiguous districts
   for the state of South Carolina.
ZS 6
ZB 3
ZR 1
ZA 0
TC 132
Z8 0
Z9 138
SN 0025-1909
UT WOS:000075653800008
ER

PT J
AU Meade, N
   Islam, T
TI Technological forecasting - Model selection, model stability, and
   combining models
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1115
EP 1130
DI 10.1287/mnsc.44.8.1115
PD AUG 1998
PY 1998
AB The paper identifies 29 models that the Literature suggests are
   appropriate for technological forecasting. These models are divided into
   three classes according to the timing of the point of inflexion in the
   innovation or substitution process. Faced with a given data set and such
   a choice, the issue of model selection needs to be addressed. Evidence
   used to aid model selection is drawn from measures of model fit and
   model stability. An analysis of the forecasting performance of these
   models using simulated data sets shows that it is easier to identify a
   class of possible models rather than the 'best' model. This leads to the
   combining of model forecasts. The performance of the combined forecasts
   appears promising with a tendency to outperform the individual component
   models.
RI Meade, Nigel/F-4965-2011; Meade, Nigel/
OI Meade, Nigel/0000-0001-6689-5052
ZB 3
TC 120
ZA 0
Z8 1
ZS 2
ZR 0
Z9 122
SN 0025-1909
EI 1526-5501
UT WOS:000075653800009
ER

PT J
AU Rothkopf, MH
   Pekec, A
   Harstad, RM
TI Computationally manageable combinational auctions
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1131
EP 1147
DI 10.1287/mnsc.44.8.1131
PD AUG 1998
PY 1998
AB There is interest in designing simultaneous auctions for situations such
   as the recent FCC radio spectrum auctions, in which the value of assets
   to a bidder depends on which other assets he or she wins. In such
   auctions, bidders may wish to submit bids for combinations of assets.
   When this is allowed the problem of determining the revenue maximizing
   set of nonconflicting bids can be difficult. We analyze this problem,
   identifying several different structures of permitted combinational bids
   for which computational tractability is constructively demonstrated and
   some structures for which computational tractability cannot be
   guaranteed.
ZA 0
ZB 7
ZS 0
Z8 24
TC 484
ZR 0
Z9 506
SN 0025-1909
UT WOS:000075653800010
ER

PT J
AU Nutt, PC
TI How decision makers evaluate alternatives and the influence of
   complexity
SO MANAGEMENT SCIENCE
VL 44
IS 8
BP 1148
EP 1166
DI 10.1287/mnsc.44.8.1148
PD AUG 1998
PY 1998
AB The evaluation of alternatives during organizational decision making was
   investigated to uncover evaluation tactics used by decision makers and
   how these tactics and complexity influenced success. Evaluation tactics
   that relied upon subjective, judgmental, bargaining, and analytical
   inferences were uncovered from 317 strategic decisions. The complexity
   of these decisions was measured by the numbers of alternatives
   considered, number of criteria used, and perceived difficulty of the
   evaluation task to identify conditions under which the evaluation
   tactics were successful. The managerial implications of evaluating
   alternatives with the tactics that used judgmental, bargaining,
   analytical, and subjective inferences under different levels of
   complexity are discussed.
ZS 1
ZR 0
ZB 0
ZA 0
Z8 1
TC 53
Z9 55
SN 0025-1909
UT WOS:000075653800011
ER

PT J
AU Subramaniam, V
TI Efficient sourcing and debt financing in imperfect product markets
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1167
EP 1178
DI 10.1287/mnsc.44.9.1167
PD SEP 1998
PY 1998
AB Supplier relations play an important role in determining a firm's
   product market strategy and by affecting the cost and quality of the
   product produced by the firm. These relations are especially significant
   because the cost of purchased materials for an average firm is more than
   half its total sales. In this paper, we model the adverse incentives of
   a firm that sources from a competitive supplier industry. We show that a
   firm's propensity to behave opportunistically towards its suppliers
   raises the firm's input costs by decreasing the number of suppliers
   servicing it. This results in a suboptimal production decision compared
   to the firm's first best choice. We argue that an appropriate level of
   debt financing alters the shareholder incentives and mitigates the
   hold-up problem. Further, we also show that at the optimal debt level,
   the firm produces its first best level of output.
TC 9
ZR 0
ZA 0
Z8 0
ZB 0
ZS 0
Z9 9
SN 0025-1909
UT WOS:000076497200002
ER

PT J
AU Banker, RD
   Khosla, I
   Sinha, KK
TI Quality and competition
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1179
EP 1192
DI 10.1287/mnsc.44.9.1179
PD SEP 1998
PY 1998
AB In recent years, the practitioner literature in operations management
   has seen a dramatic surge in articles on quality management. It reflects
   the increased emphasis on quality by U.S. firms, which has been
   attributed largely to increased competition faced by them. The question
   of how quality is influenced by competitive intensity, however, has not
   received much attention, either in the practitioner or the academic
   research literatures. The notion of competitive intensity itself has not
   been defined precisely. In this paper, we develop formal models of
   oligopolistic competition to investigate whether equilibrium levels of
   quality increase as competition intensifies. We consider three different
   competitive settings: (i) asymmetric duopolistic competition where the
   dominant firm's intrinsic demand potential decreases; (ii) a symmetric
   duopoly where the firms are precluded from cooperating in setting
   quality levels; and (iii) symmetric oligopolistic competition where the
   number of firms increases. We find that the relation between equilibrium
   quality and competitive intensity depends on what is understood by
   increased competition and, in addition, the relation is contingent on
   the values of parameters describing the cost and demand structure for
   the industry.
ZR 0
ZS 0
ZB 0
ZA 0
Z8 26
TC 249
Z9 274
SN 0025-1909
EI 1526-5501
UT WOS:000076497200003
ER

PT J
AU Balakrishnan, R
   Nagarajan, NJ
   Sivaramakrishnan, K
TI The effect of property rights and audit information quality on team
   incentives for inventory reduction
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1193
EP 1204
DI 10.1287/mnsc.44.9.1193
PD SEP 1998
PY 1998
AB We analyze how limited contractibility and the informational quality of
   audits affect inventory levels and the optimality of individual versus
   team-based production. We use a two-period agency model in which
   contractibility is limited and agents meet a fixed delivery quota each
   period. A costly audit is triggered in any period if the delivery quota
   of output for the period is not met. We show that the informativeness of
   the audit plays a crucial role in resolving coordination problems
   between agents when they are organized as a team. When the audit is
   perfectly informative about agent productivity and inventory levels,
   team-based production is optimal. The team meets its quota even though,
   in equilibrium, the audit never takes place. If the audit is not
   perfectly informative about inventory levels, we show that team-based
   production typically induces agents to endogenously reduce inventory
   levels and could even result in agents adopting a zero-inventory policy.
   When the audit is completely uninformative, individual production is
   superior to team-based production.
OI Balakrishnan, Ramji/0000-0001-5936-7219
ZB 0
TC 5
ZA 0
ZS 0
Z8 0
ZR 0
Z9 5
SN 0025-1909
UT WOS:000076497200004
ER

PT J
AU Weber, EU
   Hsee, C
TI Cross-cultural differences in risk perception but cross-cultural
   similarities in attitudes towards perceived risk
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1205
EP 1217
DI 10.1287/mnsc.44.9.1205
PD SEP 1998
PY 1998
AB In this study, respondents from the P.R.C., U.S.A., Germany, and Poland
   were found to differ in risk preference, as measured by buying prices
   for risky financial options. Chinese respondents were significantly less
   risk-averse in their pricing than Americans when risk preference was
   assessed in the traditional expected-utility framework. However, these
   apparent differences in risk preference were associated primarily with
   cultural differences in the perception of the risk of the financial
   options rather than with cultural differences in attitude towards
   perceived risk. In all cultures, an equal proportion (the majority) of
   respondents was willing to pay more for options perceived as less risky,
   i.e., were perceived-risk averse. These results are most naturally
   explained within a risk-return conceptualization of risky choice, They
   have practical implications for cross-cultural negotiation and commerce
   by suggesting the locus of cultural differences in risky choice that may
   allow for the creation of joint gains.
Z8 8
TC 421
ZS 3
ZA 0
ZR 0
ZB 22
Z9 431
SN 0025-1909
UT WOS:000076497200005
ER

PT J
AU Duan, JC
   Simonato, JG
TI Empirical martingale simulation for asset prices
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1218
EP 1233
DI 10.1287/mnsc.44.9.1218
PD SEP 1998
PY 1998
AB This paper proposes a simple modification to the standard Monte Carlo
   simulation procedure for computing the prices of derivative securities.
   The modification imposes the martingale property on the simulated sample
   paths of the underlying asset price. This procedure is referred to as
   the empirical martingale simulation (EMS). The EMS ensures that the
   price estimated by simulation satisfies the rational option pricing
   bounds. The EMS yields a substantial error reduction for the price
   estimate and can be easily coupled with the standard variance reduction
   methods. Simulation studies are conducted for European and Asian call
   options using both the Black and Scholes and GARCH option pricing
   frameworks. The results indicate that the EMS yields substantial
   variance reduction particularly for in- and at-the-money or
   longer-maturity options. The option price estimate based on the EMS is
   found to exhibit a minor small-sample bias only in few occasions. An
   analysis of the trade-off between computing time and price accuracy
   reveals that the EMS dominates the conventional simulation methods.
RI Duan, Jin-Chuan/D-2408-2016
Z8 3
ZB 0
TC 83
ZR 0
ZS 0
ZA 0
Z9 85
SN 0025-1909
UT WOS:000076497200006
ER

PT J
AU Moxnes, E
TI Not only the tragedy of the commons: Misperceptions of bioeconomics
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1234
EP 1248
DI 10.1287/mnsc.44.9.1234
PD SEP 1998
PY 1998
AB An exploratory search for explanations of mismanagement of renewable
   resources, other than the theory of the commons, was performed by an
   experiment. Eighty three subjects, mostly recruited from the fisheries
   sector in Norway, were asked to manage the same simulated virgin fish
   stock, one subject at a time. Exclusive property rights were granted to
   rule out the commons problem. Despite perfect property rights, subjects
   consistently overinvested, leading to an average overcapacity of 60%.
   The resource was reduced by an average of 15% below its optimal level.
   Overcapacity and tough "quotas" resemble the situation in Norwegian and
   other fisheries during the past few decades. The likely explanation of
   the observed behaviour is misperception of feedback, a phenomenon that
   occurs in many experimental studies of dynamically complex systems. Such
   misperceptions add a new and important dimension to the problem of
   renewable resource management, beyond the commons problem.
ZB 20
ZA 0
ZR 0
ZS 2
TC 113
Z8 2
Z9 118
SN 0025-1909
UT WOS:000076497200007
ER

PT J
AU Gonul, F
   Shi, MZ
TI Optimal mailing of catalogs: A new methodology using estimable
   structural dynamic programming models
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1249
EP 1262
DI 10.1287/mnsc.44.9.1249
PD SEP 1998
PY 1998
AB We investigate the key determinants of the optimal direct mail policy in
   a dynamic environment where customers maximize utility and the direct
   mailer maximizes profits. We measure the sensitivity of the customers to
   receiving a catalog in the mail, while controlling for customer
   characteristics such as elapsed time in responses and number of
   purchases. We apply our model to a database from a national cataloger
   that markets nonseasonal products. We summarize the results of our model
   that are valid for these types of products. We find that the dynamic
   model significantly outperforms its single-period counterpart. We find
   that it is not optimal to mail to individuals at low recency levels
   because they are likely to buy anyway. It is better to save the mailing
   dollars for customers at higher recency levels. We find that it is
   optimal to mail to customers who have purchased only a small or a medium
   number of times to induce them to continue to buy from this catalog and
   not switch to others. It is not necessary to mail often to customers who
   have purchased many times before from the company unless they have high
   recency values. We find that under the optimal mailing policy the
   cataloguer enjoys higher profits than under the current mailing policy.
ZB 1
Z8 6
ZS 0
ZR 0
TC 94
Z9 100
SN 0025-1909
UT WOS:000076497200008
ER

PT J
AU Tan, BCY
   Wei, KK
   Watson, RT
   Clapper, DL
   McLean, ER
TI Computer-mediated communication and majority influence: Assessing the
   impact in an individualistic and a collectivistic culture
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1263
EP 1278
DI 10.1287/mnsc.44.9.1263
PD SEP 1998
PY 1998
AB Strong majority influence can potentially harm organizational decisions
   by causing decision makers to engage in groupthink. This study examines
   whether and how computer-mediated communication (CMC) can reduce
   majority influence and thereby enhance the quality of decisions in some
   situations. To measure the impact of CMC on majority influence, three
   settings (unsupported, face-to-face CMC, and dispersed CMC) were
   compared. Matching laboratory experiments were carried out in an
   individualistic (the US) and a collectivistic culture (Singapore) to
   determine how the impact of CMC might be moderated by national culture.
   An intellective and a preference task were used to see whether the
   impact of CMC might be moderated by task type. The results showed that
   the impact of CMC on majority influence was contingent upon national
   culture. In the individualistic culture, majority influence was stronger
   in the unsupported setting than the face-to-face CMC and dispersed CMC
   settings. In the collectivistic culture, there were no corresponding
   differences. The results also revealed that the impact of CMC on
   majority influence was not moderated by task type. Instead, task type
   had a direct impact on majority influence. Regardless of the setting
   involved, majority influence was stronger with the preference than the
   intellective task. Besides demonstrating how cultural factors may
   moderate the impact of CMC, this study raises the broader issue of
   cultural relativism in current knowledge on CMC.
RI Wei, Kwok Kee/Q-5427-2016; Watson, Richard/
OI Wei, Kwok Kee/0000-0002-5924-606X; Watson, Richard/0000-0003-0664-8337
TC 117
ZS 0
Z8 0
ZB 1
ZA 0
ZR 0
Z9 117
SN 0025-1909
EI 1526-5501
UT WOS:000076497200009
ER

PT J
AU Hwang, JW
   Singh, MR
TI Optimal production policies for multi-stage systems with setup costs and
   uncertain capacities
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1279
EP 1294
DI 10.1287/mnsc.44.9.1279
PD SEP 1998
PY 1998
AB The increased complexity of modern manufacturing has led to
   uncertainties in production processes. Factors such as unplanned machine
   maintenance, tool unavailability, and complex process adjustments make
   it difficult to maintain a predictable level of output. To be effective,
   an appropriate production model must incorporate these uncertainties
   into the representation of the production process. This paper considers
   a one-time production of an application-specific product which must
   follow a fixed routing through the manufacturing system. The flow of
   items can be modeled as a multi-stage serial production line. The
   productive capacity is uncertain at each stage and the decision to
   produce at any stage incurs a significant setup cost. Semifinished
   products have little value and inability to satisfy the demand incurs a
   penalty for each unit of unmet demand. We show that the optimal
   production policy for this system can be characterized by two critical
   numbers, which can be computed apriori based on the cost parameters and
   distributional information for all downstream stages. Sensitivity of the
   critical numbers is also explored.
ZR 0
Z8 6
TC 25
ZS 0
ZA 0
ZB 0
Z9 30
SN 0025-1909
UT WOS:000076497200010
ER

PT J
AU Hesterberg, TC
   Nelson, BL
TI Control variates for probability and quantile estimation
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1295
EP 1312
DI 10.1287/mnsc.44.9.1295
PD SEP 1998
PY 1998
AB In stochastic systems, quantiles indicate the level of system
   performance that can be delivered with a specified probability, while
   probabilities indicate the likelihood that a specified level of system
   performance can be achieved. We present new estimators for use in
   simulation experiments designed to estimate such quantiles or
   probabilities of system performance. All of the estimators exploit
   control variates to increase their precision, which is especially
   important when extreme quantiles (in the tails of the distribution of
   system performance) or extreme probabilities (near zero or one) are of
   interest. Control variates are auxiliary random variables with known
   properties-in this case, known quantiles-and a strong stochastic
   association with the performance measure of interest. Since transforming
   a control variate can increase its effectiveness, we propose both
   continuous and discrete approximations to the optimal (
   variance-minimizing) transformation for estimating probabilities, and
   then invert the probability estimators to obtain corresponding quantile
   estimators. We also propose a direct control-variate quantile estimator
   that is not based on inverting a probability estimator. An empirical
   study using queueing, inventory and project-planning examples shows that
   substantial reductions in mean squared error can be obtained when
   estimating the 0.9, 0.95, and 0.99 quantiles.
RI Nelson, Barry L/B-7490-2009
ZA 0
Z8 0
ZB 0
ZS 0
TC 31
ZR 0
Z9 31
SN 0025-1909
UT WOS:000076497200011
ER

PT J
AU Smith, RL
   Zhang, RQ
TI Infinite horizon production planning in time-varying systems with convex
   production and inventory costs
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP 1313
EP 1320
DI 10.1287/mnsc.44.9.1313
PD SEP 1998
PY 1998
AB We consider the planning of production over the infinite horizon in a
   system with time-varying convex production and inventory holding costs.
   This production lot size problem is frequently faced in industry where a
   forecast of future demand must be made and production is to be scheduled
   based on the forecast. Because forecasts of the future are costly and
   difficult to validate, a firm would like to minimize the number of
   periods into the future it needs to forecast in order to make an optimal
   production decision today. in this paper, we first prove that under very
   general conditions finite horizon versions of the problem exist that
   lead to an optimal production level at any decision epoch. In
   particular, we show it suffices for the first period infinite horizon
   production decision to solve for a horizon that exceeds the longest time
   interval over which it can prove profitable to carry inventory. We then
   develop a closed-form expression for computing such a horizon and
   provide a simple finite algorithm to recursively compute an infinite
   horizon optimal production schedule.
ZS 0
ZR 0
ZB 0
Z8 0
ZA 0
TC 25
Z9 25
SN 0025-1909
UT WOS:000076497200012
ER

PT J
AU Glasserman, P
TI Editorial objectives stochastic models and simulation
SO MANAGEMENT SCIENCE
VL 44
IS 9
BP U3
EP U3
PD SEP 1998
PY 1998
Z8 0
ZB 0
TC 0
ZS 0
ZR 0
Z9 0
SN 0025-1909
UT WOS:000076497200001
ER

PT J
AU Nault, BR
TI Information technology and organization design: Locating decisions and
   information
SO MANAGEMENT SCIENCE
VL 44
IS 10
BP 1321
EP 1335
DI 10.1287/mnsc.44.10.1321
PD OCT 1998
PY 1998
AB We study the impact of information technology (IT) on the profitability
   of individual organization designs and on the relative profitability of
   different organization designs. We develop models where organization
   design is defined by the location of investment decision authority. We
   consider global and local investment when there is an information
   asymmetry between a central authority and decentralized
   nodes-decentralized nodes make better local investment decisions because
   of their local knowledge. We define three separate organization designs:
   a hierarchy where all investments are made by a central authority, a
   market where all investments are made by the decentralized nodes, and a
   mixed mode where global investments are made by a central authority and
   local investments are made by decentralized nodes. Because of
   complementarities between global and local investment, we show that
   there is underinvestment relative to first-best in all three
   organization designs. We also find that IT can be used to mitigate that
   underinvestment, either by bringing information to the decision maker or
   by redesigning the monitoring and incentive structure. We demonstrate
   that IT does not necessarily favor decentralized organization designs,
   and we show how the costs of coordination may result in the mixed mode
   being dominated by one or both of the alternative organization designs.
   Thus, collocation of investment decision rights and information that
   results in decisions that require coordination might not be optimal when
   the costs of not synchronizing global and local investment are high.
Z8 3
ZA 0
ZB 0
ZR 0
TC 34
ZS 0
Z9 37
SN 0025-1909
UT WOS:000076700800001
ER

PT J
AU Parnell, GS
   Conley, HW
   Jackson, JA
   Lehmkuhl, LJ
   Andrew, JM
TI Foundations 2025: A value model for evaluating future air and space
   forces
SO MANAGEMENT SCIENCE
VL 44
IS 10
BP 1336
EP 1350
DI 10.1287/mnsc.44.10.1336
PD OCT 1998
PY 1998
AB Air Force 2025 was a study directed by the Chief of Staff of the United
   States Air Force to identify key system concepts and technologies for
   achieving air and space dominance in the year 2025. The study was a
   large effort in which over 200 military experts participated for more
   than one year. We developed a Value-Focused Thinking model, which we
   used to evaluate which futuristic system concepts have the greatest
   potential to ensure future U.S. air and space dominance. We named the
   value model Foundations 2025 because it represented a return to the
   basics of air and space dominance. We used the "silver standard"
   approach for value hierarchy development. The participants identified
   key verbs to describe tasks that must be performed in 2025 to ensure air
   and space dominance. The value hierarchy was developed bottom-up by
   aggregating these verbs into higher order tasks using affinity diagrams.
   Using the value hierarchy, we used multiattribute decision analysis
   techniques to develop an additive value model with 134 attributes. The
   Foundations 2025 value model was successfully used to score 43
   futuristic system concepts and provide insights about the most promising
   system concepts and technologies. The analysis results directly
   supported the study director and the senior leadership of the United
   States Air Force.
Z8 0
TC 43
ZA 0
ZS 0
ZB 0
ZR 0
Z9 43
SN 0025-1909
UT WOS:000076700800002
ER

PT J
AU Lin, CR
   Buongiorno, J
TI Tree diversity, landscape diversity, and economics of maple-birch
   forests: Implications of Markovian models
SO MANAGEMENT SCIENCE
VL 44
IS 10
BP 1351
EP 1366
DI 10.1287/mnsc.44.10.1351
PD OCT 1998
PY 1998
AB Markov decision process (MDP) models were effective in analyzing forest
   management policies. Even the simplest standard results gave useful
   insights into forest ecology, such as how landscape diversity is shaped
   by natural catastrophes, and how forests mature through successional
   phases. The methods were also useful to predict the effects of different
   management policies on ecological and economic criteria. Optimization
   augmented the usefulness of the approach, suggesting that income from
   Wisconsin's maple-birch forests could be increased without ruining their
   diversity of landscape, tree size, and tree species. It showed that
   maximizing species diversity, defined by the distribution of trees in
   shade-tolerance classes, would require some harvest. Instead, maximum
   tree size diversity occurred in unmanaged forests, but this gave a less
   diverse landscape and no income. The MDP method allowed for the design
   of compromise policies that would maximize income while keeping
   diversity above specified limits. The opportunity cost of increasing
   tree size diversity was found to be much higher than for species
   diversity. Comparing the maximum timber income owners could have got
   with what they actually cut suggested that the amenity value of forests
   was four times that of timber. Advantages of the methods reside in the
   ability to model complex ecosystem processes with simple probability
   matrices, and in the rich MDP theory and algorithms. Limitations include
   the difficulty of defining a space set large enough for accurate
   discretization, but small enough for practical application.
ZA 0
ZB 25
ZR 0
TC 38
ZS 0
Z8 1
Z9 39
SN 0025-1909
UT WOS:000076700800003
ER

PT J
AU Ding, J
   Greenberg, BS
   Matsuo, H
TI Repetitive testing strategies when the testing process is imperfect
SO MANAGEMENT SCIENCE
VL 44
IS 10
BP 1367
EP 1378
DI 10.1287/mnsc.44.10.1367
PD OCT 1998
PY 1998
AB This paper considers the problem of test design and implementation when
   testing is imperfect. Items that are classified as conforming may be
   nonconforming, resulting in a poor outgoing quality level. Items that
   are classified as nonconforming may be conforming, resulting in
   excessive scrapping of conforming items. The failed items are commonly
   retested to reduce the scrapping problem. Alternatively, the accepted
   items may be retested to improve outgoing quality. In this paper, we
   examine the question of whether it is better to repetitively test
   rejected items, or to repetitively test accepted items. We also examine
   the relationship between the two testing policies, testing equipment
   accuracy and capacity, incoming quality, and outgoing quality
   requirements.
TC 18
ZS 0
Z8 0
ZA 0
ZR 0
ZB 0
Z9 18
SN 0025-1909
UT WOS:000076700800004
ER

PT J
AU Dey, D
   Sarkar, S
   De, P
TI A probabilistic decision model for entity matching in heterogeneous
   databases
SO MANAGEMENT SCIENCE
VL 44
IS 10
BP 1379
EP 1395
DI 10.1287/mnsc.44.10.1379
PD OCT 1998
PY 1998
AB In recent years, there has been a proliferation of database systems in
   all types of organizations. In many cases, these databases are developed
   in different departments and maintained autonomously. Much is to be
   gained, however, if databases across departments, divisions, or even
   organizations can be related to one another. One main problem of
   relating data stored in different databases is the differences in their
   representation of real-world entities, such as the use of different
   identifiers or primary keys. We present a decision theoretic model for
   matching entities across different databases. The decision to match two
   entities from two different databases inherently involves some
   uncertainty since an exact match may not be found because of errors in
   data collection, data entry, and data representation. We model this
   uncertainty using probability theory and propose an integer programming
   formulation that minimizes the total cost associated with the entity
   matching decision. The model has been implemented and validated on
   real-world data.
ZA 0
TC 29
Z8 2
ZB 0
ZR 0
ZS 0
Z9 31
SN 0025-1909
UT WOS:000076700800005
ER

PT J
AU Basuroy, S
   Nguyen, D
TI Multinomial logit market share models: Equilibrium characteristics and
   strategic implications
SO MANAGEMENT SCIENCE
VL 44
IS 10
BP 1396
EP 1408
DI 10.1287/mnsc.44.10.1396
PD OCT 1998
PY 1998
AB We specify and analyze the conditions under which the MNL market share
   models are appropriate for equilibrium analysis. Our results show that a
   linear price response function as is often used in empirical research,
   in conjunction with the typical concavity assumed in a large range of
   marketing response functions, would yield an interior equilibrium
   solution. We then consider the optimal reactions on pricing and
   marketing spending to entry and potential market expansion. In the
   context of the MNL models, we demonstrate that the entry of a new brand
   evokes a decrease in the equilibrium prices of the existing brands as a
   defensive reaction. This is true in both an expanding market as well as
   a fixed market. However, while new entry into a fixed market would
   trigger the incumbents to lower the marketing expenditure, we show that
   firms tend to raise marketing activities as they experience market
   expansion. Consequently, there exist distinct possibilities that
   marketing efforts for the existing brands increase in view of entry in
   an expanding market. Further managerial and marketing implications for
   endogeneity of the number of firms are explored.
TC 32
ZS 1
ZB 1
ZA 0
Z8 3
ZR 0
Z9 36
SN 0025-1909
UT WOS:000076700800006
ER

PT J
AU Vanderbeck, F
TI Lot-sizing with start-up times
SO MANAGEMENT SCIENCE
VL 44
IS 10
BP 1409
EP 1425
DI 10.1287/mnsc.44.10.1409
PD OCT 1998
PY 1998
AB Many practical applications of lot-sizing and scheduling problems
   involve start-up times. Operations research literature contains but few
   studies of lot-sizing models that take start-up times explicitly into
   account. Here, we review some of these studies, discuss the models and
   their complexity, and we propose further models. We consider in
   particular a single-stage single-mode multi-item lot-sizing model with
   continuous set-ups and sequence independent start-up times, which we
   solve using an integer programming column generation algorithm and we
   develop a dynamic programming procedure for the single-item subproblem
   that treats the initial stock as a decision variable. We also use
   cutting planes developed by Constantino for the multiitem polyhedra. By
   combining column and cut generation, the lower bounds that we obtain
   before branching are on average less than 2% from an optimal solution.
   Our algorithm solves instances with 3 to 5 items and 24 periods in an
   average of 50 seconds on a modern workstation, and problems with 36
   periods in an average of 750 seconds. Solutions guaranteed to be within
   2% of optimality are obtained in less than 75% of these times.
Z8 0
ZA 0
ZS 0
ZB 0
ZR 0
TC 28
Z9 28
SN 0025-1909
UT WOS:000076700800007
ER

PT J
AU Nakayama, MK
   Shahabuddin, P
TI Likelihood ratio derivative estimation for finite-time performance
   measures in generalized semi-Markov processes
SO MANAGEMENT SCIENCE
VL 44
IS 10
BP 1426
EP 1441
DI 10.1287/mnsc.44.10.1426
PD OCT 1998
PY 1998
AB This paper investigates the likelihood ratio method for estimating
   derivatives of finite-time performance measures in generalized
   semi-Markov processes (GSMPs). We develop readily verifiable conditions
   for the applicability of this method. Our conditions mainly place
   restrictions on the basic building blocks (i.e., the transition
   probabilities, the distribution and density functions of the event
   lifetimes, and the initial distribution) of the GSMP, which is in
   contrast to the structural conditions needed for infinitesimal
   perturbation analysis. We explicitly show that our conditions hold in
   many practical settings, and in particular, for large classes of
   queueing and reliability models. One intermediate result we obtain in
   this study, which is of independent value, is to formally show that the
   random variable representing the number of occurring events in a GSMP in
   a finite time horizon has finite exponential moments in a neighborhood
   of zero.
Z8 1
ZB 0
ZA 0
TC 7
ZR 0
ZS 0
Z9 8
SN 0025-1909
UT WOS:000076700800008
ER

PT J
AU Hodgson, TJ
   Cormier, D
   Weintraub, AJ
   Zozom, A
TI Note. Satisfying due dates in large job shops
SO MANAGEMENT SCIENCE
VL 44
IS 10
BP 1442
EP 1446
DI 10.1287/mnsc.44.10.1442
PD OCT 1998
PY 1998
AB For the multi-machine job shop scheduling problem, a conceptually simple
   simulation-based procedure (first proposed by Lawrence and Morton 1986)
   is shown to be both effective and efficient in providing optimal, or
   near optimal, schedules for minimizing the maximum lateness, L-max.
   Computational experimentation is used to identify the conditions under
   which the approach is most viable.
OI Hodgson, Thom/0000-0002-8077-4780
ZB 0
Z8 1
TC 21
ZS 0
ZA 0
ZR 0
Z9 22
SN 0025-1909
UT WOS:000076700800009
ER

PT J
AU Rego, C
TI A subpath ejection method for the vehicle routing problem
SO MANAGEMENT SCIENCE
VL 44
IS 10
BP 1447
EP 1459
DI 10.1287/mnsc.44.10.1447
PD OCT 1998
PY 1998
AB Generically, ejection chains are methods conceived to allow solution
   transformations to be efficiently carried out by modifying a variable
   number of their components at each step of a local search algorithm.
   We consider a subpath ejection chain method for the vehicle routing
   problem (VRP) under capacity and route length restrictions. The method
   undertakes the identification of a substructure named the flower
   reference structure which, besides coordinating moves during an ejection
   chain construction, allows the creation of neighborhood structures with
   interesting combinatorial characteristics. Specifically, we base the
   method on a fundamental property of creating alternating paths and
   cycles during an ejection chain construction.
   A new algorithm based on a Tabu search framework is proposed, and
   computational results on a set of academic and real-world problems
   indicate that the algorithm may be a good alternative to the best
   heuristic algorithms for the VRP.
ZA 0
TC 64
ZB 2
Z8 2
ZS 0
ZR 0
Z9 66
SN 0025-1909
UT WOS:000076700800010
ER

PT J
AU Hatch, NW
   Mowery, DC
TI Process innovation and learning by doing in semiconductor manufacturing
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP 1461
EP 1477
DI 10.1287/mnsc.44.11.1461
PN 1
PD NOV 1998
PY 1998
AB This payer analyzes the relationship between process innovation and
   learning by doing in the semiconductor industry where improvements in
   manufacturing yield are a catalyst for dynamic cost reductions. In
   contrast to most previous studies of learning by doing, the learning
   curve is shown here to be the product of deliberate activities intended
   to improve yields and reduce costs, rather than the incidental byproduct
   of production volume. Since some of the knowledge acquired through
   learning by doing during new process development is specific to the
   production environment where the process is developed, some knowledge is
   effectively lost when a new process is transferred to manufacturing. We
   find that dedicated process development facilities, geographic proximity
   between development and manufacturing facilities, and the duplication of
   equipment between development and manufacturing facilities are all
   significant in improving performance in introducing new technologies.
   Once in manufacturing, new processes are shown to disrupt the ongoing
   learning activities of existing processes by drawing away scarce
   engineering resources to "debug" the new processes.
ZR 0
ZS 4
TC 174
ZA 0
ZB 1
Z8 0
Z9 177
SN 0025-1909
UT WOS:000077977900001
ER

PT J
AU Dekimpe, MG
   Van de Gucht, LM
   Hanssens, DM
   Powers, KI
TI Long-run abstinence after narcotics abuse: What are the odds?
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP 1478
EP 1492
DI 10.1287/mnsc.44.11.1478
PN 1
PD NOV 1998
PY 1998
AB We consider the long-run odds that narcotics users remain abstinent
   after methadone treatment. A flexible split-hazard specification that
   allows for individual-level differences in both the long-run probability
   of eventual relapse and the short-run timing of relapse is developed.
   The model is applied to a comprehensive data set involving individual
   drug abuse and treatment histories for over 800 addicts. Our findings
   indicate (1) that the short-run success of methadone programs does not
   automatically translate into long-run abstinence, which suggests the
   need for aftercare, (2) the value of preventing a teenager or young
   adult from initiating, and (3) the possibility of identifying high-risk
   groups, both in terms of age of first daily use and in terms of
   ethnicity.
RI Hanssens, Dominique M/D-4922-2011; Dekimpe, Marnik/
OI Dekimpe, Marnik/0000-0001-5011-5269
ZA 0
ZS 0
Z8 1
TC 24
ZR 1
ZB 4
Z9 26
SN 0025-1909
EI 1526-5501
UT WOS:000077977900002
ER

PT J
AU Henderson, N
   Langford, I
TI Cross-disciplinary evidence for hyperbolic social discount rates
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP 1493
EP 1500
DI 10.1287/mnsc.44.11.1493
PN 1
PD NOV 1998
PY 1998
AB Researchers in different disciplines have independently found evidence
   to suggest that the social discount rate may be hyperbolic, rather than
   exponential, in nature. Both behaviorist research and some empirical
   economics studies support the hyperbolic discounting hypothesis. U.S.
   and U.K. government discounting dispensations for some long-run public
   development projects are explicable in terms of an underlying hyperbolic
   social discount rate. A statistical aggregation argument demonstrates
   that even if the behaviorist, economics and public choice evidence for
   hyperbolic discounting is not conclusive, the social discount rate of a
   set of people who individually express time preferences best modeled by
   exponential discounting functions is nonetheless hyperbolic.
   Further empirical economics studies of discounting preferences are
   required. Comparisons of different national discounting practices would
   also be useful to see how widespread is the use of unusually low
   exponential rates of discount for long-run projects. The application of
   hyperbolic discounting would have most impact in long-run benefit-cost
   analyses. However, government agencies would require overwhelming
   evidence before switching from exponential to hyperbolic discounting.
TC 15
Z8 0
ZS 0
ZR 0
ZA 0
ZB 0
Z9 15
SN 0025-1909
UT WOS:000077977900003
ER

PT J
AU Dhar, SK
   Raju, JS
TI The effects of cross-ruff coupons on sales and profits
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP 1501
EP 1516
DI 10.1287/mnsc.44.11.1501
PN 1
PD NOV 1998
PY 1998
AB Cross-ruff coupons are obtained at the time of purchase of a carrier
   brand and may be redeemed at a later date on a target brand. These
   coupons therefore have the ability to link consumer purchases across
   different brands as well as shopping trips. We model the effects of
   cross-ruff coupons on consumer choice behavior and derive the conditions
   under which cross-ruff coupons can lead to higher sales and profits than
   other types of package coupons. The model also provides insights into
   the selection of appropriate carrier and target brands, and on how the
   choice of an appropriate carrier or a target brand is affected when the
   categories that these brands belong to are demand complements or
   substitutes. We conduct an empirical analysis using data from 195
   different cross-ruff coupon campaigns observed in grocery stores in a
   major U.S. city over a three-month period. The data are consistent with
   the key insights provided by the model.
ZB 0
TC 20
Z8 3
ZA 0
ZS 0
ZR 0
Z9 23
SN 0025-1909
UT WOS:000077977900004
ER

PT J
AU Li, G
   Rajagopalan, S
TI Process improvement, quality, and learning effects
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP 1517
EP 1532
DI 10.1287/mnsc.44.11.1517
PN 1
PD NOV 1998
PY 1998
AB While quality has attracted significant attention in the past two
   decades, the debate is still on as to whether a firm should aim for zero
   defects or base its quality decisions on cost-benefit trade-offs. The
   continuous improvement advocates generally eschew the cost trade-off
   approach, but U.S, firms, after spending substantial sums on
   quality-related activities in the 1980s, appear to be focusing again on
   cost trade-offs and measures such as return on quality. This payer
   provides analytical support for the continuous improvement argument
   while relying on a cost trade-off analysis. We present a dynamic model
   of a monopolist making decisions on price, production, process
   improvement, and quality assurance efforts. The model is comprehensive
   and captures the effects of autonomous and induced learning on both
   productivity and quality and incorporates quality related costs in
   detail. Using this model, we show that quality improves over time, while
   process improvement effort and quality assurance effort decrease over
   time. In fact, as anecdotal and empirical evidence suggests, process
   improvement and quality assurance effort is high when quality level is
   low, and vice-versa. The optimal production rate is increasing and the
   optimal price is decreasing over time. We also provide valuable insights
   into the impact of changes in key parameters such as interest rates on
   production, price, process improvement effort, and quality assurance
   effort.
ZB 0
Z8 7
ZS 1
ZA 0
ZR 0
TC 90
Z9 98
SN 0025-1909
UT WOS:000077977900005
ER

PT J
AU Besanko, D
   Gupta, S
   Jain, D
TI Logit demand estimation under competitive pricing behavior: An
   equilibrium framework
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP 1533
EP 1547
DI 10.1287/mnsc.44.11.1533
PN 1
PD NOV 1998
PY 1998
AB Discrete choice models of demand have typically been estimated assuming
   that prices are exogenous. Since unobservable (to the researcher)
   product attributes, such as coupon availability, may impact consumer
   utility as well as price setting by firms, we treat prices as
   endogenous. Specifically, prices are assumed to be the equilibrium
   outcomes of Nash competition among manufacturers and retailers. To
   empirically validate the assumptions, we estimate logit demand systems
   jointly with equilibrium pricing equations for two product categories
   using retail scanner data and cost data on factor prices. In each
   category, we find statistical evidence of price endogeneity. We also
   find that the estimates of the price response parameter and the
   brand-specific constants are generally biased downward when the
   endogeneity of prices is ignored. Our framework provides explicit
   estimates of the value created by a brand, i.e., the difference between
   consumers' willingness to pay for a brand and its cost of production. We
   develop theoretical propositions about the relationship between value
   creation and competitive advantage for logit demand systems and use our
   empirical results to illustrate how firms use alternative value creation
   strategies to accomplish competitive advantage.
RI Gupta, Sachin/F-2515-2011; Gupta, Sachin/L-4384-2019
OI Gupta, Sachin/0000-0001-9459-5233
ZR 0
Z8 1
ZA 0
ZB 1
TC 150
ZS 0
Z9 151
SN 0025-1909
UT WOS:000077977900006
ER

PT J
AU Lambrecht, MR
   Ivens, PL
   Vandaele, NJ
TI ACLIPS: A capacity and lead time integrated procedure for scheduling
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP 1548
EP 1561
DI 10.1287/mnsc.44.11.1548
PN 1
PD NOV 1998
PY 1998
AB We propose a general hierarchical procedure to address real-life job
   shop scheduling problems. The shop typically produces a variety of
   products, each with its own arrival stream, its own route through the
   shop and a given customer due date. The procedure first determines the
   manufacturing lot sizes for each product. The objective is to minimize
   the expected lead time, and therefore we model the production
   environment as a queueing network. Given these lead times, release dates
   are set dynamically. This in turn creates a time window for every
   manufacturing order in which the various operations have to be
   sequenced. The sequencing logic is based on an Extended Shifting
   Bottleneck Procedure. These three major decisions are next incorporated
   into a four-phase, hierarchical, operational implementation scheme. A
   small numerical example is used to illustrate the methodology. The final
   objective however is to develop a procedure that is useful for large,
   real-life shops. We therefore report on a real-life application.
RI vandaele, nico/F-6877-2017
ZA 0
ZR 0
Z8 1
ZB 0
TC 64
ZS 0
Z9 64
SN 0025-1909
UT WOS:000077977900007
ER

PT J
AU Chan, LMA
   Simchi-Levi, D
TI Probabilistic analyses and algorithms for three-level distribution
   systems
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP 1562
EP 1576
DI 10.1287/mnsc.44.11.1562
PN 1
PD NOV 1998
PY 1998
AB We consider the problem of integrating inventory control and vehicle
   routing into a cost-effective strategy for a distribution system
   consisting of a single outside vendor, a fixed number of warehouses and
   many geographically dispersed retailers. Each retailer faces a constant,
   retailer specific, demand rate and inventory holding cost is charged at
   the retailers and the warehouses. We show that, in an effective strategy
   which minimizes the asymptotic long run average cost, each warehouse
   receives fully loaded trucks from the vendor but never holds inventory.
   That is, each warehouse serves only as a coordinator of the frequency,
   time and sizes of deliveries to the retailers. This insight is used to
   construct an inventory control policy and vehicle routing strategy for
   multi-echelon distribution systems. Computational results are also
   reported.
TC 32
ZB 0
ZR 0
Z8 8
ZA 0
ZS 0
Z9 40
SN 0025-1909
UT WOS:000077977900008
ER

PT J
AU Talluri, K
   van Ryzin, G
TI An analysis of bid-price controls for network revenue management
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP 1577
EP 1593
DI 10.1287/mnsc.44.11.1577
PN 1
PD NOV 1998
PY 1998
AB Bid-prices are becoming an increasingly popular method for controlling
   the sale of inventory in revenue management applications. In this form
   of control, threshold-or "bid"-prices are set for the resources or units
   of inventory (seats on flight legs, hotel rooms on specific dates, etc.)
   and a product (a seat in a fare class on an itinerary or room for a
   sequence of dates) is sold only if the offered fare exceeds the sum of
   the threshold prices of all the resources needed to supply the product.
   This approach is appealing on intuitive and practical grounds, but the
   theory underlying it is not well developed. Moreover, the extent to
   which bid-price controls represent optimal or near optimal policies is
   not well understood. Using a general model of the demand process, we
   show that bid-price control is not optimal in general and analyze why
   bid-price schemes can fail to produce correct accept/deny decisions.
   However, we prove that when leg capacities and sales volumes are large,
   bid-price controls are asymptotically optimal, provided the right bid
   prices are used. We also provide analytical upper bounds on the optimal
   revenue. In addition, we analyze properties of the asymptotically
   optimal bid prices. For example, we show they are constant over time,
   even when demand is nonstationary, and that they may not be unique.
RI Escarabajal, Juan Antonio/C-5644-2012
ZB 1
Z8 10
ZS 0
ZR 0
ZA 0
TC 184
Z9 194
SN 0025-1909
UT WOS:000077977900009
ER

PT J
AU Bajeux-Besnainou, I
   Portait, R
TI Dynamic asset allocation in a mean-variance framework
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S79
EP S95
DI 10.1287/mnsc.44.11.S79
PN 2
PD NOV 1998
PY 1998
AB The aim of this article is to analyze the portfolio strategies that are
   mean-variance efficient when continuous rebalancing is allowed between
   the current date (0) and the horizon (T). Under very general
   assumptions, when a zero-coupon bond of maturity T exists, the dynamic
   efficient frontier is a straight line, the slope of which is explicitly
   characterized. Every dynamic mean-variance efficient strategy can be
   viewed as buy and hold combinations of two funds: the zero-coupon bond
   of maturity T and a continuously rebalanced portfolio. An appropriate
   dynamic strategy defining the latter is explicitly derived for two
   particular price processes and comparisons of the Efficient Frontiers
   (Static versus Dynamic) are provided in these cases.
ZA 0
ZR 1
ZS 0
ZB 0
Z8 2
TC 32
Z9 34
SN 0025-1909
UT WOS:000077978000006
ER

PT J
AU Bhattacharya, S
   Krishnan, V
   Mahajan, V
TI Managing new product definition in highly dynamic environments
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S50
EP S64
DI 10.1287/mnsc.44.11.S50
PN 2
PD NOV 1998
PY 1998
AB In highly dynamic environments, characterized by changing customer
   preferences and uncertainty about competitive products, managing the
   development of a new product is a complex managerial task. The
   traditional practice, recommended in the literature, of reaching a sharp
   definition early in the new product development (NPD) process may not be
   optimal, desirable or even feasible in such dynamic situations. Under
   high uncertainty, forcing early finalization of specifications may
   result in a firm getting locked into an incorrect definition. Based on
   our study of NPD in the high technology industry, we present a model of
   an approach called real-time definition, in which a firm adapts its
   product definition process to the market and competitive environment.
   Uncertainty in the product definition is resolved through frequent,
   repeated interactions with customers and using a flexible development
   process. We find that early definition is optimal only in a limited set
   of situations. To maximize its anticipated profits, a firm should tune
   its definition process to the prevailing level of market uncertainty,
   the marginal value of information obtained from the customer during the
   NPD process, and its own risk-profile and internal development
   capabilities. Effects of competition on a firm's definition approach are
   also examined, and implications for managers of a NPD process are
   presented using a conceptual framework.
RI BHATTACHARYA, Shantanu Hiralal/J-4138-2014; Mahajan, Vijay/L-3952-2019; Bhattacharya, Shantanu/
OI Bhattacharya, Shantanu/0000-0001-5027-6505
ZS 1
ZR 0
Z8 0
ZA 0
ZB 1
TC 89
Z9 90
SN 0025-1909
UT WOS:000077978000004
ER

PT J
AU Desai, P
   Purohit, D
TI Leasing and selling: Optimal marketing strategies for a durable goods
   firm
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S19
EP S34
DI 10.1287/mnsc.44.11.S19
PN 2
PD NOV 1998
PY 1998
AB This paper analyzes the problems associated with marketing a durable
   through leases and sales. Academic research in this area has argued that
   in a monopolistic environment, leasing dominates selling. Hence, leasing
   and selling should not co-exist and the firm should concentrate its
   efforts solely on leasing. We show that the relative profitability of
   leasing and selling hinges on the rates at which leased and sold units
   depreciate. In particular, we find that leasing does not dominate
   selling in all cases; if sold units depreciate at a significantly higher
   rate than leased units, a monopolistic firm is better off by only
   selling its product. In addition, we find that if leaded and sold
   products depreciate at different rates, then the optimal strategy for
   the firm involves a combination of both leasing and selling. We conclude
   the paper with an empirical analysis of the depreciation rates of leased
   and sold units of a popular car model. We find that the depreciation
   rate of leased cars has been significantly lower than the depreciation
   rate of sold cars.
ZR 0
TC 127
ZA 0
Z8 6
ZS 0
ZB 0
Z9 132
SN 0025-1909
UT WOS:000077978000002
ER

PT J
AU Green, LV
   Kolesar, PJ
TI A note on approximating peak congestion in M-t/G/infinity queues with
   sinusoidal arrivals
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S137
EP S143
DI 10.1287/mnsc.44.11.S137
PN 2
PD NOV 1998
PY 1998
AB We study the M-t/G/infinity queue where customers arrive according to a
   sinusoidal function lambda(t) = lambda + A sin(2 pi t/T) and the service
   rate is mu. We show that the expected number of customers in the system
   during peak congestion can be closely approximated by (lambda + A)/mu
   for service distributions with coefficient of variation between 0 and 1.
   Motivated by a result derived by Eick, Massey, and Whitt that the time
   lag of the peak congestion from the peak of the customer arrivals is 1/2
   mu for models with deterministic service times, we show that the time
   lag for exponential service times is closely approximated by 1/mu. Based
   on a cycle length of 24 hours and regardless of the values of other
   system parameters, these approximations are of the order of 1% accuracy
   for mu = 1, and the accuracy increases rapidly with increasing mu.
ZB 0
TC 5
Z8 0
ZS 0
ZR 0
ZA 0
Z9 5
SN 0025-1909
UT WOS:000077978000011
ER

PT J
AU Laguna, M
TI Applying robust optimization to capacity expansion of one location in
   telecommunications with demand uncertainty
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S101
EP S110
DI 10.1287/mnsc.44.11.S101
PN 2
PD NOV 1998
PY 1998
AB The problem of expanding the capacity of a single facility in
   telecommunications network planning is addressed. This problem can be
   formulated as a time-dependent knapsack, when relevant information is
   assumed to be known. We introduce the use of scenarios to model
   uncertainty in key data. The problem is formulated within the robust
   optimization framework and solved exactly in two phases. The first phase
   consists of a dynamic programming recursion and the second one of a
   shortest path procedure. Experiments show that a large number of
   scenarios can be handled with this technique, because computational
   times are more sensitive to the maximum demand across all scenarios than
   to the number of scenarios considered. A user-interface based on
   Microsoft Excel is developed as a decision support system for network
   planners.
ZB 2
TC 65
ZA 0
ZS 0
ZR 0
Z8 1
Z9 66
SN 0025-1909
EI 1526-5501
UT WOS:000077978000008
ER

PT J
AU Mukherjee, AS
   Lapre, MA
   Van Wassenhove, LN
TI Knowledge driven quality improvement
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S35
EP S49
DI 10.1287/mnsc.44.11.S35
PN 2
PD NOV 1998
PY 1998
AB Little is known about the processes that make TQM effective. Why are
   some quality improvement projects more effective than others? We argue
   that TQM processes affect the way people create new knowledge, which in
   turn determines organizational effectiveness. We explore this by
   studying 62 quality improvement projects undertaken in one factory over
   a decade. Using a factor analysis we identify three learning constructs
   that characterize the learning process: scope, conceptual learning, and
   operational learning. We use OLS regressions to study the impact of
   these learning constructs on project performance. Conceptual and
   operational learning are found to play a crucial role in achieving
   goals, creating new technological knowledge, and changing factory
   personnel's attention. Contrary to the common practice of relying on
   operational learning, we suggest the application of conceptual learning
   as well, particularly if the technology is poorly understood. It
   facilitates the codification of knowledge, which enhances its
   dissemination for both present and future use.
OI Mukherjee, Amit/0000-0001-6929-2919; Lapre, Michael/0000-0003-2259-8739
ZS 0
Z8 0
ZA 0
ZB 0
ZR 0
TC 139
Z9 139
SN 0025-1909
UT WOS:000077978000003
ER

PT J
AU Murthy, I
   Sarkar, S
TI Stochastic shortest path problems with piecewise-linear concave utility
   functions
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S125
EP S136
DI 10.1287/mnsc.44.11.S125
PN 2
PD NOV 1998
PY 1998
AB This paper considers a stochastic shortest path problem where the are
   lengths are independent random variables following a normal
   distribution. In this problem, the optimal path is one that maximizes
   the expected utility, with the utility function being piecewise-linear
   and concave. Such a utility function can be used to approximate
   nonlinear utility functions that capture risk averse behaviour for a
   wide class of problems. The principal contribution of this paper is the
   development of exact algorithms to solve large problem instances. Two
   algorithms are developed and incorporated in labelling procedures.
   Computational testing is done to evaluate the performance of the
   algorithms. Overall, both algorithms are very effective in solving large
   problems quickly. The relative performance of the two algorithms is
   found to depend on the "curvature" of the piecewise linear utility
   function.
ZS 0
TC 28
Z8 0
ZR 0
ZA 0
ZB 0
Z9 28
SN 0025-1909
UT WOS:000077978000010
ER

PT J
AU Rosenblatt, MJ
   Herer, YT
   Hefter, I
TI Note. An acquisition policy for a single item multi-supplier system
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S96
EP S100
DI 10.1287/mnsc.44.11.S96
PN 2
PD NOV 1998
PY 1998
AB In this paper we consider the problem of developing an acquisition
   policy. Specifically, given a set of potential (qualified) suppliers,
   from whom should the firm buy the product, in what quantities, and how
   often? We provide properties of the optimal solution and relate them to
   the approach of using a single source as advocated by TIT. The solution
   procedure provides the periodic order quantity from each supplier; the
   order size; and the firm cycle time as well as how many times per cycle
   we should order from each supplier. We show that the maximum error of
   our solution can be made as small as desired.
Z8 0
ZA 0
TC 52
ZR 0
ZB 0
ZS 0
Z9 52
SN 0025-1909
UT WOS:000077978000007
ER

PT J
AU Sikora, R
   Shaw, MJ
TI A multi-agent framework for the coordination and integration of
   information systems
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S65
EP S78
DI 10.1287/mnsc.44.11.S65
PN 2
PD NOV 1998
PY 1998
AB This paper describes a framework for the coordination and integration of
   information systems. By modeling typical enterprise information systems
   as consisting of multiple agents with different functionalities, the
   methodology provides the representational formalism, coordination
   mechanisms, and control schemes necessary for integrating heterogeneous
   units of an information system while meeting such performance criteria
   as overall effectiveness, efficiency, responsiveness, and robustness.
   The framework is applied to the development of a manufacturing
   information system for managing the production processes for making
   printed circuit boards. Performance results confirm that the system
   integration framework is important to support complex business processes
   that involve multiple steps of activities processed by a group of agents
   across a variety of functionalities.
ZS 1
ZA 0
ZB 0
ZR 0
Z8 1
TC 69
Z9 70
SN 0025-1909
UT WOS:000077978000005
ER

PT J
AU Van den Bulte, C
   Moenaert, RK
TI The effects of R&D team co-location on communication patterns among R&D,
   marketing, and manufacturing
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S1
EP S18
DI 10.1287/mnsc.44.11.S1
PN 2
PD NOV 1998
PY 1998
AB Reducing the physical distance among R&D engineers and between R&D and
   marketing is widely believed to result in more frequent communication,
   and hence higher product development performance. However, the empirical
   evidence for the effect of co-location on communication frequency is
   problematic for two reasons: (I)the evidence often features either
   little contextual realism or doubtful internal validity, and (2) the
   analysis does not deal with the statistical problems typical of network
   data. Our study avoids the first problem by using sequential network
   data collected from a quasi-experiment at an industrial company that
   regrouped its R&D teams into a new facility. We avoid the second problem
   by using Wasserman and Iacobucci's (1988) method for the statistical
   analysis of sequential network data. Our results show that communication
   among R&D teams was enhanced after co-locating these teams.
   Surprisingly, communication frequency between R&D and marketing was not
   affected by the increased physical distance. This may suggest that
   business procedures accompanying the relocation prevented a widening gap
   between R&D and marketing. Alternatively, it may indicate that the
   effect of co-location depends on the content and medium of the
   communication flows.
RI Van den Bulte, Christophe/P-4046-2014
OI Van den Bulte, Christophe/0000-0001-9708-1596
ZB 2
ZA 0
ZS 0
Z8 0
ZR 0
TC 126
Z9 126
SN 0025-1909
UT WOS:000077978000001
ER

PT J
AU Young, MR
   Lenk, PJ
TI Hierarchical Bayes methods for multifactor model estimation and
   portfolio selection
SO MANAGEMENT SCIENCE
VL 44
IS 11
BP S111
EP S124
DI 10.1287/mnsc.44.11.S111
PN 2
PD NOV 1998
PY 1998
AB The factor model is an important construct for both portfolio managers
   and researchers in modern finance. For practitioners, factor model
   coefficients are used to guide the construction of optimal portfolios.
   For academicians, factor model parameters play a fundamental role in
   explaining equilibrium asset prices and other market phenomena. This
   paper presents a hierarchical modeling procedure that can substantially
   improve the accuracy of factor model parameter estimates through
   incorporation of cross-sectional information. It is shown that this
   improvement in parameter estimation accuracy translates into substantial
   improvement in portfolio performance. Expressions are derived that
   characterize the sensitivity of portfolio performance to parameter
   estimation error. Evidence with NYSE data suggests that the hierarchical
   estimation technique leads to superior out-of-sample portfolio
   performance when compared to alternative estimation approaches.
Z8 0
ZA 0
ZR 0
ZB 0
ZS 0
TC 5
Z9 5
SN 0025-1909
UT WOS:000077978000009
ER

PT J
AU Schultz, KL
   Juran, DC
   Boudreau, JW
   McClain, JO
   Thomas, LJ
TI Modeling and worker motivation in JIT production systems
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP 1595
EP 1607
DI 10.1287/mnsc.44.12.1595
PN 1
PD DEC 1998
PY 1998
AB This paper concerns the modeling of low inventory lines. Currently, most
   models assume that processing times are independent. We consider the
   differences in behavior of workers in low- and high-inventory production
   lines. Using a laboratory experiment we show that workers speed up when
   they are the cause of idle time on the line. This means that processing
   time distributions are not independent of the size of the buffer, of the
   processing speed of co-workers, or of the amount of inventory in the
   system. We show that the direction of these effects is predictable and
   that the magnitude is significant. In particular, there is less idle
   time and higher output than would be predicted using assumptions of
   independence. in this experiment the effect completely canceled
   productivity loss due to blocking and starving. This work is important
   in understanding both the motivation of workers in low-inventory systems
   and the implications of models of manufacturing flow lines.
ZA 0
Z8 1
TC 64
ZR 0
ZS 0
ZB 0
Z9 65
SN 0025-1909
UT WOS:000078474300001
ER

PT J
AU Labbe, M
   Marcotte, P
   Savard, G
TI A bilevel model of taxation and its application to optimal highway
   pricing
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP 1608
EP 1622
DI 10.1287/mnsc.44.12.1608
PN 1
PD DEC 1998
PY 1998
AB We consider a bilevel model where the leader wants to maximize revenues
   from a taxation scheme, while the follower rationally reacts to those
   tax levels. We focus our attention on the special case of a toll-setting
   problem defined on a multicommodity transportation network. We show that
   the general problem is NP-complete, while particular instances are
   polynomially solvable. Numerical examples are given.
OI Labbe, Martine/0000-0001-7471-2308
TC 181
Z8 1
ZB 5
ZA 0
ZS 1
ZR 0
Z9 182
SN 0025-1909
UT WOS:000078474300002
ER

PT J
AU Ha, AY
TI Incentive-compatible pricing for a service facility with joint
   production and congestion externalities
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP 1623
EP 1636
DI 10.1287/mnsc.44.12.1623
PN 1
PD DEC 1998
PY 1998
AB This paper considers the pricing problem of a service facility when
   services are jointly produced by the customers and the facility.
   Building on the work of Mendelson (1985), we model the facility as a GI
   / GI / 1 queue with customer-chosen service rates and linear delay
   costs. We show that the service rates chosen by the customers, based on
   their self-interest, are always suboptimal for the facility due to
   congestion externalities. We derive optimal incentive-compatible pricing
   schemes that can achieve optimal arrival rates and induce customers to
   choose optimal service rates. For the case of systemwide net-value
   maximization, we show that the optimal incentive-compatible pricing
   scheme consists of a variable fee that is proportional to the actual
   service time and a fixed rebate that is equal to a customer's expected
   delay cost in the queue. For the case of profit maximization of the
   facility, we show that the optimal pricing scheme again consists of a
   fixed fee and a variable fee. One insight from our analysis is that it
   may be appropriate for a service facility to reimburse each customer for
   his actual delay cost in the queue.
Z8 0
ZR 0
ZS 0
ZB 0
ZA 0
TC 26
Z9 26
SN 0025-1909
UT WOS:000078474300003
ER

PT J
AU Lobel, A
TI Vehicle scheduling in public transit and Lagrangean pricing
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP 1637
EP 1649
DI 10.1287/mnsc.44.12.1637
PN 1
PD DEC 1998
PY 1998
AB This paper investigates the solution of the linear programming (LP)
   relaxation of the multicommodity flow formulation of the multiple-depot
   vehicle scheduling problems arising in public mass transit. We develop a
   column generation technique that makes it possible to solve the huge
   linear programs that come up there. The technique, which we call
   Lagrangean pricing, is based on two different Lagrangean relaxations.
   We describe in detail the basic ingredients of our approach and give
   computational results for large-scale test data (with up to 70 million
   variables) from three German public transportation companies. Because of
   these results, we propose Lagrangean pricing as one of the basic
   ingredients of an effective-method to solve multiple-depot vehicle
   scheduling problems to proven optimality.
ZS 0
Z8 1
ZA 0
ZB 0
ZR 0
TC 62
Z9 63
SN 0025-1909
UT WOS:000078474300004
ER

PT J
AU Theodossiou, P
TI Financial data and the skewed generalized T distribution
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP 1650
EP 1661
DI 10.1287/mnsc.44.12.1650
PN 1
PD DEC 1998
PY 1998
AB This paper develops a skewed extension of the generalized t (GT)
   distribution introduced by McDonald and Newey (1988). In particular, the
   paper derives the mathematical moments and other properties of the
   distribution and assesses its ability to fit the empirical distribution
   of several financial series characterized by skewness and excess
   kurtosis. In all cases the skewed GT provides an excellent fit to the
   empirical distribution of data.
OI Theodossiou, Panayiotis/0000-0001-5556-2594
Z8 3
ZA 0
ZR 0
TC 183
ZB 3
ZS 3
Z9 189
SN 0025-1909
UT WOS:000078474300005
ER

PT J
AU Gilbert, SM
   Weng, ZK
TI Incentive effects favor nonconsolidating queues in a service system: The
   principal-agent perspective
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP 1662
EP 1669
DI 10.1287/mnsc.44.12.1662
PN 1
PD DEC 1998
PY 1998
AB In this paper, we study a service network in which an agency is
   responsible for satisfying a constraint on the expected waiting and
   service time experienced by customers. However, the agency does not
   render the actual service. Instead, it serves to coordinate
   independently operated facilities. The coordinating agency must devise a
   strategy for allocating compensation and customers to the
   self-interested operators in order to minimize its own costs. For a
   network of two facilities, we model the facilities' self-interested
   capacity decisions as the solution to a game. Using this analytical
   framework, we compare two types of customer allocation: one from a
   common queue, and one from separate queues. Our analysis shows that it
   can be in the best interest of the coordinating agency to adopt a
   separate queue allocation scheme instead of one based on a common queue.
   Although doing so sacrifices risk-pooling benefits, these can be more
   than offset by the stronger incentives that are created for the
   independent facilities.
TC 51
Z8 0
ZR 0
ZB 0
ZS 0
ZA 0
Z9 51
SN 0025-1909
UT WOS:000078474300006
ER

PT J
AU Hauser, JR
TI Research, development, and engineering metrics
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP 1670
EP 1689
DI 10.1287/mnsc.44.12.1670
PN 1
PD DEC 1998
PY 1998
AB We seek to understand how the use of Research, Development, and
   Engineering (R,D&E) metrics can lead to more effective management of
   R,D&E. This paper combines qualitative and quantitative research to
   understand and improve the use of R,D&E metrics. Our research begins
   with interviews of 43 representative Chief Technical Officers, Chief
   Executive Offices, and researchers at 10 research-intensive
   international organizations. These interviews, and an extensive review
   of the literature, provide qualitative insights. Formal mathematical
   models attempt to explore these qualitative insights based on more
   general principles.
   Our research suggests that metrics-based evaluation and management vary
   according to the characteristics of the R,D&E activity. For applied
   projects, we find that project selection can be based on market-outcome
   metrics when firms use central subsidies to account for short-termism,
   risk aversion, and scope. With an efficient form of subsidies known as
   "tin-cupping," the business units have the incentives to choose the
   projects that are in the firm's best long-term interests. For
   core-technological development, longer time delays and more risky
   programs imply that popular R,D&E effectiveness metrics lead researchers
   to select programs that are not in the firm's long-term interest. Our
   analyses suggest that firms moderate such market-outcome metrics by
   placing a larger weight on metrics that attempt to measure research
   effort more directly. These metrics include standard measures such as
   publications, citations, patents, citations to patents, and peer review.
   For basic research, the issues shift to getting the right people and
   encouraging a breadth of ideas. Unfortunately, metrics that identify the
   "best people" based on research success lead directly to
   "not-invented-here'' behaviors. Such behaviors result in research
   empires that are larger than necessary, but lead to fewer ideas. We
   suggest that firms use "research tourism" metrics, which encourage
   researchers to take advantage of research spillovers from universities,
   other industries, and, even, competitors.
RI Hauser, John R/O-3046-2019
Z8 0
TC 69
ZA 0
ZB 2
ZR 0
ZS 1
Z9 70
SN 0025-1909
UT WOS:000078474300007
ER

EF