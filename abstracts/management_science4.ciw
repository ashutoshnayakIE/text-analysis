FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Smith, JE
TI Evaluating income streams: A decision analysis approach
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP 1690
EP 1708
DI 10.1287/mnsc.44.12.1690
PN 1
PD DEC 1998
PY 1998
AB Most important decision problems-virtually all capital investments and
   planning situations-involve risky cash flow with uncertainties that are
   resolved over time. In most of these problems, the decision-maker has
   access to financial markets and may barrow and lend to smooth
   consumption over time. Yet, because of the difficulty of incorporating
   these borrowing and lending decisions into the evaluation models, these
   opportunities are rarely explicitly modeled in decision and risk
   analyses of these investments. In this paper, we study the errors
   induced by failing to account for these borrowing and lending decisions,
   and we develop extensions to the standard decision and risk analysis
   procedures that, given certain market and preference assumptions, take
   these borrowing and lending opportunities into account without
   overburdening the evaluation models.
ZB 0
ZA 0
Z8 0
TC 29
ZS 0
ZR 0
Z9 29
SN 0025-1909
UT WOS:000078474300008
ER

PT J
AU Damerdji, H
   Glynn, PW
TI Limit theory for performance modeling of future event set algorithms
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP 1709
EP 1722
DI 10.1287/mnsc.44.12.1709
PN 1
PD DEC 1998
PY 1998
AB In a discrete-event simulation, the information related to the events
   scheduled to occur in the future is kept in a data structure called the
   future event set (FES). In this paper, we study the interaction hold
   model, a popular stochastic model for FES performance analysis,
   corresponding to the superposition of a (fixed) number of renewal
   processes; The general state-space Markov chain formed by the
   discrete-time process that keeps track, at event times, of the residual
   lifetimes is shown here to be recurrent in the sense of Harris, and its
   stationary distribution is obtained. Linked lists and indexed lists, two
   popular FESs, are investigated using this model. For the interaction
   hold model, we make rigorous certain published results as well as
   introduce new ones. For example, we derive the distribution of the
   relative position of the event to be inserted in the data structure. In
   the exponential case, our analytic and empirical results confirm that
   when events with relatively short lifetimes often get regenerated upon
   their occurrence, it is better to scan a list (or sublist) from its head
   rather than tail. In the same context and for indexed lists with
   sublists with constant sizes, our results suggest that subsequent
   sublists should be of larger sizes, i.e., the first sublist should
   contain the smallest number of records, the second sublist the second
   smallest number of records, etc.
ZB 0
ZS 0
ZR 0
TC 1
ZA 0
Z8 0
Z9 1
SN 0025-1909
UT WOS:000078474300009
ER

PT J
AU Bashyam, S
   Fu, MC
TI Optimization of (s, S) inventory systems with random lead times and a
   service level constraint
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP S243
EP S256
DI 10.1287/mnsc.44.12.S243
PN 2
PD DEC 1998
PY 1998
AB A major assumption in the analysis of (s, S) inventory systems with
   stochastic lead times is that orders are received in the same sequence
   as they are placed. Even under this assumption, much of the work to date
   has focused on the unconstrained optimization of the system, in which a
   penalty cost for unsatisfied demand is assigned. The literature on
   constrained optimization, wherein a service level requirement needs to
   be met, is more sparse. In this paper, we consider the constrained
   optimization problem, where orders are allowed to cross in time. We
   propose a feasible directions procedure that is simulation based, and
   present computational results for a large number of test cases. In the
   vast majority of cases,we come within 5% of estimated optimality.
RI Fu, Michael C/N-4098-2013
OI Fu, Michael C/0000-0003-2105-4932
ZA 0
Z8 3
ZS 0
TC 73
ZB 0
ZR 0
Z9 76
SN 0025-1909
UT WOS:000078474700008
ER

PT J
AU Chen, FR
TI Echelon reorder points, installation reorder points, and the value of
   centralized demand information
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP S221
EP S234
DI 10.1287/mnsc.44.12.S221
PN 2
PD DEC 1998
PY 1998
AB We consider a serial inventory system with N stages. The material flows
   from an outside supplier to stage N, then to stage N - 1, etc., and
   finally to stage 1 where random customer demand arises. Each stage
   replenishes a stage-specific inventory position according to a
   stage-specific reorder point/order quantity policy. Two variations of
   this policy are considered. One is based on echelon stock, and the other
   installation stock. The former requires centralized demand information,
   while the latter does not. The relative cost difference between the two
   policies is called the value of centralized demand information. For
   fixed order quantities, we develop efficient algorithms for computing
   both the optimal echelon reorder points and the optimal installation
   reorder points. These algorithms enable us to conduct an extensive
   computational study to assess the value of centralized demand
   information and to understand how this value depends on several key
   system parameters, i.e., the number of stages, leadtimes, batch sizes,
   demand variability, and the desired level of customer service.
ZB 2
ZA 0
TC 183
ZR 0
ZS 0
Z8 6
Z9 188
SN 0025-1909
UT WOS:000078474700006
ER

PT J
AU Christensen, CM
   Suarez, FF
   Utterback, JM
TI Strategies for survival in fast-changing industries
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP S207
EP S220
DI 10.1287/mnsc.44.12.S207
PN 2
PD DEC 1998
PY 1998
AB Technology strategy variables tend to predominate as predictors of
   survival in the fast-changing rigid disk drive industry. Building on
   these previous studies, we here test the hypothesis that the
   technological and market strategies of a new entrant are highly
   interrelated and that their joint effect plays an important role in a
   firm's probability of survival. In particular, we propose that firms
   that target new market segments with an architectural innovation will
   tend to be more successful than those that target existing markets or
   innovate in component technology, even after controlling for all the
   competing predictors of survival.
   This paper advances the existing literature on innovation by tracing the
   main technical elements of a dominant design in the rigid disk drive
   industry over time, and provides a much more rigorous definition of the
   concept of a dominant design than we have had in the past. We find the
   notion of first-mover advantage is not applicable in the rigid disk
   drive industry. Instead, we propose the idea of an entry-window tightly
   linked to the emergence of the dominant product design as defined.
Z8 0
TC 266
ZS 1
ZA 0
ZR 0
ZB 1
Z9 267
SN 0025-1909
UT WOS:000078474700005
ER

PT J
AU Ho, TH
   Tang, CS
   Bell, DR
TI Rational shopping behavior and the option value of variable pricing
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP S145
EP S160
DI 10.1287/mnsc.44.12.S145
PN 2
PD DEC 1998
PY 1998
AB When a product's price fluctuates at a store, how should rational,
   cost-minimizing shoppers shop for it? Specifically, how frequently
   should they visit the store, and how much of the product should they buy
   when they get there? Would this rational shopping behavior differ across
   Every Day Low Price (EDLP) and Promotional Pricing (HILO) stores? If
   shoppers are rational, which retail price format is more profitable,
   EDLP or HILO? To answer these questions, we develop a normative model
   that shows how rational customers should shop when the price of the
   product is random.
   We derive a closed-form expression for the optimal purchasing policy and
   show that the optimal quantity to purchase under a given price scenario
   is linearly decreasing in the difference between the price under that
   scenario and the average price. This purchase flexibility due to price
   variability has a direct impact on shopping frequency. Indeed, the
   benefit of this purchase flexibility can be captured via an "option
   value" that implicitly reduces the fixed cost associated with each
   shopping trip. Consequently, rational shoppers should shop more often
   and buy fewer units per trip when they face higher price variability.
   Our results suggest that if two stores charge the same average price for
   a product, rational shoppers incur a lower level of expenditure at the
   store with a higher price variability. Since stores with different price
   variabilities coexist in practice, we expect stores with higher price
   variability to charge a higher average price. Thus, given two stores, a
   higher relative mean price for a given item should be indicative of
   higher price variability, and vice versa.
   These model implications are tested using multicategory scanner panel
   data from 513 households and pricing data for three stores (two EDLP
   stores ana one HILO store) and 33 product categories over a two-year
   period. We find strong empirical support for the model implications.
RI Ho, Teck-Hua/D-1630-2013; Yedidsion, Liron/M-9996-2014
OI Ho, Teck-Hua/0000-0001-5210-4977; 
ZR 0
ZS 0
TC 48
ZB 0
ZA 0
Z8 1
Z9 49
SN 0025-1909
UT WOS:000078474700001
ER

PT J
AU Hsu, JM
   Wang, XM
   Wu, CC
TI The role of earnings information in corporate dividend decisions
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP S173
EP S191
DI 10.1287/mnsc.44.12.S173
PN 2
PD DEC 1998
PY 1998
AB This paper examines the role of earnings information in the
   determination of dividend policy. I We decompose accounting earnings
   into permanent and transitory components and postulate that dividend
   policy is driven by sustainable permanent earnings. Two measures of
   permanent earnings are proposed. The first is a permanent earnings
   variable extracted from accounting earnings by a random-level shift ARMA
   model. The second measure is stock price times cost of capital. These
   two permanent earnings measures are employed in the Marsh-Merton (1987)
   model to explain corporate dividend behavior and their performance is
   compared. A generalized friction method is adopted for empirical
   estimation to account for stepwise dividend movements over time. Results
   show that the permanent earnings measure extracted from accounting
   earnings data explains dividend dynamic behavior better than stock
   price.
RI WU, Chunchi/D-2194-2010
ZA 0
ZS 0
TC 1
Z8 0
ZR 0
ZB 0
Z9 1
SN 0025-1909
UT WOS:000078474700003
ER

PT J
AU Park, JS
   Lim, BH
   Lee, Y
TI A Lagrangian dual-based branch-and-bound algorithm for the generalized
   multi-assignment problem
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP S271
EP S282
DI 10.1287/mnsc.44.12.S271
PN 2
PD DEC 1998
PY 1998
AB This paper develops a Lagrangian dual-based branch-and-bound algorithm
   for the generalized multi-assignment problem (GMAP) which includes the
   well-known generalized assignment problem (GAP) as a special case. In
   GMAP, an object may be required to be duplicated in multiple locations.
   We develop a Lagrangian dual ascent algorithm for GMAP. This dual ascent
   and the subgradient search each possess advantages that can be combined
   to develop a new Lagrangian dual search algorithm. The latter
   algorithm,when incorporated into a branch-and-bound algorithm as the
   lower bounding scheme, can accelerate the search process. Computational
   results demonstrate the efficiency and robustness of this
   branch-and-bound algorithm not only for GMAPs, but for GAPs that are
   more difficult than could be solved by previous algorithms.
ZA 0
TC 15
Z8 0
ZB 0
ZS 0
ZR 0
Z9 15
SN 0025-1909
UT WOS:000078474700010
ER

PT J
AU Pirkul, H
   Schilling, DA
TI An efficient procedure for designing single allocation hub and spoke
   systems
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP S235
EP S242
DI 10.1287/mnsc.44.12.S235
PN 2
PD DEC 1998
PY 1998
AB Given the widespread use of the hub and spoke network architecture and
   its growing importance to competitiveness in logistics, communication,
   and mass transportation, there has been considerable interest by
   practitioners and researchers alike in finding efficient methods for
   designing such networks. This paper provides a method that delivers both
   high quality solutions and firm measures of that quality, and allows
   problems to be solved in reasonable time on a desktop computer. The
   approach begins with a previously proposed tight linear programming
   formulation and uses subgradient optimization on a lagrangian relaxation
   of the model. However, to dramatically improve the performance of this
   approach, we augment a subproblem of the lagrangian relaxation model
   with a cut constraint. In computational experiments on eighty-four
   standard test problems, average gaps are 0.048%. Maximum gaps are under
   1% while average solution times on a Pentium-166 are under five minutes.
ZR 0
ZB 1
Z8 0
ZA 0
TC 53
ZS 0
Z9 53
SN 0025-1909
UT WOS:000078474700007
ER

PT J
AU Swaminathan, JM
   Tayur, SR
TI Managing broader product lines through delayed differentiation using
   vanilla boxes
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP S161
EP S172
DI 10.1287/mnsc.44.12.S161
PN 2
PD DEC 1998
PY 1998
AB In an attempt to reduce cost while maintaining good customer service,
   some of the leading manufacturers in the computer industry are delaying
   product differentiation (by exploiting component commonality) while
   managing broader product lines. In an environment where demands are
   stochastic, it seems a good strategy to store inventory in the form of
   semi-finished products (vanilla boxes) that can serve more than one
   final product. However, finding the optimal configurations and inventory
   levels of the vanilla boxes could be a challenging task. In this paper,
   we model the above problem as a two-stage integer program with recourse.
   By utilizing structural decomposition of the problem and (sub)gradient
   derivative methods, we provide an effective solution procedure. A
   special case, a variant, and several extensions are also discussed. In
   our computational section, we utilize our model to study several new
   research issues. We provide insights on the effect of demand variance,
   correlation, and capacity limitations on the optimal configuration and
   inventory levels of vanilla boxes and the performance of a vanilla
   assembly process. In addition, we compare the performance of the vanilla
   assembly process to make-to-stock and assemble-to-order processes and
   provide managerial insights on the conditions under which one might be
   better than the others. Finally, we discuss the characteristics of an
   IBM product line (which motivated this work) and the effectiveness of a
   heuristic tailored for that application.
ZR 0
ZS 0
TC 169
Z8 1
ZB 0
ZA 0
Z9 170
SN 0025-1909
UT WOS:000078474700002
ER

PT J
AU Xie, JH
   Song, XM
   Stringfellow, A
TI Interfunctional conflict, conflict resolution styles, and new product
   success: A four-culture comparison
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP S192
EP S206
DI 10.1287/mnsc.44.12.S192
PN 2
PD DEC 1998
PY 1998
AB This paper develops a model relating innovation success to the level of
   interfunctional conflict and conflict resolution methods. The model
   suggests a concave relationship between performance and the level of
   interfunctional conflict among marketing, R&D, and manufacturing. It
   also conjectures that both national culture and the level of
   interfunctional conflict influence the effectiveness of different
   conflict resolution methods.-An empirical test of the proposed framework
   involves a survey of 968 marketing managers from Japan, I-long Kong, the
   United States, and Great Britain. The results provide general support
   for the model's predictions and reveal several significant
   cross-national differences.
Z8 0
TC 89
ZS 1
ZB 0
ZA 0
ZR 0
Z9 89
SN 0025-1909
UT WOS:000078474700004
ER

PT J
AU Yi, W
   Bier, VM
TI An application of copulas to accident precursor analysis
SO MANAGEMENT SCIENCE
VL 44
IS 12
BP S257
EP S270
DI 10.1287/mnsc.44.12.S257
PN 2
PD DEC 1998
PY 1998
AB Data on accident precursors can help in estimating accident frequencies,
   since they provide a rich source of information on intersystem
   dependencies. However, Bayesian analysis of accident precursors requires
   the ability to construct joint prior distributions reflecting such
   dependencies. For example, the failure probabilities of a particular
   safety system under normal and accident conditions, respectively, will
   generally not be identical (because of the effects of the accident), but
   will almost certainly be correlated (since both failure probabilities
   reflect the performance of the same components, with the same inherent
   levels of reliability). In this paper, we explore the use of copulas (a
   method of representing joint distribution functions with particular
   marginals) to construct the needed prior distributions, and then use
   these distributions in a Bayesian analysis of hypothetical precursor
   data. This demonstrates the usefulness of copulas in practice. The same
   approach can also be used in a wide variety of other contexts where
   joint distributions with particular marginals are desired.
TC 43
ZS 0
ZA 0
Z8 0
ZR 0
ZB 0
Z9 43
SN 0025-1909
UT WOS:000078474700009
ER

PT J
AU White, RE
   Pearson, JN
   Wilson, JR
TI JIT manufacturing: A survey of implementations in small and large US
   manufacturers
SO MANAGEMENT SCIENCE
VL 45
IS 1
BP 1
EP 15
DI 10.1287/mnsc.45.1.1
PD JAN 1999
PY 1999
AB Since the early 1980s, the diffusion of Just-In-Time (JIT) manufacturing
   from Japanese manufacturers to U.S. manufacturers has progressed at an
   accelerated rate. At this stage of the diffusion process, JIT
   implementations are more common and more advanced in large U.S.
   manufacturers than in small; consequently, U.S. businessmen's
   understanding of issues associated with JIT implementations in large
   manufacturers is more developed than that of small manufacturers. When
   small manufacturers represent about 96 percent of all U.S.
   manufacturers, investigation of JIT implementations in small, as well as
   large, manufacturers is warranted.
   This survey study investigates JIT implementation differences between
   small and large U.S. manufacturers. Ten management practices that
   constitute the JIT concept are used to examine implementation of JIT
   manufacturing systems. Odds ratio were constructed to determine if an
   association exists between implemented versus not implemented and
   manufacturer size for each JIT practice. Ten changes in performance
   attributed to JIT implementation are also assessed and examined in the
   study. Logistic regression models are used to examine the relationships
   between implementation status of each of the JIT practices and of each
   of the changes in performance in small and large manufacturers. The
   results of the study show that the frequencies of the 10 JIT management
   practices implemented differ between the two groups of manufacturer
   size, and an association exists between the JIT practices implemented
   and manufacturer size. Moreover, the changes in performance attributed
   to JIT implementation vary, depending on implementation status of
   specific JIT management practices and manufacturer size.
ZS 7
ZR 0
ZA 0
ZB 3
Z8 2
TC 230
Z9 239
SN 0025-1909
EI 1526-5501
UT WOS:000082215500001
ER

PT J
AU Gavirneni, S
   Kapuscinski, R
   Tayur, S
TI Value of information in capacitated supply chains
SO MANAGEMENT SCIENCE
VL 45
IS 1
BP 16
EP 24
DI 10.1287/mnsc.45.1.16
PD JAN 1999
PY 1999
AB We incorporate information flow between a supplier and a retailer in a
   two-echelon model that captures the capacitated setting of a typical
   supply chain. We consider three situations. (1) a traditional model
   where there is no information to Be supplier prior to a demand to him
   except for past data; (2) the supplier knows the (s, S) policy used by
   the retailer as well. as the end-item demand distribution; and (3) the
   supplier has full information about the state of the retailer. Order
   up-to policies continue to be optimal for models with information flow
   for the finite horizon, the infinite horizon discounted and the infinite
   horizon average cost eases. Study of these three models enables us to
   understand the relationships between capacity, inventory,and information
   at the supplier level, as well as how they are affected by the
   retailer's (S - s) values and end-item. demand distribution. We estimate
   the savings at the supplier due to information flow and study when
   information is most beneficial.
ZB 5
ZS 1
TC 502
ZR 0
Z8 44
ZA 0
Z9 546
SN 0025-1909
UT WOS:000082215500002
ER

PT J
AU Chatterjee, S
   Singh, J
TI Are tradeoffs inherent in diversification moves? A simultaneous model
   for type of diversification and mode of expansion decisions
SO MANAGEMENT SCIENCE
VL 45
IS 1
BP 25
EP 41
DI 10.1287/mnsc.45.1.25
PD JAN 1999
PY 1999
AB Drawing on the premise that the diversification decisions are driven by
   antecedent factors such as a firm's existing resources (Teece 1982) and
   industry structural conditions, this paper develops formal hypotheses
   for reciprocity between the type of diversification and mode of
   expansion decisions. We consider the specificity of antecedent resources
   that affect these two decisions and conceptually demonstrate that there
   is a contradictory tension in trying to optimize the decisions jointly
   implying that one or both diversification decisions have to be
   sub-optimized (i.e., there has to be a trade-off). We make a conceptual
   argument that this sub-optimization is likely to be in the form of
   subordination of the mode decision subject to constraints imposed by
   resources that are highly specific to the mode decision. Following
   this,we empirically investigate this contradictory tension by using a
   simultaneous equation model (SEM) on a large sample of firms between
   1981 and 1989. The results suggest that one antecedent factor-internal
   funds-act as the key mediating influence in the joint optimization and
   leads to a subordination of the mode decision in the joint optimization
   process. However, the existence of time compression economies and market
   power benefits are the exceptions to this subordination and trade off
   process.
ZB 0
ZS 2
ZR 0
TC 43
ZA 0
Z8 0
Z9 45
SN 0025-1909
UT WOS:000082215500003
ER

PT J
AU Gawande, K
   Wheeler, T
TI Measures of effectiveness for governmental organizations
SO MANAGEMENT SCIENCE
VL 45
IS 1
BP 42
EP 58
DI 10.1287/mnsc.45.1.42
PD JAN 1999
PY 1999
AB For organizations whose objective is not necessarily the maximization of
   a financial quantity, there is little written in the economics and
   management literature about methods that quantify their effectiveness.
   Potential users of such methodologies are typically governmental
   organizations and agencies to whom Congress allocates funding
   periodically, but may also include many nonprofit organizations. Such
   research is importantly needed because government is no longer making
   outlay allocations on a merely historical basis, but is using as a
   criterion how effectively an organization uses its resources in meeting
   its objectives. In this paper we analyze the Maritime Safety Program of
   the U.S. Coast: Guard (USCG), which is responsible for monitoring the
   quality of vessels that sail in U.S. waters, and present measures of
   effectiveness (MOEs) for the Program. We do this at two levels of
   activity: at an overall program level (Level I) and at a component
   activity level (Level II). Poisson models are used to construct the MOEs
   using data on maritime casualties (accidents) between 1990-1993 from the
   real-time Marine Safety Management System (MSMS) database maintained by
   the Coast Guard. A feature of the empirical methodology is the Bayesian
   imputation of missing data. The MOEs constructed here have at least four
   important uses. First, as the name suggests, they perform the function
   that financial quantities such as returns on equity or returns on sales
   perform for private-sector organizations-that is, they are indicators of
   efficiency. Second,they can be used as inputs into allocative decisions
   within the organization. For example, the Level II MOEs can be used as
   inputs into a programming problem that determines the optimal allocation
   of resources among component activities. Third, internal performance
   evaluation across USCG Programs or across Port Units (called Marine
   safety Offices) can be based on their respective Level I MOEs. Fourth,
   and possibly the most important long-run consideration, MOEs provide the
   basis for better regulation by the government. Without MOEs the nature
   of regulation is probably suboptimal. By adopting these MOEs as
   criteria, it will be easier for the government to redesign those aspects
   of its regulation of the Coast Guard which curtail incentives.
ZS 0
ZB 0
ZR 0
Z8 0
TC 12
ZA 0
Z9 12
SN 0025-1909
UT WOS:000082215500004
ER

PT J
AU Tyagi, RK
TI On the effects of downstream entry
SO MANAGEMENT SCIENCE
VL 45
IS 1
BP 59
EP 73
DI 10.1287/mnsc.45.1.59
PD JAN 1999
PY 1999
AB We study the effects of entry in a downstream market where firms (e.g.,
   Compaq and IBM; CVS and Safeway) buy an input (e.g., microprocessor,
   grocery items) from an upstream supplier (e.g., Intel, Procter & Gamble)
   and sell their output to consumers. We show demand conditions where,
   contrary to conventional wisdom, entry of a new downstream firm lowers
   the downstream-market output and increases the consumer price. Thus
   consumers may be better off with fewer sellers in such markets. We also
   show that this entry may cause the profit of each incumbent downstream
   firm to: (i) remain unchanged; (ii) decrease; or (iii) even increase.
   Also, for a class of widely used demand conditions, the supplier's
   optimal price is shown invariant to the entry/exit of its downstream
   buyer firms. We classify all possible effects of downstream entry in
   terms of fundamental market demand conditions.
ZS 1
Z8 7
ZB 0
TC 67
ZR 0
ZA 0
Z9 75
SN 0025-1909
UT WOS:000082215500005
ER

PT J
AU Wu, G
   Gonzalez, R
TI Nonlinear decision weights in choice under uncertainty
SO MANAGEMENT SCIENCE
VL 45
IS 1
BP 74
EP 85
DI 10.1287/mnsc.45.1.74
PD JAN 1999
PY 1999
AB In most real-world decisions, consequences are tied explicitly to the
   outcome of events. Previous studies of decision making under uncertainty
   have indicated that the psychological weight attached to an event,
   called a decision weight, usually differs from the probability of that
   event. We investigate two sources of nonlinearity of decision weights:
   subadditivity of probability judgments, and the overweighting of small
   probabilities and underweighting of medium and large probabilities.
   These two sources of nonlinearity are combined into a two-stage model of
   choice under uncertainty. In the first stage, events are taken into
   subjective probability judgments, and the second stage takes probability
   judgments into decision weights. We then characterize the curvature of
   the decision weights by extending a condition employed by Wu and
   Gonzalez (1996) in the domain of risk to the domain of uncertainty and
   show that the nonlinearity of decision weights can be decomposed into
   subadditivity of probability judgments and the curvature of the
   probability weighting function. Empirical tests support the proposed
   two-stage model and indicate that decision weights are concave then
   convex. More specifically, our results lend support for a new property
   of subjective probability judgments, interior additivity (subadditive at
   the boundaries, but additive away from the boundaries), and show that
   the probability weighting function is inverse S-shaped as in Wu and
   Gonzalez (1996).
RI Gonzalez, Richard/B-6449-2008; Wu, George/B-2820-2008
OI Gonzalez, Richard/0000-0001-6334-0430; 
ZR 0
Z8 7
ZA 0
ZS 0
TC 109
ZB 5
Z9 115
SN 0025-1909
UT WOS:000082215500006
ER

PT J
AU Homem-de-Mello, T
   Shapiro, A
   Spearman, ML
TI Finding optimal material release times using simulation-based
   optimization
SO MANAGEMENT SCIENCE
VL 45
IS 1
BP 86
EP 102
DI 10.1287/mnsc.45.1.86
PD JAN 1999
PY 1999
AB We present a method for setting release times for jobs with due dates in
   a stochastic production flow line for which the sequence of jobs has
   been determined. Unlike other approaches to this problem, ours considers
   a transient situation. Thus, the flow line will typically contain work
   in process (WIP), that is, jobs that have been previously released to
   the system.
   Our goal is to develop a job release schedule that not only minimizes
   tardiness but also maximizes flexibility. The philosophy can be
   characterized as one that seeks to "release as late as possible, but no
   later!"
   Our methodology is based on Monte Carlo simulation and consequent
   optimization by a method that became known as "stochastic counterpart"
   or "sample path" simulation-based optimization techniques. We use this
   method to minimize an expected value objective function that contains
   terms for tardiness and flow time "costs." We include a discussion of
   how the cost parameters of this objective function can be obtained by
   considering a "characteristic curve" for the system. We also discuss
   means for obtaining sensitivity analysis with respect to due dates and
   service times distributions parameters. We conclude with a numerical
   example.
RI Homem-de-Mello, Tito/B-7467-2009; Shapiro, Alexander/F-3195-2011; Homem-de-Mello, Tito/
OI Homem-de-Mello, Tito/0000-0002-2044-3306
ZA 0
Z8 3
TC 51
ZS 0
ZB 0
ZR 0
Z9 54
SN 0025-1909
UT WOS:000082215500007
ER

PT J
AU Halme, M
   Joro, T
   Korhonen, P
   Salo, S
   Wallenius, J
TI A value efficiency approach to incorporating preference information in
   data envelopment analysis
SO MANAGEMENT SCIENCE
VL 45
IS 1
BP 103
EP 115
DI 10.1287/mnsc.45.1.103
PD JAN 1999
PY 1999
AB We develop a procedure and the requisite theory for incorporating
   preference information in a novel way in the efficiency analysis of
   Decision Making Units. The efficiency of Decision Making Units is
   defined in the spirit of Data Envelopment Analysis (DEA), complemented
   with Decision Maker's preference information concerning the desirable
   structure of inputs and outputs. Our procedure begins by aiding the
   Decision Maker in searching for the most preferred combination of inputs
   and outputs of Decision Making Units (for short, Most Preferred
   Solution) which are efficient in DEA. Then, assuming that the Decision
   Maker's Most Preferred Solution maximizes his/her underlying (unknown)
   value function, we approximate the indifference contour of the value
   function at this point with its possible tangent hyperplanes. Value
   Efficiency scores are then calculated for each Decision Making Unit
   comparing the inefficient units to units having the same value as the
   Most Preferred Solution. The resulting Value Efficiency scores are
   optimistic approximations of the true scores. The procedure and the
   resulting efficiency scores are immediately applicable to solving
   practical problems.
TC 153
ZB 1
Z8 3
ZS 2
ZR 0
ZA 0
Z9 157
SN 0025-1909
UT WOS:000082215500008
ER

PT J
AU Olsen, TL
TI A practical scheduling method for multiclass production systems with
   setups
SO MANAGEMENT SCIENCE
VL 45
IS 1
BP 116
EP 130
DI 10.1287/mnsc.45.1.116
PD JAN 1999
PY 1999
AB Consider a multiclass production system where many job classes share a
   single server and a setup time is incurred whenever the server changes
   class. This paper presents a simple method for scheduling these systems
   that performs well, not only with respect to mean waiting time, but also
   with respect to waiting-time variance and the outer percentiles of
   waiting time. The scheduling method is dynamic and uses the ages of
   items in each queue, as well as the queue statistics, to decide which
   queue to service next.
RI Olsen, Tava/G-4460-2019
OI Olsen, Tava/0000-0002-5477-6280
TC 14
ZB 0
ZA 0
ZR 0
ZS 0
Z8 0
Z9 14
SN 0025-1909
UT WOS:000082215500009
ER

PT J
AU Jain, DC
   Muller, E
   Vilcassim, NJ
TI Pricing patterns of cellular phones and phonecalls: A segment-level
   analysis
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 131
EP 141
DI 10.1287/mnsc.45.2.131
PD FEB 1999
PY 1999
AB One expectation of the U.S. Federal Communications Commission (FCC) in
   the early stages of the cellular communications industry was that the
   presence of two licensees in each market would ensure competition, and
   thereby result in declining prices over time for both cellular phones
   (handsets) and phonecalls. However, industry observers have noted
   recently that although the price of handsets has declined over time, the
   price of the phonecalls has not. We investigate this interesting pricing
   issue by modeling the market interaction between the providers of
   cellular services and also their interaction with customers using a game
   theoretic framework.
   A critical assumption in the development of our model is that there
   exist segments of customers with different valuations, usage levels, and
   price sensitivities for cellular service. Empirically, we provide
   support for the existence of two customer segments (viz.,
   Business/Professional and Personal) from both secondary data on industry
   usage and revenue, and primary data collected from a conjoint analysis
   study of cellular service customers.
   From the latter source, we also establish that the Business/Professional
   customers are more sensitive to prices of phonecalls than the Personal
   segment. From our analytical model, we characterize the conditions under
   which penetration and skimming pricing strategies for the handsets are
   profit-maximizing from the sellers' standpoint, and derive the
   corresponding price of phonecalls. One of our main analytical results is
   that a competitive structure can result in lower prices over time for
   the handset, but higher prices for the phonecalls, depending on
   production costs of the handset. We are thus able to provide a
   theoretical explanation for the observed price patterns for the handset
   and phonecalls.
RI Vilcassim, Naufel/C-6307-2014; Muller, Eitan/A-9310-2008
OI Muller, Eitan/0000-0002-8180-7484
TC 22
Z8 0
ZR 0
ZB 0
ZS 0
ZA 0
Z9 22
SN 0025-1909
UT WOS:000082215600001
ER

PT J
AU Shane, S
   Foo, MD
TI New firm survival: Institutional explanations for new franchisor
   mortality
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 142
EP 159
DI 10.1287/mnsc.45.2.142
PD FEB 1999
PY 1999
AB Why do some new firms succeed and others fail? Economists argue that the
   new firms fail because entrepreneurs inefficiently manage production and
   organizational design (Williamson 1985). Sociologists (e.g., Granovetter
   1985) have typically viewed this explanation as undersocialized, and
   argue that institutional legitimacy must also be considered to explain
   the survival of new firms. This paper examines the survival of 1292 new
   franchisors established in the United States from 1979-1996. The results
   show that institutional legitimacy adds to economic explanations for the
   survival of new franchisors and suggests the importance of a properly
   socialized explanation.
RI Foo, Maw Der/B-3255-2009
OI Foo, Maw Der/0000-0002-4887-081X
ZS 3
ZA 0
Z8 0
TC 106
ZB 0
ZR 0
Z9 107
SN 0025-1909
EI 1526-5501
UT WOS:000082215600002
ER

PT J
AU Loch, CH
   Huberman, BA
TI A punctuated-equilibrium model of technology diffusion
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 160
EP 177
DI 10.1287/mnsc.45.2.160
PD FEB 1999
PY 1999
AB We present an evolutionary model of technology diffusion in which an old
   and a new technology are available, both of which improve their
   performance incrementally over time. Technology adopters make repeated
   choices between the established and the new technology based on their
   perceived performance, which is subject to uncertainty. Both
   technologies exhibit positive externalities, or performance benefits
   from others using the same technology.
   We find that the superior technology will not necessarily be broadly
   adopted by the population. Externalities cause two stable usage
   equilibria to exist, one with the old technology being the standard and
   the other with the new technology the standard. Punctuations, or sudden
   shifts, in these equilibria determine the patterns of technology
   diffusion. The time for an equilibrium punctuation depends on the rate
   of incremental improvement of both technologies, and on the system's
   resistance to switching between equilibria. If the new technology has a
   higher rate of incremental improvement, it is adopted faster, and
   adoption may precede performance parity if the system's resistance to
   switching is low. Adoption of the new technology may trail performance
   parity if the system's resistance to switching is high.
ZA 0
ZB 3
TC 104
ZR 0
Z8 2
ZS 1
Z9 106
SN 0025-1909
UT WOS:000082215600003
ER

PT J
AU Anupindi, R
   Bassok, Y
TI Centralization of stocks: Retailers vs. manufacturer
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 178
EP 191
DI 10.1287/mnsc.45.2.178
PD FEB 1999
PY 1999
AB A well-known result in inventory theory is that physical centralization
   of stocks in a system with multiple retailers decreases total costs and
   increases total profits for the retailers. However, does this
   centralization also benefit the manufacturer, whose goods the retailers
   stock, when customers unsatisfied at retailers due to stock-outs are
   considered lost sales? In this paper we consider a model with two
   retailers and one manufacturer We then compare two systems: one in which
   the retailers hold stocks separately and the other in which they
   cooperate to centralize stocks at a single location. We show that
   whether or not centralization of stocks by retailers increases profits
   for the manufacturer depends on the level of "market search" in the
   supply chain. Market search is measured as the fraction of customers
   who, unsatisfied at their "local" retailer due to a stock-out, search
   for the good at, the other retailer before leaving the system.
   Specifically, we show that there exists a threshold level for market
   search above which the manufacturer loses. Furthermore, for "very high"
   search levels, even the system profit (sum of manufacturer and retailer
   profits) may decrease upon centralization. We then compare the
   performance of the two systems under optimal pricing/subsidy mechanisms
   and show that often a manufacturer is better off in a decentralized
   system with high market search. We conclude with a discussion of the
   role of information systems in the decentralized systems.
ZS 0
Z8 12
TC 133
ZB 0
ZA 0
ZR 0
Z9 145
SN 0025-1909
UT WOS:000082215600004
ER

PT J
AU Whitt, W
TI Improving service by informing customers about anticipated delays
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 192
EP 207
DI 10.1287/mnsc.45.2.192
PD FEB 1999
PY 1999
AB This paper investigates the effect upon performance in a service system,
   such as a telephone call center, of giving waiting customers state
   information. Ln particular, the paper studies two M/M/s/r queueing
   models with balking and reneging. For simplicity, it is assumed that
   each customer is willing to wait a fixed time before beginning service.
   However, customers differ, so the delay tolerances for successive
   customers are random. In particular, it is assumed that the delay
   tolerance of each customer is zero with probability beta, and is
   exponentially distributed with mean alpha(-1) conditional on the delay
   tolerance being positive. Let N be the number of customers found by an
   arrival. In Model 1, no state information is provided, so that if N
   greater than or equal to s, the customer balks with probability beta; if
   the customer enters the system, he reneges after an exponentially
   distributed time with mean alpha(-1) if he has not begun service by that
   time. In Model 2, if N = s + k greater than or equal to s, then the
   customer is told the system state k and the remaining service times of
   all customers in the system, so that he balks with probability beta + (1
   + beta)(1 - q(k)), where q(k) = P(T > S-k), T is exponentially
   distributed with mean (alpha(-1), S-k is the sum of k + 1 independent
   exponential random variables each with mean (S mu)(-1), and mu(-l) is
   the mean service time. In Model 2, all reneging is replaced by balking.
   The number of customers in the system for Model 1 is shown to be larger
   than that for Model 2 in the likelihood-ratio stochastic ordering. Thus,
   customers are more Likely to be blocked in Model 1 and are more Likely
   to be served without waiting in Model 2. Algorithms are also developed
   for computing important performance measures in these, and more general,
   birth-and-death models.
RI Whitt, Ward/D-5337-2013
OI Whitt, Ward/0000-0003-4298-9964
TC 99
ZA 0
ZR 0
ZB 0
Z8 1
ZS 1
Z9 101
SN 0025-1909
EI 1526-5501
UT WOS:000082215600005
ER

PT J
AU Clemen, RT
   Reilly, T
TI Correlations and copulas for decision and risk analysis
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 208
EP 224
DI 10.1287/mnsc.45.2.208
PD FEB 1999
PY 1999
AB The construction of a probabilistic model is a key step in most decision
   and risk analyses. Typically this is done by defining a joint
   distribution in terms of marginal and conditional distributions for the
   model's random variables. We describe an alternative approach that uses
   a copula to construct joint distributions and pairwise correlations to
   incorporate dependence among the variables. The approach is designed
   specifically to permit the use of an expert's subjective judgments of
   marginal distributions and correlations. The copula that underlies the
   multivariate normal distribution provides the basis for modeling
   dependence, but arbitrary marginals are allowed. We discuss how
   correlations can be assessed using techniques that are familiar to
   decision analysts, and we report the results of an empirical study of
   the accuracy of the assessment methods. The approach is demonstrated in
   the context of a simple example, including a study of the sensitivity of
   the results to the assessed correlations.
ZR 2
ZB 11
ZA 0
TC 201
ZS 4
Z8 3
Z9 207
SN 0025-1909
EI 1526-5501
UT WOS:000082215600006
ER

PT J
AU Taylor, JW
   Bunn, DW
TI A quantile regression approach to generating prediction intervals
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 225
EP 237
DI 10.1287/mnsc.45.2.225
PD FEB 1999
PY 1999
AB Exponential smoothing methods do not involve a formal procedure for
   identifying the underlying data generating process. The issue is then
   whether prediction intervals should be estimated by a theoretical
   approach, with the assumption that the method is optimal in some sense,
   or by an empirical procedure. Ln this paper we present an alternative
   hybrid approach which applies quantile regression to the empirical fit
   errors to produce forecast error quantile models. These models are
   functions of the lead time, as suggested by the theoretical variance
   expressions. Ln addition to avoiding the optimality assumption, the
   method is nonparametric, so there is no need for the common normality
   assumption. Application of the new approach to simple, Holt's, and
   damped Holt's exponential smoothing, using simulated and real data sets,
   gave encouraging results.
RI Bunn, Derek W/P-5247-2016
ZR 0
ZS 0
ZA 0
Z8 2
ZB 1
TC 22
Z9 23
SN 0025-1909
UT WOS:000082215600007
ER

PT J
AU Myung, YS
   Kim, HJ
   Tcha, DW
TI Design of communication networks with survivability constraints
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 238
EP 252
DI 10.1287/mnsc.45.2.238
PD FEB 1999
PY 1999
AB The rapid growth of telecommunication capacity, driven in part by the
   wide-ranging deployment of fiber-optic technology has led to increasing
   concern regarding the survivability of such networks. Ln communication
   networks, survivability is usually defined as the percentage of total
   traffic surviving some network failures in the worst case. Most of the
   survivable network design models proposed to date indirectly ensure
   network survivability by invoking a connectivity constraint, which calls
   for a prespecified number of paths between every distinct pair of nodes
   in the network. In this paper, we introduce a new network design model
   which directly addresses survivability in terms of a survivability
   constraint which specifies the allowable level of lost traffic during a
   network failure under prescribed conditions. The new model enables a
   network designer to consider a richer set of alternative network
   topologies than the existing connectivity models, and encompasses the
   connectivity models as special cases. The paper presents a procedure to
   compute link survivability, develops an integer programming formulation
   of the proposed survivability model, and discusses a special case of
   practical interest and its associated heuristic procedure. The proposed
   heuristic is tested on data from real-world problems as well as randomly
   generated problems.
RI Tcha, Dong-Wan/C-1959-2011
ZR 0
Z8 0
ZS 0
ZA 0
TC 15
ZB 0
Z9 15
SN 0025-1909
UT WOS:000082215600008
ER

PT J
AU Kumar, A
   Zhao, JL
TI Dynamic routing and operational controls in Workflow Management Systems
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 253
EP 272
DI 10.1287/mnsc.45.2.253
PD FEB 1999
PY 1999
AB Businesses around the world are paying more attention to process
   management and process automation to improve organizational efficiency
   and effectiveness. Ln this paper, we describe a general framework for
   implementing dynamic routing and operational control mechanisms in
   Workflow Management Systems (WMSs). The framework consists of three
   techniques: workflow control tables, sequence constraints, and
   event-based workflow management rules. Our approach offers several
   unique features that are missing in. commercial workflow management
   systems: (1) it provides more flexibility in process modeling and
   control; (2) it permits rework on an ad hoc basis; (3) it handles
   exceptions to routing and operational controls; and (4) it exploits
   parallelism to increase system throughput and response time. Finally,the
   workflow management techniques are applied to the case of consumer loan
   management and compared with other approaches based on static routing.
RI Zhao, J. Leon/A-3921-2008
ZS 0
ZA 0
TC 51
ZB 0
ZR 0
Z8 3
Z9 54
SN 0025-1909
EI 1526-5501
UT WOS:000082215600009
ER

PT J
AU Kang, S
   Malik, K
   Thomas, LJ
TI Lotsizing and scheduling on parallel machines with sequence-dependent
   setup costs
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 273
EP 289
DI 10.1287/mnsc.45.2.273
PD FEB 1999
PY 1999
AB Industrial lotsizing and scheduling pose very difficult analytical
   problems. We propose an unconventional model that deals with
   sequence-dependent setup costs in a multiple-machine environment. The
   sequence-splitting model splits an entire schedule into subsequences,
   leading to tractable subproblems. An optimization approach based on a
   column generation/branch and bound methodology is developed and
   heuristically adapted to test problems including five real-world problem
   instances gathered from industry.
TC 48
ZB 0
ZA 0
ZR 0
Z8 0
ZS 1
Z9 49
SN 0025-1909
UT WOS:000082215600010
ER

PT J
AU Spearman, ML
   Zhang, RQ
TI Optimal lead time policies
SO MANAGEMENT SCIENCE
VL 45
IS 2
BP 290
EP 295
DI 10.1287/mnsc.45.2.290
PD FEB 1999
PY 1999
AB This paper examines two due-date setting problems first studied by Wein
   (1991). The first problem seeks to minimize the average due-date lead
   time (due-date minus arrival date) of jobs subject to a constraint on
   the fraction of tardy jobs (Problem I) while the second uses the same
   objective subject to a constraint on average job tardiness (Problem II).
   We show that under very general conditions, Problem I leads to unethical
   practice (i,e., quote lead times for which there is no hope to achieve
   when the system is highly congested) while Problem II results in
   policies that quote lead times that are monotonically increasing with
   the congestion level. Furthermore, we prove that Problem II is
   equivalent to a policy that is widely used and is easy to compute. This
   policy quotes lead times that guarantee the same serviceability level
   (the fraction of tardy jobs) to all jobs.
ZR 0
ZB 0
TC 58
Z8 3
ZS 1
ZA 0
Z9 61
SN 0025-1909
UT WOS:000082215600011
ER

PT J
AU Fisher, M
   Ramdas, K
   Ulrich, K
TI Component sharing in the management of product variety: A study of
   automotive braking systems
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 297
EP 315
DI 10.1287/mnsc.45.3.297
PD MAR 1999
PY 1999
AB Product variety in many industries has increased steadily throughout
   this century. Component sharing-using the same version of a component
   across multiple products-is increasingly viewed by companies as a way to
   offer high variety in the marketplace while retaining low variety in
   their operations. Yet, despite the popularity of component sharing in
   industry, little is known about how to design an effective
   component-sharing strategy or about the factors that influence the
   success of such a strategy. In this paper we critically examine
   component sharing using automotive front brakes as an example. We
   consider three basic questions: (1) What are the key drivers and
   trade-offs of component-sharing decisions? (2) How much variation exists
   in actual component-sharing practice? and (3) How can this variation be
   explained? To answer these questions, we develop an analytic model of
   component sharing and show through empirical testing that this model
   explains much of the variation in sharing practice for automotive
   braking systems. We find that the optimal number of brake rotors is a
   function of the range of vehicle weights, sales volume, fixed component
   design and tooling costs, variable costs, and the variation in
   production volume across the models of the product line. We conclude
   with a discussion of the general managerial implications of our
   findings.
RI ramdas, kamalini/M-9798-2014
ZB 1
TC 177
ZA 0
ZR 0
ZS 1
Z8 1
Z9 179
SN 0025-1909
UT WOS:000082215800004
ER

PT J
AU Dada, M
   White, WD
TI Evaluating financial risk in the medicare prospective payment system
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 316
EP 329
DI 10.1287/mnsc.45.3.316
PD MAR 1999
PY 1999
AB The Medicare Prospective Payment System (PPS) is analogous to an
   insurance scheme in which financial risk is mitigated through experience
   rating. In addition, risk is also mitigated through reinsurance
   provisions. Although a provider may not want this reinsurance,
   participation is mandatory. We develop a framework for evaluating
   financial risk under the PPS. We use this framework to examine optional
   reinsurance as an alternative risk mitigation mechanism. We illustrate
   an application of optional reinsurance using data for Medicare
   psychiatric inpatient services. Our analysis indicates that viable
   schemes exist for implementing optional reinsurance as a prospective
   payment option.
ZS 0
ZR 0
ZA 0
Z8 0
ZB 0
TC 7
Z9 7
SN 0025-1909
UT WOS:000082215800005
ER

PT J
AU Xu, JF
   Chiu, SY
   Glover, F
TI Optimizing a ring-based private line telecommunication network using
   Tabu Search
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 330
EP 345
DI 10.1287/mnsc.45.3.330
PD MAR 1999
PY 1999
AB One of the private line network design problems in the
   telecommunications industry is to interconnect a set of customer
   locations through a ring of end offices so as to minimize the total
   tariff cost and provide reliability. We develop a Tabu Search method for
   the problem that incorporates long term memory, probabilistic move
   selections, hierarchical move evaluation, candidate list strategies and
   an elite solution recovery strategy. Computational results for test data
   show that the Tabu Search heuristic finds optimal solutions for all test
   problems that can be solved exactly by a branch-and-cut algorithm, while
   running about three orders of magnitude faster than the exact algorithm.
   In addition, for larger size problems that cannot be solved exactly, the
   tabu search algorithm outperforms the best local search heuristic
   currently available. The performance gap favoring Tabu Search increases
   significantly for more difficult problem instances.
TC 30
ZB 0
ZR 0
Z8 0
ZA 0
ZS 0
Z9 30
SN 0025-1909
UT WOS:000082215800006
ER

PT J
AU Lariviere, MA
   Porteus, EL
TI Stalking information: Bayesian inventory management with unobserved lost
   sales
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 346
EP 363
DI 10.1287/mnsc.45.3.346
PD MAR 1999
PY 1999
AB Retailers are frequently uncertain about the underlying demand
   distribution of a new product. When taking the empirical Bayesian
   approach of Scarf (1959), they simultaneously stock the product over
   time and learn about the distribution. Assuming that unmet demand is
   lost and unobserved, this learning must be based on observing sales
   rather than demand, which differs from sales in the event of a stockout.
   Using the framework and results of Braden and Freimer (1991), the
   cumulative learning about the underlying demand distribution is captured
   by two parameters, a scale parameter that reflects the predicted size of
   the underlying market, and a shape parameter that indicates both the
   size of the market and the precision with which the underlying
   distribution is known. An important simplification result of Scarf
   (1960) and Azoury (1985), which allows the scale parameter to be removed
   from the optimization, is shown to extend to this setting. We present
   examples that reveal two interesting phenomena: (1) A retailer may hope
   that, compared to stocking out, realized demand will be strictly less
   than the stock level, even though stocking out would signal a
   stochastically larger demand distribution, and (2) it can be optimal to
   drop a product after a period of successful sales. We also present
   specific conditions under which the following results hold: (1)
   Investment in excess stocks to enhance learning will occur in every
   dynamic problem, and (2) a product is never dropped after a period of
   poor sales. The model is extended to multiple independent markets whose
   distributions depend proportionately on a single unknown parameter. We
   argue that smaller markets should be given better service as an
   effective means of acquiring information.
RI Lariviere, Martin/AAU-6757-2020; Weller, Matt J/E-8421-2010
TC 119
ZS 2
Z8 5
ZB 0
ZR 0
ZA 0
Z9 126
SN 0025-1909
UT WOS:000082215800007
ER

PT J
AU Benartzi, S
   Thaler, RH
TI Risk aversion or myopia? Choices in repeated gambles and retirement
   investments
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 364
EP 381
DI 10.1287/mnsc.45.3.364
PD MAR 1999
PY 1999
AB We study how decision makers choose when faced with multiple plays of a
   gamble or investment. When evaluating multiple plays of a simple mixed
   gamble, a chance to win x or lose y, subjects show a sensitivity to the
   amount to lose on a single trial, holding the distribution of returns
   for the portfolio constant; that is, they display "myopic loss
   aversion." Many subjects who decline multiple plays of such a gamble
   will accept it when shown the resulting distribution. This analysis is
   applied to the problem of retirement investing. We show that workers
   invest more of their retirement savings in stocks if they are shown
   long-term (rather than one-year) rates of return.
TC 182
ZR 2
ZA 0
Z8 5
ZS 1
ZB 5
Z9 188
SN 0025-1909
UT WOS:000082215800008
ER

PT J
AU Barnett, A
TI A "parallel approach" path to estimating collision risk during
   simultaneous landings
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 382
EP 394
DI 10.1287/mnsc.45.3.382
PD MAR 1999
PY 1999
AB Airport capacity could increase if, even during inclement weather,
   independent landings could occur on parallel runways only about half a
   mile apart. A key question about such operations is whether the
   collision risk they entail is acceptably low. Pursuing that issue, we
   explore a method for estimating the chance that a plane on final
   approach during instrument flight conditions will "blunder" in a way
   that could imperil nearby aircraft. We argue that the method could yield
   an attractive combination of high estimation accuracy and relatively low
   cost.
ZR 0
ZA 0
TC 1
ZS 0
Z8 0
ZB 0
Z9 1
SN 0025-1909
UT WOS:000082215800009
ER

PT J
AU Fu, MC
   Hu, JQ
TI Efficient design and sensitivity analysis of control charts using Monte
   Carlo simulation
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 395
EP 413
DI 10.1287/mnsc.45.3.395
PD MAR 1999
PY 1999
AB The design of control charts in statistical quality control addresses
   the optimal selection of the design parameters (such as the sampling
   frequency and the control Limits) and includes sensitivity analysis with
   respect to system parameters (such as the various process parameters and
   the economic costs of sampling). The advent of more complicated control
   chart schemes has necessitated the use of Monte Carlo simulation in the
   design process, especially in the evaluation of performance measures
   such as average run length. in this paper, we apply two gradient
   estimation procedures-perturbation analysis and the Likelihood
   ratio/score function method-to derive estimators that can be used in
   gradient-based optimization algorithms and in sensitivity analysis when
   Monte Carlo simulation is employed. We illustrate the techniques on a
   general control chart that includes the Shewhart chart and the
   exponentially-weighted moving average chart as special cases. Simulation
   examples comparing the estimators with each other and with "brute force"
   finite differences demonstrate the possibility of significant variance
   reduction in settings of practical interest.
RI Fu, Michael C/N-4098-2013
OI Fu, Michael C/0000-0003-2105-4932
ZS 0
Z8 2
ZB 0
ZA 0
ZR 0
TC 25
Z9 27
SN 0025-1909
UT WOS:000082215800010
ER

PT J
AU Martello, S
   Pisinger, D
   Toth, P
TI Dynamic programming and strong bounds for the 0-1 knapsack problem
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 414
EP 424
DI 10.1287/mnsc.45.3.414
PD MAR 1999
PY 1999
AB Two new algorithms recently proved to outperform all previous methods
   for the exact solution of the 0-1 Knapsack Problem. This paper presents
   a combination of such approaches, where, in addition, valid inequalities
   are generated and surrogate relaxed, and a new initial core problem is
   adopted. The algorithm. is able to solve all classical test instances,
   with up to 10,000 variables, in less than 0.2 seconds on a HP9000-735/99
   computer. The C language implementation of the algorithm is available on
   the internet.
RI Pisinger, David/P-7951-2018; Martello, Silvano/D-3117-2011
OI Pisinger, David/0000-0001-7695-9662; Martello,
   Silvano/0000-0001-6515-1406
ZS 0
ZB 2
TC 190
ZR 0
ZA 0
Z8 8
Z9 198
SN 0025-1909
UT WOS:000082215800011
ER

PT J
AU Malone, TW
   Crowston, K
   Lee, J
   Pentland, B
   Dellarocas, C
   Wyner, G
   Quimby, J
   Osborn, CS
   Bernstein, A
   Herman, G
   Klein, M
   O'Donnell, E
TI Tools for inventing organizations: Toward a handbook of organizational
   processes
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 425
EP 443
DI 10.1287/mnsc.45.3.425
PD MAR 1999
PY 1999
AB This paper describes a novel theoretical and empirical. approach to
   tasks such as business process redesign and knowledge management. The
   project involves collecting examples of how different organizations
   perform similar processes, and organizing these examples in an on-line
   "process handbook." The handbook is intended to help people: (1)
   redesign existing organizational processes, (2) invent new
   organizational processes (especially ones that take advantage of
   information technology), and (3) share ideas about organizational
   practices.
   A key element of the work is an approach to analyzing processes at
   various levels of abstraction, thus capturing both the details of
   specific processes as well as the "deep structure" of their
   similarities. This approach uses ideas from computer science about
   inheritance and from coordination theory about managing dependencies. A
   primary advantage of the approach is that it allows people to explicitly
   represent the similarities land differences) among related processes and
   to easily find or generate sensible alternatives for how a given process
   could be performed. In addition to describing this new approach, the
   work reported here demonstrates the basic technical feasibility of these
   ideas and gives one example of their use in a field study.
RI Crowston, Kevin/C-6068-2008; Wang, Charles/B-5565-2011; Dellarocas, Chrysanthos/N-3950-2018
OI Crowston, Kevin/0000-0003-1996-3600; Wang, Charles/0000-0001-9331-8437;
   Dellarocas, Chrysanthos/0000-0001-6105-0130
ZR 0
ZS 1
Z8 12
TC 277
ZB 1
ZA 0
Z9 290
SN 0025-1909
EI 1526-5501
UT WOS:000082215800012
ER

PT J
AU Boots, NK
   Tijms, H
TI A multiserver queueing system with impatient customers
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 444
EP 448
DI 10.1287/mnsc.45.3.444
PD MAR 1999
PY 1999
AB Many real-world situations involve queueing systems in which customers
   wait for service for a limited time only and leave the system if service
   has not begun within that time. This paper considers a multiserver
   queueing system with impatient customers, where the customers arrive
   according to a Poisson process and the service requirements have a
   general distribution. A simple and insightful solution is presented for
   the loss probability. The solution is exact for exponential services and
   is an excellent heuristic for general service times.
ZA 0
TC 34
ZB 1
ZR 0
Z8 0
ZS 1
Z9 34
SN 0025-1909
UT WOS:000082215800013
ER

PT J
AU Kim, H
   Park, S
TI Optimality of the symmetric workload allocation in a single-server flow
   line system
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 449
EP 451
DI 10.1287/mnsc.45.3.449
PD MAR 1999
PY 1999
AB This paper provides a proof of the symmetrical allocation property
   (SAP), conjectured in an earlier work on the workload allocation problem
   for a manufacturing: flow line system. The system consists of N
   single-Erlang servers in series having a common interstation buffer
   capacity. SAP says a symmetric workload allocation exists among the
   optimal solutions. We first show the reciprocal of the throughput is
   increasing and jointly convex, not component-wisely, in workloads. Then
   we apply the line reversibility property to obtain an alternative
   optimal allocation symmetric for any optimal workload allocation that is
   asymmetric. A sufficient condition for SAP to hold is also given, which
   relaxes the hypothesizing assumptions on the service-time distribution
   and interstation buffer capacities.
RI Park, Sungsoo/C-2007-2011
OI Park, Sungsoo/0000-0001-8226-4955
ZA 0
ZS 0
Z8 0
ZR 0
ZB 0
TC 3
Z9 3
SN 0025-1909
UT WOS:000082215800014
ER

PT J
AU Sprecher, A
   Drexl, A
TI Note: On semi-active timetabling in resource-constrained project
   scheduling
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP 452
EP 454
DI 10.1287/mnsc.45.3.452
PD MAR 1999
PY 1999
AB The purpose of this note is to demonstrate that the branch-and-bound
   algorithm presented in Demeulemeester and Herroelen (1992) does not
   reduce the enumeration to semi-active schedules.
TC 4
Z8 0
ZR 0
ZS 0
ZA 0
ZB 0
Z9 4
SN 0025-1909
UT WOS:000082215800015
ER

PT J
AU Balachandran, B
TI Editorial objectives - Accounting
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP U3
EP U3
PD MAR 1999
PY 1999
Z8 0
ZS 0
ZR 0
ZB 0
TC 0
Z9 0
SN 0025-1909
UT WOS:000082215800001
ER

PT J
AU Boyle, PP
TI Editorial objectives - Finance
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP U5
EP U5
PD MAR 1999
PY 1999
ZB 0
Z8 0
ZR 0
ZS 0
TC 0
Z9 0
SN 0025-1909
UT WOS:000082215800003
ER

PT J
AU Smith, JE
   Weber, M
TI Editorial objectives - Decision analysis
SO MANAGEMENT SCIENCE
VL 45
IS 3
BP U4
EP U4
PD MAR 1999
PY 1999
TC 0
ZS 0
ZR 0
ZB 0
Z8 0
Z9 0
SN 0025-1909
UT WOS:000082215800002
ER

PT J
AU Terwiesch, C
   Loch, CH
TI Measuring the effectiveness of overlapping development activities
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 455
EP 465
DI 10.1287/mnsc.45.4.455
PD APR 1999
PY 1999
AB Overlapping development activities is widely used to reduce project
   completion times in product development. However, research on the
   applicability of the concept in different technological environments
   remains scarce. So far, very few industry-specific studies have
   statistically confirmed an accelerating effect of overlap. In the
   present article we statistically measure the effectiveness of
   overlapping development activities in reducing project completion time.
   Building on analytical research in operations management, we argue that
   this effectiveness differs with the organization's capability to resolve
   uncertainty early in the process. Projects benefit more from overlap if
   they are able to resolve uncertainty early. This contingency view to
   overlapping development activities is tested based on data from 140
   completed development projects across several global electronics
   industries.
Z8 3
TC 126
ZB 0
ZS 1
ZA 0
ZR 0
Z9 130
SN 0025-1909
UT WOS:000082216100001
ER

PT J
AU Lieberman, MB
   Demeester, L
TI Inventory reduction and productivity growth: Linkages in the Japanese
   automotive industry
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 466
EP 485
DI 10.1287/mnsc.45.4.466
PD APR 1999
PY 1999
AB The Literature on JIT production suggests a causal Link between
   work-in-process inventory and manufacturing productivity. Such a
   connection has been described in numerous case studies but never tested
   statistically. This paper uses historical data for 52 Japanese
   automotive companies to evaluate the inventory-productivity
   relationship. We find that firms increased their productivity rank
   during periods of substantial inventory reduction. More detailed tests
   suggest that inventory reductions stimulated gains in productivity On
   average, each 10% reduction in inventory led to about a 1% gain in labor
   productivity, with a lag of about one year. Such effects were more
   immediate for Toyota affiliates, but undetectable for close suppliers of
   Nissan. These findings imply that inventory reduction served as an
   important driver of process improvement for many Japanese automotive
   companies, although some firms emphasized other methods.
RI DEMEESTER, Lieven/D-2235-2010
TC 81
ZS 2
ZB 0
ZR 0
ZA 0
Z8 0
Z9 82
SN 0025-1909
UT WOS:000082216100002
ER

PT J
AU Chintagunta, PK
TI Variety seeking, purchase timing, and the "lightning bolt" brand choice
   model
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 486
EP 498
DI 10.1287/mnsc.45.4.486
PD APR 1999
PY 1999
AB The "Lightning Bolt" (LB) model provides a comprehensive framework for
   accommodating the effects of habit persistence, unobserved
   heterogeneity, and state dependence on household brand choice behavior.
   This paper presents a discrete, dynamic brand-choice model that belongs
   to the LB class of models. We propose a method for incorporating the
   effects of variety seeking into the LB model formulation. The proposed
   formulation explicitly links brand choice and purchase timing behavior
   via the effect of state dependence. This state-dependence based linkage
   between brand choice and purchase timing comes about due to the
   attribute satiation notion associated with household variety seeking
   behavior.
   Empirical implementation of the model specification requires recognizing
   that interpurchase times, like brand choices, also depend upon marketing
   variables and household characteristics. A hazard model is specified to
   capture this relationship. Empirical results are presented using
   household-level data for two different products. Our results reveal the
   following. (1) State dependence effects decline over time. Hence,
   households' brand switching and repeat purchase probabilities vary over
   time, independent of any variation in marketing mix activities. (2)
   Accounting for the effects of marketing variables on interpurchase times
   may be important when empirically estimating the preposed model. While
   the nature of substantive implications is largely unchanged, the
   magnitudes of the different effects are nevertheless affected. (3) We
   find evidence for purchase reinforcement land its effects declining over
   time), but no evidence for attribute satiation based variety seeking
   behavior. (4) A comparison of the model's predictive ability with those
   from two extant specifications reveals that the proposed model
   outperforms rival specifications.
RI Chintagunta, Pradeep K/A-4764-2017; Chintagunta, Pradeep/
OI Chintagunta, Pradeep/0000-0003-2854-5216
ZB 0
ZA 0
TC 22
Z8 5
ZS 0
ZR 0
Z9 27
SN 0025-1909
UT WOS:000082216100003
ER

PT J
AU Vilcassim, NJ
   Kadiyali, V
   Chintagunta, PK
TI Investigating dynamic multifirm market interactions in price and
   advertising
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 499
EP 518
DI 10.1287/mnsc.45.4.499
PD APR 1999
PY 1999
AB Diagnosing the nature and magnitude of competitive interactions among
   firms is important for developing effective marketing strategies. In
   this paper, we formulate a game-theoretic model of firm interaction to
   analyze the dynamic price and advertising competition among firms in a
   given product market. Firm (or brand) level demand functions account for
   the contemporaneous and carry-over effects of these marketing
   activities, and also allow for the effects of competitor actions. Firms
   take into consideration the actions of their rivals, as well as their
   own demand and cost functions (both production and advertising) when
   determining the profit-maximizing price and advertising levels. Our
   formulation enables us to quantify not only the direction and magnitude
   of competitive reactions, but also to identify the underlying form of
   market conduct that generates the particular pattern of interaction. We
   specify and estimate a fully structural econometric model for three
   firms constituting a distinct sub-market within a personal-care product
   category. We estimate the demand and competitive interaction parameters,
   as well as the production and advertising cost functions for each firm.
   We then derive implications for competitive interactions and market
   structure. Interestingly, we find that while firms seem to compete on
   advertising, they price cooperatively, thereby enhancing their
   price-cost margins.
RI Vilcassim, Naufel/C-6307-2014; Chintagunta, Pradeep K/A-4764-2017; Chintagunta, Pradeep/
OI Chintagunta, Pradeep/0000-0003-2854-5216
ZA 0
Z8 3
TC 65
ZS 0
ZR 0
ZB 0
Z9 67
SN 0025-1909
UT WOS:000082216100004
ER

PT J
AU Jia, JM
   Dyer, JS
   Butler, JC
TI Measures of perceived risk
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 519
EP 532
DI 10.1287/mnsc.45.4.519
PD APR 1999
PY 1999
AB Based on our previous work on the standard measure of risk, this paper
   presents two classes of measures for perceived risk by decomposing a
   lottery into its mean and standard risk. One of the classes of our risk
   measures presumes that there is no risk when there is no uncertainty
   involved, and the other allows different degenerate lotteries to be
   evaluated with different values of "risk." The former has more
   prescriptive appeal in risky decision making, but the latter may have
   more descriptive power for subjective risk judgments. Our risk measures
   can also take into account the asymmetric effects of losses and gains on
   perceived risk based on an appropriate choice of the standard measure of
   risk. The perceived risk models we propose unify a large body of
   empirical evidence regarding risk judgments, and provide sufficient
   flexibility to better capture people's perceptions of risk than
   previously developed risk models, in particular, our risk measures
   provide clear ways to accommodate financial measures of risk and
   psychological measures of risk, and they can be incorporated into
   preference models in an appealing form based on mean-risk tradeoffs.
ZS 0
ZB 2
ZR 0
TC 58
ZA 0
Z8 6
Z9 64
SN 0025-1909
EI 1526-5501
UT WOS:000082216100005
ER

PT J
AU Keeney, RL
TI The value of Internet commerce to the customer
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 533
EP 542
DI 10.1287/mnsc.45.4.533
PD APR 1999
PY 1999
AB Internet commerce has the potential to offer customers a better deal
   compared to purchases by conventional methods in many situations. To
   make this potential a reality, businesses must focus on the values of
   their customers. We interviewed over one-hundred individuals about all
   the pros and cons of using Internet commerce that they experienced or
   envisioned. The results were organized into twenty-five categories of
   objectives that were influenced by Internet purchases. These categories
   were separated into means objectives and fundamental objectives used to
   describe the bottom line consequences of concern to customers. These
   results are applicable to designing an Internet commerce system for a
   business, creating and redesigning products, and increasing value to
   customers. The set of fundamental objectives also provides the
   foundation for developing a quantitative model of customer values.
RI Levy, Yair/A-4759-2009
ZB 2
ZR 0
ZA 0
Z8 6
TC 358
ZS 7
Z9 366
SN 0025-1909
UT WOS:000082216100006
ER

PT J
AU Bottcher, J
   Drexl, A
   Kolisch, R
   Salewski, F
TI Project scheduling under partially renewable resource constraints
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 543
EP 559
DI 10.1287/mnsc.45.4.543
PD APR 1999
PY 1999
AB We consider a generalization of the classical resource constrained
   project scheduling problem. We introduce so-called partially renewable
   resources by assuming for each resource a capacity on subsets of
   periods. The concept of partially renewable resources is a fundamental
   tool in order to make, e.g., timetabling and shift scheduling aspects,
   amenable to project scheduling. In addition, partially renewable
   resources serve to model complicated labor regulations. Furthermore,
   they cover traditional renewable and nonrenewable resource constraints
   as special cases.
   We consider makespan minimization as objective. For the exact solution
   of the problem we employ a basic enumeration scheme. Ln order to speed
   up convergence, we formulate bounds which take into account future
   resource consumption of partially renewable resources. Moreover, we
   generalize the serial scheduling scheme in order to get fast
   approximation methods.
   A rigorous assessment of the procedures is provided by solving ProGen
   instances generated under a full factorial test design. Besides the
   well-known problem parameters we employ additionally three parameters
   which control the generation of partially renewable resources.
RI Kolisch, Rainer/W-7505-2019
OI Kolisch, Rainer/0000-0002-8001-3009
TC 57
ZR 1
ZB 0
ZS 0
Z8 2
ZA 0
Z9 60
SN 0025-1909
UT WOS:000082216100007
ER

PT J
AU Das, TK
   Gosavi, A
   Mahadevan, S
   Marchalleck, N
TI Solving semi-Markov decision problems using average reward reinforcement
   learning
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 560
EP 574
DI 10.1287/mnsc.45.4.560
PD APR 1999
PY 1999
AB A large class of problems of sequential decision making under
   uncertainty, of which the underlying probability structure is a Markov
   process, can be modeled as stochastic dynamic programs (referred to, in
   general, as Markov decision problems or MDPs). However, the
   computational complexity of the classical MDP algorithms, such as value
   iteration and policy iteration, is prohibitive and can grow intractably
   with the size of the problem and its related data. Furthermore, these
   techniques require for each action the one step transition probability
   and reward matrices, and obtaining these is often unrealistic for large
   and complex systems. Recently, there has been much interest in a
   simulation-based stochastic approximation framework called reinforcement
   learning (RL), for computing near optimal policies for MDPs. RL has been
   successfully applied to very large problems, such as elevator
   scheduling, and dynamic channel allocation of cellular telephone
   systems. In this paper, we extend RL to a more general class of decision
   tasks that are referred to as semi-Markov decision problems (SMDPs). In
   particular, we focus on SMDPs under the average-reward criterion. We
   present a new model-free RL algorithm called SMART (Semi-Markov Average
   Reward Technique). We present a detailed study of this algorithm on a
   combinatorially large problem of determining the optimal preventive
   maintenance schedule of a production inventory system. Numerical results
   from both the theoretical model and the RL algorithm are presented and
   compared.
OI Gosavi, Abhijit/0000-0002-9703-4076
ZR 0
TC 93
ZB 2
ZA 0
Z8 12
ZS 0
Z9 104
SN 0025-1909
UT WOS:000082216100008
ER

PT J
AU Ruben, RA
   Jacobs, FR
TI Batch construction heuristics and storage assignment strategies for
   walk/ride and pick systems
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 575
EP 596
DI 10.1287/mnsc.45.4.575
PD APR 1999
PY 1999
AB The retrieval of items from storage is a chore faced by virtually every
   business concern. Walk/ride and pick systems are a popular method for
   performing this chore in many applications. When retrieval requests
   consist of multiple items, order pickers must travel to numerous storage
   locations to complete each order. When these requests are made in
   sufficient volume, a method of order retrieval known as batch picking is
   often used. Batch picking is a popular approach in the mail-order
   industry and is employed in industrial settings such as tool cribs and
   in warehouses, which service assembly line operations.
   Batch construction heuristics are developed and tested under three
   strategies for assigning storage space to individual items that have
   been suggested in the literature. Our results are derived from the
   simulation of a single hypothetical warehouse model. Specifically, we
   employ a model that is square in travel distance and assume the walk and
   pick method of order retrieval with sequential one-way travel.
   Sensitivity analysis is performed on workforce level and batch size. Our
   results indicate that the methods used for constructing batches of
   orders and for assigning storage space to individual items can
   significantly impact order retrieval efforts in warehouses of this type.
Z8 1
ZA 0
ZS 1
TC 58
ZB 1
ZR 0
Z9 59
SN 0025-1909
UT WOS:000082216100009
ER

PT J
AU Cooper, WW
   Park, KS
   Yu, G
TI IDEA and AR-IDEA: Models for dealing with imprecise data in DEA
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 597
EP 607
DI 10.1287/mnsc.45.4.597
PD APR 1999
PY 1999
AB Data Envelopment Analysis (DEA) is a nonparametric approach to
   evaluating the relative efficiency of decision making units (DMUs) that
   use multiple inputs to produce multiple outputs. An assumption
   underlying DEA is that all the data assume the form of specific
   numerical values. In some applications, however, the data may be
   imprecise. For instance, some of the data may be known only within
   specified bounds, while other data may be known only in terms of ordinal
   relations. DEA with imprecise data or, more compactly, the Imprecise
   Data Envelopment Analysis (IDEA) method developed in this paper permits
   mixtures of imprecisely- and exactly-known data, which the IDEA models
   transform into ordinary linear programming forms. This is carried even
   further in the present paper to comprehend the now extensively employed
   Assurance Region (AR) concepts in which bounds are placed on the
   variables rather than the data. We refer to this approach as AR-IDEA,
   because it replaces conditions on the variables with transformations of
   the data and thus also aligns the developments we describe in this paper
   with what are known as cone-ratio envelopments in DEA. As a result, one
   unified approach, referred to as the AR-IDEA model, is achieved which
   includes not only imprecise data capabilities but also assurance region
   and cone-ratio envelopment concepts.
ZA 1
ZB 10
ZR 0
ZS 2
Z8 24
TC 260
Z9 284
SN 0025-1909
UT WOS:000082216100010
ER

PT J
AU Grosskopf, S
   Hayes, KJ
   Taylor, LL
   Weber, WL
TI Anticipating the consequences of school reform: A new use of DEA
SO MANAGEMENT SCIENCE
VL 45
IS 4
BP 608
EP 620
DI 10.1287/mnsc.45.4.608
PD APR 1999
PY 1999
AB We use DEA-type Linear programming techniques to simulate a basic
   component of educational reform-eliminating restrictions on the
   allocation of school personnel. Our technique allows us to identify
   potential output gains (or equivalently potential cost savings) from
   reform. We can also identify which personnel groups are likely to gain
   and lose under this reform. When we apply our model to a sample of Texas
   school districts, we find evidence that the educational establishment
   has substantial economic rents to protect from school reform, and that
   the primary beneficiaries of reform are likely to be affluent school
   districts with few minority students. The technique, which relies on the
   relationship between the direct and indirect distance functions, can be
   easily generalized to measure the potential gains from removing other
   input restrictions such as union work rules, environmental regulations,
   or deed restrictions.
RI Taylor, Lori/AAH-2766-2019; GROSSKOPF, Shawnax/H-4031-2013
Z8 0
TC 55
ZB 0
ZS 0
ZA 0
ZR 0
Z9 55
SN 0025-1909
UT WOS:000082216100011
ER

PT J
AU Shepherd, DA
TI Venture capitalists' assessment of new venture survival
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 621
EP 632
DI 10.1287/mnsc.45.5.621
PD MAY 1999
PY 1999
AB This study investigates whether VCs' assessment policies of new venture
   survival are consistent with those arising from the strategy literature
   (using two established strategy perspectives). Strategy scholars suggest
   the nature of the markets, competition, and decisions made by the
   management team affect a new venture's survival chances. The findings
   demonstrate that VCs' assessment policies are predominantly consistent
   with those proposed by strategy scholars-providing insight into why VCs
   consider certain criteria in their assessment of new venture survival as
   well as why some criteria are more important in their assessment than
   others. Through this increased understanding of venture capitalists'
   decision making, entrepreneurs seeking capital may be better able to
   address their requests for funding to those criteria venture capitalists
   find most critical to the survival of a new venture. venture capitalists
   may use these findings to better understand their own decision making
   process, which, in turn, provides the opportunity to increase evaluation
   efficiency.
ZR 1
Z8 1
ZS 3
ZB 1
TC 228
ZA 0
Z9 232
SN 0025-1909
UT WOS:000082216200001
ER

PT J
AU Lee, H
   Whang, SJ
TI Decentralized multi-echelon supply chains: Incentives and information
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 633
EP 640
DI 10.1287/mnsc.45.5.633
PD MAY 1999
PY 1999
AB Consider a supply chain in which a product must pass through multiple
   sites located in series before it is finally delivered to outside
   customers. Incentive problems may arise in this system when decisions
   are delegated to corresponding site managers, each maximizing his/her
   own performance metric. From the overall system's point of view, the
   decentralized supply chain may not be as efficient as the centralized
   one. In practice, alternative performance mechanisms are often used to
   align the incentives of the different managers in a supply chain. This
   paper discusses the cost conservation incentive compatibility, and
   informational decentralizability properties of these mechanisms. Ln
   particular, for a special type of supply chain, we show that a
   performance measurement scheme involving transfer pricing, consignment,
   shortage reimbursement, and an additional backlog penalty at the last
   downstream site satisfies all these properties.
ZB 0
TC 249
ZR 0
ZA 0
ZS 2
Z8 34
Z9 285
SN 0025-1909
UT WOS:000082216200002
ER

PT J
AU Ulrich, KT
   Ellison, DJ
TI Holistic customer requirements and the design-select decision
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 641
EP 658
DI 10.1287/mnsc.45.5.641
PD MAY 1999
PY 1999
AB When confronted with the task of developing a new product, a firm
   chooses either to design new components, unique to the product
   application, or to select components from those offered in the catalogs
   of suppliers or from those already in use in its other products. We call
   this the design-select decision. The benefits of selecting an existing
   component include minimizing investment, exploiting economies of scale,
   and preserving organizational focus. On the other hand, designing
   product-specific components allows a firm to (a) maximize product
   performance with respect to holistic customer requirements-those
   requirements that arise in a complex way from most of the components of
   a product; (b) minimize the size and mass of a product; and (c) minimize
   the true variable costs of production. When these benefits exceed those
   from selecting existing components, firms will tend to design
   product-specific components. Our approach is to develop this theory by
   linking concepts from marketing, technological innovation, and
   engineering design. This theory yields four testable hypotheses. A
   cross-sectional analysis of 225 products finds substantial support for
   the theory.
Z8 2
ZS 0
TC 71
ZR 0
ZB 0
ZA 0
Z9 73
SN 0025-1909
UT WOS:000082216200003
ER

PT J
AU Jehiel, P
TI Information aggregation and communication in organizations
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 659
EP 669
DI 10.1287/mnsc.45.5.659
PD MAY 1999
PY 1999
AB Operating units must communicate their private information regarding
   decisions to be taken in organizations. This paper characterizes the
   optimal communication structures assuming that (i) a decision maker is
   fired whenever he makes a decision that proves wrong ex post relative to
   the status quo; and ii) direct communication in a group of k units may
   result in the loss of messages with a probability that solely depends on
   the group size. Several levels of partitioning with direct communication
   taking place in each group are required. It is shown that there exists a
   group size that allows communication technology to be exploited
   optimally: The optimal communication structure is such that it is
   essentially composed of groups of this size only at every level of
   partitioning.
RI Jehiel, Philippe/AAG-2354-2020
Z8 0
ZR 0
ZB 0
ZS 0
ZA 0
TC 11
Z9 11
SN 0025-1909
EI 1526-5501
UT WOS:000082216200004
ER

PT J
AU Bollen, NPB
TI Real options and product life cycles
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 670
EP 684
DI 10.1287/mnsc.45.5.670
PD MAY 1999
PY 1999
AB In this paper, I develop an option valuation framework that explicitly
   incorporates a product life cycle. I then use the framework to value the
   real option to change a project's capacity. Standard techniques for
   valuing real options typically ignore product life cycle models and
   specify instead a constant expected growth rate for demand or price. I
   show that this specification can lead to significant error in the
   valuation of capacity options. In particular, the standard technique
   tends to undervalue the option to contract capacity and overvalue the
   option to expand capacity. This result has important implications for
   capital investment decisions, especially in high-technology industries
   that feature regular introductions of newly improved products.
Z8 2
ZB 0
ZA 0
ZR 0
TC 77
ZS 0
Z9 79
SN 0025-1909
UT WOS:000082216200005
ER

PT J
AU Cachon, GP
   Lariviere, MA
TI Capacity allocation using past sales: When to turn-and-earn
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 685
EP 703
DI 10.1287/mnsc.45.5.685
PD MAY 1999
PY 1999
AB Consider a supplier selling to multiple retailers. Demand varies across
   periods, but the supplier's capacity and wholesale price are fixed. If
   demand is high, the retailers' needs exceed capacity, and the supplier
   must implement an allocation mechanism to dole out production. We
   examine how the choice of mechanism impacts retailer actions and supply
   chain performance. In particular,we analyze turn-and-earn allocation, a
   method commonly used in the automobile industry. This scheme bases
   current allocations on past sales and thus enables retailers to
   influence-their future allocations; they compete for scarce capacity
   even if they do not compete for customers.
   We show that turn-and-earn induces the retailers to increase their sales
   when demand is low and the supplier's capacity is otherwise
   underutilized. Supplier profits thus increase. The impact on the supply
   chain depends on how restrictive capacity is. With mildly tight
   capacity, the retailers' higher sales rate does not significantly lower
   their profits but does reduce the cost of idle capacity. Supply chain
   performance improves; With extremely tight capacity, the retailers'
   intense competition dissipates more profits than the supplier gains, and
   supply chain performance suffers. Consequently, turn-and-earn does not
   generally coordinate the system. It is best characterized asa means for
   the supplier to increase her profits at the expense of the retailers and
   potentially even the supply chain. Furthermore, these results hold even
   if the retailers can hold inventory in anticipation of scarce capacity.
RI Lariviere, Martin/AAU-6757-2020
ZB 1
TC 100
ZS 0
ZR 0
ZA 0
Z8 8
Z9 108
SN 0025-1909
UT WOS:000082216200006
ER

PT J
AU Ichniowski, C
   Shaw, K
TI The effects of human resource management systems on economic
   performance: An international comparison of US and Japanese plants
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 704
EP 721
DI 10.1287/mnsc.45.5.704
PD MAY 1999
PY 1999
AB This study uses personally collected data from 41 steel production lines
   to assess the effects of Japanese and U.S. human resource management
   (HRM)) practices on worker productivity. The Japanese production Lines
   employ a common system of HRM practices including: problem-solving
   teams, extensive orientation, training throughout employees'
   careers,extensive information sharing, rotation across jobs, employment
   security, and profit sharing. A majority of U.S. plants now have one or
   two features of this system of HRM practices, but only a minority have a
   comprehensive system of innovative work practices that parallels the
   full system of practices found among the Japanese manufacturers.
   We find that the Japanese lines are significantly more productive than
   the U.S. lines. However, U.S. manufacturers that have adopted a full
   system of innovative HRM practices patterned after the Japanese system
   achieve levels of productivity and quality equal to the performance of
   the Japanese manufacturers. This study's evidence helps reconcile
   conflicting views about the effectiveness of adopting Japanese-style
   worker involvement schemes in the United States. United States
   manufacturers that have adopted a definition of employee participation
   that extends only to problem-solving teams or information sharing do not
   see large improvements in productivity. However, U.S. manufacturers that
   adopt a broader definition of participation that mimics the full
   Japanese HRM system see substantial performance gains.
Z8 3
ZR 0
ZA 0
ZB 3
ZS 2
TC 203
Z9 208
SN 0025-1909
UT WOS:000082216200007
ER

PT J
AU Campbell, GM
TI Cross-utilization of workers whose capabilities differ
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 722
EP 732
DI 10.1287/mnsc.45.5.722
PD MAY 1999
PY 1999
AB This paper develops a model for allocating cross-trained workers at the
   beginning of a shift multidepartment service environment. It assumes
   departments are trying to maximize objective functions that are concave
   with respect to the number of workers assigned. Worker capabilities are
   described by parameters that range from zero to one, with fractional
   values representing workers who are less than fully qualified. The
   nonlinear programming model presented is a variant of the generalized
   assignment: problem. The model is used in a series of experiments to
   investigate the value of cross-utilization as a function of factors such
   as demand variability and levels of cross-training. Results show that
   the benefits of cross-utilization can be substantial, and in many cases
   a small degree of cross-training can capture most of the benefits.
   Beyond a certain amount additional cross-training adds little additional
   value, and the preferred amount depends heavily on the level of demand
   variability.
TC 95
ZA 0
ZB 0
Z8 3
ZS 0
ZR 0
Z9 98
SN 0025-1909
UT WOS:000082216200008
ER

PT J
AU van der Laan, E
   Salomon, M
   Dekker, R
   Van Wassenhove, L
TI Inventory control in hybrid systems with remanufacturing
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 733
EP 747
DI 10.1287/mnsc.45.5.733
PD MAY 1999
PY 1999
AB This paper is on production planning and inventory control in systems
   where manufacturing and remanufacturing operations occur simultaneously.
   Typical for these hybrid systems is, that both the output of the
   manufacturing process and the output of the remanufacturing process can
   be used to fulfill customer demands. Here, we consider a relatively
   simple hybrid system, related to a single component durable product. For
   this system, we present a methodology to analyse a PUSH control strategy
   tin which all returned products are remanufactured as early as possible)
   and a PULL control strategy tin which all returned products are
   remanufactured as late as is convenient). The main contributions of this
   paper are (i) to compare traditional systems without remanufacturing to
   PUSH and to PULL controlled systems with remanufacturing, and (ii) to
   derive managerial insights into the inventory related effects of
   remanufacturing.
RI Dekker, Rommert/E-7620-2012
OI Dekker, Rommert/0000-0003-3823-1990
ZB 5
Z8 0
ZA 0
ZR 0
TC 209
ZS 0
Z9 209
SN 0025-1909
UT WOS:000082216200009
ER

PT J
AU Alrefaei, MH
   Andradottir, S
TI A simulated annealing algorithm with constant temperature for discrete
   stochastic optimization
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 748
EP 764
DI 10.1287/mnsc.45.5.748
PD MAY 1999
PY 1999
AB We present a modification of the simulated annealing algorithm designed
   for solving discrete stochastic optimization problems. Like the original
   simulated annealing algorithm, our method has the hill climbing feature,
   so it can find global optimal solutions to discrete stochastic
   optimization problems with many local solutions. However, our method
   differs from the original simulated annealing algorithm in that it uses
   a constant (rather than decreasing) temperature. We consider two
   approaches for estimating the optimal solution. The first approach uses
   the number of visits the algorithm makes to the different: states
   (divided by a normalizer) to estimate the optimal solution. The second
   approach uses the state that has the best average estimated objective
   function value as estimate of the optimal solution. We show that both
   variants of our method are guaranteed to converge almost surely to the
   set of global optimal solutions, and discuss how our work applies in the
   discrete deterministic optimization setting. We also show how both
   variants can be applied for solving discrete optimization problems when
   the objective function values are estimated using either transient or
   steady-state simulation. Finally, we include some encouraging numerical
   results documenting the behavior of the two variants of our algorithm
   when applied for solving two versions of a particular discrete
   stochastic optimization problem, and compare their performance with that
   of other variants of the simulated annealing algorithm designed for
   solving discrete stochastic optimization problems.
RI Alrefaei, Mahmoud/N-5131-2016
OI Alrefaei, Mahmoud/0000-0002-2291-9670
ZR 0
ZB 1
ZA 0
ZS 0
TC 120
Z8 2
Z9 121
SN 0025-1909
UT WOS:000082216200010
ER

PT J
AU Kapuscinski, R
   Tayur, S
TI Variance vs. standard deviation: Variability reduction through
   operations reversal
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 765
EP 767
DI 10.1287/mnsc.45.5.765
PD MAY 1999
PY 1999
AB We show that if the analysis of the model of Lee and Tang used standard
   deviation rather than variance, some nonintuitive predictions of their
   analysis would be eliminated.
ZB 0
ZA 0
ZR 0
ZS 0
Z8 2
TC 11
Z9 13
SN 0025-1909
UT WOS:000082216200011
ER

PT J
AU Webster, S
TI Remarks on: "Some extensions of the discrete lotsizing and scheduling
   problem"
SO MANAGEMENT SCIENCE
VL 45
IS 5
BP 768
EP 769
DI 10.1287/mnsc.45.5.768
PD MAY 1999
PY 1999
ZS 0
ZB 0
TC 2
ZR 0
Z8 0
Z9 2
SN 0025-1909
UT WOS:000082216200012
ER

PT J
AU Fisher, ML
   Ittner, CD
TI The impact of product variety on automobile assembly operations:
   Empirical evidence and simulation analysis
SO MANAGEMENT SCIENCE
VL 45
IS 6
BP 771
EP 786
DI 10.1287/mnsc.45.6.771
PD JUN 1999
PY 1999
AB This study examines the impact of product variety on automobile assembly
   plant performance using data from GM's Wilmington, Delaware plant,
   together with simulation analyses of a more general auto assembly line.
   We extend prior product variety studies by providing evidence on the
   magnitude of variety-related production losses, the mechanisms through
   which variety impacts performance, and the effects of option bundling
   and labor staffing policies on the costs of product variety. The
   empirical analyses indicate that greater day-to-day variability in
   option content (but not mean option content per car) has a significant
   adverse impact on total labor hours per car produced, overhead hours per
   car produced, assembly line downtime, minor repair and major rework, and
   inventory levels, but does not have a significant short-run impact on
   total direct labor hours. However, workstations with higher variability
   in option content have greater slack direct labor resources to buffer
   against process time variation, introducing an additional cost of
   product variety. The simulation results support these findings in that
   once each;workstation is optimally buffered against process time
   variation, product variety has an insignificant impact on direct
   assembly labor. The simulations also show that bundling options can
   reduce the amount of buffer capacity required, and that random variation
   is more pernicious to productivity than product variety, supporting the
   efforts of some auto makers to aggressively attack the causes of random
   variation.
ZB 1
ZR 0
TC 199
ZS 3
Z8 2
ZA 0
Z9 202
SN 0025-1909
UT WOS:000082216300001
ER

PT J
AU Maxwell, K
   Van Wassenhove, L
   Dutta, S
TI Performance evaluation of general and company specific models in
   software development effort estimation
SO MANAGEMENT SCIENCE
VL 45
IS 6
BP 787
EP 803
DI 10.1287/mnsc.45.6.787
PD JUN 1999
PY 1999
AB In this paper we present the results of our effort estimation analysis
   of a European Space Agency database consisting of 108 software
   development projects. We develop and evaluate simple empirical effort
   estimation models that include only those productivity factors found to
   be significant for these projects and determine if models based on a
   multicompany database can be successfully used to make effort
   estimations within a specific company. This was accomplished by
   developing company specific effort estimation models based on the
   significant productivity factors of a particular company and by
   comparing the results with those from general ESA models on a holdout
   sample of the company. To our knowledge, no other published research has
   yet developed and analysed software development effort estimation models
   in this way. Effort predictions made on a holdout sample of the
   individual company's projects using general models were less accurate
   than the company specific model. However, it is likely that in the
   absence of enough resources and data for a company to develop its own
   model, the application of general models may be more accurate than the
   use of guessing and intuition.
RI dutta, soumitra/C-1625-2010
ZA 0
Z8 3
ZS 0
ZR 0
ZB 0
TC 35
Z9 38
SN 0025-1909
UT WOS:000082216300002
ER

PT J
AU Zwick, R
   Chen, XP
TI What price fairness? A bargaining study
SO MANAGEMENT SCIENCE
VL 45
IS 6
BP 804
EP 823
DI 10.1287/mnsc.45.6.804
PD JUN 1999
PY 1999
AB Our study concerns bargaining behavior in situations where one party is
   in a stronger position than the other. We investigate both the tradeoff
   the favored party makes between pursuing his strategic advantage and
   giving weight to other players' concern for fairness, and the tradeoff
   the disadvantaged player makes between pursuing a fair outcome from a
   disadvantaged position and the cost of that pursuit, in particular, we
   hypothesize that the degree to which strategically strong players
   attempt to exploit their strategic advantage depends on their potential
   costs for doing so. Similarly, the degree to which weak players persist
   in seeking "fairness" is also a function of how much it (potentially)
   costs them to do so.
   Students negotiated in pairs over the division of $HK50 using a finite
   horizon, fixed-cost (per rejection) alternating offer rule. Each pair
   consisted of a high-cost and a low-cost bargainer. In accordance with
   the hypothesis, the willingness of the high-cost bargainers to demand
   fairness and to persist in their demands was a function of how much it
   cost them to do so, and the degree to which the low-cost bargainers
   attempted to exploit their strategic advantage depended on their own
   cost of rejection. We conclude that "fairness" has a price such that the
   higher its price, the lower the "demand" for it. This suggests that
   demands for fairness are subject to cost-benefit evaluation, are in this
   sense deliberate, and are well thought out.
Z8 1
ZR 1
ZA 0
ZS 0
TC 25
ZB 2
Z9 27
SN 0025-1909
EI 1526-5501
UT WOS:000082216300003
ER

PT J
AU Boyer, KK
TI Evolutionary patterns of flexible automation and performance: A
   longitudinal study
SO MANAGEMENT SCIENCE
VL 45
IS 6
BP 824
EP 842
DI 10.1287/mnsc.45.6.824
PD JUN 1999
PY 1999
AB This study presents a longitudinal analysis of patterns of investment in
   advanced manufacturing technologies (AMT) and financial performance.
   Investments in AMT from 112 manufacturing plants in the metal-working
   industries are examined. Data were collected via a mail survey
   administered to 202 plants in 1994, and readministered to 112 of the
   same plants in 1996. This study seeks to fill a void in the area of
   technology management, which is comprised primarily of cross-sectional
   studies that do not address the dynamic nature of investments in
   technology. Four major conclusions are drawn from the data. First,
   several individual technologies have higher investments in 1996 than in
   1994. In particular, electronic mail has the largest increase in
   investment, a finding that suggests that manufacturing firms are finding
   ways to take advantage of the exploding potential of electronic
   communication. Our second conclusion is that plants invest in technology
   in an incremental fashion over time rather than using an all-or-nothing
   approach. Plants with low investments follow one of three technology
   strategies as their investments in AMTs evolve: (1) continued low
   investment, (2) investment primarily in design-based technologies, or
   (3) equalized investment in design, manufacturing, and administrative
   AMTs. Third, analysis of the degree of manufacturing involvement in
   developing business strategy indicates that plants that have a more
   proactive role for manufacturing invest greater resources in AMTs.
   Finally, while AMT investment was not positively associated with
   performance in a cross-sectional analysis, longitudinal analysis of data
   collected two years later does reveal a relationship. In short, the
   analysis supports the proposition that there is a lag between initial
   investment and resulting performance improvements.
RI Boyer, Kenneth K/E-9025-2010; Boyer, Kenneth K./
OI Boyer, Kenneth K./0000-0001-8186-7893
ZA 0
TC 65
ZB 0
ZS 0
Z8 0
ZR 0
Z9 65
SN 0025-1909
UT WOS:000082216300004
ER

PT J
AU Cachon, GP
TI Managing supply chain demand variability with scheduled ordering
   policies
SO MANAGEMENT SCIENCE
VL 45
IS 6
BP 843
EP 856
DI 10.1287/mnsc.45.6.843
PD JUN 1999
PY 1999
AB This paper studies supply chain demand variability in a model with one
   supplier and N retailers that face stochastic demand. Retailers
   implement scheduled ordering policies: Orders occur at fixed intervals
   and are equal to some multiple of a fixed batch size. A method is
   presented that exactly evaluates costs. Previous research demonstrates
   that the supplier's demand variance declines as the retailers' order
   intervals are balanced, i.e., the same number of retailers order each
   period. This research shows that the supplier's demand variance will
   (generally) decline as the retailers' order interval is lengthened or as
   their batch size is increased. Lower supplier demand variance can
   certainly lead to lower inventory at the supplier. This paper finds that
   reducing supplier demand variance with scheduled ordering policies can
   also lower total supply chain costs.
ZB 0
ZS 1
ZR 0
Z8 9
TC 120
ZA 0
Z9 129
SN 0025-1909
EI 1526-5501
UT WOS:000082216300005
ER

PT J
AU Masuda, Y
   Whang, S
TI Dynamic pricing for network service: Equilibrium and stability
SO MANAGEMENT SCIENCE
VL 45
IS 6
BP 857
EP 869
DI 10.1287/mnsc.45.6.857
PD JUN 1999
PY 1999
AB Consider a data communication network owned and operated by a single
   organization. The network has an infinite number of small users and is
   managed by a system manager (SM) whose objective is to maximize the net
   value of the system as a whole. The objective of this paper is to study
   pricing mechanisms that induce the optimal arrival rates when the SM has
   no full knowledge of the demand in advance. We investigate the system
   behavior under three alternative dynamic pricing rules and users'
   expectations models, and characterize the equilibrium and its stability
   conditions.
RI Masuda, Yasushi/A-7426-2008
OI Masuda, Yasushi/0000-0001-7557-7478
ZS 0
Z8 1
ZA 0
ZR 0
ZB 0
TC 47
Z9 48
SN 0025-1909
UT WOS:000082216300006
ER

PT J
AU Whitt, W
TI Predicting queueing delays
SO MANAGEMENT SCIENCE
VL 45
IS 6
BP 870
EP 888
DI 10.1287/mnsc.45.6.870
PD JUN 1999
PY 1999
AB This paper investigates the possibility of predicting each customer's
   waiting time in queue before starting service in a multiserver service
   system with the first-come first-served service discipline, such as a
   telephone call center. A predicted waiting-time distribution or an
   appropriate summary statistic such as the mean or the 90th percentile
   may be communicated to the customer upon arrival and possibly thereafter
   in order to improve customer satisfaction. The predicted waiting-time
   distribution may also be used by the service provider to better manage
   the service system, e.g., to help decide when to add additional service
   agents. The possibility of making reliable predictions is enhanced by
   exploiting information about system state, including the number of
   customers in the system ahead of the current customer. Additional
   information beyond the number of customers in the system may be obtained
   by classifying customers and the service agents to which they are
   assigned. For nonexponential service times, the elapsed service times of
   customers in service can often be used to advantage to compute
   conditional-remaining-service-time distributions. Approximations are
   proposed to convert the distributions of remaining service times into
   the distribution of the desired customer waiting time. The analysis
   reveals the advantage from exploiting additional information.
RI Whitt, Ward/D-5337-2013
OI Whitt, Ward/0000-0003-4298-9964
ZR 0
TC 37
ZS 0
Z8 2
ZB 0
ZA 0
Z9 39
SN 0025-1909
EI 1526-5501
UT WOS:000082216300007
ER

PT J
AU Bollapragada, R
   Rao, U
TI Single-stage resource allocation and economic lot scheduling on
   multiple, nonidentical production lines
SO MANAGEMENT SCIENCE
VL 45
IS 6
BP 889
EP 904
DI 10.1287/mnsc.45.6.889
PD JUN 1999
PY 1999
AB This paper focuses on simultaneous resource allocation, lot-sizing, and
   scheduling in a multimachine, deterministic ELSP environment. We
   consider the problem of apportioning item production to distinct
   manufacturing lines with different costs and capabilities (production
   rates). The objective is to minimize the long-run average production,
   setup, inventory, and shortage penalty costs (due to lost sales).
   Restricting attention to rotation schedules, we develop a concave
   minimization model of the problem, generate heuristic solutions and a
   lower bound on the cost of any feasible solution. Computational
   experiments indicate that our heuristic solution is within a few percent
   of the lower bound. We also investigate sensitivity of costs to model
   parameters,and illustrate how our model may be used to determine target
   values for equipment utilization.
ZB 0
ZS 0
ZR 0
ZA 0
Z8 0
TC 17
Z9 17
SN 0025-1909
UT WOS:000082216300008
ER

PT J
AU Almeida, P
   Kogut, B
TI Localization of knowledge and the mobility of engineers in regional
   networks
SO MANAGEMENT SCIENCE
VL 45
IS 7
BP 905
EP 917
DI 10.1287/mnsc.45.7.905
PD JUL 1999
PY 1999
AB Knowledge, once generated, spills only imperfectly among firms and
   nations. We posit that since institutions and labor networks vary by
   region, there regional variations in the localization of spillovers. We
   investigate the relationship between the mobility of major patent
   holders and the localization of technological knowledge through the
   analysis of patent citations of important semiconductor innovations. We
   find that knowledge localization is specific to only certain regions
   (particularly Silicon Valley) and that the degree of localization varies
   across regions. By analyzing data on the interfirm mobility of patent
   holders, we empirically show that the interfirm mobility of engineers
   influences the local transfer of knowledge. The flow of knowledge is
   embedded in regional labor networks.
RI McBee, David J/F-3968-2012
ZS 7
ZA 0
ZR 1
TC 1242
Z8 24
ZB 15
Z9 1273
SN 0025-1909
UT WOS:000082216400001
ER

PT J
AU King, A
TI Retrieving and transferring embodied data: Implications for the
   management of interdependence within organizations
SO MANAGEMENT SCIENCE
VL 45
IS 7
BP 918
EP 935
DI 10.1287/mnsc.45.7.918
PD JUL 1999
PY 1999
AB This research helps to link theories of sticky information with
   organizational design and governance. It suggests that information
   embodied in process material can allow downstream tasks to uncover
   information about upstream tasks. It shows that downstream operators can
   use this information to negotiate interdependence problems with upstream
   operators. Data presented in this article begin to uncover when such
   information retrieval and exchange occurs, and how managers can
   encourage it. Finally, the article discusses implications for theories
   of operational design and governance.
RI King, Andrew A/E-1684-2011
OI King, Andrew A/0000-0002-3447-5376
ZR 0
ZS 0
ZB 2
ZA 0
Z8 0
TC 36
Z9 36
SN 0025-1909
UT WOS:000082216400002
ER

PT J
AU Cachon, GP
   Zipkin, PH
TI Competitive and cooperative inventory policies in a two-stage supply
   chain
SO MANAGEMENT SCIENCE
VL 45
IS 7
BP 936
EP 953
DI 10.1287/mnsc.45.7.936
PD JUL 1999
PY 1999
AB We investigate a two-stage serial supply chain with stationary
   stochastic demand and fixed transportation times. Inventory holding
   costs are charged at each stage, and each stage may incur a consumer
   backorder penalty cost, e.g. the upper stage (the supplier) may dislike
   backorders at the lower stage (the retailer). We consider two games. In
   both, the stages independently choose base stock policies to minimize
   their costs. The games differ in how the firms track their inventory
   levels (in one, the firms are committed to tracking echelon inventory;
   in the other they track local inventory). We compare the policies chosen
   under this competitive regime to those selected to minimize total supply
   chain costs, i.e., the optimal solution. We show that the games (nearly
   always) have a unique Nash equilibrium, and it differs from the optimal
   solution. Hence, competition reduces efficiency. Furthermore, the two
   games' equilibria are different, so the tracking method influences
   strategic behavior. We show that the system optimal solution can be
   achieved as a Nash equilibrium using simple linear transfer payments.
   The value of cooperation is context specific: In some settings
   competition increases total cost by only a fraction of a percent,
   whereas in other settings the cost increase is enormous. We also discuss
   Stackelberg equilibria.
TC 292
ZA 0
ZR 1
ZB 2
Z8 34
ZS 1
Z9 327
SN 0025-1909
UT WOS:000082216400003
ER

PT J
AU Van Mieghem, JA
TI Coordinating investment, production, and subcontracting
SO MANAGEMENT SCIENCE
VL 45
IS 7
BP 954
EP 971
DI 10.1287/mnsc.45.7.954
PD JUL 1999
PY 1999
AB We value the option of subcontracting to improve financial performance
   and system coordination by analyzing a competitive stochastic investment
   game with recourse. The manufacturer and subcontractor decide separately
   on their capacity investment levels. Then demand uncertainty is resolved
   and both parties have the option to subcontract when deciding on their
   production and sales. We analyze and present outsourcing conditions for
   three contract types: (1) price-only contracts where an ex-ante transfer
   price is set for each unit supplied by the subcontractor; (2) incomplete
   contracts, where both parties negotiate over the subcontracting
   transfer; and (3) state-dependent price-only and incomplete contracts
   for which we show an equivalence result.
   While subcontracting with these three contract types can coordinate
   production decisions in the supply system, only state-dependent
   contracts can eliminate all decentralization costs and coordinate
   capacity investment decisions. The minimally sufficient price-only
   contract that coordinates our supply chain specifies transfer prices for
   a small number (6 in our model) of contingent scenarios. Our
   game-theoretic model allows the analysis of the role of transfer prices
   and of the bargaining power of buyer and supplier. We find that
   sometimes firms may be better off leaving some contract parameters
   unspecified ex-ante and agreeing to negotiate ex-post. Also, a
   price-focused strategy for managing subcontractors can backfire because
   a lower transfer price may decrease the manufacturer's profit. Finally,
   as with financial options, the option value of subcontracting increases
   as markets are more volatile or more negatively correlated.
ZS 1
ZR 0
Z8 1
TC 189
ZB 0
ZA 0
Z9 190
SN 0025-1909
UT WOS:000082216400004
ER

PT J
AU Doyle, JR
TI Elicitation and context effects in judgments: Fixed sum versus fixed
   scale frames
SO MANAGEMENT SCIENCE
VL 45
IS 7
BP 972
EP 979
DI 10.1287/mnsc.45.7.972
PD JUL 1999
PY 1999
AB Two apparently similar methods for making numerical judgments about a
   set of objects (point allocation and direct rating) have been shown to
   yield different profiles of values (here, numerical judgments) attached
   to Ranks. Direct rating typically leads to a nearly linear relationship
   of Value with Rank. When using point allocation, people tend to produce
   a half U-shape of Value with Rank, evidenced by a positive quadratic
   term in Rank, which is not present for direct rating. We argue that
   point allocation imposes a fixed-sum frame on the judgment task.
   Furthermore, certain problems, such as allocating a budget, are
   intrinsically framed as fixed-sum. These problems also lead to quadratic
   curvature of numerical judgment with Rank. We discuss the implications
   of these effects, both in formal and informal contexts.
ZA 0
Z8 0
ZS 0
ZB 1
ZR 0
TC 3
Z9 3
SN 0025-1909
UT WOS:000082216400005
ER

PT J
AU Federgruen, A
   Katalan, Z
TI The impact of adding a make-to-order item to a make-to-stock production
   system
SO MANAGEMENT SCIENCE
VL 45
IS 7
BP 980
EP 994
DI 10.1287/mnsc.45.7.980
PD JUL 1999
PY 1999
AB Stochastic Economic Lot Scheduling Problems (ELSPs) involve settings
   where several items need to be produced in a common facility with
   limited capacity, under significant uncertainty regarding demands, unit
   production times, setup times, or combinations thereof. We consider
   systems where some products are made-to-stock while another product line
   is made-to-order. We present a rich and effective class of strategies
   for which a variety of cost and performance measures can be evaluated
   and optimized efficiently by analytical methods. These include inventory
   level and waiting-time distributions, as well as average setup, holding,
   and backlogging costs. We also characterize how strategy choices are
   affected by the system parameters. The availability of efficient
   analytical evaluation and optimization methods permits us to address the
   impact of product line diversification or standardization on the
   performance of the manufacturing system, in particular the logistical
   implications of adding low-volume specialized models to a given
   make-to-stock product line.
Z8 0
ZA 0
ZR 0
ZS 1
ZB 0
TC 57
Z9 58
SN 0025-1909
EI 1526-5501
UT WOS:000082216400006
ER

PT J
AU Bielza, C
   Muller, P
   Insua, DR
TI Decision analysis by augmented probability simulation
SO MANAGEMENT SCIENCE
VL 45
IS 7
BP 995
EP 1007
DI 10.1287/mnsc.45.7.995
PD JUL 1999
PY 1999
AB We provide a generic Monte Carlo method to find the alternative of
   maximum expected utility in a decision analysis. We define an artificial
   distribution on the product space of alternatives and states, and show
   that the optimal alternative is the mode of the implied marginal
   distribution on the alternatives. After drawing a sample from the
   artificial distribution, we may use exploratory data analysis tools to
   approximately identify the optimal alternative. We illustrate our method
   for some important types of influence diagrams.
RI Bielza, Concha/F-9277-2013
OI Bielza, Concha/0000-0001-7109-2668
TC 38
ZB 2
ZA 0
Z8 0
ZS 0
ZR 0
Z9 38
SN 0025-1909
UT WOS:000082216400007
ER

PT J
AU Bharadwaj, AS
   Bharadwaj, SG
   Konsynski, BR
TI Information technology effects on firm performance as measured by
   Tobin's q
SO MANAGEMENT SCIENCE
VL 45
IS 7
BP 1008
EP 1024
DI 10.1287/mnsc.45.7.1008
PD JUL 1999
PY 1999
AB Despite increasing anecdotal evidence that information technology (IT)
   assets contribute to firm performance and future growth potential of
   firms, the empirical results relating IT investments to firm performance
   measures have been equivocal. However, the bulk of the studies have
   relied exclusively on accounting-based measures of firm performance,
   which largely tend to ignore IT's contribution to performance dimensions
   such as strategic flexibility and intangible value. Ln this paper, we
   use Tobin's q, a financial market-based measure of firm performance and
   examine the association between IT investments and firm q values, after
   controlling for a variety of industry factors and firm-specific
   variables. The results based on data from 1988-1993 indicate that, in
   all of the five years, the inclusion of the IT expenditure variable in
   the model increased the variance explained in q significantly. The
   results also showed that, for all five years, IT investments had a
   significantly positive association with Tobin's q value. Our results are
   consistent with the notion that IT contributes to a firm's future
   performance potential, which a forward-looking measure such as the q is
   better able to capture.
RI huangg, wen/H-1191-2011
ZR 0
ZA 1
TC 489
ZB 1
Z8 9
ZS 5
Z9 503
SN 0025-1909
UT WOS:000082216400008
ER

PT J
AU Marsden, JR
   Tung, YA
TI The use of information system technology to develop tests on insider
   trading and asymmetric information
SO MANAGEMENT SCIENCE
VL 45
IS 8
BP 1025
EP 1040
DI 10.1287/mnsc.45.8.1025
PD AUG 1999
PY 1999
AB Issues related to insider trading remain popular research topics.
   Empirical studies using historical data are Limited by two key factors:
   1) the inability to identify exactly who possesses inside information,
   and 2) the inability to identify the accuracy of information possessed.
   Advances in information system. technology enable us to overcome these
   problems in the laboratory. Using this technology, we create a research
   shell to conduct experiments where we can identify the exact type and
   quality of information accessible by each trader. Our system includes
   the capability to monitor individual activities in accessing inside
   information. The system can automatically impose a monetary penalty if
   random monitoring identifies a trader accessing inside information. Our
   experiments involve traders who receive access to inside information
   without initial knowledge of the quality of that information. The
   results indicate that traders were able to outperform the market if
   penalties for being caught accessing such information were not included.
   Once penalties were included, however, no significant performance
   differences were observed. Finally, in a second set of experiments
   involving a simplified market with infrequent electronic monitoring and
   low penalty amounts, inside information seemed to be rapidly and
   effectively disseminated to traders possessing no inside information.
ZS 2
Z8 0
ZB 0
TC 10
ZA 0
ZR 0
Z9 12
SN 0025-1909
UT WOS:000082479400001
ER

PT J
AU Krishna, A
   Zhang, ZJ
TI Short- or long-duration coupons: The effect of the expiration date on
   the profitability of coupon promotions
SO MANAGEMENT SCIENCE
VL 45
IS 8
BP 1041
EP 1056
DI 10.1287/mnsc.45.8.1041
PD AUG 1999
PY 1999
AB United States firms collectively spend over $6.5 billion annually on
   coupon promotions and are becoming increasingly concerned with their
   profitability. FSI (free-standing-insert) data show that coupon duration
   varies across brands. In this paper, we show how coupon duration can
   affect coupon profitability. We also provide answers for some empirical
   observations on coupon duration. We explain, for example, why (i) coupon
   duration will vary across firms, such that large market share firms will
   give short-duration coupons and small market share firms will give
   long-duration coupons; (ii) longer coupon duration for one brand will
   increase redemption for coupons of that brand and of a competing brand;
   (iii) coupon duration will affect coupon profitability.
ZB 1
ZA 0
ZR 0
TC 41
ZS 0
Z8 1
Z9 42
SN 0025-1909
UT WOS:000082479400002
ER

PT J
AU Fischer, GW
   Carmon, Z
   Ariely, D
   Zauberman, G
TI Goal-based construction of preferences: Task goals and the prominence
   effect
SO MANAGEMENT SCIENCE
VL 45
IS 8
BP 1057
EP 1075
DI 10.1287/mnsc.45.8.1057
PD AUG 1999
PY 1999
AB Preferences inferred from choice are more likely to favor the
   alternative that is superior with respect to the prominent (most
   important or salient) attribute than are preferences inferred from
   matching (direct tradeoff) judgments. This prominence effect violates
   standard models of rational choice and complicates the task of measuring
   preferences. In this article, we propose a new task-goal hypothesis
   regarding the prominence effect: The prominent attribute receives more
   weight in tasks whose goal is to differentiate among options than in
   tasks whose goal is to equate options. We use this hypothesis to
   generalize the prominence effect beyond choice and matching to several
   additional tasks, including the choice-based matching and difference
   comparison methods that are widely employed in decision analysis. The
   results of three studies provide strong support for the task-goat
   account of the prominence effect and cast doubt on competing
   explanations. We discuss the implications of these findings for
   descriptive decision theory and for preference measurement in decision
   analysis, public policy, and marketing.
RI Carmon, Ziv/A-6161-2009
TC 100
ZB 9
ZS 0
ZR 0
ZA 0
Z8 1
Z9 101
SN 0025-1909
UT WOS:000082479400003
ER

PT J
AU Chen, FG
TI Decentralized supply chains subject to information delays
SO MANAGEMENT SCIENCE
VL 45
IS 8
BP 1076
EP 1090
DI 10.1287/mnsc.45.8.1076
PD AUG 1999
PY 1999
AB We consider a supply chain whose members are divisions of the same firm.
   The divisions are managed by different individuals with only local
   inventory information. Both the material and information flows in the
   supply chain are subject to delays. Under the assumption that the
   division managers share a common goal to optimize the overall
   performance of the supply chain (i.e., they act as a team), we
   characterize the optimal decision rules for the divisions. The team
   solution reveals the role of information leadtimes in determining the
   optimal replenishment strategies. We then show that the owner of the
   firm can manage the divisions as cost centers without compromising the
   systemwide performance. This is achieved by using an
   incentive-compatible measurement scheme based on accounting inventory
   levels. Finally, we investigate the impact of irrational behavior on
   supply chain performance and demonstrate that it is important for the
   upstream members of the supply chain to have access to accurate customer
   demand information.
Z8 8
ZR 0
ZB 1
ZA 0
TC 128
ZS 0
Z9 136
SN 0025-1909
UT WOS:000082479400004
ER

PT J
AU Cachon, GP
   Lariviere, MA
TI Capacity choice and allocation: Strategic behavior and supply chain
   performance
SO MANAGEMENT SCIENCE
VL 45
IS 8
BP 1091
EP 1108
DI 10.1287/mnsc.45.8.1091
PD AUG 1999
PY 1999
AB We consider a simple supply chain in which a single supplier sells to
   several downstream retailers. The suppliers has limited capacity, and
   retailers are privately informed of their optimal stocking levels. If
   retailer orders exceed available capacity, the supplier allocates
   capacity using a publicly known allocation mechanism, a mapping from
   retailer orders to capacity assignments. We show that a broad class of
   mechanisms are prone to manipulation: Retailers will order more than
   they need to gain a more favorable allocation. Another class of
   mechanisms induces the retailers to order exactly their needs, thereby
   revealing their private information. However, there does not exist a
   truth-inducing mechanism that maximizes total retailer profits.
   We also consider the supplier's capacity choice. We show that a
   manipulable mechanism may lead the supplier to choose a higher level of
   capacity than she would under a truth-inducing mechanism. Nevertheless,
   her choice will appear excessively restrictive relative to the
   prevailing distribution of orders. Furthermore, switching to a
   truth-inducing mechanism can lower profits for the supplier, the supply
   chain, and even her retailers. Hence, truth-telling is not a universally
   desirable goal.
ZB 1
ZA 0
ZS 0
TC 243
Z8 33
ZR 0
Z9 276
SN 0025-1909
UT WOS:000082479400005
ER

PT J
AU Silverman, BS
TI Technological resources and the direction of corporate diversification:
   Toward an integration of the resource-based view and transaction cost
   economics
SO MANAGEMENT SCIENCE
VL 45
IS 8
BP 1109
EP 1124
DI 10.1287/mnsc.45.8.1109
PD AUG 1999
PY 1999
AB This study considers how a firm's resource base affects the choice of
   industries into which the firm diversifies. It offers two main
   extensions of prior research. First, it operationalizes technological
   resources at a more detailed level than in prior studies, thereby
   enabling a more stringent analysis of the direction of diversification.
   This analysis shows that the predictive power of the "resource-based
   view of the firm" is greatly improved when resources are measured at a
   finer level. Second, the study integrates principles from transaction
   cost economics into resource-based predictions concerning
   diversification. In particular, it tests the common assumption that
   rent-generating resources are too asset specific to allow contracting.
   The findings point to circumstances where resources can be and are
   exploited through contracting rather than through diversification.
ZS 4
ZA 0
Z8 6
ZR 0
TC 329
ZB 5
Z9 338
SN 0025-1909
UT WOS:000082479400006
ER

PT J
AU Asmussen, S
   Rubinstein, RY
TI Sensitivity analysis of insurance risk models via simulation
SO MANAGEMENT SCIENCE
VL 45
IS 8
BP 1125
EP 1141
DI 10.1287/mnsc.45.8.1125
PD AUG 1999
PY 1999
AB We show how, from a single simulation run, to estimate the ruin
   probabilities and their sensitivities (derivatives) in a classic
   insurance risk model under various distributions of the number of claims
   and the claim size. Similar analysis is given for the tail probabilities
   of the accumulated claims during a fixed period. We perform sensitivity
   analysis with respect to both distributional and structural parameters
   of the underlying risk model. In the former case, we use the score
   function method and in the latter, a combination of the push-out method
   and the score function. We finally show how, from the same sample path,
   to derive a consistent estimator of the optimal solution in an
   optimization problem associated with excess-of-loss reinsurance.
RI Asmussen, Soren/L-1977-2013
ZR 0
Z8 0
ZS 0
ZB 0
ZA 0
TC 6
Z9 6
SN 0025-1909
UT WOS:000082479400007
ER

PT J
AU Ernst, R
   Kouvelis, P
TI The effects of selling packaged goods on inventory decisions
SO MANAGEMENT SCIENCE
VL 45
IS 8
BP 1142
EP 1155
DI 10.1287/mnsc.45.8.1142
PD AUG 1999
PY 1999
AB In this paper, we study within a newsboy type modeling framework the
   common business practice of retail firms to sell. products not only as
   independent items, but also as part of multiproduct packets (packaged
   goods). Our emphasis is on understanding the effects of such practices
   on the inventory decisions of the firm. We provide insights on the
   resulting level of suboptimality when inventory decisions are made with
   demand information only on the independent items and without accounting
   for the demand substitution structure induced between independent items
   and packaged goods. Our stylized model studies an environment with two
   products that are not direct substitutes for each other, sold either
   independently or as part of a packet that contains one unit of each. We
   provide necessary and sufficient optimality conditions for this model
   and suggest an efficient numerical search for obtaining the optimal
   stocking levels. An extensive computational study allowed us to provide
   insights on the nature of the optimal stocking policies, the
   suboptimality of independent newsboy policies, the effects of demand
   correlation among individual products and multiproduct packets, and the
   determining role of induced substitution structure among products during
   stockout occasions on the profitability of the inventory system.
RI Kouvelis, Panos/ABG-2350-2020
ZS 0
ZR 0
Z8 11
TC 66
ZB 0
ZA 0
Z9 76
SN 0025-1909
UT WOS:000082479400008
ER

PT J
AU Ziarati, K
   Soumis, F
   Desrosiers, J
   Solomon, MM
TI A branch-first, cut-second approach for locomotive assignment
SO MANAGEMENT SCIENCE
VL 45
IS 8
BP 1156
EP 1168
DI 10.1287/mnsc.45.8.1156
PD AUG 1999
PY 1999
AB The problem of assigning locomotives to trains consists of selecting the
   types and number of engines that minimize the fixed and operational
   locomotive costs resulting from providing sufficient power to pull
   trains on fixed schedules. The force required to gull a train is often
   expressed in terms of horsepower and tonnage requirements rather than in
   terms of number of engines. This complicates the solution process of the
   integer programming formulation and usually creates a large integrality
   gap. Furthermore, the solution of the linearly relaxed problem is
   strongly fractional.
   To obtain integer solutions, we propose a novel branch-and-cut approach.
   The core of the method consists of branching decisions that define on
   one branch the projection of the problem on a low-dimensional subspace.
   There, the facets of the polyhedron describing a restricted constraint
   set can be easily derived. We call this approach branch-fil st,
   cut-second. We first derive facets when at most two types of engines are
   used. We then extend the branching rule to cases involving additional
   locomotive types.
   We have conducted computational experiments using actual data from the
   Canadian National railway company. Simulated test-problems involving two
   or more locomotive types were solved over 1-, 2-, and 3-day rolling
   horizons. The cuts were successful in reducing the average integrality
   gap by 52% for the two-type case and by 34% when more than 25 types were
   used. Furthermore, the branch-first, cut-second approach was
   instrumental in improving the best known solution for an almost
   2,000-leg weekly problem involving 26 locomotive types. It reduced the
   number of locomotives by 11, or 1.1%, at an equivalent savings of
   $3,000,000 per unit. Additional tests on different weekly data produced
   almost identical results.
RI Ziarati, koorush/W-7421-2018
OI Ziarati, koorush/0000-0001-7618-6807
ZS 1
ZB 0
ZR 0
ZA 0
Z8 1
TC 36
Z9 38
SN 0025-1909
EI 1526-5501
UT WOS:000082479400009
ER

PT J
AU Gardner, ES
TI Note: Rule-based forecasting vs. damped-trend exponential smoothing
SO MANAGEMENT SCIENCE
VL 45
IS 8
BP 1169
EP 1176
DI 10.1287/mnsc.45.8.1169
PD AUG 1999
PY 1999
AB This paper evaluates the ex ante performance of rule-based time series
   forecasting systems proposed in earlier research. The author shows that
   comparable performance can be obtained with a simpler alternative, a
   damped-trend version of exponential smoothing fitted to minimize the
   Mean-Absolute-Deviation (MAD) criterion. The results suggest that the
   performance of rule-based systems would be improved through this
   alternative and that time series forecasters should consider MAD fits in
   model development.
ZR 0
Z8 0
ZS 0
TC 16
ZB 0
Z9 16
SN 0025-1909
UT WOS:000082479400010
ER

PT J
AU Harker, PT
   Zenios, S
TI Performance of financial institutions
SO MANAGEMENT SCIENCE
VL 45
IS 9
BP 1175
EP 1176
PD SEP 1999
PY 1999
RI Harker, Patrick T/A-9467-2013; Zenios, Stavros A/F-3346-2013
OI Harker, Patrick T/0000-0003-0659-3102; Zenios, Stavros
   A/0000-0001-7576-4898
ZR 0
ZA 0
TC 1
Z8 0
ZS 0
ZB 0
Z9 1
SN 0025-1909
EI 1526-5501
UT WOS:000083015800001
ER

PT J
AU Grifell-Tatje, E
   Lovell, CAK
TI Profits and productivity
SO MANAGEMENT SCIENCE
VL 45
IS 9
BP 1177
EP 1193
DI 10.1287/mnsc.45.9.1177
PD SEP 1999
PY 1999
AB In this study we consider the linkage between productivity change and
   profit change. We develop an analytical framework in which profit change
   between one period and the next is decomposed into three sources: (i) a
   productivity change effect (which includes a technical change effect and
   an operating efficiency effect), (ii) an activity effect (which includes
   a product mix effect, a resource mix effect, and a scale effect), and
   (iii) a price effect. We then show how to quantify the contribution of
   each effect, using only observed prices and quantities of products and
   resources in the two periods. We illustrate our analytical decomposition
   of profit change with an empirical application to Spanish banking during
   the period 1987-1994.
RI Grifell-Tatje, Emili/F-7659-2010; Grifell - Tatje, Emili/
OI Grifell - Tatje, Emili/0000-0002-0953-2711
TC 93
Z8 3
ZB 1
ZS 0
ZA 0
ZR 0
Z9 96
SN 0025-1909
UT WOS:000083015800002
ER

PT J
AU Krishnan, MS
   Ramaswamy, V
   Meyer, MC
   Damien, P
TI Customer satisfaction for financial services: The role of products,
   services, and information technology
SO MANAGEMENT SCIENCE
VL 45
IS 9
BP 1194
EP 1209
DI 10.1287/mnsc.45.9.1194
PD SEP 1999
PY 1999
AB In this paper, we study the drivers of customer satisfaction for
   financial services. We discuss a full Bayesian analysis based on data
   collected from customers of: a leading financial services company. Our
   approach allows us to explicitly accommodate missing data and enables
   quantitative assessment of the impact of the drivers of satisfaction
   across the customer population. We find that satisfaction with product
   offerings is a primary driver of overall customer satisfaction, The
   quality of customer service with respect to financial statements and
   services provided through different channels of delivery, such as
   information technology enabled call centers and traditional branch
   offices, are also important in determining overall satisfaction.
   However, our analysis indicates that the impact of these service
   delivery factors may differ substantially across customer segments. In
   order to facilitate managerial action, we discuss how specific
   operational quality attributes for designing and delivering financial
   services can be leveraged to enhance satisfaction with product offerings
   and service delivery. Our approach and findings have significant
   implications for managing customer satisfaction in the financial
   services industry.
ZB 0
ZA 0
Z8 2
TC 81
ZS 2
ZR 0
Z9 83
SN 0025-1909
UT WOS:000083015800003
ER

PT J
AU Frei, FX
   Kalakota, R
   Leone, AJ
   Marx, LM
TI Process variation as a determinant of bank performance: Evidence from
   the retail banking study
SO MANAGEMENT SCIENCE
VL 45
IS 9
BP 1210
EP 1220
DI 10.1287/mnsc.45.9.1210
PD SEP 1999
PY 1999
AB This paper explores the relation between retail banks' branch-based
   processes and financial performance. There are 11 processes included in
   this study, which represent the bulk of the activities performed in a
   typical retail branch (e.g., opening checking accounts). The first
   finding of this study is that the financial performance of banks that
   perform be tt er across these processes tend to be better than that of
   other banks. in addition to the variation in process performance across
   banks, there is also substantial variation across processes within
   banks. That is, banks that performed well in one process often performed
   quite badly in another. We present an analytical model that shows that
   improvement in process variation can be more important than improvement
   in aggregate process performance when dealing with certain customer
   segments. Empirical evidence from the Wharton Financial Institution
   Center Retail Banking Study of bank holding companies in the United
   States provides support.
RI Leone, Andrew/A-8632-2009
OI Leone, Andrew/0000-0002-8694-375X
ZA 0
ZS 0
Z8 0
ZR 0
TC 54
ZB 0
Z9 54
SN 0025-1909
UT WOS:000083015800004
ER

PT J
AU Soteriou, A
   Zenios, SA
TI Operations, quality, and profitability in the provision of banking
   services
SO MANAGEMENT SCIENCE
VL 45
IS 9
BP 1221
EP 1238
DI 10.1287/mnsc.45.9.1221
PD SEP 1999
PY 1999
AB We develop a framework for combining strategic benchmarking marking of
   the services offered by bank branches, In particular, a cascade of
   efficiency with efficiency benchmarking models is developed guided by
   the service-profit chain. Three models-based on the nonparametric
   technique of Data Envelopment Analysis-are developed in order to
   implement the framework in a practical setting: (i) an operational
   efficiency model, (ii) a service quality efficiency model, and (iii) a
   profitability efficiency model. The use of the models is illustrated
   using data from the branches of a commercial bank. Empirical results
   indicate that we gain superior insights by analyzing simultaneously the
   design of operations together with the quality of the provided services
   and profitability, rather than by benchmarking these three dimensions
   separately. Relationships are also established between operational
   efficiency and profitability, and between operational efficiency and
   service quality.
RI Zenios, Stavros A/F-3346-2013; Soteriou, Andreas/
OI Zenios, Stavros A/0000-0001-7576-4898; Soteriou,
   Andreas/0000-0001-8527-3742
ZA 0
TC 144
Z8 3
ZB 3
ZR 0
ZS 0
Z9 147
SN 0025-1909
EI 1526-5501
UT WOS:000083015800005
ER

PT J
AU Allen, F
   Gale, D
TI Innovations in financial services, relationships, and risk sharing
SO MANAGEMENT SCIENCE
VL 45
IS 9
BP 1239
EP 1253
DI 10.1287/mnsc.45.9.1239
PD SEP 1999
PY 1999
AB Relationships between intermediaries and their customers have become
   increasingly important in recent years. This paper argues that the need
   for costly ex ante information acquisition and analysis is a major
   barrier to the participation of investors and firms in sophisticated
   markets. Long-term relationships between intermediaries and their
   customers, in which intermediaries provide implicit insurance to
   customers, can be an effective substitute for costly ex ante
   investigation. Ln this way, intermediaries allow firms and investors to
   reap the benefits of financial markets. Relationships are easiest to
   sustain when the ongoing benefits to both parties are high. As a result,
   competition may lower the benefits that can be obtained from
   relationships.
OI Gale, Douglas/0000-0003-1099-7732
ZR 0
ZA 0
ZB 0
ZS 0
TC 25
Z8 1
Z9 26
SN 0025-1909
UT WOS:000083015800006
ER

PT J
AU Cummins, JD
   Weiss, MA
   Zi, HM
TI Organizational form and efficiency: The coexistence of stock and mutual
   property-liability insurers
SO MANAGEMENT SCIENCE
VL 45
IS 9
BP 1254
EP 1269
DI 10.1287/mnsc.45.9.1254
PD SEP 1999
PY 1999
AB This article introduces a new approach, cross-frontier analysis, for
   estimating the relative efficiency of alternative organizational forms
   in an industry. The technique is illustrated by analyzing a sample of
   stock and mutual property-liability insurers using nonparametric
   frontier efficiency methods. Cross-frontier analysis measures the
   relative efficiency of each organizational form by computing the
   efficiency of each stock (mutual) firm relative to a reference set
   consisting of all mutual (stock) firms. We test agency-theoretic
   hypotheses about organizational form, including the managerial
   discretion and expense preference hypotheses. The results indicate that
   stocks and mutuals are opera ting on separate production and cost
   frontiers and thus represent distinct technologies. Consistent with the
   managerial discretion hypothesis,the stock technology dominates the
   mutual technology for producing stock outputs and the mutual technology
   dominates the stock technology far producing mutual outputs. However,
   consistent with the expense preference hypothesis, the stock cost
   frontier dominates the mutual cost frontier. Our findings thus suggest a
   richer interpretation of organizational form than provided by previous
   researchers.
RI Cummins, J David/R-5426-2017
ZR 0
Z8 2
ZS 1
ZB 1
ZA 0
TC 138
Z9 140
SN 0025-1909
UT WOS:000083015800007
ER

PT J
AU Seiford, LM
   Zhu, J
TI Profitability and marketability of the top 55 US commercial banks
SO MANAGEMENT SCIENCE
VL 45
IS 9
BP 1270
EP 1288
DI 10.1287/mnsc.45.9.1270
PD SEP 1999
PY 1999
AB Utilizing recent developments in data envelopment analysis (DEA), this
   paper examines the performance of the top 55 U.S. commercial banks via a
   two-stage production process that separates profitability and
   marketability. Substantial performance inefficiency is uncovered in both
   dimensions. Relatively large banks exhibit better performance on
   profitability, whereas smaller banks tend to perform better with respect
   to marketability. New context-dependent performance measures are defined
   for profitability and marketability which employ a DEA stratification
   model and a DEA attractiveness measure. When combined with the original
   DEA measure, the context-dependent performance measure better
   characterizes the profitability and marketability of 55 U.S. commercial
   banks. The new approach identifies areas for improved bank performance
   over the two-stage production process. The effect of acquisition on
   efficiency and attractiveness is also examined.
RI Zhu, Joe/E-7999-2014
OI Zhu, Joe/0000-0001-6103-080X
ZB 6
Z8 14
ZA 1
ZS 4
ZR 0
TC 508
Z9 519
SN 0025-1909
EI 1526-5501
UT WOS:000083015800008
ER

PT J
AU Bollapragada, S
   Morton, TE
TI Myopic heuristics for the random yield problem
SO OPERATIONS RESEARCH
VL 47
IS 5
BP 713
EP 722
DI 10.1287/opre.47.5.713
PD SEP-OCT 1999
PY 1999
AB We consider a single item periodic review inventory problem with random
   yield and stochastic demand. The yield is proportional to the quantity
   ordered, with the multiplicative factor being a random variable. The
   demands are stochastic and are independent across the periods, but they
   need not be stationary. The holding, penalty, and ordering costs are
   linear. Any unsatisfied demands are backlogged. Two cases for the
   ordering cost are considered: The ordering cost can be proportional to
   either the quantity ordered (e.g., in house production) or the quantity
   received (e.g., delivery by an external supplier). Random yield problems
   have been addressed previously in the literature, but no constructive
   solutions or algorithms are presented except for simple heuristics that
   are far from optimal. In this paper, we present a novel analysis of the
   problem in terms of the inventory position at the end of a period. This
   analysis provides interesting insights into the problem and leads to
   easily implementable and highly accurate myopic heuristics. A detailed
   computational study is done to evaluate the heuristics. The study is
   done for the infinite horizon case, with stationary yields and demands
   and for the finite horizon case with a 26-period seasonal demand
   pattern. The best of our heuristics has worst-case errors of 3.0% and
   5.0% and average errors of 0.6% and 1.2% for the infinite and finite
   horizon cases, respectively.
TC 78
ZA 0
ZS 0
ZR 0
Z8 3
ZB 0
Z9 81
SN 0030-364X
UT WOS:000083377900006
ER

PT J
AU Gardner, DT
   Rogers, JS
TI Planning electric power systems under demand uncertainty with different
   technology lead times
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1289
EP 1306
DI 10.1287/mnsc.45.10.1289
PD OCT 1999
PY 1999
AB Demand uncertainty is a key concern of electric utility planners. While
   the greater use of short lead time technologies provides one possible
   way to deal with this problem, it is not clear how they are best
   deployed. The approach taken in this paper is to examine a capacity mix
   model that explicitly accounts for differences in technology lead times.
   Key results that are obtained include the characterization of the
   optimal solution and the development of a new set of technology
   screening criteria, in practice, the "lead time order" (i.e., the set of
   available technologies ordered by ascending length of lead time) is
   typically the inverse of the so-called merit order (i.e., the set of
   available technologies ordered by ascending operating cost). We show
   that for this case, the optimal solution may be determined with relative
   ease. A numerical example demonstrates that some short lead time
   technologies screened out by standard planning methods may enter the
   optimal solution when differences in lead time are considered, while
   some long lead time technologies may leave. Ln addition, the optimal
   expected level of reliability may be greater.
ZS 0
TC 9
ZA 0
ZR 0
ZB 0
Z8 0
Z9 9
SN 0025-1909
UT WOS:000083526500001
ER

PT J
AU Drexl, A
   Haase, K
TI Fast approximation methods for sales force deployment
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1307
EP 1323
DI 10.1287/mnsc.45.10.1307
PD OCT 1999
PY 1999
AB Sales force deployment involves the simultaneous resolution of four
   interrelated subproblems: sales force sizing, salesman location, sales
   territory alignment, and sales resource allocation. The first subproblem
   deals with selecting the appropriate number of salesman. The salesman
   location aspect of the problem involves determining the location of each
   salesman in one sales coverage unit. Sales territory alignment may be
   viewed as the problem of grouping sales coverage units into larger
   geographic clusters called sales territories. Sales resource allocation
   refers to the problem of allocating scarce salesman time to the aligned
   sales coverage units. All four subproblems have to be resolved in order
   to maximize Profit of the selling organization. Ln this paper a novel
   nonlinear mixed-integer programming model is formulated which covers all
   four subproblems simultaneously. For the solution of the model we
   present approximation methods capable of solving large-scale, real-world
   instances. The methods, which provide lower bounds for the optimal
   objective function value, are benchmarked against upper bounds. On
   average the solution gap, i.e., the difference between upper and lower
   bounds, is about 3%. Furthermore, we show how the methods can be used to
   analyze various problem settings of practical relevance. Finally, an
   application in the beverage industry is presented.
ZA 0
ZB 1
TC 48
Z8 0
ZR 0
ZS 5
Z9 50
SN 0025-1909
UT WOS:000083526500002
ER

PT J
AU Villas-Boas, JM
   Winer, RS
TI Endogeneity in brand choice models
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1324
EP 1338
DI 10.1287/mnsc.45.10.1324
PD OCT 1999
PY 1999
AB Applications of random utility models to scanner data have been widely
   presented in marketing for the last 20 years. One particular problem
   with these applications is that they have ignored possible correlations
   between the independent variables in the deterministic component of
   utility (price, promotion, etc.) and the stochastic component or error
   term. In fact, marketing-mix variables, such as price, not only affect
   brand purchasing probabilities but are themselves endogenously set by
   marketing managers. This work tests whether these endogeneity problems
   are important enough to warrant consideration when estimating random
   utility models with scanner panel data. Our results show that not
   accounting for endogeneity may result in a substantial bias in the
   parameter estimates.
RI Winer, Russell/ABH-5955-2020; Villas-Boas, J. Miguel/
OI Villas-Boas, J. Miguel/0000-0003-1299-4324
ZB 2
ZR 0
ZA 0
ZS 0
Z8 0
TC 250
Z9 251
SN 0025-1909
UT WOS:000083526500003
ER

PT J
AU Tsay, AA
TI The quantity flexibility contract and supplier-customer incentives
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1339
EP 1358
DI 10.1287/mnsc.45.10.1339
PD OCT 1999
PY 1999
AB Consider a supply chain consisting of two independent agents, a supplier
   (e.g., a manufacturer) and its customer (e.g., a retailer), the latter
   in turn serving an uncertain market demand. To reconcile
   manufacturing/procurement time lags with a need for timely response to
   the market, such supply chains often must commit resources to production
   quantities based on forecasted rather than realized demand.
   The customer typically provides a planning forecast of its intended
   purchase, which does not entail commitment. Benefiting from
   overproduction while not bearing the immediate costs, the customer has
   incentive to initially overforecast before eventually purchasing a
   lesser quantity. The supplier must in turn anticipate such behavior in
   its production quantity decision. This individually rational behavior
   results in an inefficient supply chain.
   This paper models the incentives of the two parties, identifying causes
   of inefficiency and suggesting remedies. Particular attention is given
   to the Quantity Flexibility (QF) contract, which couples the customer's
   commitment to purchase no less than a certain percentage below the
   forecast with the supplier's guarantee to deliver up to a certain
   percentage above. Under certain conditions, this method can allocate the
   costs of market demand uncertainty so as to lead the individually
   motivated supplier and customer to the systemwide optimal outcome. We
   characterize the implications of QF contracts for the behavior and
   performance of both parties, and the supply chain as a whole.
OI Tsay, Andy/0000-0002-4082-8027
ZB 6
ZS 1
Z8 72
ZA 0
ZR 0
TC 522
Z9 594
SN 0025-1909
UT WOS:000083526500004
ER

PT J
AU Childs, PD
   Triantis, AJ
TI Dynamic R&D investment policies
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1359
EP 1377
DI 10.1287/mnsc.45.10.1359
PD OCT 1999
PY 1999
AB This paper examines dynamic R&D investment policies and the valuation of
   R&D programs in a contingent claims framework. We incorporate the
   following characteristics of R&D programs into our model:
   learning-by-doing, collateral learning between different projects in the
   program, interaction between project cash flows, periodic reevaluations
   of the program, different intensities of investment, capital rationing
   constraints, and competition. We show that a firm may invest in multiple
   projects even if only one can be implemented after development is
   complete. Furthermore, the firm may significantly alter its funding
   policy over time. For example, it may simultaneously develop multiple
   projects for a period of time, then focus on a lead project, and
   potentially resume funding of a "backup" project if the lead project
   fails to deliver on its early promise. We show how a firm can forecast
   expected R&D spending through time for an optimally executed R&D
   program. While project volatility plays an important role in determining
   R&D program value, we find that for high volatility projects the optimal
   investment policy is not very sensitive to changes in (or misestimation
   of) volatility. In considering whether to accelerate development of a
   project, a firm should balance the adverse effects of increased costs
   and the loss of investment flexibility against the positive effects of
   rapid uncertainty resolution and accelerated cash flows. In the presence
   of a budget constraint that prevents the firm from simultaneously
   accelerating projects and developing projects in parallel, we find that,
   if one project significantly dominates another early in the development
   stage, the option to accelerate the lead project is likely to be more
   valuable than the option to exchange projects. Thus, the backup project
   would be shelved in order to commit extra resources to development of
   the lead project. Finally, competition from other firms leads to more
   parallel investment in the early development stages of projects, less
   parallel investment in the latter stages of development, and lower
   overall investment.
Z8 2
ZS 2
ZA 0
TC 81
ZR 1
ZB 0
Z9 85
SN 0025-1909
UT WOS:000083526500005
ER

PT J
AU Li, CL
   Kouvelis, P
TI Flexible and risk-sharing supply contracts under price uncertainty
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1378
EP 1398
DI 10.1287/mnsc.45.10.1378
PD OCT 1999
PY 1999
AB We study supply contracts for deterministic demand but in an environment
   of uncertain prices. We develop valuation methodologies for different
   types of supply contracts. A "time-inflexible contract" requires the
   firm to specify not only how many units it will purchase, but also the
   timing of the purchase. A "time-flexible contract" allows the firm to
   specify the purchase amount over a given period of time without
   specifying the exact time of purchase. Other than time flexibility, the
   suppliers may offer "quantity flexibility" to the firm as well, i.e.,
   purchase quantities could be within a prespecified quantity window.
   Finally, "risk-sharing" features can be incorporated in the contract in
   terms of the purchase price that the firm eventually pays to a supplier.
   Within a prespecified price window the firm pays the realized price, but
   outside of it the firm shares, in an agreed way, added costs or
   benefits.
   Given the structure of a supply contract, we study the firm's decision
   when to purchase and how many units in each purchase such that the
   expected net present value of the purchase cost plus inventory holding
   cost is minimized. We discuss optimal purchasing strategies for both
   time-flexible and time-inflexible contracts with risk-sharing features.
   Other interesting results include the analysis of two-supplier sourcing
   environments and the exploitation of quantity flexibility in such
   contracts. Our discussion illustrates how time flexibility, quantity
   flexibility, supplier selection, and risk sharing, when carefully
   exercised can effectively reduce the sourcing cost in environments of
   price uncertainty.
RI Kouvelis, Panos/ABG-2350-2020; Li, Chung-Lun/
OI Li, Chung-Lun/0000-0002-4225-0855
ZB 0
ZA 0
ZS 0
TC 143
Z8 15
ZR 0
Z9 158
SN 0025-1909
UT WOS:000083526500006
ER

PT J
AU Muralidhar, K
   Parsa, R
   Sarathy, R
TI A general additive data perturbation method for database security
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1399
EP 1415
DI 10.1287/mnsc.45.10.1399
PD OCT 1999
PY 1999
AB The security of organizational databases has received considerable
   attention in the literature in recent years. This can be attributed to a
   simultaneous increase in the amount of data being stored in databases,
   the analysis of such data, and the desire to protect confidential data.
   Data perturbation methods are often used to protect confidential,
   numerical data from unauthorized queries while providing maximum access
   and accurate information to legitimate queries. To provide accurate
   information, it is desirable that perturbation does not result in a
   change in relationships between attributes. In the presence of
   nonconfidential attributes, existing methods will result in such a
   change. This study describes a new method (General Additive Data
   Perturbation) that does not change relationships between attributes. Al
   existing methods of additive data perturbation are shown to be special
   cases of this method. When the database has a multivariate normal
   distribution, the new method provides maximum security and minimum bias.
   For nonnormal databases, the new method provides better security and
   bias performance than the multiplicative data perturbation method.
RI Muralidhar, Krishnamurty/A-7618-2009; Sarathy, Rathindra/
OI Sarathy, Rathindra/0000-0001-7352-2676
ZB 1
TC 72
ZS 0
Z8 5
ZA 0
ZR 0
Z9 76
SN 0025-1909
UT WOS:000083526500007
ER

PT J
AU Alfredsson, P
   Verrijdt, J
TI Modeling emergency supply flexibility in a two-echelon inventory system
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1416
EP 1431
DI 10.1287/mnsc.45.10.1416
PD OCT 1999
PY 1999
AB We consider a two-echelon inventory system for service parts. To obtain
   high service levels at a low cost we allow not only for normal supply of
   parts but also for emergency supply options in terms of lateral
   transshipments and direct deliveries. After presenting the strategy we
   use for satisfying customer demand, we construct an analytical model
   that we use to calculate relevant performance measures. Simulation shows
   that our model produces accurate estimates, and that the performance of
   the inventory system is insensitive to the lead-time distribution. After
   introducing a cost structure we show that the strategy we propose can
   result in considerable savings when compared to using only normal
   supply. Comparison of the results of our model with the results of other
   models indicates that the combined use of lateral transshipments and
   direct deliveries can lead to significant cost savings.
ZS 1
ZA 0
TC 114
ZR 0
Z8 13
ZB 1
Z9 128
SN 0025-1909
EI 1526-5501
UT WOS:000083526500008
ER

PT J
AU Gelles, GM
   Mitchell, DW
TI Broadly decreasing risk aversion
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1432
EP 1439
DI 10.1287/mnsc.45.10.1432
PD OCT 1999
PY 1999
AB his paper considers decision-making in the presence of two additive risk
   sources, with no restrictions on the relation between the two risks. A
   utility function is said to exhibit broad DARA if and only if a rise in
   wealth always decreases the magnitude of the risk premium for one of the
   risks vis-a-vis the other. A condition on utility functions giving this
   property is derived: utility must be of the linear plus exponential
   form. It is shown that certain problems involving portfolios and
   risk-averse firms give unambiguous comparative statics if and only if
   utility exhibits broad DARA.
ZB 0
Z8 0
ZA 0
ZS 0
TC 4
ZR 0
Z9 4
SN 0025-1909
UT WOS:000083526500009
ER

PT J
AU Ahuja, RK
   Orlin, JB
   Sechi, GM
   Zuddas, P
TI Algorithms for the simple equal flow problem
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1440
EP 1455
DI 10.1287/mnsc.45.10.1440
PD OCT 1999
PY 1999
AB The minimum cost flow problem is to determine a least cost shipment of a
   commodity through a network G = (N, A) in order to satisfy demands at
   certain nodes from available supplies at other nodes. In this paper, we
   study a variant of the minimum cost flow problem where we are given a
   set R subset of or equal to A of arcs and require that each are in R
   must carry the same amount of flow. This problem, which we call the
   simple equal flow problem, arose while modeling a water resource system
   management in Sardinia, Italy. We consider the simple equal flow problem
   in a directed network with n nodes, m arcs, and where all are capacities
   and node supplies are integer and bounded by U. We develop several
   algorithms for the simple equal flow problem - the network simplex
   algorithm, the parametric simplex algorithm, the combinatorial
   parametric algorithm, the binary search algorithm, and the capacity
   scaling algorithm. The binary search algorithm solves the simple equal
   flow problem in O(log(nU)) applications of any minimum cost flow
   algorithm. The capacity scaling algorithm solves it in O(m(m + n log n)
   log (nU)) time, which is almost the same time needed to solve the
   minimum cost flow problem by the capacity scaling algorithm. These
   algorithms can be easily modified to obtain an integer solution of the
   simple equal flow problem.
RI zuddas, paola/E-5733-2013; Sechi, Giovanni M/; Orlin, James/
OI Sechi, Giovanni M/0000-0002-6004-4561; Orlin, James/0000-0002-7488-094X
Z8 0
ZR 0
ZS 0
ZA 0
TC 20
ZB 0
Z9 20
SN 0025-1909
UT WOS:000083526500010
ER

PT J
AU Gurnani, H
   Tang, CS
TI Note: Optimal ordering decisions with uncertain cost and demand forecast
   updating
SO MANAGEMENT SCIENCE
VL 45
IS 10
BP 1456
EP 1462
DI 10.1287/mnsc.45.10.1456
PD OCT 1999
PY 1999
AB We determine the optimal ordering policy for a retailer who has two
   instants to order a seasonal product from a manufacturer prior to a
   single selling season. While the demand is uncertain, the retailer can
   improve the forecast by utilizing the market signals observed between
   the first and second instants. However, because of the nature of the
   manufacturing environment, the unit cost at the second instant is
   uncertain and could be higher (or lower) than the unit cost at the first
   instant. To determine the profit-maximizing ordering strategies at both
   instants, the retailer has to evaluate the trade-off between a more
   accurate forecast and a potentially higher unit cost at the second
   instant. We present a nested newsvendor model for determining the
   optimal order quantity at each instant and characterize the conditions
   under which it is optimal for the retailer to delay its order until the
   second instant.
OI tang, christopher/0000-0001-9597-7620
ZS 0
Z8 27
TC 157
ZA 0
ZR 0
ZB 2
Z9 181
SN 0025-1909
EI 1526-5501
UT WOS:000083526500011
ER

PT J
AU Campa, JM
   Guillen, MF
TI The internalization of exports: Firm- and location-specific factors in a
   middle-income country
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1463
EP 1478
DI 10.1287/mnsc.45.11.1463
PD NOV 1999
PY 1999
AB Firms make strategic choices about foreign market access on the basisof
   location factors in the home and export countries, as well as on their
   ownership advantages. The empirical analysis is based on a sample of 837
   manufacturing companies in a typical middle-income country (Spain), in
   which firms are starting to internationalize through investments or
   alliances in distribution. Following theoretical expectations, the
   greater the level of such ownership factors as intangible technological
   assets, product variability, and resource availability, the higher the
   likelihood of internalization, and in particular internalization by
   proprietary distribution instead of by commercial alliance. But most
   importantly, location factors in the home country and in the export
   market have an independent effect on the likelihood and mode of
   internalization. Proprietary distribution channels are preferred when
   the firm's competitors are based in richer countries than the home
   country, and when the export market is well known to the firm.
CT 55th Annual Meeting of the Academy-of-Management
CY AUG 06-09, 1995
CL VANCOUVER, CANADA
SP Acad Management
ZB 0
ZR 0
TC 63
Z8 0
ZA 0
ZS 0
Z9 63
SN 0025-1909
EI 1526-5501
UT WOS:000084168900001
ER

PT J
AU Levitt, RE
   Thomsen, J
   Christiansen, TR
   Kunz, JC
   Jin, Y
   Nass, C
TI Simulating project work processes and organizations: Toward a
   micro-contingency theory of organizational design
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1479
EP 1495
DI 10.1287/mnsc.45.11.1479
PD NOV 1999
PY 1999
AB The Virtual Design Team (VDT) extends and operationalizes Galbraith's
   (1973) information-processing view of organizations. VDT simulates the
   micro-level information processing, communication, and coordination
   behavior of participants in a project organization and predicts several
   measures of participant and project-level performance. VDT-1 (Cohen
   1991) and VDT-2 (Christiansen 1993) modeled project organizations
   containing actors with perfectly congruent goals engaged in complex but
   routine engineering design work within static organization structures.
   VDT-S extends the VDT-2 work process representation to include measures
   of activity flexibility, complexity, uncertainty, and interdependence
   strength. It explicitly models the effects of goal incongruency between
   agents on their information processing and communication behavior while
   executing more flexible tasks. These extensions allow VDT to model more
   flexible organizations executing less routine work processes. VDT thus
   bridges rigorously between cognitive and social psychological
   micro-organization theory and sociological and economic
   macro-organization theory for project teams. VDT-3 has been used to
   model and simulate the design of two major subsystems of a complex
   satellite launch vehicle. This case study provides initial evidence that
   the micro-contingency theory embodied in VDT-5 can be used to predict
   organizational breakdowns, and to evaluate alternative organizational
   changes to mitigate identified risks. VDT thus supports true
   "organizational engineering" for project teams.
OI Levitt, Raymond/0000-0001-8222-6967
ZR 0
Z8 2
TC 126
ZB 1
ZA 0
ZS 1
Z9 129
SN 0025-1909
UT WOS:000084168900002
ER

PT J
AU van Ryzin, G
   Mahajan, S
TI On the relationship between inventory costs and variety benefits in
   retail assortments
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1496
EP 1509
DI 10.1287/mnsc.45.11.1496
PD NOV 1999
PY 1999
AB Consider a category of product variants distinguished by some attribute
   such as color or flavor. A retailer must construct an assortment for the
   category, i.e., select a subset variants to stock and determine purchase
   quantities for each offered variant. We analyze this problem using a
   multinomial logit model to describe the consumer choice process and a
   newsboy model to represent the retailer's inventory cost. We show that
   the optimal assortment has a simple structure and provide insights on
   how various factors affect the optimal level of assortment variety. We
   also develop a formal definition of the level of fashion in a category
   using the theory of majorization and examine its implications for
   category profits.
TC 227
ZS 0
ZB 0
ZR 0
ZA 0
Z8 4
Z9 230
SN 0025-1909
UT WOS:000084168900003
ER

PT J
AU Cheng, F
   Sethi, SP
TI A periodic review inventory model with demand influenced by promotion
   decisions
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1510
EP 1523
DI 10.1287/mnsc.45.11.1510
PD NOV 1999
PY 1999
AB In this paper, we use a Markov decision process (MDP) to model the joint
   inventory-promotion decision problem. The state variable of the MDP
   represents the demand state brought about by changing environmental
   factors as well as promotion decisions. The demand state in a period
   determines the distribution of the random demand in that period. Optimal
   inventory and promotion decision policies in the finite horizon problem
   are obtained via dynamic programming. Under certain conditions, we show
   that there is a threshold inventory level P for each demand state such
   that if the threshold is exceeded, then it is desirable to promote the
   product. For the proportional ordering cost case, the optimal inventory
   replenishment policy is a base-stock type policy with the optimal
   base-stock level dependent on the promotion decision.
RI Sethi, Suresh P/C-4517-2012
ZA 0
ZR 0
ZS 1
Z8 5
TC 39
ZB 0
Z9 45
SN 0025-1909
EI 1526-5501
UT WOS:000084168900004
ER

PT J
AU Swamidass, PM
   Nair, SS
   Mistry, SI
TI The use of a neural factory to investigate the effect of product line
   width on manufacturing performance
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1524
EP 1538
DI 10.1287/mnsc.45.11.1524
PD NOV 1999
PY 1999
AB The dual goals of this study are: (1) to develop an empirically valid
   neural model of U.S. factories in a range of industries producing
   discrete products, and (2) to use the model to test the effect of
   changes in product line width On plant performance variables.
   Accordingly, a neural factory was developed using 59 input and 5
   output/performance variables, and was trained using field data collected
   from 385 U.S, manufacturing plants. The model was validated using a
   holdout sample before conducting sensitivity tests. The study
   demonstrates that, through the use of parametric sensitivity analysis,
   the neural factory could be used to investigate the relationship between
   inputs and performance of a factory.
   While the focused factory principle would favor a smaller product line,
   economies of score theory would favor a larger product line for the good
   of the factory; this implies a rather complex relationship between
   product line width (PLW) and plant performance. The neural factory was
   used to study the sensitivity of output/performance variables when
   product line width was varied over a range extending from 10% to 200% of
   the average values. The sensitivity analysis of the neural factory shows
   that, as the product line increases, it (1) does not affect
   cost-of-goods-sold (COGS), (2) decreases return on investment, (3) has a
   negative effect on the top management's perception of manufacturing
   performance, (4) increases inventory turns, and (5) increases sales per
   employee.
   The explanations for these findings show how complex and intertwined the
   relationships between PLW and performance variables are. They enhance
   our understanding of PLW and provide some new directions for future
   empirical research.
RI Swamidass, Paul/D-5758-2012
OI Swamidass, Paul/0000-0002-1725-6024
ZA 0
ZS 0
ZB 0
Z8 0
ZR 0
TC 10
Z9 10
SN 0025-1909
UT WOS:000084168900005
ER

PT J
AU Goldengorin, B
   Sierksma, G
   Tijssen, GA
   Tso, M
TI The data-correcting algorithm for the minimization of supermodular
   functions
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1539
EP 1551
DI 10.1287/mnsc.45.11.1539
PD NOV 1999
PY 1999
AB The Data-Correcting (DC) Algorithm is a recursive branch-and-bound type
   algorithm, in which the data of a given problem instance are
   "heuristically corrected" at each branching in such a way that the new
   instance will be as close as possible to polynomially solvable and the
   result satisfies a prescribed accuracy (the difference between optimal
   and current solution). In this paper the DC algorithm is applied to
   determining exact or approximate global minima of supermodular
   functions. The working of the algorithm is illustrated by an instance of
   the Simple Plant Location (SPL) Problem. Computational results, obtained
   for the Quadratic Cost Partition Problem (QCP), show that the DC
   algorithm outperforms a branch-and-cut algorithm, not only for sparse
   graphs but also for nonsparse graphs (with density more than 40%), often
   with speeds 100 times faster.
RI Goldengorin, Boris/H-7172-2016
OI Goldengorin, Boris/0000-0001-7399-581X
ZR 0
Z8 0
ZB 0
ZA 0
TC 33
ZS 0
Z9 33
SN 0025-1909
UT WOS:000084168900006
ER

PT J
AU Bielza, C
   Shenoy, PP
TI A comparison of graphical techniques for asymmetric decision problems
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1552
EP 1569
DI 10.1287/mnsc.45.11.1552
PD NOV 1999
PY 1999
AB We compare four graphical techniques for representation and solution of
   asymmetric decision problems-decision trees, influence diagrams,
   valuation networks, and sequential decision diagrams. We solve a
   modified version of Covaliu and Oliver's Reactor problem using each of
   the four techniques. For each technique, we highlight the strengths,
   weaknesses, and some open issues that perhaps can be resolved with
   further research.
RI Shenoy, Prakash P./A-7939-2009; Bielza, Concha/F-9277-2013
OI Shenoy, Prakash P./0000-0002-8425-896X; Bielza,
   Concha/0000-0001-7109-2668
ZR 0
ZA 0
ZB 0
TC 32
Z8 1
ZS 0
Z9 33
SN 0025-1909
UT WOS:000084168900007
ER

PT J
AU Kleinman, NL
   Spall, JC
   Naiman, DQ
TI Simulation-based optimization with stochastic approximation using common
   random numbers
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1570
EP 1578
DI 10.1287/mnsc.45.11.1570
PD NOV 1999
PY 1999
AB The method of Common Random Numbers is a technique used to reduce the
   variance of difference estimates in simulation optimization problems.
   These differences are commonly used to estimate gradients of objective
   functions as part of the process of determining optimal values for
   parameters of a simulated system. asymptotic results exist which show
   that using the Common Random Numbers method in the iterative Finite
   Difference Stochastic Approximation optimization algorithm (FDSA) can
   increase the optimal rate of convergence of the algorithm from the
   typical rate of k(-1/3) to the faster k(-1/2), where k is the
   algorithm's iteration number. Simultaneous Perturbation Stochastic
   Approximation (SPSA) is a newer and often much more efficient
   optimization algorithm, and we will show that this algorithm, too,
   converges faster when the Common Random Numbers method is used. We will
   also provide multivariate asymptotic covariance matrices for both the
   SPSA and FDSA errors.
RI Naiman, Daniel Q/A-3304-2010
OI Naiman, Daniel Q/0000-0001-6504-9081
ZS 0
ZA 0
ZR 0
ZB 1
TC 34
Z8 3
Z9 37
SN 0025-1909
EI 1526-5501
UT WOS:000084168900008
ER

PT J
AU Whitt, W
TI Partitioning customers into service groups
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1579
EP 1592
DI 10.1287/mnsc.45.11.1579
PD NOV 1999
PY 1999
AB We explore the issues of when and how to partition arriving customers
   into service groups that will be served separately, in a first-come
   first-served manner, by multiserver service systems having a provision
   for waiting, and how to assign an appropriate number of servers to each
   group. We assume that customers can be classified upon arrival, so that
   different service groups can have different service-time distributions.
   We provide methodology for quantifying the tradeoff between economies of
   scale associated with larger systems and the benefit of having customers
   with shorter service times separated from other customers with longer
   service times, as is done in service systems with express lines. To
   properly quantify this tradeoff, it is important to characterize
   service-time distributions beyond their means. In particular, it is
   important to also determine the variance of the service-time
   distribution of each service group. Assuming Poisson arrival processes,
   we then can model the congestion experienced by each server group as an
   M/G/s queue with unlimited waiting room. We use previously developed
   approximations for M/G/s performance measures to quickly evaluate
   alternative partitions.
RI Whitt, Ward/D-5337-2013
OI Whitt, Ward/0000-0003-4298-9964
TC 33
ZB 0
ZA 0
ZS 0
Z8 0
ZR 0
Z9 33
SN 0025-1909
UT WOS:000084168900009
ER

PT J
AU Sueyoshi, T
TI DEA duality on Returns to Scale (RTS) in production and cost analyses:
   An occurrence of multiple solutions and differences between
   production-based and cost-based RTS estimates
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1593
EP 1608
DI 10.1287/mnsc.45.11.1593
PD NOV 1999
PY 1999
AB This article discusses the concept of RTS (Returns To Scale) in the
   framework of DEA (Data Envelopment Analysis) production and cost
   analyses, focusing on an occurrence of multiple solutions and how to
   deal with such a difficulty. Dual relationships between production-based
   and cost-based RTS estimates are also theoretically discussed in this
   study.
ZB 1
TC 49
ZS 2
ZR 0
ZA 0
Z8 1
Z9 52
SN 0025-1909
EI 1526-5501
UT WOS:000084168900010
ER

PT J
AU Fruchter, GE
TI The many-player advertising game
SO MANAGEMENT SCIENCE
VL 45
IS 11
BP 1609
EP 1611
DI 10.1287/mnsc.45.11.1609
PD NOV 1999
PY 1999
AB This study extends the time-variant closed-loop strategy of Fruchter and
   Kalish (1997) to the n-player advertising game. We demonstrate that
   solving an n-player game using 2 players results in overadvertising.
TC 28
ZA 0
Z8 3
ZR 0
ZB 0
ZS 0
Z9 31
SN 0025-1909
UT WOS:000084168900011
ER

PT J
AU Bakos, Y
   Brynjolfsson, E
TI Bundling information goods: Pricing, profits, and efficiency
SO MANAGEMENT SCIENCE
VL 45
IS 12
BP 1613
EP 1630
DI 10.1287/mnsc.45.12.1613
PD DEC 1999
PY 1999
AB We study the strategy of bundling a large number of information goods,
   such as those increasingly available on the Internet, and selling them
   for a fixed price. We analyze the optimal bundling strategies for a
   multiproduct monopolist, and we find that bundling very large numbers of
   unrelated information goods can be surprisingly profitable. The reason
   is that the law of large numbers makes it much easier to predict
   consumers' valuations for a bundle of goods than their valuations for
   the individual goods when sold separately. As a result, this "predictive
   value of bundling" makes it possible to achieve greater sales, greater
   economic efficiency, and greater profits per good from a bundle of
   information goods than can be attained when the same goods are sold
   separately. Our main results do not extend to most physical goods, as
   the marginal costs of production for goods not used by the buyer
   typically negate any benefits from the predictive value of large-scale
   bundling.
   While determining optimal bundling strategies for more than two goods is
   a notoriously difficult problem, we use statistical techniques to
   provide strong asymptotic results and bounds on profits for bundles of
   any arbitrary size. We show how our model can be used to analyze the
   bundling of complements and substitutes, bundling in the presence of
   budget constraints, and bundling of goods with various types of
   correlations and how each of these conditions can lead to limits on
   optimal bundle size. In particular we find that when different market
   segments of consumers differ systematically in their valuations for
   goods, simple bundling will no longer be optimal. However, by offering a
   menu of different bundles aimed at each market segment, bundling makes
   traditional price discrimination strategies more powerful by reducing
   the role of unpredictable idiosyncratic components of valuations. The
   predictions of our analysis appear to be consistent with empirical
   observations of the markets for Internet and online content, cable
   television programming, and copyrighted music.
RI Brynjolfsson, Erik/H-2412-2012; Bakos, Yannis/P-8841-2019
ZR 0
ZA 0
Z8 17
ZB 3
ZS 2
TC 434
Z9 450
SN 0025-1909
UT WOS:000085030900001
ER

PT J
AU Van Mieghem, JA
   Dada, M
TI Price versus production postponement: Capacity and competition
SO MANAGEMENT SCIENCE
VL 45
IS 12
BP 1631
EP 1649
DI 10.1287/mnsc.45.12.1631
PD DEC 1999
PY 1999
AB This article presents a comparative analysis of possible postponement
   strategies in a two-stage decision model where firms make three
   decisions: capacity investment, production (inventory) quantity, and
   price. Typically, investments are made while the demand curve is
   uncertain. The strategies differ in the timing of the operational
   decisions relative to the realization of uncertainty.
   We show how competition, uncertainty, and the timing of operational
   decisions influence the strategic investment decision of the firm and
   its value. In contrast to production postponement, price postponement
   makes the investment and production (inventory) decisions relatively
   insensitive to uncertainty. This suggests that managers can make optimal
   capacity decisions by deterministic reasoning if they have some price
   flexibility. Under price postponement, additional postponement of
   production has relatively small incremental value. Therefore, it may be
   worthwhile to consider flexible ex-post pricing before production
   postponement reengineering. While more postponement increases firm
   value, it is counterintuitive that this also makes the optimal capacity
   decision more sensitive to uncertainty. We highlight the different
   impact of more timely information, which leads to higher investment and
   inventories, and of reduced demand uncertainty, which decreases
   investment and inventories. Our analysis suggests appropriateness
   conditions for simple make-to-stock and make-to-order strategies. We
   also present technical sufficiency and uniqueness conditions. Under
   price postponement, these results extend to oligopolistic and perfect
   competition for which pure equilibria are derived. Interestingly, the
   relative value of operational postponement techniques seems to increase
   as the industry becomes more competitive.
ZS 1
ZB 0
TC 193
ZA 0
Z8 1
ZR 0
Z9 194
SN 0025-1909
EI 1526-5501
UT WOS:000085030900002
ER

PT J
AU Krishnan, TV
   Bass, FM
   Jain, DC
TI Optimal pricing strategy for new products
SO MANAGEMENT SCIENCE
VL 45
IS 12
BP 1650
EP 1663
DI 10.1287/mnsc.45.12.1650
PD DEC 1999
PY 1999
AB Robinson and Lakhani (1975) initiated a long research stream In
   marketing when they used the Bass model (1969) to develop optimal
   pricing path for a new product. A careful analysis of the extant
   literature reveals that the research predominantly suggests that the
   optimal price path should be largely based on the sales growth pattern.
   However, in the real world we rarely find new products that have such
   pricing pattern. We observe either a monotonically declining pricing
   pattern or an increase-decrease pricing pattern that does not seem close
   to the sales path. In this paper, we use a variation of the generalized
   Bass model (called GEM) developed by Bass et al. (1994) that yields
   optimal pricing policies that are consistent with empirical data.
ZS 0
ZR 0
Z8 8
ZA 0
TC 113
ZB 1
Z9 119
SN 0025-1909
UT WOS:000085030900003
ER

PT J
AU Schultz, KL
   Juran, DC
   Boudreau, JW
TI The effects of low inventory on the development of productivity norms
SO MANAGEMENT SCIENCE
VL 45
IS 12
BP 1664
EP 1678
DI 10.1287/mnsc.45.12.1664
PD DEC 1999
PY 1999
AB Low inventory, a crucial part of just-in-time (JIT) manufacturing
   systems, enjoys increasing application worldwide, vet the behavioral
   effects of such systems remain largely unexplored. Operations research
   (OR) models of low-inventory systems typically use a simplifying
   assumption that processing times of individual workers are independent
   random variables. This leads to predictions that low-inventory systems
   will exhibit production interruptions leading to lower productivity. Yet
   empirical results suggest that low-inventory systems do not exhibit the
   predicted productivity losses. This paper develops a model integrating
   feedback, goal setting, group cohesiveness, task norms, and peer
   pressure to predict how individual behavior may adjust to alleviate
   production interruptions in low-inventory systems. In doing so we
   integrate previous research on the development of task norms. Operations
   research models are used to show how norms can significantly improve
   throughput by decreasing variance and increasing the speed of the
   slowest workers, even if accompanied by decreases in speed of the
   fastest workers. Findings suggest that low-inventory systems induce
   individual and group responses that cause behavioral changes that
   mitigate production interruptions.
ZR 0
ZA 0
Z8 0
ZB 0
ZS 1
TC 52
Z9 52
SN 0025-1909
EI 1526-5501
UT WOS:000085030900004
ER

PT J
AU Chen, FR
TI 94%-effective policies for a two-stage serial inventory system with
   stochastic demand
SO MANAGEMENT SCIENCE
VL 45
IS 12
BP 1679
EP 1696
DI 10.1287/mnsc.45.12.1679
PD DEC 1999
PY 1999
AB A two-stage inventory system is considered where Poisson demand occurs
   at Stage I, and Stage 1 replenishes its inventory from Stage 2, which in
   turn orders from an outside supplier with unlimited stock. Each
   shipment, either to Stage 2 or to Stage 1, incurs a fixed setup cost.
   Under the assumption that the supply leadtime at Stage 2 is zero, we
   characterize a simple heuristic policy whose long-run average cost is
   guaranteed to be within 6% of optimality, i.e., a 94%-effective policy.
   The paper also provides heuristic policies for more general inventory
   systems and reports computational results.
ZA 0
TC 12
ZS 0
Z8 0
ZR 0
ZB 0
Z9 12
SN 0025-1909
UT WOS:000085030900005
ER

PT J
AU Ehtamo, H
   Hamalainen, RP
   Heiskanen, P
   Teich, J
   Verkama, M
   Zionts, S
TI Generating pareto solutions in a two-party setting: Constraint proposal
   methods
SO MANAGEMENT SCIENCE
VL 45
IS 12
BP 1697
EP 1709
DI 10.1287/mnsc.45.12.1697
PD DEC 1999
PY 1999
AB This paper presents a class of methods, called constraint proposal
   methods, for generating Pareto-optimal solutions in two-party
   negotiations. In these methods joint tangents of the decision makers'
   value functions are searched by adjusting an artificial plane
   constraint. The problem of generating Pareto-optimal solutions
   decomposes into ordinary multiple criteria decision-making problems for
   the individual decision makers and into a coordination problem for an
   assisting mediator. Depending on the numerical iteration scheme used to
   solve the coordination problem, different constraint proposal methods
   are obtained. We analyze and illustrate the behaviour of some iteration
   schemes by numerical examples using both precise and imprecise answers
   from decision makers. An example of a method belonging to the class
   under study is the RAMONA method, that has been previously described
   from a practical point of view. We present the underlying theory for it
   by describing it as a constraint proposal method, and include some
   applications.
OI Hamalainen, Raimo/0000-0002-4285-0092
TC 52
ZS 0
ZR 0
ZB 0
Z8 0
ZA 0
Z9 52
SN 0025-1909
UT WOS:000085030900006
ER

PT J
AU Chowdhury, SD
   Duncan, GT
   Krishnan, R
   Roehrig, SF
   Mukherjee, S
TI Disclosure detection in multivariate categorical databases: Auditing
   confidentiality protection through two new matrix operators
SO MANAGEMENT SCIENCE
VL 45
IS 12
BP 1710
EP 1723
DI 10.1287/mnsc.45.12.1710
PD DEC 1999
PY 1999
AB As databases grow more prevalent and comprehensive, database
   administrators seek to limit disclosure of confidential information
   while still providing access to data. Practical databases accommodate
   users with heterogeneous needs for access. Each class of data user is
   accorded access to only certain views. Other views are considered
   confidential, and hence to be protected. Using illustrations from health
   care and education, this article addresses inferential disclosure of
   confidential views in multidimensional categorical databases. It
   demonstrates that any structural, so data-value-independent method for
   detecting disclosure can fail. Consistent with previous work for two-way
   tables, it presents a data-value-dependent method to obtain tight lower
   and upper bounds for confidential data values. For two-dimensional
   projections of categorical databases, it exploits the network structure
   of a linear programming (LP) formulation to develop two transportation
   flow algorithms that are both computationally efficient and insightful.
   These algorithms can be easily implemented through two new matrix
   operators, cell-maxima and cell-minima. Collectively, this method is
   called matrix comparative assignment (MCA). Finally, it extends both the
   LP and MCA approaches to inferential disclosure when accessible views
   have been masked.
ZS 0
ZB 0
ZA 0
ZR 0
Z8 0
TC 33
Z9 33
SN 0025-1909
UT WOS:000085030900007
ER

PT J
AU Clark, E
   Jokung, O
TI A note on asset proportions, stochastic dominance, and the 50% rule
SO MANAGEMENT SCIENCE
VL 45
IS 12
BP 1724
EP 1727
DI 10.1287/mnsc.45.12.1724
PD DEC 1999
PY 1999
AB In this note we analyze the composition of an optimal portfolio by
   considering the cumulative conditional expected outcome of two dependent
   assets. We develop a conditional stochastic dominance relation and show
   that for any concave von Neumann-Morgenstern utility function, the
   proportion of wealth invested in the dominant asset will be greater than
   50%.
ZB 0
ZA 0
ZS 0
TC 12
Z8 0
ZR 0
Z9 12
SN 0025-1909
UT WOS:000085030900008
ER

PT J
AU Harstad, RM
   Rothkopf, MH
TI An "alternating recognition" model of English auctions
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 1
EP 12
DI 10.1287/mnsc.46.1.1.15128
PD JAN 2000
PY 2000
AB We present an alternative abstraction of an English (oral ascending)
   auction to the standard, in Milgrom and Weber (1982), that accords more
   closely with practices in some auction markets. In particular, the
   assumptions that exits are irrevocable and necessarily public are
   dropped, making endogenous the decision to compete silently and
   privately, or openly. In the model, the price rises in a stylization of
   an auctioneer alternately recognizing two bidders who affirm willingness
   to pay the current price. The auctioneer pays attention to other bidders
   only when a recognized bidder exits. Such exits may be temporary,
   although we construct an equilibrium in which there is no benefit to
   exit and reentry. The number of public exits is stochastic; frequently a
   losing "bidder" will remain silent, giving no indication of his
   willingness to pay, and hence yielding no useful inference about his
   private information. Thus, the source of the expected revenue advantage
   of English auctions over second-price auctions is only stochastically
   available. Moreover, when public exits are incomplete, the ordinal rank
   of the bidder whose private information can be inferred is unknown,
   making that information less valuable. Consequently, the Simpler formula
   for expected revenue in second-price auctions may be the preferred
   approximation for English auctions.
ZB 0
Z8 0
ZA 0
ZR 0
ZS 0
TC 19
Z9 19
SN 0025-1909
UT WOS:000085645700002
ER

PT J
AU Russo, JE
   Meloy, MG
   Wilks, TJ
TI Predecisional distortion of information by auditors and salespersons
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 13
EP 27
DI 10.1287/mnsc.46.1.13.15127
PD JAN 2000
PY 2000
AB As people are deciding between two alternatives, they may distort new
   information to support whichever alternative is tentatively preferred.
   The presence of such predecisional distortion of information was tested
   in decisions made by two groups of professionals, auditors and
   salespersons. Both groups exhibited substantial distortion of
   information, with Little reduction for professional decisions compared
   to nonprofessional ones. However, auditors' distortion was significantly
   smaller than that of salespersons. In addition, holding professionals
   accountable for their decisions, akin to a supervisory review, lowered
   distortion somewhat for salespersons but not at all for auditors. The
   latter seemed to act as if they were always being held accountable.
   Because people seem unaware that they are distorting information, at
   least at the moment this bias is occurring, they are fully convinced of
   the soundness of their choices. This may make it difficult for
   distortion to be detected by decision makers themselves or even by
   supervisors who cannot completely duplicate their subordinate's
   knowledge.
ZS 0
ZA 0
Z8 0
ZR 0
TC 76
ZB 10
Z9 76
SN 0025-1909
UT WOS:000085645700003
ER

PT J
AU Sinclair, G
   Klepper, S
   Cohen, W
TI What's experience got to do with it? Sources of cost reduction in a
   large specialty chemicals producer
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 28
EP 45
DI 10.1287/mnsc.46.1.28.15133
PD JAN 2000
PY 2000
AB Conventional learning curves relating unit cost to measures of
   production experience are estimated for 221 specialty chemicals produced
   by a Fortune 500 company. Detailed records on cost and R&D coupled with
   insights from company personnel are used to explain the variation across
   products in the rate of cost reduction. Products that exhibited the
   strongest relationship between unit cost and measures of production
   experience were subject to specific initiatives, particularly process
   R&D. The R&D was not, however, generally motivated or informed, by
   production experience. However, cumulative past output, the most
   commonly used measure of production experience, was related to expected
   future output, which conditioned the expected future returns from R&D
   and the choice of R&D projects. Thus, cumulative output was connected to
   unit costs through its role in conditioning incentives to undertake
   process R&D rather than as a proxy for production experience. This
   suggests that the strong relationship commonly found between unit cost
   and measures of production experience may reflect incentives to reduce
   cost as much as learning from production experience.
Z8 0
TC 86
ZA 0
ZR 0
ZB 5
ZS 0
Z9 86
SN 0025-1909
UT WOS:000085645700004
ER

PT J
AU Das, SR
   Sundaram, RK
TI A discrete-time approach to arbitrage-free pricing of credit derivatives
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 46
EP 62
DI 10.1287/mnsc.46.1.46.15124
PD JAN 2000
PY 2000
AB This paper develops a framework for modelling risky debt and valuing
   credit derivatives that is flexible and simple to implement, and that
   is, to the maximum extent possible, based on observables. Our approach
   is based on expanding the Heath-Jarrow-Morton term-structure model to
   allow for defaultable debt. Rather than follow the procedure of implying
   out the behavior of spreads from assumptions concerning the default
   process, we work directly with the evolution of spreads. The
   risk-neutral drifts in the resulting model possess a recursive
   representation that facilitates implementation and makes it possible to
   handle path-dependence and early exercise features without difficulty.
   The framework permits embedding a variety of specifications for default;
   we present an empirical example of a default structure which provides
   promising calibration results.
ZS 0
ZB 0
TC 30
Z8 0
ZR 0
ZA 0
Z9 30
SN 0025-1909
EI 1526-5501
UT WOS:000085645700005
ER

PT J
AU Lehner, JM
TI Shifts of reference points for framing of strategic decisions and
   changing risk-return associations
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 63
EP 76
DI 10.1287/mnsc.46.1.63.15130
PD JAN 2000
PY 2000
AB Previous results on nonlinear risk-return associations, predicted by
   prospect theory, are replicated with mean quadratic differences instead
   of variance as a measure of risk. In contrast to assumptions of these
   studies, results with a sample from the COMPUSTAT-database provide
   evidence that at least a minority of firms shift to individual reference
   levels, which are represented here through levels of minimal risk.
   Further, changes of environmental conditions as an alternative
   explanation for switching risk-return relationships are tested against
   prospect theory predictions. It is shown that risk-return relationships
   remain stable as long as the relative position to the individual
   reference level is stable. This explains switching risk-return
   relationships better than changing environmental conditions.
RI Lehner, Johannes M/H-1296-2018
OI Lehner, Johannes M/0000-0003-2947-1685
ZS 0
ZR 0
TC 50
ZB 0
ZA 0
Z8 2
Z9 52
SN 0025-1909
UT WOS:000085645700006
ER

PT J
AU Ha, AY
TI Stock rationing in an M/E-k/1 make-to-stock queue
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 77
EP 87
DI 10.1287/mnsc.46.1.77.15135
PD JAN 2000
PY 2000
AB This paper considers the stock rationing problem of a single-item,
   make-to-stock production system with several demand classes and lost
   sales. When demand is Poisson and processing time has an Erlang
   distribution, we show that a single-state variable called work storage
   level can be employed to completely capture the information regarding
   inventory level and the status of current production. The optimal
   rationing policy can be characterized by a sequence of monotone critical
   work storage levels. For each demand class, there exists a work storage
   level at or below which it is optimal to start rejecting the demand of
   this class in anticipation of future arrival of higher-priority demands.
   The optimal production policy can also be characterized by a critical
   work storage level. Our numerical examples indicate that a critical
   stock level policy, which ignores information on the status of current
   production, performs very well.
ZR 0
ZA 0
TC 89
ZB 0
ZS 0
Z8 3
Z9 92
SN 0025-1909
UT WOS:000085645700007
ER

PT J
AU Fischer, GW
   Luce, MF
   Jia, JM
TI Attribute conflict and preference uncertainty: Effects on judgment time
   and error
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 88
EP 103
DI 10.1287/mnsc.46.1.88.15131
PD JAN 2000
PY 2000
AB This research investigates preference uncertainty generated as a
   function of specific alternative characteristics during multiattribute
   evaluative judgments. We propose that preference uncertainty has at
   least two behavioral manifestations: longer judgment times and greater
   response error in expressed preferences. We investigate two hypotheses
   regarding stimulus-based causes of preference uncertainty. As predicted
   by our attribute conflict hypothesis, greater within-alternative
   conflict (discrepancy among the attributes of an evaluative alternative)
   led to longer judgment times and greater response error. As predicted by
   our attribute extremity hypothesis, greater attribute extremity (very
   high or low attribute values) resulted in shorter judgment times and
   less response error. We also found that judgment times and response
   errors were strongly positively correlated at the item level, consistent
   with our assumption that preference uncertainty generated by stimulus
   characteristics is manifested in judgment time and error. Finally, we
   found that the item-level preference uncertainty effects proposed here
   operate in parallel with strategy-level, effort-accuracy tradeoffs
   observable across participants. These findings are consistent with the
   RandMAU random multiattribute utility model developed in a companion
   article by Fischer et al. (2000).
ZA 0
ZB 2
ZR 0
Z8 0
TC 48
ZS 0
Z9 48
SN 0025-1909
UT WOS:000085645700008
ER

PT J
AU Roundy, RO
   Muckstadt, JA
TI Heuristic computation of periodic-review base stock inventory policies
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 104
EP 109
DI 10.1287/mnsc.46.1.104.15129
PD JAN 2000
PY 2000
AB We study the problem of determining production quantities in each period
   of an infinite horizon for a single item produced in a capacity-limited
   facility. The demand for the product is random, and it is independent
   and identically distributed from period to period. The demand is
   observed at the beginning of a time period, but it need not be filled
   until the end of the period. Unfilled demand is backordered. A base
   stock or order-up-to policy is used. The shortfall is the order-up-to
   level minus the inventory position. The inventory system is easily
   understood and managed if we know the distribution of the shortfall. We
   develop a new approximation for this distribution, and perform extensive
   computational tests of existing approximations. Our new approximation
   works extremely well as long as the coefficient of variation of the
   demand is less than two. Far practical applications this is by far the
   most interesting case; No known approximations work well consistently
   when the coefficient of variation of the demand is greater than two.
ZR 0
ZA 0
TC 24
ZS 0
Z8 0
ZB 0
Z9 24
SN 0025-1909
UT WOS:000085645700009
ER

PT J
AU Mackenzie, KD
TI Processes and their frameworks
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 110
EP 125
DI 10.1287/mnsc.46.1.110.15126
PD JAN 2000
PY 2000
AB A process is a time-dependent sequence of events governed by a process
   framework. A group process has five components: the entities performing
   the process, the steps or elements of a process, the relationship
   between any pair of elements, the links to other processes, and the
   resources and their characteristics-in-use involved with the elements. A
   process framework is denoted by Y = F(C) where Y is the set of outcomes
   or consequences of a process, C is the set of considerations or elements
   in the process, and F is the network linking the considerations to each
   other and to the outcomes. The properties of the set of considerations,
   the linkages between pairs of consequences, the set of outcomes or
   consequences, the network, F, and the use of process frameworks are
   discussed in detail with examples. Process models are compared to
   variable models.
ZB 0
ZA 0
ZS 0
ZR 0
TC 39
Z8 1
Z9 40
SN 0025-1909
UT WOS:000085645700010
ER

PT J
AU Ouorou, A
   Mahey, P
   Vial, JP
TI A survey of algorithms for convex multicommodity flow problems
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 126
EP 147
DI 10.1287/mnsc.46.1.126.15132
PD JAN 2000
PY 2000
AB Routing problems appear frequently when dealing with the operation of
   communication or transportation networks. Among them, the message
   routing problem plays a determinant role in the optimization of network
   performance. Much of the motivation for this work comes from this
   problem which is shown to belong to the class of nonlinear convex
   multicommodity flow problems. This paper emphasizes the message routing
   problem in data networks, but it includes a broader literature overview
   of convex multicommodity flow problems. We present and discuss the main
   solution techniques proposed for solving this class of large-scale
   convex optimization problems. We conduct some numerical experiments on
   the message routing problem with four different techniques.
ZB 0
ZR 0
ZS 4
Z8 2
ZA 0
TC 92
Z9 97
SN 0025-1909
UT WOS:000085645700011
ER

PT J
AU Wolfe, WJ
   Sorensen, SE
TI Three scheduling algorithms applied to the earth observing systems
   domain
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 148
EP 166
DI 10.1287/mnsc.46.1.148.15134
PD JAN 2000
PY 2000
AB This paper describes three approaches to assigning tasks to earth
   observing satellites (EOS). A fast and simple priority dispatch method
   is described and shown to produce acceptable schedules most of the time.
   A look ahead algorithm is then introduced that outperforms the
   dispatcher by about 12% with only a small increase in run time. These
   algorithms set the stage for the introduction of a genetic algorithm
   that uses job permutations as the population. The genetic approach
   presented here is novel in that it uses two additional binary variables,
   one to allow the dispatcher to occasionally skip a job in the queue and
   another to allow the dispatcher to occasionally allocate the worst
   position to the job. These variables are included in the recombination
   step in a natural way. The resulting schedules improve on the look ahead
   by as much as 15% at times and 3% on average. We define and use the
   "window-constrained packing" problem to model the bare bones of the EOS
   scheduling problem.
ZS 0
ZR 0
ZA 0
Z8 62
TC 144
ZB 3
Z9 200
SN 0025-1909
UT WOS:000085645700012
ER

PT J
AU Fare, R
   Grosskopf, S
TI Research note. Decomposing technical efficiency with care
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP 167
EP 168
DI 10.1287/mnsc.46.1.167.15125
PD JAN 2000
PY 2000
RI GROSSKOPF, Shawnax/H-4031-2013; Fare, Rolf/H-5932-2013
ZS 0
Z8 0
ZR 0
ZB 0
TC 14
Z9 14
SN 0025-1909
UT WOS:000085645700013
ER

PT J
AU Hopp, WJ
   Lovejoy, WS
TI Editorial objectives - Manufacturing, distribution, and service
   operations
SO MANAGEMENT SCIENCE
VL 46
IS 1
BP U3
EP U3
PD JAN 2000
PY 2000
Z8 0
ZB 0
ZR 0
ZS 0
TC 0
Z9 0
SN 0025-1909
UT WOS:000085645700001
ER

PT J
AU Iansiti, M
TI How the incumbent can win: Managing technological transitions in the
   semiconductor industry
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 169
EP 185
DI 10.1287/mnsc.46.2.169.11922
PD FEB 2000
PY 2000
AB The paper reports on an empirical study of the management of
   technological transitions. It focuses on project-level mechanisms for
   the generation of knowledge through experimentation and for its
   accumulation through individual experience. It proposes a model that
   links these mechanisms to effectiveness in the management of
   revolutionary and evolutionary development approaches. This argument is
   tested with data describing projects conducted by all major competitors
   in the semiconductor industry. Each project was aimed at a technological
   transition, defined as the introduction of a major new generation of
   process technology. The analysis shows substantial differences among
   competitors in the approach taken (i.e., evolutionary vs. revolutionary)
   and results achieved. Additionally, it shows that individual
   organizations can migrate, over time, from evolution to revolution and
   vice versa. The analysis further indicates that accumulating experience
   and generating knowledge through experimentation are significantly
   associated with project performance. While product performance
   improvement through revolution is associated with research experience
   and with parallel experimentation capacity, improvement through
   evolution is associated with project experience and minimum experimental
   iteration time.
ZB 0
TC 58
ZR 0
Z8 4
ZS 0
ZA 0
Z9 62
SN 0025-1909
UT WOS:000086130700001
ER

PT J
AU Venkatesh, V
   Davis, FD
TI A theoretical extension of the Technology Acceptance Model: Four
   longitudinal field studies
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 186
EP 204
DI 10.1287/mnsc.46.2.186.11926
PD FEB 2000
PY 2000
AB The present research develops and tests a theoretical extension of the
   Technology Acceptance Model (TAM) that explains perceived usefulness and
   usage intentions in terms of social influence and cognitive instrumental
   processes. The extended model, referred to as TAM2, was tested using
   longitudinal data collected regarding four different systems at four
   organizations (N = 156), two involving voluntary usage and two involving
   mandatory usage. Model constructs were measured at three points in time
   at each organization: preimplementation, one month postimplementation,
   and three months postimplementation. The extended model was strongly
   supported for all four organizations at all three points of measurement,
   accounting for 40%-60% of the variance in usefulness perceptions and
   34%-52% of the variance in usage intentions. Both social influence
   processes (subjective norm, voluntariness, and image) and cognitive
   instrumental processes (job relevance, output quality, result
   demonstrability, and perceived ease of use) significantly influenced
   user acceptance. These findings advance theory and contribute to the
   foundation for future research aimed at improving our understanding of
   user adoption behavior.
RI James, Philip John J/H-4651-2012; Holt, Karen/B-6501-2011; Venkatesh, Viswanath/ABD-9343-2020; Bush, Richard G/G-3018-2011; Tavares, Antonio JV/A-7115-2008; Davis, Fred D/A-9842-2008
OI James, Philip John J/0000-0003-1851-9778; 
Z8 62
ZS 75
ZR 2
ZB 153
TC 6502
ZA 12
Z9 6626
SN 0025-1909
UT WOS:000086130700002
ER

PT J
AU Arya, A
   Fellingham, J
   Glover, J
   Sivaramakrishnan, K
TI Capital budgeting, the hold-up problem, and information system design
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 205
EP 216
DI 10.1287/mnsc.46.2.205.11927
PD FEB 2000
PY 2000
AB In this article, we explore the connection between information system
   design and incentives for project search. The choice of an information
   system affects the level of managerial slack that is generated during
   project implementation. Whether slack is beneficial or costly to an
   organization has been the subject of debate. Ln our model of the hold-up
   problem in capital budgeting, there are both costs and benefits to
   having managerial slack. The cost of slack is the consumption of
   perquisites by the manager. The benefit of slack is that it can serve as
   a motivational tool. The possibility of increasing his slack may
   encourage a self-interested manager to conduct a more diligent search
   for a profitable project. To trade off the costs and benefits of slack
   in our model, an optimal information system sometimes incorporates
   coarse information, late information, and a mix of monitored and
   self-reported information. These features are familiar to accountants.
   Accounting incorporates both verified (monitored) and unverified
   (self-reported) information and provides information that is aggregated
   (coarse) and historical (late).
ZR 0
ZA 0
Z8 0
ZB 0
TC 25
ZS 0
Z9 25
SN 0025-1909
UT WOS:000086130700003
ER

PT J
AU Cetinkaya, S
   Lee, CY
TI Stock replenishment and shipment scheduling for vendor-managed inventory
   systems
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 217
EP 232
DI 10.1287/mnsc.46.2.217.11923
PD FEB 2000
PY 2000
AB Vendor-managed inventory (VMI) is a supply-chain initiative where the
   supplier is authorized to manage inventories of agreed-upon
   stock-keeping units at retail. locations. The benefits of VMI are well
   recognized by successful retail businesses such as Wal-Mart. In VMI,
   distortion of demand information (known as bullwhip effect) transferred
   from the downstream supply-chain member (e.g., retailer) to the upstream
   member (e.g., supplier) is minimized, stockout situations ape less
   frequent, and inventory-carrying costs are reduced. Furthermore, a VMI
   supplier has the liberty of controlling the downstream resupply
   decisions rather than filling orders as they are placed. Thus, the
   approach offers a framework for synchronizing inventory and
   transportation decisions.
   In this paper, we present an analytical model for coordinating inventory
   and transportation decisions in VMI systems. Although the coordination
   of inventory and transportation has been addressed in the literature,
   our particular problem has not been explored previously. Specifically,
   we consider a vendor realizing a sequence of random demands from a group
   of retailers located in a given geographical region. ideally, these
   demands should be shipped immediately. However, the vendor has the
   autonomy of holding small orders until an agreeable dispatch time with
   the expectation that an economical consolidated dispatch quantity
   accumulates. As a result, the actual inventory requirements at the
   vendor are partly dictated by the parameters of the shipment-release
   policy in use. We compute the optimum replenishment quantity and
   dispatch frequency simultaneously. We develop a renewal-theoretic model
   for the case of Poisson demands, and present analytical results.
RI Weller, Matt J/E-8421-2010
ZA 0
ZB 2
ZR 0
Z8 47
ZS 3
TC 320
Z9 370
SN 0025-1909
UT WOS:000086130700004
ER

PT J
AU Karni, E
   Mongin, P
TI On the determination of subjective probability by choices
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 233
EP 248
DI 10.1287/mnsc.46.2.233.11929
PD FEB 2000
PY 2000
AB The paper explores the uniqueness properties of the subjective
   probabilities in two axiomatizations of state-dependent preferences
   Karni, Schmeidler, and Vind's (KSV 1983) system depends on selecting an
   arbitrary auxiliary probability, and as such, does not guarantee the
   uniqueness of the derived subjective probability. However, an axiom
   system initially designed by Karni and Schmeidler (KS 1981) and further
   elaborated upon here does guarantee the desired uniqueness as well as a
   useful property of "stability" of the derived solution. When the
   preference relation displays state-independence, even the KS
   probabilities may not agree with those derived from the classic
   Anscombe-Aumann (AA 1963) theorem. However, we claim that, in this case,
   the KS rather than the AA probabilities are the appropriate
   representation of the agent's beliefs.
Z8 0
ZB 0
ZR 0
TC 26
ZS 0
ZA 0
Z9 26
SN 0025-1909
UT WOS:000086130700005
ER

PT J
AU Cooper, LG
   Giuffrida, G
TI Turning datamining into a management science tool: New algorithms and
   empirical results
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 249
EP 264
DI 10.1287/mnsc.46.2.249.11932
PD FEB 2000
PY 2000
AB This article develops and illustrates a new knowledge discovery
   algorithm tailored to the action requirements of management science
   applications. The challenge is to develop tactical planning forecasts at
   the SKU level. We use a traditional market-response model to extract
   information from continuous variables and use datamining techniques on
   the residuals to extract information from the many-valued nominal
   variables, such as the manufacturer or merchandise category. This
   combination means that a more complete array of information can be used
   to develop tactical planning forecasts. The method is illustrated using
   records of the aggregate sales during promotion events conducted by a
   95-store retail chain in a single trading area. In a longitudinal cross
   validation, the statistical forecast (PromoCast(TM)) predicted the exact
   number of cases of merchandise needed in 49% of the promotion events and
   was within +/- one case in 82% of the events. The dataminer developed
   rules from an independent sample of 1.6 million observations and applied
   these rules to almost 460,000 promotion events in the validation
   process. The dataminer had sufficient confidence to make recommendations
   on 46% of these forecasts. In 66% of those recommendations, the
   dataminer indicated that the forecast should not be changed. In 96% of
   those promotion events where "no change" was recommended, this was the
   correct "action" to take. Even including these "no change"
   recommendations, the dataminer decreased the case error by 9% across all
   promotion events in which rules applied.
RI GIUFFRIDA, Giovanni/AAN-3229-2020
OI GIUFFRIDA, Giovanni/0000-0001-5490-779X
ZB 0
TC 28
ZA 0
ZR 0
Z8 2
ZS 0
Z9 30
SN 0025-1909
EI 1526-5501
UT WOS:000086130700006
ER

PT J
AU Carrillo, JE
   Gaimon, C
TI Improving manufacturing performance through process change and knowledge
   creation
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 265
EP 288
DI 10.1287/mnsc.46.2.265.11925
PD FEB 2000
PY 2000
AB A model is introduced to guide a profit maximizing firm in its quest to
   enhance performance through process change. The key benefit sought from
   process change is a long term increase in effective capacity. However,
   realizing success from process change is not trivial. First, while
   process change may increase effective capacity in the long run, the
   disruptions during implementation typically reduce short term capacity.
   Second, competitive forces such as decreasing revenue streams and
   shrinking product life cycles complicate the implementation of process
   change. Third, while knowledge may enhance the ultimate benefits derived
   from process change, the correct timing and means of knowledge creation
   are difficult to discern. Lastly, a variety of trade-offs must be
   evaluated when selecting the particular process change to pursue. For
   example, choices range from hardware and software replacements to
   modification of manufacturing procedures.
   The model introduced here explicitly considers both the short term loss
   due to disruption and the long term gain in effective capacity
   associated with the process change. In addition, investments in the
   accumulation of knowledge are investigated for their potential to
   enhance process change effectiveness. Knowledge is generated from
   investment in preparation and training (learning-before-doing) and as a
   by-product of process change (learning-by-doing). Analysis of the model
   provides managerial recommendations for several key decisions relating
   to process change implementation including: (i) the selection of an
   appropriate process change alternative, (ii) the rate and timing for
   investment in process change, and (iii) the rate and timing for
   investment in preparation and training. New results are reported
   reflecting the important relationship between process change and
   knowledge. For example, we show that under certain conditions, a firm
   should optimally delay investment in process change until sufficient
   accumulation of knowledge is achieved. More generally, we identify
   conditions whereby investment in process change occurs at an increasing
   rate over time. This result is particularly important since it
   demonstrates a limitation of the existing literature where process
   change always occurs at a decreasing rate.
RI Wang, Charles/B-5565-2011
OI Wang, Charles/0000-0001-9331-8437
ZR 1
TC 79
Z8 1
ZB 1
ZS 1
ZA 0
Z9 81
SN 0025-1909
UT WOS:000086130700007
ER

PT J
AU Gotoh, JY
   Konno, H
TI Third degree stochastic dominance and mean-risk analysis
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 289
EP 301
DI 10.1287/mnsc.46.2.289.11928
PD FEB 2000
PY 2000
AB In their recent article, Ogryczak and Ruszczynski (1999) proved that
   those portfolios associated with the efficient frontiers generated by
   mean-lower semi-standard deviation model and mean- (lower semi-)absolute
   deviation model are efficient in the sense of second degree stochastic
   dominance. This rather surprising result reveals the importance of lower
   partial risk models in portfolio analysis.
   In this paper, we extend the results of Ogryczak and Ruszczynski for
   second degree stochastic dominance to third degree stochastic dominance.
   We show that portfolios on a significant portion of the efficient
   frontier generated by mean-lower semi-skewness model are efficient in
   the sense of third degree stochastic dominance. Also, we prove that the
   portfolios generated by mean-variance-skewness model are semi-efficient
   in the sense of third degree stochastic dominance.
RI Gotoh, Jun-ya/D-4290-2011; Gotoh, Jun-ya/
OI Gotoh, Jun-ya/0000-0002-0097-7298
ZA 0
TC 29
ZS 0
Z8 7
ZR 0
ZB 3
Z9 36
SN 0025-1909
UT WOS:000086130700008
ER

PT J
AU Hill, RR
   Reilly, CH
TI The effects of coefficient correlation structure in two-dimensional
   knapsack problems on solution procedure performance
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 302
EP 317
DI 10.1287/mnsc.46.2.302.11930
PD FEB 2000
PY 2000
AB This paper presents the results of an empirical study of the effects of
   coefficient correlation structure and constraint slackness settings on
   the performance of solution procedures on synthetic two-dimensional
   knapsack problems (2KP). The population correlation structure among 2KP
   coefficients, the level of constraint slackness, and the type of
   correlation (product moment or rank) are varied in this study.
   Representative branch-and-bound and heuristic solution procedures are
   used to investigate the influence of these problem parameters on
   solution procedure performance. Population correlation structure, and in
   particular the interconstraint component of the correlation structure,
   is found to be a significant factor influencing the performance of both
   the algorithm and the heuristic. In addition, the interaction between
   constraint slackness and population correlation structure is found to
   influence solution procedure performance.
ZA 0
Z8 1
ZR 0
ZS 0
ZB 0
TC 30
Z9 31
SN 0025-1909
EI 1526-5501
UT WOS:000086130700009
ER

PT J
AU Stadtler, H
TI Improved rolling schedules for the dynamic single-level lot-sizing
   problem
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 318
EP 326
DI 10.1287/mnsc.46.2.318.11924
PD FEB 2000
PY 2000
AB A major argument for favoring simple lot-sizing heuristics-like the
   Silver/Meal or Groff's heuristic-to solve instances of the dynamic
   single-level uncapacitated lot-sizing problem (SLLSP) instead of exact
   algorithms-like those of Wagner/Whitin or Federgruen/Tzur-is that exact
   algorithms applied in a rolling horizon environment are heuristics too
   and may be outperformed by simple heuristics.
   This article shows how to modify the model of the SLLSP by looking
   beyond the planning horizon. Extensive tests within a rolling horizon
   environment have demonstrated that the modified model solved by an exact
   algorithm now performs at least as well as well-known heuristics and is
   fairly insensitive to the length of the planning horizon.
   Furthermore, our principal idea of improving rolling schedules by
   considering only a portion of the fixed cost related to a decision with
   an impact on periods beyond the planning horizon is applicable to a wide
   range of decision models.
ZA 0
Z8 1
ZR 0
ZB 0
TC 60
ZS 0
Z9 61
SN 0025-1909
UT WOS:000086130700010
ER

PT J
AU Chen, KD
   Hausman, WH
TI Technical note: Mathematical properties of the optimal product line
   selection problem using choice-based conjoint analysis
SO MANAGEMENT SCIENCE
VL 46
IS 2
BP 327
EP 332
DI 10.1287/mnsc.46.2.327.11931
PD FEB 2000
PY 2000
AB Selecting and pricing product lines is an essential activity in many
   businesses, in recent years, quantitative approaches for such tasks have
   been gaining in popularity. One often-employed method is to use data
   from traditional rankings/ratings-based conjoint analysis and attack the
   product line selection problem with enumeration or heuristics. In this
   note, we employ a relatively new methodology known as choice-based
   conjoint analysis (to model customer preferences) and investigate its
   mathematical properties when used to model the product line selection
   problem. Despite some inherent limitations resulting from its aggregated
   formulation, we show that this more parsimonious conjoint approach has
   some special mathematical properties that lead to an efficient optimal
   algorithm to tackle the product line/price selection problem. As a
   result, problems of realistic size can be solved efficiently using
   standard, commercially available mathematical programming codes.
RI Murphy, Kyle C./B-2358-2010
OI Murphy, Kyle C./0000-0002-4077-6239
ZS 0
TC 84
ZA 0
Z8 7
ZR 0
ZB 0
Z9 91
SN 0025-1909
UT WOS:000086130700011
ER

PT J
AU Behrens, DA
   Caulkins, JP
   Tragler, G
   Feichtinger, G
TI Optimal control of drug epidemics: Prevent and treat - But not at the
   same time?
SO MANAGEMENT SCIENCE
VL 46
IS 3
BP 333
EP 347
DI 10.1287/mnsc.46.3.333.12068
PD MAR 2000
PY 2000
AB Drug use and related problems change substantially over time, so it
   seems plausible that drug interventions should vary too. To investigate
   this possibility, we set up a continuous time version of the first-order
   difference equation model of cocaine use introduced by Everingham and
   Rydell (1994), extended to make initiation an endogenous function of
   prevalence. We then formulate and solve drug treatment and prevention
   spending decisions in the framework of dynamic optimal control under
   different assumptions about how freely drug control budgets can be
   manipulated. Insights include: (1) The effectiveness of prevention and
   treatment depend critically on the stage in the epidemic in which they
   are employed. Prevention is most appropriate when there are relatively
   few heavy users, e.g. in the beginning of an epidemic. Treatment is more
   effective later. (2) Hence, the optimal mix of interventions varies over
   time. (3) The transition period when it is optimal to use extensively
   both prevention and treatment is brief. (4) Total social costs increase
   dramatically if control is delayed.
ZA 0
ZB 3
Z8 0
ZR 0
ZS 0
TC 38
Z9 38
SN 0025-1909
EI 1526-5501
UT WOS:000086283700001
ER

PT J
AU Zhang, ZJ
   Krishna, A
   Dhar, SK
TI The optimal choice of promotional vehicles: Front-loaded or rear-loaded
   incentives?
SO MANAGEMENT SCIENCE
VL 46
IS 3
BP 348
EP 362
DI 10.1287/mnsc.46.3.348.12062
PD MAR 2000
PY 2000
AB We examine the key factors that influence a firm's decision whether to
   use front-loaded or rear-loaded incentives. When using price packs,
   direct mail coupons, FSI coupons or peel-off coupons, consumers obtain
   an immediate benefit upon purchase or a front-loaded incentive. However,
   when buying products with in-pack coupons or products affiliated with
   loyalty programs, promotion incentives are obtained on the next purchase
   occasion or later, i.e., a rear-loaded incentive. Our analysis shows
   that the innate choice process of consumers in a market (variety-seeking
   or inertia) is an important determinant of the relative impact of
   front-loaded and rear-loaded promotions. While in both variety-seeking
   and inertial markets, the sales impact and the sales on discount are
   higher for front-loaded promotions than for rear-loaded promotions, from
   a profitability perspective, rear-loaded promotions may be better than
   front-loaded promotions. We show that in markets with high
   variety-seeking it is more profitable for a firm to rear-load, and in
   markets with high inertia it is more profitable to front-load. Model
   implications are verified using two empirical studies: (a) a
   longitudinal experiment (simulating markets with variety-seeking
   consumers and inertial consumers) and (b) market data on promotion
   usage. The data in both studies are consistent with the model
   predictions.
Z8 1
TC 57
ZR 1
ZB 1
ZS 0
ZA 0
Z9 59
SN 0025-1909
UT WOS:000086283700002
ER

PT J
AU Park, K
   Lee, K
   Park, S
   Lee, H
TI Telecommunication node clustering with node compatibility and network
   survivability requirements
SO MANAGEMENT SCIENCE
VL 46
IS 3
BP 363
EP 374
DI 10.1287/mnsc.46.3.363.12066
PD MAR 2000
PY 2000
AB We consider the node clustering problem that arises in designing a
   survivable two-level telecommunication network. The problem
   simultaneously determines an optimal partitioning of the whole network
   into clusters (local networks) and hub locations in each cluster.
   Intercluster traffic minimization is chosen as the clustering criterion
   to improve the service quality. Various constraints on the clustering
   are considered which reflect both the physical structures of local
   networks, such as the connectivity requirement, and the node
   compatibility relations such as community of interest or policy.
   Additional constraints may be imposed on the hub selection to ensure
   network survivability. We propose an integer programming formulation of
   the problem by decomposing the entire problem into a master problem and
   a number of column generation problems. The master problem is solved by
   column generation and the column generation problems by branch-and-cut.
   We develop and use strong cutting-planes for the cluster generation
   subproblems. Computational results using real data are reported.
RI Park, Sungsoo/C-2007-2011; Lee, Heesang/
OI Park, Sungsoo/0000-0001-8226-4955; Lee, Heesang/0000-0002-2796-6126
ZA 0
ZS 0
ZB 0
ZR 0
Z8 0
TC 22
Z9 22
SN 0025-1909
UT WOS:000086283700003
ER

PT J
AU Zhao, W
   Zheng, YS
TI Optimal dynamic pricing for perishable assets with nonhomogeneous demand
SO MANAGEMENT SCIENCE
VL 46
IS 3
BP 375
EP 388
DI 10.1287/mnsc.46.3.375.12063
PD MAR 2000
PY 2000
AB We consider a dynamic pricing model for selling a given stock of a
   perishable product over a finite time horizon. Customers, whose
   reservation price distribution changes over time, arrive according to a
   nonhomogeneous Poisson process. We show that at any given time, the
   optimal price decreases with inventory. We also identify a sufficient
   condition under which the optimal price decreases over time for a given
   inventory level. This sufficient condition requires that the willingness
   of a customer to pay a premium for the product does not increase over
   time. In addition to shedding managerial insight, these structural
   properties enable efficient computation of the optimal policy.
   Numerical studies are conducted to show the revenue impact of dynamic
   price policies. Price changes are set to compensate for statistical
   fluctuations of demand and to respond to shifts of the reservation
   price. For the former, our examples show that using optimal dynamic
   optimal policies achieves 2.4-7.3% revenue improvement over the optimal
   single price policy. For the latter, the revenue increase can be as high
   as 100%. These results explain why yield management has become so
   essential to fashion retailing and travel service industries.
ZB 1
ZR 0
ZS 0
ZA 0
TC 251
Z8 36
Z9 285
SN 0025-1909
UT WOS:000086283700004
ER

PT J
AU Hazen, G
TI Preference factoring for stochastic trees
SO MANAGEMENT SCIENCE
VL 46
IS 3
BP 389
EP 403
DI 10.1287/mnsc.46.3.389.12067
PD MAR 2000
PY 2000
AB Stochastic trees are extensions of decision trees that facilitate the
   modeling of temporal uncertainties. Their primary application has been
   to medical treatment decisions. It is often convenient to present
   stochastic trees in factored form, allowing loosely coupled pieces of
   the model to be formulated and presented separately. Ln this paper, we
   show how the notion of factoring can be extended as well to preference
   components of the stochastic model. We examine updateable-state utility,
   a flexible class of expected utility models that permit stochastic trees
   to be rolled back much in the manner of decision trees. We show that
   preference summaries for updateable-state utility can be factored out of
   the stochastic tree. In addition, we examine utility decompositions
   which can arise when factors in a stochastic tree are treated as
   attributes in a multiattribute utility function.
RI Hazen, Gordon/B-7463-2009
ZA 0
Z8 0
ZS 0
ZR 0
ZB 0
TC 11
Z9 11
SN 0025-1909
EI 1526-5501
UT WOS:000086283700005
ER

PT J
AU Schweitzer, ME
   Cachon, GP
TI Decision bias in the newsvendor problem with a known demand
   distribution: Experimental evidence
SO MANAGEMENT SCIENCE
VL 46
IS 3
BP 404
EP 420
DI 10.1287/mnsc.46.3.404.12070
PD MAR 2000
PY 2000
AB In the newsvendor problem a decision maker orders inventory before a one
   period selling season with stochastic demand. If too much is ordered,
   stock is left over at the end of the period, whereas if too little is
   ordered, sales are lost. The expected profit-maximizing order quantity
   is well known, but little is known about how managers actually make
   these decisions. We describe two experiments that investigate newsvendor
   decisions across different profit conditions. Results from these studies
   demonstrate that choices systematically deviate from these that maximize
   expected profit. Subjects order too few of high-profit products and too
   many of low-profit products. These results are not consistent with
   risk-aversion, risk-seeking preferences, Prospect Theory preferences,
   waste aversion, stockout aversion, or the consequences of
   underestimating opportunity costs. Two explanations are consistent with
   the data. One, subjects behave as if their utility function incorporates
   a preference to reduce ex-post inventory error, the absolute difference
   between the chosen quantity and realized demand. Two, subjects suffer
   from the anchoring and insufficient adjustment bias. Feedback and
   training did not mitigate inventory order errors. We suggest techniques
   to improve decision making.
ZS 0
ZR 0
Z8 84
TC 498
ZA 0
ZB 4
Z9 579
SN 0025-1909
UT WOS:000086283700006
ER

PT J
AU Doerr, KH
   Klastorin, TD
   Magazine, MJ
TI Synchronous unpaced flow lines with worker differences and overtime cost
SO MANAGEMENT SCIENCE
VL 46
IS 3
BP 421
EP 435
DI 10.1287/mnsc.46.3.421.12064
PD MAR 2000
PY 2000
AB In this paper, we consider the design of a synchronous, unpaced how line
   where workers operate at different skill levels and overtime is used, if
   necessary, to meet a daily production quota. The line is unpaced in the
   sense that items only move to the next workstation when all workers on
   the line have completed their respective tasks. The design problem in
   this case is to assign both workers and tasks to workstations to
   minimize the expected sum of regular and overtime costs. To solve this
   problem, we develop an optimization algorithm for smaller problems and a
   heuristic algorithm for larger problems, which we use to investigate the
   sensitivity of total expected cost to changes in the price of overtime,
   hiring practices, worker differences, and the overall amount of work
   time variability. Based on an extensive computational analysis, we found
   that (1) planned overtime is frequently beneficial, (2) more workers
   should be hired as worker variability increases, and (3) increases in
   overtime costs frequently yield a relatively lower percentage increase
   in total expected cost. Other managerial implications are discussed in
   the paper.
OI Doerr, Kenneth/0000-0002-7763-7304
ZB 0
ZR 0
TC 18
ZS 0
ZA 0
Z8 0
Z9 18
SN 0025-1909
UT WOS:000086283700007
ER

PT J
AU Chen, F
   Drezner, Z
   Ryan, JK
   Simchi-Levi, D
TI Quantifying the bullwhip effect in a simple supply chain: The impact of
   forecasting, lead times, and information
SO MANAGEMENT SCIENCE
VL 46
IS 3
BP 436
EP 443
DI 10.1287/mnsc.46.3.436.12069
PD MAR 2000
PY 2000
AB An important observation in supply chain management, known as the
   bullwhip effect, suggests that demand variability increases as one moves
   up a supply chain In this payer we quantify this effect for simple,
   two-stage supply chains consisting of a single retailer and a single
   manufacturer. Our model includes two of the factors commonly assumed to
   cause the bullwhip effect: demand forecasting and order lead times. We
   extend these results to multiple-stage supply chains with and without
   centralized customer demand information and demonstrate that the
   bullwhip effect can be reduced, but not completely eliminated, by
   centralizing demand information.
RI Chen, Frank Youhua/K-9156-2015; Weller, Matt J/E-8421-2010; Ryan, Jennifer/
OI Chen, Frank Youhua/0000-0003-4707-9361; Ryan,
   Jennifer/0000-0002-8045-8614
ZB 6
ZR 0
ZS 8
TC 998
ZA 0
Z8 116
Z9 1121
SN 0025-1909
UT WOS:000086283700008
ER

PT J
AU Corbett, CJ
   de Groote, X
TI A supplier's optimal quantity discount policy under asymmetric
   information
SO MANAGEMENT SCIENCE
VL 46
IS 3
BP 444
EP 450
DI 10.1287/mnsc.46.3.444.12065
PD MAR 2000
PY 2000
AB In the supply-chain literature, an increasing body of work studies how
   suppliers can use incentive schemes such as quantity discounts to
   influence buyers' ordering behaviour, thus reducing the supplier's (and
   the total supply chain's) costs. Various functional forms for such
   incentive schemes have been proposed, but a critical assumption always
   made is that the supplier has full information about the buyer's cost
   structure. We derive the optimal quantity discount policy under
   asymmetric information and compare it to the situation where the
   supplier has full information.
RI corbett, charles j/B-2454-2008
OI corbett, charles j/0000-0003-1814-3977
ZS 0
ZR 0
Z8 71
TC 348
ZB 0
ZA 0
Z9 417
SN 0025-1909
UT WOS:000086283700009
ER

PT J
AU Harter, DE
   Krishnan, MS
   Slaughter, SA
TI Effects of process maturity on quality, cycle time, and effort in
   software product development
SO MANAGEMENT SCIENCE
VL 46
IS 4
BP 451
EP 466
DI 10.1287/mnsc.46.4.451.12056
PD APR 2000
PY 2000
AB The information technology (IT) industry is characterized by rapid
   innovation and intense competition. To survive, IT firms must develop
   high quality software products on time and at low cost. A key issue is
   whether high levels of quality can be achieved without adversely
   impacting cycle time and effort. Conventional beliefs hold that
   processes to improve software quality can be implemented only at the
   expense of longer cycle times and greater development effort. However,
   an alternate view is that quality improvement, faster cycle time, and
   effort reduction can be simultaneously attained by reducing defects and
   rework. In this study, we empirically investigate the relationship
   between process maturity, quality, cycle time, and effort for the
   development of 30 software products by a major IT firm. We find that
   higher levels of process maturity as assessed by the Software
   Engineering Institute's Capability Maturity Model(TM) are associated
   with higher product quality, but also with increases in development
   effort. However, our findings indicate that the reductions in cycle time
   and effort due to improved quality outweigh the increases from achieving
   higher levels of process maturity. Thus, the net effect of process
   maturity is reduced cycle time and development effort.
TC 238
ZR 0
ZS 5
ZB 1
Z8 2
ZA 0
Z9 245
SN 0025-1909
UT WOS:000087312800002
ER

PT J
AU Lee, HL
   Padmanabhan, V
   Taylor, TA
   Whang, SJ
TI Price protection in the personal computer industry
SO MANAGEMENT SCIENCE
VL 46
IS 4
BP 467
EP 482
DI 10.1287/mnsc.46.4.467.12058
PD APR 2000
PY 2000
AB Price protection is a commonly used practice between manufacturers and
   retailers in the personal computer (PC) industry, motivated by drastic
   declines of product values during the product life cycle. It is a form
   of rebate given by the manufacturer to the retailer for units unsold at
   the retailer when the price drops during the product life cycle. It is a
   controversial policy in the PC industry because it is not clear how such
   a policy benefits the supply chain and its participants. We show that
   price protection is an instrument for channel coordination. For products
   with long manufacturing lead times, so the retailer has a single buying
   opportunity, a properly chosen price protection credit coordinates the
   channel. For products with shorter manufacturing lead times, so the
   retailer has two buying opportunities, price protection alone cannot
   guarantee channel coordination when wholesale prices are exogenous.
   However, when the price protection credit is set endogenously together
   with the wholesale prices, channel coordination is restored. In the
   two-buying-opportunity setting with fixed wholesale prices, we show that
   price protection has two primary impacts: (1) shifting sales forward in
   time and (2) increasing total sales. Finally, we present a simple
   numerical example that suggests, given the current economics of the PC
   industry, that price protection under fixed wholesale prices may benefit
   the total chain and the retailer but hurt the manufacturer.
RI Padmanabhan, V./B-3659-2010; Padmanabhan, Vineet/
OI Padmanabhan, Vineet/0000-0002-5571-839X
Z8 14
ZA 0
ZS 0
TC 97
ZR 0
ZB 1
Z9 111
SN 0025-1909
UT WOS:000087312800003
ER

PT J
AU Dewan, R
   Freimer, M
   Seidmann, A
TI Organizing distribution channels for information goods on the Internet
SO MANAGEMENT SCIENCE
VL 46
IS 4
BP 483
EP 495
DI 10.1287/mnsc.46.4.483.12053
PD APR 2000
PY 2000
AB Rapid technological developments and deregulation of the
   telecommunications industry have changed the way in which content
   providers distribute and price their goods and services. Instead of
   selling a bundle of content and access through proprietary networks,
   these firms are shifting their distribution channels to the Internet. In
   this new setting, the content and Internet service providers find
   themselves in a relationship that is simultaneously cooperative and
   competitive. We find that proprietary content providers prefer the
   Internet channels to direct channels only if the access market is
   sufficiently competitive. Furthermore, maintaining a direct channel in
   addition to the Internet channels changes the equilibrium enough that
   the proprietary content providers prefer having the Internet channels,
   regardless of the level of competition in the access market.
   Telecommunications technology developments uniformly increase content
   providers' profit. On the other hand, the technology impact on Internet
   service provider profits is nonmonotonic: Their profits may increase or
   decrease as a result of lower telecommunication costs. While initially
   the ISP profit increases as more customers are drawn to the Internet, it
   eventually decreases as the spatial competition becomes more intense. We
   also show that proprietary content providers should benefit from having
   some free content available at the Internet service providers' sites to
   induce more customers to join the Internet.
Z8 1
TC 29
ZA 0
ZB 0
ZR 0
ZS 0
Z9 30
SN 0025-1909
EI 1526-5501
UT WOS:000087312800004
ER

PT J
AU Kim, N
   Chang, DR
   Shocker, AD
TI Modeling intercategory and generational dynamics for a growing
   information technology industry
SO MANAGEMENT SCIENCE
VL 46
IS 4
BP 496
EP 512
DI 10.1287/mnsc.46.4.496.12059
PD APR 2000
PY 2000
AB Previous studies dealing with product growth have dealt only with
   substitution effects among successive generations of one product
   category and not with complementarity and competition provided by
   related product categories.
   Based on a broadened concept of the competitive information technology
   (IT) market, we develop a dynamic market growth model that is able to
   incorporate both interproduct category and technological substitution
   effects simultaneously. The market potential for each category or
   generation is treated as a variable rather than a constant parameter,
   which is typical of recently growing IT sectors such as wireless
   telecommunications. The model is calibrated, its plausibility discussed,
   and its face and predictive validity assessed using data on wireless
   telecommunications services from two Asian markets.
   Results show that the market potential (and sales growth) of one
   category or generation is significantly affected by others and by the
   overall structure of a geographic market. The model is shown to make
   relatively good predictions even when the data from recently introduced
   categories/generations are limited.
RI Chang, Dae Ryun/AAC-1184-2019; KIM, Namwoon/
OI Chang, Dae Ryun/0000-0002-2224-7421; KIM, Namwoon/0000-0001-8884-9241
ZB 1
TC 66
ZS 0
ZR 0
ZA 0
Z8 3
Z9 69
SN 0025-1909
UT WOS:000087312800005
ER

PT J
AU Mendelson, H
TI Organizational architecture and success in the information technology
   industry
SO MANAGEMENT SCIENCE
VL 46
IS 4
BP 513
EP 529
DI 10.1287/mnsc.46.4.513.12060
PD APR 2000
PY 2000
AB This paper studies an organizational architecture that I call
   information-age architecture. I define a measure of organizational IQ
   and test whether it is related to financial and market success using
   data from the fast-moving information technology industry. Higher
   organizational IQ is associated with higher profitability and growth.
   This relationship is stronger in business environments that are
   characterized by faster clockspeeds.
ZS 1
ZA 1
Z8 1
ZR 0
TC 112
ZB 0
Z9 114
SN 0025-1909
EI 1526-5501
UT WOS:000087312800006
ER

PT J
AU Anderson, MC
   Banker, RD
   Ravindran, S
TI Executive compensation in the information technology industry
SO MANAGEMENT SCIENCE
VL 46
IS 4
BP 530
EP 547
DI 10.1287/mnsc.46.4.530.12055
PD APR 2000
PY 2000
AB An innovative business practice attributed to the information technology
   (IT) industry is the aggressive use of employee stock options to
   compensate executives and other employees. In this study, we investigate
   whether the greater use of stock options in the IT industry can be
   explained on the basis of general economic relationships that apply to
   firms in all industries. To examine differences in compensating top
   executives, we estimate a system of simultaneous equations that is
   designed to accommodate interconnections between performance, the level
   of compensation, and the mix of compensation components. We document
   that the shares of both bonus and option pay increase with performance
   and that the pay level and the extent of incentive pay positively affect
   firm performance. We identify economic factors that may influence the
   use of options and show that there are significant differences in these
   factors between IT and other industries. We find that, while much of the
   greater use of options by IT firms is explained by the economic factors,
   significant residual differences remain. We also find that, when
   performance and other factors are considered, the level of executive pay
   in the IT industry is not higher than in other industries.
TC 80
ZB 0
ZR 0
ZA 0
ZS 0
Z8 2
Z9 82
SN 0025-1909
UT WOS:000087312800007
ER

PT J
AU Dewan, S
   Kraemer, KL
TI Information technology and productivity: Evidence from country-level
   data
SO MANAGEMENT SCIENCE
VL 46
IS 4
BP 548
EP 562
DI 10.1287/mnsc.46.4.548.12057
PD APR 2000
PY 2000
AB This paper studies a key driver of the demand for the products and
   services of the global IT industry-returns from IT investments. We
   estimate an intercountry production function relating IT and non-IT
   inputs to GDP output, on panel data from 36 countries over the 1985-1993
   period. We find significant differences between developed and developing
   countries with respect to their structure of returns from capital
   investments. For the developed countries in the sample, returns from IT
   capital investments are estimated to be positive and significant, while
   returns from non-IT capital investments are not commensurate with
   relative factor shares. The situation is reversed for the developing
   countries subsample, where returns from non-IT capital are quite
   substantial, but those from IT capital investments are not statistically
   significant. We estimate output growth contributions of IT and non-IT
   capital and discuss the contrasting policy implications for capital
   investment by developed and developing economies.
TC 313
ZA 0
Z8 5
ZS 2
ZR 1
ZB 2
Z9 319
SN 0025-1909
UT WOS:000087312800008
ER

PT J
AU Brynjolfsson, E
   Smith, MD
TI Frictionless commerce? A comparison of Internet and conventional
   retailers
SO MANAGEMENT SCIENCE
VL 46
IS 4
BP 563
EP 585
DI 10.1287/mnsc.46.4.563.12061
PD APR 2000
PY 2000
AB here have been many claims that the Internet represents a new nearly
   "frictionless market." Our research empirically analyzes the
   characteristics of the Internet as a channel for two categories of
   homogeneous products-books and CDs. Using a data set of over 8,500 price
   observations collected over a period of 15 months, we compare pricing
   behavior at 41 Internet and conventional retail outlets.
   We find that prices on the Internet are 9-16% lower than prices in
   conventional outlets, depending on whether taxes, shipping, and shopping
   costs are included in the price. Additionally, we find that Internet
   retailers' price adjustments over time are up to 100 times smaller than
   conventional retailers' price adjustments-presumably reflecting lower
   menu costs in Internet channels. We also find that levels of price
   dispersion depend importantly on the measures employed. When we compare
   the prices posted by different Internet retailers we find substantial
   dispersion. Internet retailer prices differ by an average of 33% for
   books and 25% for CDs. However, when we weight these prices by proxies
   for market share, we find dispersion is lower in Internet channels than
   in conventional channels, reflecting the dominance of certain heavily
   branded retailers.
   We conclude that while there is lower friction in many dimensions of
   Internet competition, branding, awareness, and trust remain important
   sources of heterogeneity among Internet retailers.
RI Brynjolfsson, Erik/H-2412-2012; Smith, Michael/B-7307-2008; Smith, Michael/
OI Smith, Michael/0000-0002-6706-9382
ZS 11
ZB 9
ZR 0
Z8 37
TC 995
ZA 0
Z9 1040
SN 0025-1909
EI 1526-5501
UT WOS:000087312800009
ER

PT J
AU Kelly, F
   Steinberg, R
TI A combinatorial auction with multiple winners for universal service
SO MANAGEMENT SCIENCE
VL 46
IS 4
BP 586
EP 596
DI 10.1287/mnsc.46.4.586.12054
PD APR 2000
PY 2000
AB We describe a discrete-time auction procedure called PAUSE (Progressive
   Adaptive User Selection Environment) for use in assigning COLR (Carrier
   of Last Resort) responsibility for universal service. The auction
   incorporates synergies by permitting all combinatorial bids, is
   transparent to the bidders, allows for multiple winners, and minimizes
   the possibility of bidder collusion. The procedure is computationally
   tractable for the auctioneer and thus very efficient to run. The
   inherent computational complexity of combinatorial bidding cannot be
   eliminated. However, in this auction the computational burden of
   evaluating synergies rests with the bidders claiming those synergies,
   while the auctioneer simply checks that a bid is valid.
ZB 0
TC 67
ZS 0
ZR 0
Z8 7
ZA 0
Z9 74
SN 0025-1909
UT WOS:000087312800010
ER

PT J
AU Mendelson, H
   Whang, SJ
TI Introduction to the special issue on the information technology industry
SO MANAGEMENT SCIENCE
VL 46
IS 4
BP I
EP III
DI 10.1287/mnsc.46.4.i
PD APR 2000
PY 2000
ZR 0
ZB 0
Z8 0
ZA 0
ZS 0
TC 6
Z9 6
SN 0025-1909
EI 1526-5501
UT WOS:000087312800001
ER

PT J
AU Lapre, MA
   Mukherjee, AS
   Van Wassenhove, LN
TI Behind the learning curve: Linking learning activities to waste
   reduction
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 597
EP 611
DI 10.1287/mnsc.46.5.597.12049
PD MAY 2000
PY 2000
AB This exploratory research on a decade of Total Quality Management in one
   factory opens up the black box of the learning curve. Based on the
   organizational learning literature, we derive a quality learning curve
   that links different types of learning in quality improvement projects
   to the evolution of the factory's waste rate. Only 25% of the quality
   improvement projects-which acquired both know-why and
   know-how-accelerated waste reduction. The other 75% of the projects
   either impeded or did not affect waste reduction. In complex and dynamic
   production environments, locally acquired knowledge is difficult to
   disseminate. The combination of know-why and know-how facilitates its
   dissemination.
RI Levy, Yair/A-4759-2009; Lapre, Michael/
OI Lapre, Michael/0000-0003-2259-8739
ZA 0
TC 201
ZR 0
ZB 2
Z8 5
ZS 2
Z9 207
SN 0025-1909
UT WOS:000087565200001
ER

PT J
AU Rulke, DL
   Galaskiewicz, J
TI Distribution of knowledge, group network structure, and group
   performance
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 612
EP 625
DI 10.1287/mnsc.46.5.612.12052
PD MAY 2000
PY 2000
AB This study investigates the effect of knowledge distribution and group
   structure on performance in MBA game teams. We found that group
   performance was contingent on the distribution of knowledge within the
   group and networks of social relationships among group members. Studying
   39 teams of MBA students in two management simulation games, we found
   that, in general, groups that had broadly distributed knowledge, i.e.,
   groups made up of members who had general knowledge, outperformed groups
   that had knowledge concentrated in different members, i.e., groups made
   up of members who had specialized or both specialized and general
   knowledge. However, the advantage that the former enjoyed over the
   latter disappeared when groups of specialists or mixed groups had
   decentralized network structures.
ZS 0
TC 175
Z8 3
ZB 3
ZR 0
ZA 0
Z9 177
SN 0025-1909
UT WOS:000087565200002
ER

PT J
AU Lee, HL
   So, KC
   Tang, CS
TI The value of information sharing in a two-level supply chain
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 626
EP 643
DI 10.1287/mnsc.46.5.626.12047
PD MAY 2000
PY 2000
AB Many companies have embarked on initiatives that enable more demand
   information sharing between retailers and their upstream suppliers.
   While the literature on such initiatives in the business press is
   proliferating, it is not clear how one can quantify the benefits of
   these initiatives and how one can identify the drivers of the magnitudes
   of these benefits. Using analytical models, this paper aims at
   addressing these questions for a simple two-level supply chain with
   nonstationary end demands. Our analysis suggests that the value of
   demand information sharing can be quite high, especially when demands
   are significantly correlated over time.
RI Weller, Matt J/E-8421-2010; tang, christopher/
OI tang, christopher/0000-0001-9597-7620
ZS 6
ZB 11
ZR 0
Z8 103
ZA 0
TC 1081
Z9 1185
SN 0025-1909
UT WOS:000087565200003
ER

PT J
AU Feng, YY
   Xiao, BC
TI A continuous-time yield management model with multiple prices and
   reversible price changes
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 644
EP 657
DI 10.1287/mnsc.46.5.644.12050
PD MAY 2000
PY 2000
AB This article studies a continuous-time yield management model in which
   reversible price changes are allowed. We assume that perishable assets
   are offered at a set of discrete price levels. Demand at each level is a
   Poisson process. To maximize the expected revenue, management controls
   the price dynamically as sales evolve. We show that a subset of these
   prices that form a concave envelope is potentially optimal. We formulate
   the problem into an intensity control model and derive the optimal
   solution in closed form. Properties of the optimal solution and their
   policy implementations are discussed. Numerical examples are provided.
RI Escarabajal, Juan Antonio/C-5644-2012
ZR 0
TC 107
Z8 33
ZA 0
ZS 0
ZB 1
Z9 136
SN 0025-1909
UT WOS:000087565200004
ER

PT J
AU Lioui, A
   Poncet, P
TI The minimum variance hedge ratio under stochastic interest rates
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 658
EP 668
DI 10.1287/mnsc.46.5.658.12045
PD MAY 2000
PY 2000
AB In an environment where interest rates are stochastic, we examine the
   case of a "pure" hedger endowed with a fixed position in a long term
   bond. In contrast to conventional wisdom according to which the
   difference between hedging through forward contracts and futures is
   immaterial, it turns out that the minimum variance hedge ratio using
   forwards comprises two terms instead of one only when using futures. The
   magnitude of the difference between the two hedge ratios may be
   important under some plausible assumptions. This result is due to the
   presence of additional interest rate risk that bears on the
   profit-and-loss statement associated with the forward position. This
   sheds some additional light on the respective features of forward and
   futures contracts written on interest rate-sensitive securities.
ZS 0
TC 12
ZA 0
Z8 0
ZR 0
ZB 0
Z9 12
SN 0025-1909
UT WOS:000087565200005
ER

PT J
AU Fischer, GW
   Jia, JM
   Luce, MF
TI Attribute conflict and preference uncertainty: The RandMAU model
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 669
EP 684
DI 10.1287/mnsc.46.5.669.12051
PD MAY 2000
PY 2000
AB This paper extends the behavioral results reported in Fischer et al.
   (2000) by developing a model addressing preference uncertainty in
   multiattribute evaluation. The model is motivated by two hypotheses
   regarding properties of multiattribute profiles that lead to greater
   preference uncertainty. Our attribute conflict hypothesis predicts that
   greater within-alternative conflict (discrepancy among the attributes of
   an alternative) leads to more preference uncertainty. Our attribute
   extremity hypothesis predicts that greater attribute extremity (very
   high or low attribute values) leads to less preference uncertainty. To
   provide a deeper explanation of attribute conflict and extremity
   effects, we develop RandMAU, a family of additive (RandAUF) and
   multiplicative (RandMUF) random weights multiattribute utility models.
   In RandMAU models, preference uncertainty is represented as random
   variation in both the weighting parameters governing trade-offs among
   attributes and the curvature parameters governing single-attribute
   evaluations. Simulation results show that RandMUF successfully predicts
   both the attribute conflict and attribute extremity effects exhibited by
   the experimental participants in Fischer et al. (2000). It also predicts
   an outcome value effect on error whose form depends on the shape of
   single-attribute functions and on the type of multiattribute combination
   rule.
ZS 0
ZB 1
ZA 0
ZR 0
TC 27
Z8 0
Z9 27
SN 0025-1909
UT WOS:000087565200006
ER

PT J
AU Ruefli, TW
   Wiggins, RR
TI Technical note: Longitudinal performance stratification - An iterative
   Kolmogorov-Smirnov approach
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 685
EP 692
DI 10.1287/mnsc.46.5.685.12046
PD MAY 2000
PY 2000
AB The stratification of entities into statistically distinct levels of
   performance over time is a problem encountered in a number of research
   and management settings. Traditional techniques to address this issue
   (e.g., cluster analysis) often require, either ex ante or ex post, the
   exogenous specification of the number of groups to be employed in
   further analysis-and are not especially suited to dealing with
   distributions over time. The methodology presented here iteratively
   applies the Kolmogorov-Smirnov two-sample test to identify the number
   and membership of statistically significantly different performance
   strata on a longitudinal basis. Monte Carlo simulations compare the new
   methodology with traditional clustering techniques. An application that
   stratifies mutual funds by returns illustrates the technique.
ZS 1
Z8 0
ZR 0
ZB 0
TC 13
Z9 13
SN 0025-1909
UT WOS:000087565200007
ER

PT J
AU Mamer, JW
   McBride, RD
TI A decomposition-based pricing procedure for large-scale linear programs:
   An application to the linear multicommodity flow problem
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 693
EP 709
DI 10.1287/mnsc.46.5.693.12042
PD MAY 2000
PY 2000
AB We propose and test a new pricing procedure for solving large-scale
   structured linear programs. The procedure interactively solves a relaxed
   subproblem to identify potential entering basic columns. The subproblem
   is chosen to exploit special structure, rendering it easy to solve. The
   effect of the procedure is the reduction of the number of pivots needed
   to solve the problem. Our approach is motivated by the column-generation
   approach of Dantzig-Wolfe decomposition. We test our procedure on two
   sets of multicommodity flow problems. One group of test problems arises
   in routing telecommunications traffic and the second group is a set of
   logistics problem which have been widely used to test multicommodity
   flow algorithms.
RI Mamer, John/D-9874-2012
ZB 0
ZS 0
ZA 0
ZR 0
Z8 1
TC 29
Z9 30
SN 0025-1909
EI 1526-5501
UT WOS:000087565200008
ER

PT J
AU Sprecher, A
TI Scheduling resource-constrained projects competitively at modest memory
   requirements
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 710
EP 723
DI 10.1287/mnsc.46.5.710.12044
PD MAY 2000
PY 2000
AB We consider the resource-constrained project scheduling problem. The
   purpose of this paper is to direct and focus to a branch-and-bound
   concept that can, by simple adaptations, operate on a wide range of
   problem settings. The general approach can, e.g., deal with multimode
   problems, resource availability varying with time, and a wide range of
   objectives. Even the simple assembly Lint balancing problem of type-1
   can be competitively approached with some modifications. Although the
   algorithm is the most general and simple one currently available for
   resource-constrained project scheduling, the computational performance
   can compete with the best approaches available for the single-mode
   problem. The algorithm uses far less memory than the state-of-the-art
   procedure, i.e., 256 KB versus 24 MB, for solving the standard benchmark
   set with projects consisting of 32 activities within comparable time. if
   both approaches are allowed to make limited use of memory, i.e., 256 KB,
   then more than 97% of the benchmark instances can be solved within
   fractions of the time required by the current state-of-the-art
   procedure. The truncated version of our algorithm achieves at 256 KB
   approximately the results of the truncated version of the
   state-of-the-art approach at 24 MB. Since in general the memory
   requirements exponentially grow with the number of activities the
   project consists of, memory will become a critical resource, and the
   strategy to access previously stored information will gain fundamental
   importance when solving larger projects.
TC 56
ZB 1
ZS 1
ZR 0
ZA 0
Z8 3
Z9 59
SN 0025-1909
UT WOS:000087565200009
ER

PT J
AU Belvaux, G
   Wolsey, LA
TI bc-prod: A specialized branch-and-cut system for lot-sizing problems
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 724
EP 738
DI 10.1287/mnsc.46.5.724.12048
PD MAY 2000
PY 2000
AB bc - prod is a prototype modelling and optimization system designed and
   able to tackle a wide variety of the discrete-time lot-sizing problems
   arising both in practice and in the literature. To use be - prod, the
   user needs to formulate his/her problem as a mixed integer program using
   XPRESS-MP's mp - model, a standard mathematical programming modelling
   language, taking into account a reserved set of key words for specific
   lot-sizing objects, such as production variables, storage, and demand
   data, etc. The problem is then solved by the XPRESS-MP branch-and-bound
   system including lot-sizing specific preprocessing, cutting planes for
   different aspects of lot-sizing problems, plus general cutting planes,
   and a lot-sizing-specific primal heuristic. Results are presented for a
   wide variety of big bucket and small bucket models with set-up and
   start-up costs and times.
ZR 0
Z8 9
ZA 0
TC 103
ZS 0
ZB 0
Z9 111
SN 0025-1909
UT WOS:000087565200010
ER

PT J
AU Song, JS
TI A note on assemble-to-order systems with batch ordering
SO MANAGEMENT SCIENCE
VL 46
IS 5
BP 739
EP 743
DI 10.1287/mnsc.46.5.739.12043
PD MAY 2000
PY 2000
AB We study an assemble-to-order inventory system. The stocks are held for
   components, with final products assembled only when customer orders are
   realized. Customer orders form a multivariate compound Poisson process,
   component replenishment leadtimes are constant, and demands in excess of
   inventory on hand are backlogged. The component inventories are
   controlled by (R, nQ) policies. We show that under certain general
   conditions the inventory position vector has a uniform equilibrium
   distribution. This result generalizes the corresponding single-item
   theory considerably. It allows us to express the key performance
   measures of the system, such as order fill rates and average order-based
   backorders, as the averages of their counterparts in the base-stock
   systems.
Z8 4
ZR 0
ZS 0
ZB 0
ZA 0
TC 30
Z9 34
SN 0025-1909
UT WOS:000087565200011
ER

PT J
AU Krishnan, MS
   Kriebel, CH
   Kekre, S
   Mukhopadhyay, T
TI An empirical analysis of productivity and quality in software products
SO MANAGEMENT SCIENCE
VL 46
IS 6
BP 745
EP 759
DI 10.1287/mnsc.46.6.745.11941
PD JUN 2000
PY 2000
AB We examine the relationship between life-cycle productivity and
   conformance quality in software products. The effects of product size,
   personnel capability, software process, usage of tools, and higher
   front-end investments on productivity and conformance quality were
   analyzed to derive managerial implications based on primary data
   collected on commercial software projects from a leading vendor. Our key
   findings are as follows. First, our results provide evidence for
   significant increases in life-cycle productivity from improved
   conformance quality in software products shipped to the customers. Given
   that the expenditure on computer software has been growing over the last
   few decades, empirical evidence for cost savings through quality
   improvement is a significant contribution to the literature. Second, our
   study identifies several quality drivers in software products. Our
   findings indicate that higher personnel capability, deployment of
   resources in initial stages of product development (especially design)
   and improvements in software development process factors are associated
   with higher quality products.
OI Mukhopadhyay, Tridas/0000-0001-6691-9595
Z8 2
ZA 0
ZS 1
ZB 0
TC 133
ZR 0
Z9 136
SN 0025-1909
UT WOS:000088189100001
ER

PT J
AU van Ryzin, G
   McGill, J
TI Revenue management without forecasting or optimization: An adaptive
   algorithm for determining airline seat protection levels
SO MANAGEMENT SCIENCE
VL 46
IS 6
BP 760
EP 775
DI 10.1287/mnsc.46.6.760.11936
PD JUN 2000
PY 2000
AB We investigate a simple adaptive approach to optimizing seat protection
   levels in airline revenue management systems. The approach uses only
   historical observations of the relative frequencies of certain
   seat-filling events to guide direct adjustments of the seat protection
   levels in accordance with the optimality conditions of Brumelle and
   McGill (1993). Stochastic approximation theory is used to prove the
   convergence of this adaptive algorithm to the optimal protection levels.
   in a simulation study, we compare the revenue performance of this
   adaptive approach to a more traditional method that combines a censored
   forecasting method with a common seat allocation heuristic (EMSR-b).
RI Escarabajal, Juan Antonio/C-5644-2012; McGill, Jeff/
OI McGill, Jeff/0000-0002-1652-9932
ZA 0
Z8 0
TC 73
ZS 0
ZB 0
ZR 0
Z9 73
SN 0025-1909
UT WOS:000088189100002
ER

PT J
AU Baiman, S
   Fischer, PE
   Rajan, MV
TI Information, contracting, and quality costs
SO MANAGEMENT SCIENCE
VL 46
IS 6
BP 776
EP 789
DI 10.1287/mnsc.46.6.776.11939
PD JUN 2000
PY 2000
AB This article analyzes the relation between product quality, the cost of
   quality, and the information that can be contracted upon. We consider a
   setting where a risk neutral supplier sells an intermediate product to a
   risk neutral buyer. The supplier incurs prevention costs to reduce the
   probability of selling a defective product, and the buyer incurs
   appraisal costs to identify defects. Both decisions are subject to moral
   hazard. We show that the first-best outcome can be obtained if either:
   (i) the supplier's prevention decision is contractible; or (ii) the
   buyer's appraisal decision and either internal failure (i.e., the
   product's failing the buyer's appraisal test) or external failure (i.e.,
   the product's failing after being sold by the buyer) are contractible
   events; or (iii) both internal and external failure are contractible
   events. We then focus on the second-best setting where actions and
   failures are not contractible and study the effect of making the buyer's
   appraisal result contractible. Relative to first-best, if a buyer's
   return decision is contractible (but not his appraisal result), the
   supplier incurs lower prevention costs, the buyer incurs higher
   appraisal costs, expected internal failure costs are higher, and the
   total cost of quality is higher. The expected costs of external failure,
   however, may actually be lower relative to first-best. We then show that
   installing an information system that makes the appraisal result
   contractible reduces the inefficiency associated with the seller's
   prevention activity, increases the inefficiency associated with the
   buyer's quality appraisal activity, and unambiguously improves product
   quality.
RI van Lent, Laurence/G-5298-2010
TC 184
ZR 0
ZB 0
ZA 0
ZS 1
Z8 41
Z9 222
SN 0025-1909
UT WOS:000088189100003
ER

PT J
AU Arya, A
   Fellingham, J
   Schroeder, D
TI Accounting information, aggregation, and discriminant analysis
SO MANAGEMENT SCIENCE
VL 46
IS 6
BP 790
EP 806
DI 10.1287/mnsc.46.6.790.11935
PD JUN 2000
PY 2000
AB Aggregation is a pervasive theme in accounting. The preparation of
   financial statements involves extensive aggregation-information
   regarding several transactions is summarized using a few account
   balances. In this article, we study Linear, double-entry aggregation
   rules. The level of aggregation (transactions versus account balance
   information) affects a decision maker's ability to discriminate between
   two entities. We show Brat the orientation of the discriminant function
   relative to the row space and the nullspace (two fundamental subspaces)
   of the double-entry matrix determines the information loss due to
   aggregation. In addition, we observe that an interdependency in account
   balances is introduced by the double-entry process. The cause and effect
   property (debit and credit) translates into a negative covariance being
   introduced among account balances; this, in turn, affects the decision
   maker's optimal use of information. Finally, in discussing benefits to
   aggregation, we present an example in which adopting a double-entry
   aggregation rule serves as a commitment device for the owner.
Z8 0
ZS 0
ZR 0
TC 3
ZA 0
ZB 0
Z9 3
SN 0025-1909
UT WOS:000088189100004
ER

PT J
AU Kuntz, L
   Scholtes, S
TI Measuring the robustness of empirical efficiency valuations
SO MANAGEMENT SCIENCE
VL 46
IS 6
BP 807
EP 823
DI 10.1287/mnsc.46.6.807.11937
PD JUN 2000
PY 2000
AB We study the robustness of empirical efficiency valuations of production
   processes in an extended Farrell model. Based on input and output data,
   an empirical efficiency status-efficient or inefficient-is assigned to
   each of the processes. This status may change if the data of the
   observed processes change. As illustrated by a capacity planning problem
   for hospitals in Germany, the need arises to gauge the robustness of
   empirical efficiency valuations. The example suggests to gauge the
   robustness of the efficiency valuation for a process with respect to
   perturbations of prespecified elements of the data. A natural measure of
   robustness is the minimal perturbation, in terms of a suitable distance
   function, of the chosen data elements that is necessary to change the
   efficiency status of the process under investigation. Farrell's (1957)
   efficiency score is an example of such a robustness measure. We give
   further examples of relevant data perturbations for which the robustness
   measure can be computed efficiently. We then focus on weighted maximum
   norm distance functions, such as the maximal absolute or percentage
   deviation, but allow for independent perturbations of the elements of an
   arbitrary a priori fixed subset of the data. In this setting, the
   robustness measure is naturally related to a certain threshold value for
   a Linear monotone one-parameter family of perturbations and can be
   calculated by means of a Linear programming-based bisection method.
   Closed form solutions in terms of Farrell's efficiency score are
   obtained for specific perturbations, Following the theoretical
   developments, we revisit the hospital capacity planning problem to
   illustrate the managerial relevance of our techniques.
TC 15
Z8 0
ZB 0
ZR 0
ZS 0
ZA 0
Z9 15
SN 0025-1909
UT WOS:000088189100005
ER

PT J
AU Rivkin, JW
TI Imitation of complex strategies
SO MANAGEMENT SCIENCE
VL 46
IS 6
BP 824
EP 844
DI 10.1287/mnsc.46.6.824.11940
PD JUN 2000
PY 2000
AB Researchers examining loosely coupled systems, knowledge management, and
   complementary practices in organizations have proposed, informally, that
   the complexity of a successful business strategy can deter imitation of
   the strategy. This paper explores this proposition rigorously. A simple
   model is developed that parametrizes the two aspects of strategic
   complexity: the number of elements in a strategy and the interactions
   among those elements. The model excludes conventional resource-based and
   game-theoretic barriers to imitation altogether. The model is used to
   show that complexity makes the search for an optimal strategy
   intractable in the technical sense of the word provided by the theory of
   NP-completeness. Consequently, would-be copycats must rely on search
   heuristics or on learning, not on algorithmic "solutions," to match the
   performance of superior firms. However, complexity also undermines
   heuristics and learning, in the face of complexity, firms that follow
   simple hill-climbing heuristics are quickly snared on low "local peaks,"
   and firms that try to learn and mimic a high performer's entire strategy
   suffer large penalties from small errors. The model helps to explain why
   some winning strategies remain unmatched even though they are open to
   public scrutiny; why certain bundles of organizational practices diffuse
   slowly even though they lead to superior performance; and why some
   strategies yield superior returns even after many of their critical
   ingredients are adopted by competitors. The analysis also suggests roles
   for management science and managerial choice in a world of complex
   strategies.
RI Holman, B.J./E-8868-2010; Wang, Charles/B-5565-2011; DEL RIO, MIGUEL ANGEL MONTANES/F-2359-2013
OI Wang, Charles/0000-0001-9331-8437; 
ZB 7
TC 544
ZR 1
ZA 0
ZS 1
Z8 7
Z9 552
SN 0025-1909
UT WOS:000088189100006
ER

PT J
AU Herer, YT
   Raz, T
TI Optimal parallel inspection for finding the first nonconforming unit in
   a batch - An information theoretic approach
SO MANAGEMENT SCIENCE
VL 46
IS 6
BP 845
EP 857
DI 10.1287/mnsc.46.6.845.11933
PD JUN 2000
PY 2000
AB We consider the case of a batch of discrete units produced by a process
   subject to failures under a known probability distribution function, and
   apply information theory to the problem of finding the first
   nonconforming unit in the batch at minimum cost. Two distinct but
   related aspects of this problem were treated: determining which units
   should be inspected, and determining how many units should be sent for
   inspection at the same time. The solution is based on the principles of
   inspecting the product units that maximize the reduction in the
   uncertainty regarding the location of the first nonconforming unit, and
   of minimizing the cost per unit of uncertainty reduced. These principles
   are formalized by means of a series of theorems leading to an
   easy-to-implement algorithm for managing parallel inspection. This
   approach is successfully compared with the optimal solution obtained
   with dynamic programming and with other heuristics.
ZB 0
TC 13
ZR 0
ZA 0
ZS 0
Z8 0
Z9 13
SN 0025-1909
UT WOS:000088189100007
ER

PT J
AU Bogetoft, P
   Tama, JM
   Tind, J
TI Convex input and output projections of nonconvex production possibility
   sets
SO MANAGEMENT SCIENCE
VL 46
IS 6
BP 858
EP 869
DI 10.1287/mnsc.46.6.858.11938
PD JUN 2000
PY 2000
AB In this paper we characterize the smallest production possibility set
   that contains a specified set of (input, output) combinations. In
   accordance with neoclassical production economics, this possibility set
   has convex projections into the input and output spaces (convex
   isoquants), and it satisfies the assumption of free disposability. We
   obtain it by means of a possibly infinite recursion which builds the
   possibility set as an ever larger union of convex Sets. We remark on the
   nature of the approximations obtained by truncating the recursion, and
   we obtain a necessary and sufficient condition, checkable in one
   iteration for the recursion to stop in the next. For the case in which
   the recursion stops, we provide a succinct characterization of the
   dominance relations among the constituent sets produced by the
   procedure. Finally, we present examples of both finite and infinite
   cases. The example for the finite case illustrates the construction of
   the possibility set along with its associated production and consumption
   sets.
Z8 1
TC 35
ZR 0
ZB 0
ZS 1
ZA 0
Z9 36
SN 0025-1909
UT WOS:000088189100008
ER

PT J
AU Ng, MC
TI A remark on third degree stochastic dominance
SO MANAGEMENT SCIENCE
VL 46
IS 6
BP 870
EP 873
DI 10.1287/mnsc.46.6.870.11934
PD JUN 2000
PY 2000
AB This note presents two counterexamples to illustrate that neither
   implication of Theorem 4 in Levy (1992) is correct.
ZA 0
ZR 0
TC 8
Z8 0
ZS 0
ZB 1
Z9 8
SN 0025-1909
UT WOS:000088189100009
ER

PT J
AU So, KC
   Tang, CS
TI Modeling the impact of an outcome-oriented reimbursement policy on
   clinic, patients, and pharmaceutical firms
SO MANAGEMENT SCIENCE
VL 46
IS 7
BP 875
EP 892
DI 10.1287/mnsc.46.7.875.12040
PD JUL 2000
PY 2000
AB Tackling the steep increase in drug costs is an especially important
   issue among many health care providers and insurers. To entice the
   clinics to become more cost efficient, the U.S. federal government, as
   well as many HMOs, have developed various cost containment initiatives
   recently. However, the impact of these initiatives on the patients'
   well-being, the clinic's profitability, and the pharmaceutical firm's
   profitability has nor been formally analyzed. Tn this paper we develop a
   mathematical model that is intended to examine the impact of a
   reimbursement policy for drug usage. Despite the simplistic structure of
   our model, the analysis enhances our understanding of the joint impact
   of the reimbursement policy on the patients, the clinic, and the
   pharmaceutical firm. Thus, our analysis can provide valuable information
   for evaluating the effectiveness of implementing such a reimbursement
   policy. In addition, we utilize the data gathered from a clinic to help
   support the assumptions and results of the underlying model.
OI tang, christopher/0000-0001-9597-7620
ZB 0
ZA 0
ZR 0
ZS 0
Z8 0
TC 15
Z9 15
SN 0025-1909
UT WOS:000088497000001
ER

PT J
AU Schwartz, E
   Smith, JE
TI Short-term variations and long-term dynamics in commodity prices
SO MANAGEMENT SCIENCE
VL 46
IS 7
BP 893
EP 911
DI 10.1287/mnsc.46.7.893.12034
PD JUL 2000
PY 2000
AB In this article, we develop a two-factor model of commodity prices that
   allows mean-reversion in short-term prices and uncertainty in the
   equilibrium level to which prices revert. Although these two factors are
   not directly observable, they may be estimated from spot and futures
   prices. Intuitively, movements in prices for long-maturity futures
   contracts provide information about the equilibrium price level, and
   differences between the prices for the short- and long-term contracts
   provide information about short-term variations in prices. We show that,
   although this model does not explicitly consider changes in convenience
   yields over time, this short-term/long-term model is equivalent to the
   stochastic convenience yield model developed in Gibson and Schwartz
   (1990). We estimate the parameters of the model using prices for oil
   futures contracts and apply the model to some hypothetical oil-linked
   assets to demonstrate its use and some of its advantages over the
   Gibson-Schwartz model.
ZS 9
Z8 15
ZA 0
TC 442
ZB 3
ZR 0
Z9 465
SN 0025-1909
UT WOS:000088497000002
ER

PT J
AU Carr, S
   Lovejoy, W
TI The inverse newsvendor problem: Choosing an optimal demand portfolio for
   capacitated resources
SO MANAGEMENT SCIENCE
VL 46
IS 7
BP 912
EP 927
DI 10.1287/mnsc.46.7.912.12036
PD JUL 2000
PY 2000
AB The classical newsvendor problem is one of optimally choosing a level of
   capacity to respond to a known demand distribution. The inverse
   newsvendor problem is one of optimally choosing a demand distribution
   with fixed capacity. The applications of the inverse problem include
   industrial settings where demand management is relatively less costly
   than capacity adjustments. Demand distributions are chosen from an
   opportunity set, which reflects the set of market opportunities for the
   firm. We analyze the firm's profit as a function of these demand
   alternatives, provide solution methods and insights, and identify
   inefficient and dominated distributions. We provide results when the
   opportunity set is known or only partially known. We extend the results
   to cases in which there are multiple prioritized customer classes that
   share the firm's productive capacity. This paper was motivated by an
   industrial application in a firm selling a semicommodity product into
   three prioritized industrial sectors. We review the application of our
   methods to this setting.
ZS 0
TC 52
ZR 0
ZA 0
ZB 1
Z8 5
Z9 57
SN 0025-1909
UT WOS:000088497000003
ER

PT J
AU Tyagi, RK
TI Sequential product positioning under differential costs
SO MANAGEMENT SCIENCE
VL 46
IS 7
BP 928
EP 940
DI 10.1287/mnsc.46.7.928.12038
PD JUL 2000
PY 2000
AB This paper examines the product positioning decisions of firms that
   enter a market sequentially and that have potentially different cost
   structures. It shows that if the first mover knows the second mover to
   have a lower production cost, it positions away from the most attractive
   location in the market; further, the larger the second-mover's cost
   advantage, the farther away the first mover positions from the most
   attractive location. The payer also models uncertainty in the
   first-mover's mind about the later-entrant's cost structure, and shows
   that an increase in this uncertainty (in the sense of mean-preserving
   spread) also makes the first mover position farther from the most
   attractive location in the market. Overall, this payer suggests that
   unless the first entrant in a market is certain that the later entrant
   will not have a superior cost structure, it may be better off leaving
   the best position in the market vacant and having a niche or fringe
   product.
TC 57
ZR 0
ZA 0
Z8 5
ZS 0
ZB 0
Z9 61
SN 0025-1909
UT WOS:000088497000004
ER

PT J
AU Feng, YY
   Gallego, C
TI Perishable asset revenue management with Markovian time dependent demand
   intensities
SO MANAGEMENT SCIENCE
VL 46
IS 7
BP 941
EP 956
DI 10.1287/mnsc.46.7.941.12035
PD JUL 2000
PY 2000
AB Many industries face the problem of selling a fixed stock of items over
   a finite horizon. These industries include airlines selling seats before
   planes depart, hotels renting rooms before midnight, theaters selling
   seats before curtain time, and retailers selling seasonal items with
   long procurement lead times. Given a sunk investment in seats, rooms, or
   winter coats, the objective for these industries is to maximize revenues
   in excess of salvage value. When demand is price sensitive and
   stochastic, pricing is an effective tool to maximize expected revenues.
   In this paper we address the problem of deciding the optimal timing of
   price changes within a given menu of allowable, possibly time dependent,
   price paths each of which is associated with a general Poisson process
   with Markovian, time dependent, predictable intensities. We show that a
   set of variational inequalities characterize the value functions and the
   optimal (possibly random) time changes. In addition, we develop an
   efficient algorithm to compute the optimal value functions and the
   optimal pricing policy.
RI Escarabajal, Juan Antonio/C-5644-2012
TC 73
ZS 0
ZA 0
Z8 16
ZR 0
ZB 0
Z9 89
SN 0025-1909
UT WOS:000088497000005
ER

PT J
AU Cai, XQ
   Teo, KL
   Yang, XQ
   Zhou, XY
TI Portfolio optimization under a minimax rule
SO MANAGEMENT SCIENCE
VL 46
IS 7
BP 957
EP 972
DI 10.1287/mnsc.46.7.957.12039
PD JUL 2000
PY 2000
AB This paper provides a new portfolio selection rule. The objective is to
   minimize the maximum individual risk and we use an l(infinity) function
   as the risk measure. We provide an explicit analytical solution for the
   model and are thus able to Plot the entire efficient frontier. Our
   selection rule is very conservative. One of the features of the solution
   is that it does not explicitly involve the covariance of the asset
   returns.
RI Yang, Xiaoqi/E-2070-2011; YANG, Xiaoqi/
OI YANG, Xiaoqi/0000-0002-5583-4032
ZA 0
ZR 0
TC 94
Z8 19
ZS 1
ZB 1
Z9 113
SN 0025-1909
UT WOS:000088497000006
ER

PT J
AU Bertazzi, L
   Speranza, MG
   Ukovich, W
TI Exact and heuristic solutions for a shipment problem with given
   frequencies
SO MANAGEMENT SCIENCE
VL 46
IS 7
BP 973
EP 988
DI 10.1287/mnsc.46.7.973.12032
PD JUL 2000
PY 2000
AB We consider the problem of shipping several products from an origin to a
   destination when a discrete set of shipping frequencies is available, in
   such a way that the sum of the transportation and inventory costs is
   minimized. This problem, which is known to be NP-hard, has applications
   in transportation planning and in location analysis. In this paper we
   derive dominance rules for the problem solutions that allow a tightening
   of the bounds on the problem variables and improve the efficiency of a
   known branch-and-bound algorithm. Moreover, we present some heuristics
   and compare them with two different modifications of an EOQ-type
   algorithm for the solution of the problem with continuous frequencies.
OI Speranza, Maria Grazia/0000-0002-8893-5227
Z8 3
TC 14
ZS 0
ZB 0
ZA 0
ZR 0
Z9 17
SN 0025-1909
UT WOS:000088497000007
ER

PT J
AU Arkin, BL
   Leemis, LM
TI Nonparametric estimation of the cumulative intensity function for a
   nonhomogeneous Poisson process from overlapping realizations
SO MANAGEMENT SCIENCE
VL 46
IS 7
BP 989
EP 998
DI 10.1287/mnsc.46.7.989.12037
PD JUL 2000
PY 2000
AB A nonparametric technique for estimating the cumulative intensity
   function of a nonhomogeneous Poisson process from one or more
   realizations on an interval is extended here to include realizations
   that overlap. This technique does not require any arbitrary parameters
   from the modeler, and the estimated cumulative intensity function can be
   used to generate a point process for simulation by inversion.
ZS 1
TC 33
ZA 0
ZR 0
Z8 1
ZB 0
Z9 34
SN 0025-1909
UT WOS:000088497000008
ER

PT J
AU Bertsimas, D
   Perakis, G
   Tayur, S
TI A new algebraic geometry algorithm for integer programming
SO MANAGEMENT SCIENCE
VL 46
IS 7
BP 999
EP 1008
DI 10.1287/mnsc.46.7.999.12033
PD JUL 2000
PY 2000
AB We propose a new algorithm for solving integer programming (IP) problems
   that is based on ideas from algebraic geometry. The method provides a
   natural generalization of the Farkas lemma for IP, leads to a way of
   performing sensitivity analysis, offers a systematic enumeration of all
   feasible solutions, and gives structural information of the feasible set
   of a given IP. We provide several examples that offer insights on the
   algorithm and its properties.
ZA 0
ZR 0
ZB 0
TC 11
ZS 0
Z8 2
Z9 13
SN 0025-1909
UT WOS:000088497000009
ER

PT J
AU Oguz, O
TI Bounds on the opportunity cost of neglecting reoptimization in
   mathematical programming
SO MANAGEMENT SCIENCE
VL 46
IS 7
BP 1009
EP 1012
DI 10.1287/mnsc.46.7.1009.12041
PD JUL 2000
PY 2000
AB Postoptimality or sensitivity analysis are well-developed subjects in
   almost all branches of mathematical programming. In this note, we
   propose a simple formula which can toe used to get preliminary bounds on
   the value of this type of analysis for a specific class of mathematical
   programming problems. We also show that our bounds are tight.
ZB 0
ZA 0
ZS 0
Z8 0
TC 6
ZR 0
Z9 6
SN 0025-1909
UT WOS:000088497000010
ER

PT J
AU Zaric, GS
   Brandeau, ML
   Barnett, PG
TI Methadone maintenance and HIV prevention: A cost-effectiveness analysis
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1013
EP 1031
DI 10.1287/mnsc.46.8.1013.12025
PD AUG 2000
PY 2000
AB We assess the cost-effectiveness of maintenance treatment for heroin
   addiction, with emphasis on its role in preventing HIV infection. The
   analysis is based on a dynamic compartmental model of the HIV epidemic
   among a population of adults, ages 18 to 44. The population is divided
   into nine compartments according to infection status and risk group. The
   model takes into account disease transmission from drug injection and
   sexual contacts. The health benefits of methadone maintenance and the
   resulting HIV infections averted are measured in terms of Life years
   gained and quality-adjusted life years gained. Costs considered include
   all health-care costs (including cost of HIV care and other health care)
   and the cost of methadone maintenance. The analysis shows that expanding
   existing methadone maintenance programs is a cost-effective health-care
   intervention that can play an important role in slowing the spread of
   HIV and improving the length and quality of life for injection drug
   users (IDUs), and that such expansion is cost-effective even in
   populations with low HIV prevalence among IDUs. Incremental expansion of
   methadone maintenance programs was found to have a cost-effectiveness
   ratio of between $9,700 and $17,200 per life year gained, and between
   $6,300 and $10,900 per quality-adjusted Life year gained. Although
   methadone maintenance treatment is provided to IDUs,the analysis shows
   that significant benefits accrue to non-IDU members of the population.
   Sensitivity analysis shows that new methadone maintenance treatment
   slots will be cost-effective even if they are twice as expensive and
   half as effective in reducing risky behavior as current methadone
   maintenance programs.
RI Zaric, Gregory/B-7665-2013
ZR 0
ZB 8
Z8 0
TC 38
ZS 0
ZA 0
Z9 38
SN 0025-1909
EI 1526-5501
UT WOS:000088961000001
ER

PT J
AU Cachon, GP
   Fisher, M
TI Supply chain inventory management and the value of shared information
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1032
EP 1048
DI 10.1287/mnsc.46.8.1032.12029
PD AUG 2000
PY 2000
AB In traditional supply chain inventory management, orders are the only
   information firms exchange, but information technology now allows firms
   to share demand and inventory data quickly and inexpensively. We study
   the value of sharing these data in a model with one supplier, N
   identical retailers, and stationary stochastic consumer demand. There
   are inventory holding: costs and back-order penalty costs. We compare a
   traditional information policy that does not use shared information with
   a full information policy that does exploit shared information. in a
   numerical study we find that supply chain costs are 2.2% lower on
   average with the full information policy than with the traditional
   information policy, and the maximum difference is 12.1%. We also develop
   a simulation-based lower bound over all feasible policies. The cost
   difference between the traditional information policy and the lower
   bound is an upper bound on the value of information sharing: Ln the same
   study, that difference is 3.4% on average, and no more than 13.8%. We
   contrast the value of information sharing with two other benefits of
   information technology, faster and cheaper order processing, which lead
   to shorter lead times and smaller batch sizes, respectively. In our
   sample, cutting lead times nearly in half reduces costs by 21% on
   average, and cutting batches in half reduces costs by 22% on average.
   For the settings we study, we conclude that implementing information
   technology to accelerate and smooth the physical flow of goods through a
   supply chain is significantly more valuable than using information
   technology to expand the flow of information.
RI Weller, Matt J/E-8421-2010
TC 853
ZS 6
ZA 0
Z8 74
ZR 1
ZB 7
Z9 933
SN 0025-1909
UT WOS:000088961000002
ER

PT J
AU Kouvelis, P
   Lariviere, MA
TI Decentralizing cross-functional decisions: Coordination through internal
   markets
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1049
EP 1058
DI 10.1287/mnsc.46.8.1049.12022
PD AUG 2000
PY 2000
AB A firm faces many problems that are inherently cross-functional. To
   solve them successfully requires the coordinated actions of many
   functional representatives acting in a decentralized setting. Functional
   managers, however, respond to their own individual incentives and may
   consequently fail to maximize the overall profits of the firm. We
   examine this issue in a setting in which the output of early actions
   limits the range of later actions, and we propose an incentive scheme
   that allows the system to be successfully decentralized. Our mechanism
   is based on linear transfer prices for the intermediate output that are
   implemented through an internal market; a market maker buys the output
   from one function and sells it to another. She is not obliged to sell at
   the same price at which she bought and may set prices solely to provide
   incentives. We illustrate the flexibility of the scheme by applying it
   to several models in the operations management literature.
RI Lariviere, Martin/AAU-6757-2020; Kouvelis, Panos/ABG-2350-2020
ZS 0
ZB 1
Z8 0
ZR 0
TC 31
ZA 0
Z9 31
SN 0025-1909
UT WOS:000088961000003
ER

PT J
AU Dowell, G
   Hart, S
   Yeung, B
TI Do corporate global environmental standards create or destroy market
   value?
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1059
EP 1074
DI 10.1287/mnsc.46.8.1059.12030
PD AUG 2000
PY 2000
AB Arguments can be made on both sides of the question of whether a
   stringent global corporate environmental standard represents a
   competitive asset or Liability for multinational enterprises (MNEs)
   investing in emerging and developing markets. Analyzing the global
   environmental standards of a sample of U.S.-based MNEs in relation to
   their stock market performance, we find that firms adopting a single
   stringent global environmental standard have much higher market values,
   as measured by Tobin's q, than firms defaulting to less stringent, or
   poorly enforced host country standards. Thus, developing countries that
   use lax environmental regulations to attract foreign direct investment
   may end up attracting poorer quality, and perhaps less competitive,
   firms. Our results also suggest that externalities are incorporated to a
   significant extent in firm valuation. We discuss plausible reasons for
   this observation.
RI Yeung, Bernard/AAV-7146-2020; Hart, Stuart L./R-3764-2019; Yeung, Bernard/B-5759-2016
OI Yeung, Bernard/0000-0002-6902-863X; Yeung, Bernard/0000-0003-0949-6965
Z8 3
ZA 2
ZB 19
ZS 6
TC 537
ZR 1
Z9 548
SN 0025-1909
UT WOS:000088961000004
ER

PT J
AU Raju, JS
   Roy, A
TI Market information and firm performance
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1075
EP 1084
DI 10.1287/mnsc.46.8.1075.12024
PD AUG 2000
PY 2000
AB he value of new information depends on how accurate the information is,
   but it may also depend on the characteristics of the firm and the nature
   of the industry it operates in. We develop a game-theoretic model to
   understand how firm and industry characteristics moderate the effect of
   market information on firm profits. Our results suggest that information
   is more valuable when product substitutability is higher, suggesting
   that information is of greater value in more competitive industries. Our
   results also suggest that although industry size does not affect the
   value of information, information is more valuable for larger firms. We
   find that, except under some conditions, more precise market information
   has a greater impact on profits in a Stackelberg mode of conduct than in
   a Bertrand-Nash mode.
ZR 0
ZS 0
ZA 0
ZB 1
Z8 7
TC 121
Z9 128
SN 0025-1909
UT WOS:000088961000005
ER

PT J
AU Dennis, D
   Meredith, J
TI An empirical analysis of process industry transformation systems
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1085
EP 1099
DI 10.1287/mnsc.46.8.1085.12031
PD AUG 2000
PY 2000
AB recess industries share many characteristics because their
   transformation systems are designed for nondiscrete materials. Hence,
   the process industries typically are lumped together in a general group
   and contrasted from the discrete industries as a whole. The result is a
   poor understanding of the differences between distinct types of process
   industries. In this article, 19 different process industry sites are
   analyzed for the purpose of identifying the key differences between
   their transformation systems. Using cluster analysis, seven major
   subtypes of process industries are identified within the sample: (1)
   process job shop, (2) fast batch, (3) custom blending, (4) stock hybrid,
   (5) custom hybrid, (6) multistage continuous, and (7) rigid continuous.
   It is shown how these seven subtypes differ on the composite dimensions
   of (1) materials diversity, (2) equipment, (3) materials movement, and
   (4) run time. The research and managerial implications of these results
   are discussed.
ZS 0
ZR 0
TC 40
ZA 0
ZB 2
Z8 0
Z9 40
SN 0025-1909
UT WOS:000088961000006
ER

PT J
AU Clemen, RT
   Fischer, GW
   Winkler, RL
TI Assessing dependence: Some experimental results
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1100
EP 1115
DI 10.1287/mnsc.46.8.1100.12023
PD AUG 2000
PY 2000
AB Constructing decision- and risk-analysis probability models often
   requires measures of dependence among variables.;Although data are
   sometimes available to estimate such measures, in many applications they
   must be obtained by means of subjective judgment by experts. We discuss
   two experimental studies that compare the accuracy of six different
   methods for assessing dependence. Our results lead to several
   conclusions: First, simply asking experts to report a correlation is a
   reasonable approach. Direct estimation-is more accurate than the other
   methods studied, is not prone to mathematically inconsistent responses
   (as are some other measures), and is judged to be less difficult than
   alternate methods. In addition, directly assessed correlations showed
   less variability than the correlations derived from other assessment
   methods. Our results also show that experience with the variables can
   improve performance somewhat, as can training in a given assessment
   method. Finally, if a judge uses several different assessment methods,
   an average of the resulting estimates can also lead to better
   performance.
Z8 2
ZS 1
ZR 0
ZB 2
TC 60
ZA 0
Z9 63
SN 0025-1909
UT WOS:000088961000007
ER

PT J
AU Hansen, AT
   Jorgensen, PL
TI Analytical valuation of American-style Asian options
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1116
EP 1136
DI 10.1287/mnsc.46.8.1116.12027
PD AUG 2000
PY 2000
AB This article derives the first analytical pricing formulas for
   American-style Asian options of the so-called floating strike type.
   Geometric as well as arithmetic averaging Is considered. The setup is a
   standard Black-Scholes framework where the price of the underlying
   security evolves according to a geometric Brownian motion. A
   decomposition result that splits up the value of the floating strike
   American option into the price of an otherwise equivalent European
   option and an early exercise premium is first presented. This
   decomposition result is then manipulated further for the two separate
   types of averaging. With geometric averaging we derive an exact pricing
   formula, whereas with arithmetic averaging we develop an analytical
   approximation formula that proves to be very precise. Numerical examples
   are provided.
OI Jorgensen, Peter Lochte/0000-0003-2109-2250
ZR 0
TC 19
ZA 0
ZS 0
Z8 2
ZB 0
Z9 21
SN 0025-1909
UT WOS:000088961000008
ER

PT J
AU Hsu, A
   Wilcox, RT
TI Stochastic prediction in multinomial logit models
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1137
EP 1144
DI 10.1287/mnsc.46.8.1137.12028
PD AUG 2000
PY 2000
AB It is standard practice to form predictions from multinomial logit
   models by ignoring the estimation error associated with the parameter
   estimates and solving for the predicted endogeneous variable (market
   share) in terms of the exogenous variables and the point estimates of
   the parameters. It has long been recognized in the econometrics
   literature that this type of nonstochastic prediction, which ignores the
   sampling distribution of the parameter estimates, leads to incorrect
   inferences about the endogenous variable. We offer a simulation-based
   approach for approximating the exact stochastic prediction. We show that
   this approach provides very accurate approximations with minimal
   computation time and would be easy to implement in industrial
   applications.
ZA 0
ZR 0
ZS 0
ZB 0
TC 8
Z8 0
Z9 8
SN 0025-1909
UT WOS:000088961000009
ER

PT J
AU Fragniere, E
   Gondzio, J
   Sarkissian, R
   Vial, JP
TI A structure-exploiting tool in algebraic modeling languages
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1145
EP 1158
DI 10.1287/mnsc.46.8.1145.12026
PD AUG 2000
PY 2000
AB A new concept is proposed for linking algebraic modeling languages with
   structure-exploiting solvers. SPI (Structure-Passing Interface) is a
   program that retrieves structure new concept is proposed for linking
   algebraic modeling languages with structure from an anonymous
   mathematical program built by an algebraic modeling language. SPI passes
   the special structure of the problem to an SES (Structure-Exploiting
   Solver). An integration of SPI and SES leads to SET
   (Structure-Exploiting Tool) and can be used with any algebraic modeling
   language. This approach relies on the idea that most exploitable block
   structures can be easily detected from the algebraic formulation of
   models. It should enable algebraic modeling languages to access the
   large body of algorithmic techniques which require problem structure.
OI Fragniere, Emmanuel/0000-0001-5373-9720; Fragniere,
   Emmanuel/0000-0001-9628-4543
ZA 0
Z8 0
ZS 0
ZR 0
ZB 0
TC 12
Z9 12
SN 0025-1909
EI 1526-5501
UT WOS:000088961000010
ER

PT J
AU Hsu, VN
TI Dynamic economic lot size model with perishable inventory
SO MANAGEMENT SCIENCE
VL 46
IS 8
BP 1159
EP 1169
DI 10.1287/mnsc.46.8.1159.12021
PD AUG 2000
PY 2000
AB This paper considers an economic lot size (ELS) model for perishable
   products where an inventory stock's deterioration rate and its carrying
   cost in each period depend on the age of the stock. We discuss
   situations where the traditional ELS models are not applicable, and
   propose a new model with general concave production and inventory cost
   functions, We explore the structural properties of the optimal solutions
   and use them to develop a dynamic programming algorithm which solves the
   problem in polynomial time. We also consider special cases of the
   general model which are solvable with reduced computational
   complexities.
TC 58
ZR 0
ZS 0
Z8 6
ZB 1
ZA 0
Z9 64
SN 0025-1909
UT WOS:000088961000011
ER

PT J
AU Akesson, F
   Lehoczky, JP
TI Path generation for quasi-Monte Carlo simulation of mortgage-backed
   securities
SO MANAGEMENT SCIENCE
VL 46
IS 9
BP 1171
EP 1187
PD SEP 2000
PY 2000
AB Monte Carlo simulation is playing an increasingly important role in the
   pricing and hedging of complex, path dependent financial instruments.
   Low discrepancy simulation methods offer the potential to provide faster
   rates of convergence than those of standard Monte Carlo methods;
   however, in high dimensional problems special methods are required to
   ensure that the faster convergence rates hold. Indeed, Ninomiya and
   Tezuka (1996) have shown high-dimensional examples, in which low
   discrepancy methods perform worse than Monte Carlo methods. The
   principal component construction introduced by Acworth et al. (1998)
   provides one solution to this problem. However, the computational effort
   required to generate each path grows quadratically with the dimension of
   the problem. This article presents two new methods that offer accuracy
   equivalent, in terms of explained variability, to the principal
   components construction with computational requirements that are
   Linearly related to the problem dimension. One method is to take into
   account knowledge about the payoff function, which makes it more
   flexible than the Brownian Bridge construction. Numerical results are
   presented that show the benefits of such adjustments. The different
   methods are compared for the case of pricing mortgage backed securities
   using the Hull-White term structure model.
ZR 0
ZS 0
ZB 0
ZA 0
TC 17
Z8 1
Z9 18
SN 0025-1909
EI 1526-5501
UT WOS:000089646300002
ER

PT J
AU Browne, S
TI Risk-constrained dynamic active portfolio management
SO MANAGEMENT SCIENCE
VL 46
IS 9
BP 1188
EP 1199
DI 10.1287/mnsc.46.9.1188.12233
PD SEP 2000
PY 2000
AB Active portfolio management is concerned with objectives related to the
   outperformance of the return of a target benchmark portfolio. In this
   paper, we consider a dynamic active portfolio management problem where
   the objective is related to the tradeoff between the achievement of
   performance goals and the risk of a shortfall. Specifically, we consider
   an objective that relates the probability of achieving a given
   performance objective to the time it takes to achieve the objective.
   This allows a new direct quantitative analysis of the risk/return
   tradeoff, with risk defined directly in terms of probability of
   shortfall relative to the benchmark, and return defined in terms of the
   expected time to reach investment goals relative to the benchmark. The
   resulting optimal policy is a state-dependent policy that provides new
   insights. As a special case, our analysis includes the case where the
   investor wants to minimize the expected time until a given performance
   goal is reached subject to a constraint on the shortfall probability.
Z8 5
ZS 0
ZB 0
TC 39
ZR 2
ZA 0
Z9 44
SN 0025-1909
UT WOS:000089646300003
ER

PT J
AU D'Amato, RM
   D'Aquila, RT
   Wein, LM
TI Management of antiretroviral therapy for HIV infection: Analyzing when
   to change therapy
SO MANAGEMENT SCIENCE
VL 46
IS 9
BP 1200
EP 1213
DI 10.1287/mnsc.46.9.1200.12235
PD SEP 2000
PY 2000
AB We analyze two joint decisions in the management of HIV-infected
   patients on antiretroviral therapy: how frequently to measure a
   patient's virus level, and when to switch therapy. The underlying
   stochastic model captures the initial suppression and eventual rebound
   of the virus level in the blood of a typical HIV-infected patient
   undergoing treatment. We consider two classes of policies: a viral load
   policy, which triggers a change in therapy when the current virus level
   divided by the smallest level achieved thus far exceeds a prespecified
   threshold, and a proactive policy, which is similar to the viral load
   policy but also switches drugs at a prespecified time if no evidence of
   viral rebound has been seen. We find approximate analytical expressions
   for the probability of switching before the virus reaches its nadir
   (minimum value) and the mean delay in detection of viral rebound (i.e.,
   the time interval from when the viral nadir occurs until the switch in
   therapy). Numerical results show that the proactive policy outperforms
   (i.e., a smaller detection delay for a given probability of prenadir
   switching) the viral load policy and recent recommendations by an expert
   AIDS panel, and may delay the onset of multidrug resistance in a
   significant proportion of patients who experience drug failure.
Z8 0
ZR 0
ZB 0
ZS 1
ZA 0
TC 7
Z9 7
SN 0025-1909
UT WOS:000089646300004
ER

PT J
AU L'Ecuyer, P
   Lemieux, C
TI Variance reduction via lattice rules
SO MANAGEMENT SCIENCE
VL 46
IS 9
BP 1214
EP 1235
DI 10.1287/mnsc.46.9.1214.12231
PD SEP 2000
PY 2000
AB This is a review article on lattice methods for multiple integration
   over the unit hypercube, with a variance-reduction viewpoint. It also
   contains some new results and ideas. The aim is to examine the basic
   principles supporting these methods and how they can be used effectively
   for the simulation models that are typically encountered in the area of
   management science. These models can usually be reformulated as
   integration problems over the unit hypercube with a large (sometimes
   infinite) number of dimensions. We examine selection criteria for the
   lattice rules and suggest criteria which take into account the quality
   of the projections of the lattices over selected low-dimensional
   subspaces. The criteria are strongly related to those used for selecting
   linear congruential and multiple recursive random number generators.
   Numerical examples illustrate the effectiveness of the approach.
RI L'Ecuyer, Pierre/O-6577-2019
OI L'Ecuyer, Pierre/0000-0002-3184-0796
ZR 1
ZB 0
TC 81
ZS 0
Z8 0
ZA 0
Z9 82
SN 0025-1909
EI 1526-5501
UT WOS:000089646300005
ER

PT J
AU Resnick, S
   Samorodnitsky, G
TI A heavy traffic approximation for workload processes with heavy tailed
   service requirements
SO MANAGEMENT SCIENCE
VL 46
IS 9
BP 1236
EP 1248
DI 10.1287/mnsc.46.9.1236.12234
PD SEP 2000
PY 2000
AB A system with heavy tailed service requirements under heavy load having
   a single server has an equilibrium waiting time distribution which is
   approximated by the Mittag-Leffler distribution. This fact is understood
   by a direct analysis of the weak convergence of a sequence of negative
   drift random walks with heavy right tail and the associated all time
   maxima of these random walks. This approach complements the recent
   transform view of Boxma and Cohen (1997).
ZS 0
Z8 0
ZB 0
ZR 0
TC 10
Z9 10
SN 0025-1909
EI 1526-5501
UT WOS:000089646300006
ER

PT J
AU Van Mieghem, JA
TI Price and service discrimination in queuing systems: Incentive
   compatibility of Gc mu scheduling
SO MANAGEMENT SCIENCE
VL 46
IS 9
BP 1249
EP 1267
DI 10.1287/mnsc.46.9.1249.12238
PD SEP 2000
PY 2000
AB This article studies the optimal prices and service quality grades that
   a queuing system-the "firm"-provides to heterogeneous,
   utility-maximizing customers who measure quality by their experienced
   delay distributions. Results are threefold: First, delay cost curves are
   introduced that allow for a flexible description of a customer's quality
   sensitivity. Second, a comprehensive executable approach is proposed
   that analytically specifies scheduling, delay distributions and prices
   for arbitrary delay sensitivity curves. The tractability of this
   approach derives from porting heavy-traffic Brownian results into the
   economic analysis. The generalized c mu (Gc mu) scheduling rule that
   emerges is dynamic so that, in general, service grades need not
   correspond to a static priority ranking. A benchmarking example
   investigates the value of differentiated service. Third, the notions of
   grade and rate incentive compatibility (IC) are introduced to study this
   system under asymmetric information and are established for Gc mu
   scheduling when service times are homogeneous and customers atomistic.
   Grade IC induces correct grade choice resulting in perfect service
   discrimination; rate IC additionally induces centralized-optimal rates.
   Dynamic Gc mu scheduling exhibits negative feedback that, together with
   time-dependent pricing, can also yield rate incentive compatibility with
   heterogeneous service times. Finally, multiplan pricing, which offers
   all customers a menu with a choice of multiple rate plans, is analyzed.
ZA 0
Z8 0
ZS 0
TC 71
ZR 0
ZB 1
Z9 71
SN 0025-1909
UT WOS:000089646300007
ER

PT J
AU Glasserman, P
TI Introduction to the special issue on stochastic models and simulation
SO MANAGEMENT SCIENCE
VL 46
IS 9
BP III
EP IV
PD SEP 2000
PY 2000
Z8 0
ZB 0
ZS 0
TC 0
ZR 0
Z9 0
SN 0025-1909
UT WOS:000089646300001
ER

PT J
AU Atuahene-Gima, K
   Evangelista, F
TI Cross-functional influence in new product development: An exploratory
   study of marketing and R&D perspectives
SO MANAGEMENT SCIENCE
VL 46
IS 10
BP 1269
EP 1284
DI 10.1287/mnsc.46.10.1269.12273
PD OCT 2000
PY 2000
AB Previous research in new product development (NPD) has focused on the
   participation of marketing and R&D personnel, but little attention has
   been paid to their influence. This study examined the effects of
   marketing's and R&D's influence and participation on new product
   performance and the differential effects of personal, new product, and
   organizational factors on their influence in the NPD process as seen
   from each other's perspective. The results suggest that marketing's and
   R&D's self-reported influence and their influence as reported by the
   other have a differential impact on new product performance. Unlike
   R&D's participation as perceived by marketing, marketing's participation
   as perceived by R&D affects new product performance only when its
   influence is high. The results also suggest that marketing's and R&D's
   influence in the NPD process is differentially affected by personal, new
   product, and organizational factors.
RI Evangelista, Felicitas/J-2864-2019
OI Evangelista, Felicitas/0000-0002-2758-1461
TC 106
ZA 0
ZB 0
Z8 3
ZR 0
ZS 0
Z9 109
SN 0025-1909
EI 1526-5501
UT WOS:000165320400001
ER

PT J
AU DeCanio, SJ
   Dibble, C
   Amir-Atefi, K
TI The importance of organizational structure for the adoption of
   innovations
SO MANAGEMENT SCIENCE
VL 46
IS 10
BP 1285
EP 1299
DI 10.1287/mnsc.46.10.1285.12270
PD OCT 2000
PY 2000
AB Organizational structure affects both the overall behavior of firms and
   the situations of individuals and subunits within firms. The effect of
   exogenous changes in the environment (market prices, costs, or
   regulations) on organizations can be partitioned into the immediate
   direct effect of the change and the full effect after organizational
   structure has had time to adjust. This paper develops a computational
   model of the diffusion of a profitable innovation through a firm, and
   uses numerical simulations to calculate the relative importance of the
   direct and structural adjustment components of changes in profitability.
   One finding is that a failure to recognize the importance of
   organizational structure on the performance of firms will lead to
   serious bias in estimation of the costs or benefits of a change in
   external circumstances. The type of network model developed also has
   implications for the individuals and divisions that make up the firm. We
   examine some of the structural characteristics of well-adapted
   organizations, and show that asymmetries and economic inequalities
   emerge even when the individual agents' personal characteristics are
   identical.
ZR 0
ZS 2
ZB 2
ZA 0
TC 53
Z8 4
Z9 58
SN 0025-1909
UT WOS:000165320400002
ER

PT J
AU Das, SS
   Van de Ven, AH
TI Competing with new product technologies: A process model of strategy
SO MANAGEMENT SCIENCE
VL 46
IS 10
BP 1300
EP 1316
DI 10.1287/mnsc.46.10.1300.12276
PD OCT 2000
PY 2000
AB This paper draws upon research in the economics of technical change and
   in the social construction of technology to develop and test a process
   model of strategy. We conducted a longitudinal study of leading firms
   that were sponsoring new and competing product technologies in two
   industries: the videoplayer industry and the medical diagnostic imaging
   industry. We built original datasets on the actions of these firms, and
   then empirically examined the strategy process. Our findings indicate
   that the nature of the product technology, whether novel or evolved, and
   the market, whether concentrated or dispersed, influences when firms use
   technical or institutional strategies to get their new product
   technology accepted by the market.
ZR 1
Z8 0
ZA 0
ZB 0
TC 38
ZS 1
Z9 39
SN 0025-1909
UT WOS:000165320400003
ER

PT J
AU Zenios, SA
   Fuloria, PC
TI Managing the delivery of dialysis therapy: A multiclass fluid model
   analysis
SO MANAGEMENT SCIENCE
VL 46
IS 10
BP 1317
EP 1336
DI 10.1287/mnsc.46.10.1317.12271
PD OCT 2000
PY 2000
AB Motivated by the exceptionally high mortality statistics of dialysis
   patients and the ongoing debate about the adequacy of the current
   reimbursement for dialysis in the United States, ave pursue a detailed
   analysis of the dialysis delivery system. The analysis is based on a
   multiclass fluid model for the dialysis facility, which combines a
   pharmacokinetics model of dialysis and an empirically validated model of
   dialysis-specific mortality. Assuming that the facility operates under
   budget and capacity constraints, our analysis determines the main
   factors that affect the delivery of dialysis. Numerical results, which
   are representative of the dialysis environment in the US, demonstrate
   the accuracy of the model and provide concrete insights about the
   operations of the dialysis facility. A major finding is that an
   improvement in the technology of dialysis is likely to have a more
   substantial impact on the overall Life expectancy of the dialysis
   population as compared to an increase in the dialysis reimbursement
   rate.
ZB 0
ZS 0
Z8 0
TC 4
ZR 0
ZA 0
Z9 4
SN 0025-1909
UT WOS:000165320400004
ER

PT J
AU Pennings, JME
   Smidts, A
TI Assessing the construct validity of risk attitude
SO MANAGEMENT SCIENCE
VL 46
IS 10
BP 1337
EP 1348
DI 10.1287/mnsc.46.10.1337.12275
PD OCT 2000
PY 2000
AB Two major approaches to measuring risk attitude are compared. One, based
   on the expected I utility model is derived from responses to lotteries
   and direct scaling. The other measure is a psychometric approach based
   on Likert statements that produces a unidimensional risk attitude scale.
   The data are from computer-assisted interviews of 346 Dutch
   owner-managers of hog farms, who made decisions about their own
   businesses. While the measures demonstrate some degree of convergent
   validity, those measures based on lotteries were better predictors of
   actual market behavior. In contrast the psychometric scale showed more
   agreement to self-reported measures of innovativeness, market
   orientation, and the intention to reduce risk. In light of the higher
   predictive validity of lottery-based measurements, we recommend
   elicitation methods based on the expected utility paradigm.
RI Smidts, Ale/B-8701-2008; Smidts, Ale/
OI Smidts, Ale/0000-0002-6699-1172
TC 115
ZA 0
ZS 0
ZR 0
Z8 1
ZB 6
Z9 116
SN 0025-1909
UT WOS:000165320400005
ER

PT J
AU Glasserman, P
   Heidelberger, P
   Shahabuddin, P
TI Variance reduction techniques for estimating value-at-risk
SO MANAGEMENT SCIENCE
VL 46
IS 10
BP 1349
EP 1364
DI 10.1287/mnsc.46.10.1349.12274
PD OCT 2000
PY 2000
AB This paper describes, analyzes and evaluates an algorithm for estimating
   portfolio loss probabilities using Monte Carlo simulation. Obtaining
   accurate estimates of such loss probabilities is essential to
   calculating value-at-risk, which is a quantile of the loss distribution.
   The method employs a quadratic (''delta-gamma'') approximation to the
   change in portfolio value to guide the selection of effective variance
   reduction techniques; specifically importance sampling and stratified
   sampling. If the approximation is exact, then the importance sampling is
   shown to be asymptotically optimal. Numerical results indicate that an
   appropriate combination of importance sampling and stratified sampling
   can result in large variance reductions when estimating the probability
   of large portfolio losses.
ZB 0
TC 88
ZS 1
Z8 4
ZA 0
ZR 0
Z9 93
SN 0025-1909
EI 1526-5501
UT WOS:000165320400006
ER

PT J
AU Dorndorf, U
   Pesch, E
   Phan-Huy, T
TI A time-oriented branch-and-bound algorithm for resource-constrained
   project scheduling with generalised precedence constraints
SO MANAGEMENT SCIENCE
VL 46
IS 10
BP 1365
EP 1384
DI 10.1287/mnsc.46.10.1365.12272
PD OCT 2000
PY 2000
AB Resource-constrained project scheduling with generalised precedence
   constraints is a very general scheduling model with applications in
   areas such as make-to-order production planning. We describe a
   time-oriented branch-and-bound algorithm that uses
   constraint-propagation techniques which actively exploit the temporal
   and resource constraints of the problem in order to reduce the search
   space. Extensive computational experiments with systematically generated
   test problems show that the algorithm solves more problems to optimality
   than other exact solution procedures which have recently been proposed,
   and that the truncated version of the algorithm is also a very good
   heuristic.
RI Pesch, Erwin/M-2308-2015
OI Pesch, Erwin/0000-0003-0182-870X
ZR 1
ZA 0
TC 64
Z8 4
ZS 0
ZB 1
Z9 69
SN 0025-1909
UT WOS:000165320400007
ER

PT J
AU Repenning, NP
TI Drive out fear (unless you can drive it in): The role of agency and job
   security in process improvement
SO MANAGEMENT SCIENCE
VL 46
IS 11
BP 1385
EP 1396
DI 10.1287/mnsc.46.11.1385.12084
PD NOV 2000
PY 2000
AB Understanding the wide range of outcomes achieved by firms trying to
   implement Total Quality Management (TQM) and similar process improvement
   initiatives presents a challenge to management theory: A few firms reap
   sustained benefits from their programs, but most efforts fail and are
   abandoned. In this paper I study one dimension of this phenomenon: the
   role of impending layoffs in determining employee commitment to process
   improvement. Currently, the literature provides two opposing theories
   concerning the effect of job security on the ability of firms to
   implement change initiatives. The "Drive Out Fear" school argues that
   firms must commit to job security, while the ''Drive In Fear'' school
   emphasizes the positive role that insecurity plays in motivating change.
   In this study a contract theoretic model is developed to analyze the
   role of agency in process improvement. The main insight of the study is
   that there are two types of job security, internal and external, that
   have opposing impacts on the firm's ability to implement improvement
   initiatives. The distinction is useful in explaining the results of
   different case studies and can reconcile the two change theories.
ZA 0
ZS 0
ZB 0
Z8 0
ZR 0
TC 22
Z9 22
SN 0025-1909
UT WOS:000165797500001
ER

PT J
AU Donohue, KL
TI Efficient supply contracts for fashion goods with forecast updating and
   two production modes
SO MANAGEMENT SCIENCE
VL 46
IS 11
BP 1397
EP 1411
DI 10.1287/mnsc.46.11.1397.12088
PD NOV 2000
PY 2000
AB We examine the problem of developing supply contracts that encourage
   proper coordination of forecast information and production decisions
   between a manufacturer and distributor of high fashion, seasonal
   products operating in a two-mode production environment. The first
   production mode is relatively cheap but requires a long lead time while
   the second is expensive but offers quick turnaround. We focus on
   contracts of the form (w(1), W-2, b) where w(i) is the wholesale price
   offered for production mode i and b is a return price offered for items
   left over at the end of the season. We find that such a contract can
   coordinate the manufacturer and distributor to act in the best interest
   of the channel. The pricing conditions needed to ensure an efficient
   solution vary depending on the degree of demand forecast improvement
   between periods and the manufacturer's access to forecast information.
   We also examine whether these conditions ensure a Pareto optimal
   solution with respect to two traditional production settings.
ZB 1
ZR 0
ZA 0
TC 325
ZS 1
Z8 53
Z9 376
SN 0025-1909
UT WOS:000165797500002
ER

PT J
AU Toktay, LB
   Wein, LM
   Zenios, SA
TI Inventory management of remanufacturable products
SO MANAGEMENT SCIENCE
VL 46
IS 11
BP 1412
EP 1426
DI 10.1287/mnsc.46.11.1412.12082
PD NOV 2000
PY 2000
AB We address the procurement of new components for recyclable products in
   the context of Kodak's single-use camera. The objective is to find an
   ordering policy that minimizes the total expected procurement, inventory
   holding, and lost sales cost. Distinguishing characteristics of the
   system are the uncertainty and unobservability associated with return
   flows of used cameras. We model the system as a closed queueing network,
   develop a heuristic procedure for adaptive estimation and control, and
   illustrate our methods with disguised data from Kodak. Using this
   framework, we investigate the effects of various system characteristics
   such as informational structure, procurement delay, demand rate, and
   length of the product's life cycle.
OI Toktay, L. Beril/0000-0001-7446-8253
ZS 0
TC 231
ZR 0
ZB 8
Z8 22
ZA 0
Z9 253
SN 0025-1909
UT WOS:000165797500003
ER

PT J
AU Chang, MH
   Harrington, JE
TI Centralization vs. decentralization in a multi-unit organization: A
   computational model or a retail chain as a multi-agent adaptive system
SO MANAGEMENT SCIENCE
VL 46
IS 11
BP 1427
EP 1440
DI 10.1287/mnsc.46.11.1427.12085
PD NOV 2000
PY 2000
AB A computational model of a retail chain is developed in which store
   managers continually search for better practices. Search takes place
   over a rugged landscape defined over the space of store practices. The
   main objective of this research is to determine how the amount of
   discretion given to store managers as to how they run their stores
   influences the rate of innovation at the store level. We find that
   greater decentralization enhances firm performance when stores' markets
   are sufficiently different, the horizon is sufficiently long, and
   markets are sufficiently stable.
ZB 2
ZA 0
ZS 0
Z8 1
ZR 0
TC 50
Z9 51
SN 0025-1909
UT WOS:000165797500004
ER

PT J
AU Wang, YZ
   Cohen, MA
   Zheng, YS
TI A two-echelon repairable inventory system with stocking-center-dependent
   depot replenishment lead times
SO MANAGEMENT SCIENCE
VL 46
IS 11
BP 1441
EP 1453
DI 10.1287/mnsc.46.11.1441.12081
PD NOV 2000
PY 2000
AB Consider a two-echelon repairable inventory system consisting of a
   central depot and multiple stocking centers. The centers provide parts
   replacement service to customers and replenish their inventory from the
   depot, following a one-for-one policy. The depot fills center
   replenishment orders on a first-come-first-serve basis. Defectives
   received at the centers are passed to the depot for repair and depot
   inventory replenishment. For this system, existing models (e.g., the
   METRIC model) usually assume that the depot replenishment lead times
   (DRLTs) are i.i.d., which however, does not fit well into the service
   parts logistics system that motivated this research. Because the DRLTs
   consist of the sum of repair times, defective return times, and
   transportation times, they are different across stocking centers, which
   are located globally.
   We study the impact of such center-dependent DRLTs on system
   performance. We derive probability distributions of the random delays at
   the depot experienced by center replenishment orders. We prove that a
   center with shorter DRLTs experiences shorter delays, and therefore,
   delivers better customer service. We show that for such systems, using
   the i.i.d. DRLT assumption introduces errors in estimating system
   performance. These errors become significant when both the demand rates
   and the depot planned inventory level are low.
ZR 0
ZS 0
TC 33
ZA 0
ZB 0
Z8 1
Z9 34
SN 0025-1909
EI 1526-5501
UT WOS:000165797500005
ER

PT J
AU De Wolf, D
   Smeers, Y
TI The gas transmission problem solved by an extension of the simplex
   algorithm
SO MANAGEMENT SCIENCE
VL 46
IS 11
BP 1454
EP 1465
DI 10.1287/mnsc.46.11.1454.12087
PD NOV 2000
PY 2000
AB The problem of distributing gas through a network of pipelines is
   formulated as a cost minimization subject to nonlinear flow-pressure
   relations, material balances, and pressure bounds. The solution method
   is based on piecewise linear approximations of the nonlinear
   flow-pressure relations. The approximated problem is solved by an
   extension of the Simplex method. The solution method is tested on
   real-world data and compared with alternative solution methods.
ZR 1
TC 176
Z8 7
ZA 0
ZS 0
ZB 2
Z9 182
SN 0025-1909
UT WOS:000165797500006
ER

PT J
AU Dasgupta, A
   Ghosh, M
TI Inducing performance in a queue via prices: The case of a riverine port
SO MANAGEMENT SCIENCE
VL 46
IS 11
BP 1466
EP 1484
DI 10.1287/mnsc.46.11.1466.12083
PD NOV 2000
PY 2000
AB To optimize large-scale queuing systems configurations, OR professionals
   typically use discrete event simulation packages to examine in detail
   the movement of entities through such systems, assuming stochastic but
   fixed arrival patterns. Demand aspects are, however, routinely ignored
   as few attempts are made to capture the feedback effect of queue
   performance on the arrival process. Econometricians, on the other hand,
   use a simultaneous equations estimation approach relying on past data,
   but they typically disregard the technological insights provided by
   simulation. This paper combines both tools to study the ailing port
   system of Calcutta, India, and concludes that raising prices will
   improve both economic and engineering performances. Microeconomic models
   of shipowner behavior are constructed to explain the nature of the
   empirical findings. Finally, full-equilibrium demand elasticities are
   calculated using the dual prices from an appropriate nonlinear program,
   which are then compared to the benchmark value expected of
   profit-maximizing behavior.
ZA 0
TC 5
ZS 1
ZR 0
ZB 0
Z8 0
Z9 6
SN 0025-1909
EI 1526-5501
UT WOS:000165797500007
ER

PT J
AU Bleichrodt, H
   Pinto, JL
TI A parameter-free elicitation of the probability weighting function in
   medical decision analysis
SO MANAGEMENT SCIENCE
VL 46
IS 11
BP 1485
EP 1496
DI 10.1287/mnsc.46.11.1485.12086
PD NOV 2000
PY 2000
AB An important reason why people violate expected utility theory is
   probability weighting. Previous studies on the probability weighting
   function typically assume a specific parametric form, exclude
   heterogeneity in individual preferences, and exclusively consider
   monetary decision making. This study presents a method to elicit the
   probability weighting function in rank-dependent expected utility theory
   that makes no prior assumptions about the functional form of the
   probability weighting function. We use both aggregate and individual
   subject data, thereby allowing for heterogeneity of individual
   preferences, and we examine probability weighting in a new domain,
   medical decision making. There is significant evidence of probability
   weighting both at the aggregate and at the individual subject level. The
   modal probability weighting function is inverse S-shaped, displaying
   both lower subadditivity and upper subadditivity. Probability weighting
   is in particular relevant at the boundaries of the unit interval.
   Compared to studies involving monetary outcomes, we generally find more
   elevation of the probability weighting function. The robustness of the
   empirical findings on probability weighting indicates its importance.
   Ignoring probability weighting in modeling decision under risk and in
   utility measurement is likely to lead to descriptively invalid theories
   and distorted elicitations.
RI prades, jose luis pinto/B-7069-2008
OI prades, jose luis pinto/0000-0002-9684-3410
Z8 10
ZA 0
ZR 0
ZB 5
ZS 0
TC 240
Z9 249
SN 0025-1909
UT WOS:000165797500008
ER

PT J
AU Abdellaoui, M
TI Parameter-free elicitation of utility and probability weighting
   functions
SO MANAGEMENT SCIENCE
VL 46
IS 11
BP 1497
EP 1512
DI 10.1287/mnsc.46.11.1497.12080
PD NOV 2000
PY 2000
AB This paper proposes a two-step method to successively elicit utility
   functions and decision weights under rank-dependent expected utility
   theory and its "more descriptive" version: cumulative prospect theory.
   The novelty of the method is that it is parameter-free, and thus elicits
   the whole individual preference functional without imposing any prior
   restriction. This method is used in an experimental study to elicit
   individual utility and probability weighting functions for monetary
   outcomes in the gain and loss domains. Concave utility functions are
   obtained for gains and convex utility functions for losses. The elicited
   weighting functions satisfy upper and lower subadditivity and are
   consistent with previous parametric estimations. The data also show that
   the probability weighting function for losses is more "elevated" than
   for gains.
ZR 0
ZB 19
TC 422
ZA 0
ZS 1
Z8 29
Z9 448
SN 0025-1909
UT WOS:000165797500009
ER

PT J
AU Morrison, PD
   Roberts, JH
   von Hippel, E
TI Determinants of user innovation and innovation sharing in a local market
SO MANAGEMENT SCIENCE
VL 46
IS 12
BP 1513
EP 1527
DI 10.1287/mnsc.46.12.1513.12076
PD DEC 2000
PY 2000
AB It is known that end users of products and services sometimes innovate,
   and that innovations developed by users sometimes become the basis for
   important new commercial products and services. It has also been argued
   and to some extent shown that such innovations will be found
   concentrated in a "lead user" segment of the user community. However,
   neither the characteristics of innovating users nor the scope of the
   community that they "lead" has been explored in depth.
   In this paper, we explore the characteristics of innovation, innovators,
   and innovation sharing by library users of OPAC information search
   systems in Australia. This market has capable users, but it is
   nonetheless clearly a "follower" with respect to worldwide technological
   advance. We find that 26% of users in this local market nonetheless do
   modify their OPACs in both major and minor ways, and that OPAC
   manufacturers judge many of these user modifications to be of commercial
   interest. We find that we can distinguish modifying from nonmodifying
   users on the basis of a number of factors, including their "leading-edge
   status" and their in-house technical capabilities. We find that many
   innovating users freely share their innovations with others, and find
   that we can distinguish users that share information about their
   modifications from users that do not. We conclude by considering some
   implications of our findings for idea generation practices in marketing.
RI Roberts, John H/B-4947-2014; Roberts, John/
OI Roberts, John/0000-0002-8662-584X
ZR 0
ZS 6
Z8 8
TC 271
ZB 4
ZA 0
Z9 284
SN 0025-1909
UT WOS:000166263400001
ER

PT J
AU Alles, M
   Amershi, A
   Datar, S
   Sarkar, R
TI Information and incentive effects of inventory in JIT production
SO MANAGEMENT SCIENCE
VL 46
IS 12
BP 1528
EP 1544
DI 10.1287/mnsc.46.12.1528.12079
PD DEC 2000
PY 2000
AB This paper provides an economic rationale for modern manufacturing
   control practices such as the minimal inventories in Just in Time (JIT)
   systems, zero-defect policies, and continuous improvement. The popular
   and academic literature contains descriptive studies on the mechanics of
   these systems and their perceived benefits. We use a model of production
   to analyze both informational and incentive rationales for reduced
   inventories. A TIT-like environment of low inventory levels is optimal
   in our model because it helps workers to better observe and understand
   the production process and to think and act creatively to improve
   operational reliability and yields. Empirical evidence using data
   obtained from 116 plants worldwide supports our conclusions about the
   effect of reduced inventories on process reliability, product quality,
   and cost.
ZA 0
ZR 0
Z8 0
ZS 0
ZB 0
TC 15
Z9 15
SN 0025-1909
UT WOS:000166263400002
ER

PT J
AU Pratt, JW
TI Efficient risk sharing: The last frontier
SO MANAGEMENT SCIENCE
VL 46
IS 12
BP 1545
EP 1553
DI 10.1287/mnsc.46.12.1545.12075
PD DEC 2000
PY 2000
AB When rational risk-averse agents must choose among and share monetary
   risks, it is known that efficient sharing is typically nonlinear, even
   with common beliefs. Wherever it is, the sharing rule may affect the
   choice, randomized choice may allow everyone to gain, and indeed a
   randomized choice between unacceptable risks may be acceptable. An
   important exception occurs if the agents' utility functions are all
   exponential, all logarithmic, or all the same power (HARA). Then choices
   should accord with a group utility function of the same form independent
   of the sharing rule, randomization never helps, and ail efficient
   sharing rules are linear. This self-contained paper simplifies, refines,
   and completes earlier analyses, identifying all exceptions; they are the
   linear sharing rules that make the agents' utilities agree. Aside from
   HARA, this can only occur for precisely one linear sharing rule or, in
   periodic versions of HARA, countably many.
ZS 0
Z8 0
ZB 0
TC 9
ZA 0
ZR 0
Z9 9
SN 0025-1909
UT WOS:000166263400003
ER

PT J
AU Faraj, S
   Sproull, L
TI Coordinating expertise in software development teams
SO MANAGEMENT SCIENCE
VL 46
IS 12
BP 1554
EP 1568
DI 10.1287/mnsc.46.12.1554.12072
PD DEC 2000
PY 2000
AB Like all teams, knowledge teams must acquire and manage critical
   resources in order to accomplish their work. The most critical resource
   for knowledge teams is expertise, or specialized skills and knowledge,
   but the mere presence of expertise on a team is insufficient to produce
   high-quality work. Expertise must be managed and coordinated in order to
   leverage its potential. That is, teams must be able to manage their
   skill and knowledge interdependencies effectively through expertise
   coordination, which entails knowing where expertise is located, knowing
   where expertise is needed, and bringing needed expertise to bear. This
   study investigates the importance of expertise coordination through a
   cross-sectional investigation of 69 software development teams. The
   analysis reveals that expertise coordination shows a strong relationship
   with team performance that remains significant over and above team input
   characteristics, presence of expertise, and administrative coordination.
RI Faraj, Samer/B-7934-2008
OI Faraj, Samer/0000-0002-6585-0351
ZR 0
ZS 5
Z8 7
ZB 7
ZA 0
TC 771
Z9 781
SN 0025-1909
UT WOS:000166263400004
ER

PT J
AU Johnson, MP
   Hurter, AP
TI Decision support for a housing mobility program using a multiobjective
   optimization model
SO MANAGEMENT SCIENCE
VL 46
IS 12
BP 1569
EP 1584
DI 10.1287/mnsc.46.12.1569.12077
PD DEC 2000
PY 2000
AB As result of public housing reform and welfare reform, the operating
   environment of public housing authorities has changed significantly.
   Given these policy initiatives, housing mobility programs represent
   viable strategies for providing public housing residents with access to
   economically healthy, integrated neighborhoods.
   In this paper we present a decision support methodology to assist the
   design of housing mobility programs. This methodology incorporates
   economic models for estimating dollar-valued impacts associated with
   tenant relocation, and a multiobjective optimization model for
   generating alternative relocation schemes associated with various
   objective function weights. Using data for Lake County, Illinois and
   Chicago, we demonstrate that nondominated allocations represent
   significant trade-offs between dollar-valued and non-dollar-valued
   policy objectives; existing distributions of subsidized housing
   represent suboptimal solutions to the housing relocation problem; and
   increases in available rental housing can result in housing dispersion
   schemes that have positive net economic benefits relative to the status
   quo.
ZS 0
ZB 0
TC 9
ZA 0
ZR 0
Z8 0
Z9 9
SN 0025-1909
UT WOS:000166263400005
ER

PT J
AU Xanthopulos, Z
   Melachrinoudis, E
   Solomon, MM
TI Interactive multiobjective group decision making with interval
   parameters
SO MANAGEMENT SCIENCE
VL 46
IS 12
BP 1585
EP 1601
DI 10.1287/mnsc.46.12.1585.12071
PD DEC 2000
PY 2000
AB This paper proposes a new framework for the solution of interactive
   multiobjective group decision-making problems with interval parameters.
   Its novelty stems from a learning phase where decision makers (DMs)
   explore the structural characteristics of the specific Multiple Criteria
   Decision Making (MCDM) problem. This provides important and timely
   feedback to the DMs. Its core consists of four indices and their
   relationships.
   The solution framework consists of three stages. In the first, each DM
   provides the limits of variation for each problem parameter. These are
   subsequently combined into a unique interval of variation. Then, the
   stochastic multiobjective problem is transformed into a deterministic
   one. In the second stage, DMs use the four MCDM characteristics to
   familiarize themselves with the problem before expressing their
   preferences for nondominated solutions. The DMs are then guided through
   an interactive procedure to find their best nondominated solutions. In
   the last stage, all best nondominated solutions provided by the DMs are
   combined using a twofold approach to find the best-compromise
   nondominated solution. This final choice represents the opinion of the
   group of DMs. Our results show that the learning phase is beneficial to
   DMs in judging the quality of solutions, leading to better informed
   decisions.
ZB 0
TC 19
ZR 0
ZS 0
Z8 0
ZA 0
Z9 19
SN 0025-1909
EI 1526-5501
UT WOS:000166263400006
ER

PT J
AU Gilbert, SM
TI Coordination of pricing and multiple-period production across multiple
   constant priced goods
SO MANAGEMENT SCIENCE
VL 46
IS 12
BP 1602
EP 1616
DI 10.1287/mnsc.46.12.1602.12073
PD DEC 2000
PY 2000
AB This paper addresses the problem of jointly determining prices and
   production schedules for a set of items that are produced on the same
   production equipment. Under the assumptions that the production setup
   costs are negligible and that demand is seasonal but price dependent, we
   exploit the special structure of the problem to develop a solution
   procedure. Through a set of numerical examples, we demonstrate how a
   product's contribution to aggregate seasonality can increase its optimal
   price. Our examples also demonstrate that, among products that
   experience demand peaks during the firm's busy season, those that peak
   early in the busy season should be priced more aggressively than those
   that peak later.
ZB 0
Z8 3
TC 46
ZR 0
ZS 0
ZA 0
Z9 49
SN 0025-1909
UT WOS:000166263400007
ER

PT J
AU Stiving, M
TI Price-endings when prices signal quality
SO MANAGEMENT SCIENCE
VL 46
IS 12
BP 1617
EP 1629
DI 10.1287/mnsc.46.12.1617.12078
PD DEC 2000
PY 2000
AB This paper provides a theoretical explanation for why firms behave as
   though they use round prices to signal quality. By replacing the linear
   demand curve in Bagwell and Riordan's (1991) price as a signal of
   quality model with a kinked demand curve, and analyzing what price
   endings firms are most likely to use, the following observations can be
   made: (1) Firms that are using high prices to signal quality are more
   likely to set those prices at round numbers, and (2) price-endings
   themselves are not necessarily signals of quality. A simulation was
   conducted to demonstrate that these findings generally hold true even in
   the presence of demand spikes at 9-ending prices (e.g., Schindler and
   Kibarian 1996). Finally, empirical evidence is provided to demonstrate
   that firms tend to use more round prices for higher-quality products,
   and that this relationship is even stronger for product categories where
   consumers are less able to detect the true level of quality prior to
   purchase.
ZA 0
Z8 2
ZR 0
ZB 1
ZS 1
TC 62
Z9 64
SN 0025-1909
UT WOS:000166263400008
ER

PT J
AU Brusco, MJ
   Jacobs, LW
TI Optimal models for meal-break and start-time flexibility in continuous
   tour scheduling
SO MANAGEMENT SCIENCE
VL 46
IS 12
BP 1630
EP 1641
DI 10.1287/mnsc.46.12.1630.12074
PD DEC 2000
PY 2000
AB This paper presents a compact integer-programming model for large-scale
   continuous tour scheduling problems that incorporate meal-break window,
   start-time band, and start-time interval policies. For practical
   scheduling environments, generalized set-covering formulations (GSCFs)
   of such problems often contain hundreds of millions of integer decision
   variables, usually precluding identification of optimal solutions. As an
   alternative, we present an implicit integer-programming model that
   frequently has fewer than 1,500 variables and can be formulated and
   solved using PC-based hardware and software platforms. An empirical
   study using labor-requirement distributions for customer service
   representatives at a Motorola, Inc. call center was used to demonstrate
   the importance of having a model that can evaluate tradeoffs among the
   various scheduling policies.
ZA 0
ZS 0
ZB 0
TC 53
Z8 1
ZR 0
Z9 54
SN 0025-1909
UT WOS:000166263400009
ER

PT J
AU Krishnan, V
   Ulrich, KT
TI Product development decisions: A review of the literature
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 1
EP 21
DI 10.1287/mnsc.47.1.1.10668
PD JAN 2001
PY 2001
AB his paper is a review of research in product development, which we
   define as the transformation of a market opportunity into a product
   available for sale. Our review is broad, encompassing work in the
   academic fields of marketing, operations management, and engineering
   design. The value of this breadth is in conveying the shape of the
   entire-research landscape. We focus on product development projects
   within a single firm. We also devote our attention to the development of
   physical goods, although much of the work we describe applies to
   products of all kinds. We look inside the "black box" of product
   development at the fundamental decisions that are made by intention or
   default. In doing so,:we adopt the perspective of product development as
   a deliberate business process involving hundreds of decisions, many of
   which can be usefully supported by knowledge and tools. We contrast this
   approach to prior reviews of the literature, which tend to examine the
   importance of environmental and contextual variables, such as market
   growth rate, the competitive environment, or the level of top-management
   support.
ZS 22
ZR 0
ZB 8
Z8 15
TC 805
ZA 0
Z9 836
SN 0025-1909
EI 1526-5501
UT WOS:000167034600002
ER

PT J
AU Ramdas, K
   Sawhney, MS
TI A cross-functional approach to evaluating multiple line extensions for
   assembled products
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 22
EP 36
DI 10.1287/mnsc.47.1.22.10667
PD JAN 2001
PY 2001
AB Assembled product manufacturers often introduce line extensions that
   share components with existing products, or among themselves, resulting
   in cost interactions among products because of shared costs, and revenue
   interactions because of cannibalization. We present a cross-functional
   approach to evaluating multiple line extensions that simultaneously
   considers revenue implications of component sharing at the product level
   and cost implications at the component level. We develop a
   source-of-volume model and a measurement procedure to decompose the
   life-cycle sales volume from a line extension into sales from
   cannibalization, competitive draw, and demand expansion. We develop an
   activity-based costing procedure for estimating the life-cycle costs of
   line extensions that share components. We develop an optimization model
   that uses these revenue and cost estimates to identify a subset of line
   extensions that maximizes incremental profits. We implement our approach
   at a quartz wristwatch manufacturer. Results suggest that our approach
   would have improved profits for the firm by over 5%, while actually
   launching fewer line extensions. We also find that the drivers of
   cannibalization are counterintuitive. In simulation studies, our
   approach outperforms three managerial heuristics. We demonstrate that
   this approach is most valuable when cannibalization dominates
   competitive draw as a source of volume, and discuss its relative merits
   under low and high parts-sharing.
RI ramdas, kamalini/M-9798-2014
Z8 1
ZS 0
ZB 0
TC 59
ZR 0
ZA 0
Z9 60
SN 0025-1909
UT WOS:000167034600003
ER

PT J
AU Desai, P
   Kekre, S
   Radhakrishnan, S
   Srinivasan, K
TI Product differentiation and commonality in design: Balancing revenue and
   cost drivers
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 37
EP 51
DI 10.1287/mnsc.47.1.37.10672
PD JAN 2001
PY 2001
AB Product design decisions substantially affect the cost and revenue
   drivers. A design configuration with commonality can lower manufacturing
   cost. However, such a design may hinder the ability to extract price
   premiums through product differentiation. We explicitly investigate the
   marketing-manufacturing trade-off and derive analytical implications for
   three possible design configurations: unique, premium-common, and
   basic-common. Our model considers two distinct segments of consumers.
   Some of the implications of our analysis are not readily apparent. For
   example, when the high-quality component is made common, the average
   quality of the products offered to the two segments increases. One may
   infer that with higher average quality, higher prices or higher total
   revenues might ensue. However, this may not be the case, as detailed in
   the paper. Finally, our analysis provides a useful framework to develop
   an index that can rank order components in terms of their attractiveness
   for commonality.
TC 161
ZA 0
ZB 0
Z8 9
ZS 0
ZR 0
Z9 169
SN 0025-1909
EI 1526-5501
UT WOS:000167034600004
ER

PT J
AU Krishnan, V
   Gupta, S
TI Appropriateness and impact of platform-based product development
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 52
EP 68
DI 10.1287/mnsc.47.1.52.10665
PD JAN 2001
PY 2001
AB In their quest to manage the complexity of offering greater product
   variety, firms in many industries are considering platform-based product
   development. Product platforms, which are component and subsystem assets
   shared across a product-family, enable a firm to better leverage
   investments in product design and development. While the platform
   approach offers a number of benefits, it also imposes certain additional
   costs that have not received adequate research attention. In this paper,
   we use an industrial example both to illustrate some of the costs and
   benefits of platform-based product development and to motivate the
   development of a mathematical model. The model is formulated to better
   understand the appropriateness of product platforms and their impact on
   product-planning decisions. Our results indicate that platforms are not
   appropriate for extreme levels of market diversity or high levels of
   nonplatform scale economies. Also, a firm's product positioning and
   introduction sequence decisions made during the product-planning phase
   are significantly impacted by the presence of platforms. Specifically, a
   platform increases the separation among products and offers a multitude
   of product introduction strategies. We translate our model findings into
   a managerial framework.
ZR 1
Z8 7
TC 178
ZS 2
ZB 2
ZA 0
Z9 186
SN 0025-1909
UT WOS:000167034600005
ER

PT J
AU Goldenberg, J
   Lehmann, DR
   Mazursky, D
TI The idea itself and the circumstances of its emergence as predictors of
   new product success.
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 69
EP 84
DI 10.1287/mnsc.47.1.69.10670
PD JAN 2001
PY 2001
AB In view of the distressingly low rate of success in new product
   introduction, it is important to identify predictive guidelines early
   in:the new product development process so that better choices can be
   made and unnecessary costs avoided. In this paper, we propose a
   framework for early analysis based on the success potential embodied in
   the product-idea itself and the circumstances of its emergence. Based on
   two studies reporting actual introductions, we identified several
   determinants (such as how the ideas originated, their specific
   configurations, and the level of technology required for their
   implementation) that significantly distinguish successful from
   unsuccessful new products in the marketplace. We suggest that these
   factors, together with already known factors of success/failure, may aid
   in the estimation of the potential of a concept early in its
   development.
TC 169
ZR 0
ZA 0
Z8 1
ZB 2
ZS 2
Z9 172
SN 0025-1909
UT WOS:000167034600006
ER

PT J
AU Huchzermeier, A
   Loch, CH
TI Project management under risk: Using the real options approach to
   evaluate flexibility in R&D
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 85
EP 101
DI 10.1287/mnsc.47.1.85.10661
PD JAN 2001
PY 2001
AB Managerial flexibility has value in the context of uncertain R&D
   projects, as management can repeatedly gather information about
   uncertain project and market characteristics and, based on this
   information, change its course of action. This value is now well
   accepted and referred to as "real option value." We introduce, in
   addition to the familiar real option of abandonment, the option of
   corrective action that management can take during the project. The
   intuition from options pricing theory is that higher uncertainty in
   project pay offs increases the real option value of managerial decision
   flexibility. However, R&D managers face uncertainty not only in payoffs,
   but also from many other sources. We identify five example types of R&D
   uncertainty, in market payoffs, project budgets, product performance,
   market requirements, and project schedules. How do they influence the
   value from managerial flexibility? We find that if uncertainty is
   resolved or costs/revenues occur after all decisions have been made,
   more variability may "smear out" contingencies and thus reduce the value
   of flexibility In addition, variability may reduce the probability of
   flexibility ever being exercised, which also reduces its value. This
   result runs counter to established option pricing theory intuition and
   contributes to a better risk management in R&D projects. Our model
   builds intuition for R&D managers as to when it is and when it is not
   worthwhile to delay commitments-for example, by postponing a design
   freeze, thus maintaining flexibility in R&D projects.
ZS 6
Z8 10
ZB 2
TC 273
ZR 0
ZA 0
Z9 286
SN 0025-1909
UT WOS:000167034600007
ER

PT J
AU Dahan, E
   Mendelson, H
TI An extreme-value model of concept testing
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 102
EP 116
DI 10.1287/mnsc.47.1.102.10666
PD JAN 2001
PY 2001
AB We model concept testing in new product development as a search for the
   most profitable solution to a design problem. When allocating resources,
   developers must balance the cost of testing multiple designs against the
   potential profits that may result. We propose extreme-value theory as a
   mathematical abstraction of the concept-testing process. We investigate
   the trade-off between the benefits and costs of parallel concept testing
   and derive closed-form solutions for the case of profits that follow
   extreme-value distributions. We analyze the roles of the scale and
   tail-shape parameters of the profit distribution as well as the cost of
   testing in determining the optimal number of tests and total budget for
   the concept phase of NPD. Using an example, we illustrate how to
   estimate and interpret the scale and tail-shape parameters. We find that
   the impact of declining concept-testing costs on expected profits, the
   number of concepts tested, and total spending depend on the scale/cost
   ratio and tail-shape parameter of the profit distribution.
ZS 2
ZB 3
Z8 1
ZA 0
ZR 0
TC 93
Z9 96
SN 0025-1909
EI 1526-5501
UT WOS:000167034600008
ER

PT J
AU Fleming, L
TI Recombinant uncertainty in technological search
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 117
EP 132
DI 10.1287/mnsc.47.1.117.10671
PD JAN 2001
PY 2001
AB While the Course of technological change is widely accepted to be highly
   uncertain and unpredictable, little work has identified or studied the
   ultimate sources and causes of that uncertainty. This paper proposes
   that purely technological uncertainty derives from inventors' search
   processes with unfamiliar components and component combinations.
   Experimentation with new components and new combinations leads to Less
   useful inventions on average, but it also implies an increase in the
   variability that can result in both failure and breakthrough. Negative
   binomial count and dispersion models with patent citation data
   demonstrate that new combinations are indeed more variable. Ln contrast
   to predictions, however, the reuse of components has a nonmonotonic and
   eventually positive effect on variability.
RI McBee, David J/F-3968-2012
Z8 21
ZB 45
ZS 4
TC 1043
ZA 1
ZR 0
Z9 1066
SN 0025-1909
UT WOS:000167034600009
ER

PT J
AU MacCormack, A
   Verganti, R
   Iansiti, M
TI Developing products on "Internet time": The anatomy of a flexible
   development process
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 133
EP 150
DI 10.1287/mnsc.47.1.133.10663
PD JAN 2001
PY 2001
AB Uncertain and dynamic environments present fundamental challenges to
   managers of the new product development process. Between successive
   product generations, significant evolutions can occur in both the
   customer needs a product must address and the technologies it employs to
   satisfy these needs. Even within a single development project, firms
   must respond to new information, or risk developing a product that is
   obsolete the day it is launched. This paper examines the characteristics
   of an effective development process in one such environment-the Internet
   software industry. Using data on 29 completed development projects we
   show that in this industry, constructs that support a more flexible
   development process are associated with better-performing projects. This
   flexible process is characterized by the ability to generate and respond
   to new information for a longer proportion of a development cycle. The
   constructs that support such a process are greater investments in
   architectural design, earlier feedback on product performance from the
   market, and the use of a development team with greater amounts of
   "generational" experience. Our results suggest that investments in
   architectural design play a dual role in a flexible process: First
   through the need to select an architecture that maximizes product
   performance and, second, through the need to select an architecture that
   facilitates development process flexibility. We provide examples from
   our fieldwork to support this view.
OI VERGANTI, ROBERTO/0000-0002-5824-4062
TC 239
ZR 0
ZB 1
Z8 0
ZS 2
ZA 0
Z9 241
SN 0025-1909
UT WOS:000167034600010
ER

PT J
AU Tatikonda, MV
   Montoya-Weiss, MM
TI Integrating operations and marketing perspectives of product innovation:
   The influence of organizational process factors and capabilities on
   development performance
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 151
EP 172
DI 10.1287/mnsc.47.1.151.10669
PD JAN 2001
PY 2001
AB This paper adopts a multidisciplinary view of innovation by integrating
   operations and marketing perspectives of product development. The
   conceptual framework builds on the resource-based view of the firm and
   organizational information-processing theory to characterize
   relationships among organizational process factors, product development
   capabilities, critical uncertainties, and operational/market performance
   in product development projects. Data from a cross-sectional sample of
   120 completed development projects for assembled goods is analyzed via a
   two-stage hierarchical moderated regression approach. The findings show
   that: (1) the organizational process factors studied are associated with
   achievement of operational outcome targets for product quality, unit
   cost, and time-to-market; (2) achievement of operational outcomes aids
   the achievement of market outcomes, in turn suggesting that development
   capabilities are indeed valuable firm resources; and (3) these
   relationships are robust under conditions of technological, market, and
   environmental uncertainty. This article provides practical insight into
   how product development projects can be better managed for operational
   and market success. Additionally, this article sets a theoretical and
   empirical basis for future research on the influence of organizational
   process factors and capabilities on diverse product-innovation outcomes.
Z8 2
TC 347
ZS 2
ZB 1
ZR 0
ZA 0
Z9 351
SN 0025-1909
EI 1526-5501
UT WOS:000167034600011
ER

PT J
AU Baiman, S
   Fischer, PE
   Rajan, MV
TI Performance measurement and design in supply chains
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 173
EP 188
DI 10.1287/mnsc.47.1.173.10673
PD JAN 2001
PY 2001
AB This paper examines the relationship between product architecture,
   supply-chain performance metrics, and supply-chain efficiency. We model
   the contracting relationship between a supplier and a buyer. The
   supplier is privately informed about the outcome of his
   design/production investment. The buyer both appraises the supplier's
   component and does further processing/component production of his own.
   If the final product produced by the buyer;exhibits decoupling and no
   function sharing with respect to the components (termed separable
   architecture), the first-best outcome is attained if both internal and
   external failures are contractible. When only one type of failure can be
   contracted on, we derive conditions under which contracting on internal
   failure is superior to contracting on external failure, and vice versa.
   If the buyer's final product has a nonseparable architecture with
   respect to the components, first-best cannot be achieved even if both
   internal and external failures are contractible. The value of
   contracting on internal failure alone is unaffected by the architecture
   design, while that of external failure declines relative to the
   separable setting; the net result is often to make the former the
   uniformly dominant performance metric. Our results highlight the
   interaction between the performance metrics used for contracting within
   the supply chain, the architecture of the product produced by the supply
   chain, and the incentive efficiency of the chain.
TC 89
ZS 1
ZA 0
ZB 1
ZR 0
Z8 29
Z9 115
SN 0025-1909
UT WOS:000167034600012
ER

PT J
AU Novak, S
   Eppinger, SD
TI Sourcing by design: Product complexity and the supply chain
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP 189
EP 204
DI 10.1287/mnsc.47.1.189.10662
PD JAN 2001
PY 2001
AB This paper focuses on the connection between product complexity and
   vertical integration I using original empirical evidence from the auto
   industry. A rich literature has addressed the choice between internal
   production and external sourcing of components in the auto industry.
   More recent literature has developed the concept of product architecture
   as another choice variable that may be one of the important contributors
   to product complexity. In this paper, we connect these two important
   decisions and study them jointly. We use the property rights approach to
   argue that complexity in product design and vertical integration of
   production are complements: that in-house production is more attractive
   when product complexity is high, as firms seek to capture the; benefits
   of their investment in the skills needed to coordinate development of
   complex designs. We test this hypothesis with a simultaneous equations
   model applied to data from the luxury-performance segment of the auto
   industry. We find a significant and positive relationship between
   product complexity and vertical integration. This has implications for
   optimal incentive structures within firms, as well as for interpreting
   firm performance.
RI E G, KAVILAL/O-2779-2015
ZA 0
ZS 2
ZR 0
TC 322
Z8 6
ZB 1
Z9 330
SN 0025-1909
UT WOS:000167034600013
ER

PT J
AU Ulrich, KT
TI Introduction to the special issue on design and development
SO MANAGEMENT SCIENCE
VL 47
IS 1
BP V
EP VI
DI 10.1287/mnsc.47.1.0.10664
PD JAN 2001
PY 2001
ZR 0
ZS 0
TC 5
ZB 0
ZA 0
Z8 1
Z9 6
SN 0025-1909
UT WOS:000167034600001
ER

PT J
AU Shane, S
TI Technological opportunities and new firm creation
SO MANAGEMENT SCIENCE
VL 47
IS 2
BP 205
EP 220
DI 10.1287/mnsc.47.2.205.9837
PD FEB 2001
PY 2001
AB Research on the creation of new high-technology companies has typically
   focused either on industry-level factors such as market structure and
   technology regime or on individual-level factors such as the work
   experience of entrepreneurs. This study complements these approaches by
   examining the effect of technological opportunities on firm formation.
   Ln particular, the study shows that the probability that an invention
   will be commercialized through firm formation is influenced by its
   importance, radicalness, and patent scope.
RI DEL RIO, MIGUEL ANGEL MONTANES/F-2359-2013
TC 323
ZA 0
ZS 3
ZB 4
ZR 0
Z8 4
Z9 328
SN 0025-1909
EI 1526-5501
UT WOS:000167719700001
ER

PT J
AU Besanko, D
   Dranove, D
   Shanley, M
TI Exploiting a cost advantage and coping with a cost disadvantage
SO MANAGEMENT SCIENCE
VL 47
IS 2
BP 221
EP 235
DI 10.1287/mnsc.47.2.221.9840
PD FEB 2001
PY 2001
AB This paper provides an empirical investigation of how firms with cost
   advantages (cost disadvantages) exploit (cope with) their advantages
   (disadvantages) through their pricing behavior. Guided by microeconomic
   theory and insights from the industrial organization literature, we
   develop testable implications about the effect of industry structure and
   firmspecific characteristics on the pass-through elasticity: The rate at
   which changes in a firm's cost relative to competitors translates into
   changes in the firm's price relative to competitors. We test these
   implications using data from the PIMS Competitive Strategy database. The
   results indicate that a firm's pass-through elasticity systematically
   depends on whether the firm operates in a commodity or noncommodity
   industry, the firm's capacity utilization, and its cost and quality
   position in its industry. The pass-through elasticity is also shown to
   depend in a nonlinear way on market concentration.
ZB 0
ZR 0
Z8 0
TC 13
ZA 0
ZS 0
Z9 13
SN 0025-1909
UT WOS:000167719700002
ER

PT J
AU Eisenberg, L
   Noe, TH
TI Systemic risk in financial systems
SO MANAGEMENT SCIENCE
VL 47
IS 2
BP 236
EP 249
DI 10.1287/mnsc.47.2.236.9835
PD FEB 2001
PY 2001
AB We consider default by firms that are part of a single clearing
   mechanism. The obligations of all firms within the system are determined
   simultaneously in a fashion consistent with the priority of debt claims
   and the limited liability of equity We first show, via a fixed-point
   argument, that there always exists a "clearing payment vector" that
   clears the obligations of the members of the clearing system; under mild
   regularity conditions, this clearing vector is unique. Next, we develop
   an algorithm that both clears the financial system in a computationally
   efficient fashion and provides information on the systemic risk faced by
   the individual system firms. Finally, we produce qualitative comparative
   statics for financial systems. These comparative statics imply that, in
   contrast to single-firm results, even unsystematic, nondissipative
   shocks to the system will lower the total value of the system and may
   lower the value of the equity of some of the individual system firms.
ZB 18
ZR 3
Z8 10
ZA 0
ZS 1
TC 411
Z9 423
SN 0025-1909
UT WOS:000167719700003
ER

PT J
AU Chen, CL
TI Design for the environment: A quality-based model for green product
   development
SO MANAGEMENT SCIENCE
VL 47
IS 2
BP 250
EP 263
DI 10.1287/mnsc.47.2.250.9841
PD FEB 2001
PY 2001
AB Green product development, which addresses environmental issues through
   product design and innovation as opposed to the traditional
   end-of-pipe-control approach, is receiving significant attention from
   customers, industries, and governments around the world. in this paper
   we develop a quality-based model for analyzing the strategic and policy
   issues concerning the development of products with conflicting
   traditional and environmental attributes. On the demand side of the
   problem, we use the framework of conjoint analysis to structure the
   preferences of the ordinary and green customers. On the supply side, we
   apply the theories in optimal product design and market segmentation to
   analyze the producer's strategic decisions regarding the number of
   products introduced and their prices and qualities. On the policy side,
   we evaluate the effects of environmental standards on the economic and
   environmental consequences of green product development. By jointly
   considering the interactions among the customers' preferences, the
   producer's product strategies, and the environmental standards imposed
   by governments, we present some interesting findings that can be used to
   manage and regulate the development of green products. Two major
   findings show that green product development and stricter environmental
   standards might not necessarily benefit the environment.
Z8 5
TC 284
ZS 3
ZR 0
ZB 11
ZA 0
Z9 292
SN 0025-1909
EI 1526-5501
UT WOS:000167719700004
ER

PT J
AU Keskinocak, P
   Ravi, R
   Tayur, S
TI Scheduling and reliable lead-time quotation for orders with availability
   intervals and lead-time sensitive revenues
SO MANAGEMENT SCIENCE
VL 47
IS 2
BP 264
EP 279
DI 10.1287/mnsc.47.2.264.9836
PD FEB 2001
PY 2001
AB Motivated by applications in the manufacturing and service industries,
   we consider two models for coordinating scheduling with lead-time
   quotation: a basic model. with a single customer type, and an enhanced
   model where an additional second customer type expects immediate service
   or production. In both models, revenues Obtained from the customers are
   sensitive to the lead time, there is a threshold of lead time above
   which the customer does not place an order, and the quoted lead times
   are 100% reliable. These models are related to well-known scheduling
   problems, which have been studied in both offline and online settings.
   We introduce the immediate quotation case and study it with the
   (traditional) online version. We provide complexity results for the
   offline case, and perform competitive analysis for the online cases. A
   natural question of bridging the gap between the online and quotation
   models leads us to the delayed quotation model, which we study briefly.
   The analysis of these models provides useful qualitative insights as
   well.
OI Ravi, R/0000-0001-7603-1207
TC 77
Z8 6
ZR 0
ZS 0
ZA 0
ZB 0
Z9 82
SN 0025-1909
UT WOS:000167719700005
ER

PT J
AU Christensen, PO
   Feltham, GA
TI Efficient timing of communication in multiperiod agencies
SO MANAGEMENT SCIENCE
VL 47
IS 2
BP 280
EP 294
DI 10.1287/mnsc.47.2.280.9839
PD FEB 2001
PY 2001
AB This paper examines communication in a two-period principal/agent model
   in which the agent receives a private signal about the second outcome
   before the first outcome is realized. No communication is compared with
   communication at three possible dates: before the first outcome (early),
   at the first outcome/consumption date (normal), and between the initial
   consumption date and the second outcome (delayed). Delayed communication
   is shown to have no value if the agent's information is perfect, but can
   have value if it is imperfect. Early and normal communication can be
   used to "smooth" compensation across periods and, hence, generally have
   incremental value over delayed communication if the agent cannot borrow
   or save. However, the "smoothing" benefits disappear if he can borrow
   and save. Early and normal communication are equivalent if the agent has
   domain-additive exponential preferences and the private signal is
   uninformative about the first outcome. If the private signal is
   informative about the first outcome, the incremental value of early
   compared with normal communication attains its maximum for "medium"
   informativeness. A unifying example is used throughout.
ZB 0
TC 5
ZS 0
ZA 0
Z8 0
ZR 0
Z9 5
SN 0025-1909
UT WOS:000167719700006
ER

PT J
AU Hoyland, K
   Wallace, SW
TI Generating scenario trees for multistage decision problems
SO MANAGEMENT SCIENCE
VL 47
IS 2
BP 295
EP 307
DI 10.1287/mnsc.47.2.295.9834
PD FEB 2001
PY 2001
AB In models of decision making under uncertainty we often are faced with
   the problem of representing the uncertainties in a form suitable for
   quantitative models. If the uncertainties are expressed in terms of
   multivariate continuous distributions, or a discrete distribution with
   far too many outcomes, we normally face two possibilities: either
   creating a decision model with internal sampling, or trying to find a
   simple discrete approximation of the given distribution that serves as
   input to the model. This paper presents a method based on nonlinear
   programming that can be used to generate a limited number of discrete
   outcomes that satisfy specified statistical properties. Users are free
   to specify any statistical properties they find relevant, and the method
   can handle inconsistencies in the specifications. The basic idea is to
   minimize some measure of distance between the statistical properties of
   the generated outcomes and the specified properties. We illustrate the
   method by single- and multiple-period problems. The results are
   encouraging in that a limited number of generated outcomes indeed have
   statistical properties that are close to or equal to the specifications.
   We discuss how to verify that the relevant statistical properties are
   captured in these specifications, and argue that what are the relevant
   properties, will be problem dependent.
RI Wallace, Stein W/D-6813-2014
Z8 16
TC 335
ZB 4
ZR 1
ZA 0
ZS 2
Z9 353
SN 0025-1909
UT WOS:000167719700007
ER

PT J
AU Thomke, S
   Bell, DE
TI Sequential testing in product development
SO MANAGEMENT SCIENCE
VL 47
IS 2
BP 308
EP 323
DI 10.1287/mnsc.47.2.308.9838
PD FEB 2001
PY 2001
AB A fundamental problem in managing product development is the optimal
   timing, frequency, and fidelity of sequential testing activities that
   are carried out to evaluate novel product concerts and designs. In this
   paper, we develop a mathematical model that treats testing as an
   activity that generates information about technical and customer-need
   related problems An analysis of the model results in several important
   findings. First, optimal testing strategies need to balance the tension
   between several variables, including the increasing cost of redesign,
   the cost of a test as function of fidelity and the correlation between
   sequential tests. Second, a Simple form of our model results in an
   EOQ-like result: The optimal number of tests (called the Economic
   Testing Frequency or ETF) is the square root of the ratio of avoidable
   cost and the cost of a test. Third, the relationship between sequential
   tests can have an impact on optimal testing strategies. If sequential
   tests are increasing refinements of one another, managers should invest
   their budgets in a few high-fidelity tests, whereas if the tests
   identify problems independently of one another it may be more effective
   if developers carry out a higher number of lower-fidelity tests. Using
   examples, the implications for managerial practice are discussed and
   suggestions for further research undertakings are provided.
ZS 0
TC 61
Z8 0
ZB 0
ZR 0
ZA 0
Z9 61
SN 0025-1909
UT WOS:000167719700008
ER

PT J
AU Aksin, OZ
   Harker, PT
TI Modeling a phone center: Analysis of a multichannel, multiresource
   processor shared loss system
SO MANAGEMENT SCIENCE
VL 47
IS 2
BP 324
EP 336
PD FEB 2001
PY 2001
AB This payer presents a model for the study of operations at an inbound
   call center. The call center is modeled as a multiclass processor shared
   loss system, where the interacting effects of human, telecommunication,
   and information technology resources are explicitly incorporated.
   Product form solutions and approximations for this type of system are
   provided along with expressions for performance measures like blocking
   and reneging. Some structural properties of system throughput are
   analyzed in an effort to pave the way for future optimization studies
   dealing with the design and management of phone centers.
RI /Y-8764-2018; Harker, Patrick T/A-9467-2013
OI /0000-0002-8892-9601; Harker, Patrick T/0000-0003-0659-3102
Z8 0
ZS 0
ZA 0
TC 19
ZR 0
ZB 0
Z9 19
SN 0025-1909
UT WOS:000167719700009
ER

PT J
AU Azoulay, P
   Shane, S
TI Entrepreneurs, contracts, and the failure of young firms
SO MANAGEMENT SCIENCE
VL 47
IS 3
BP 337
EP 358
DI 10.1287/mnsc.47.3.337.9771
PD MAR 2001
PY 2001
AB Although economic theory has emphasized that moral hazard and hold-up
   problems influence the design of contracts, very little is known about
   the process by which explicit contracts are established and the effect
   of contractual arrangements on firm performance. This paper attempts to
   demonstrate that firms are selected for survival on the basis of
   contracting efficiency. Based on a statistical analysis of 170 new
   franchise contracts and interviews with the founders of 16 of these new
   franchise systems, we show that new franchise chains that adopt
   exclusive territories are more Likely to survive over time than chains
   that do not. Moreover, successful and failed entrepreneurs possess
   different information about how to design contracts. These entrepreneurs
   undertake "contractual experiments" based on the information they
   possess. Those whose experiments prove to be more consistent with
   economic theory are rewarded for their superior information with
   survival.
RI Azoulay, Pierre/B-1405-2008; Azoulay, Pierre/
OI Azoulay, Pierre/0000-0001-6511-4824
ZR 0
Z8 1
ZS 0
ZB 0
ZA 0
TC 67
Z9 68
SN 0025-1909
EI 1526-5501
UT WOS:000167651100001
ER

PT J
AU Hendricks, KB
   Singhal, VR
TI The long-run stock price performance of firms with effective TQM
   programs
SO MANAGEMENT SCIENCE
VL 47
IS 3
BP 359
EP 368
DI 10.1287/mnsc.47.3.359.9773
PD MAR 2001
PY 2001
AB This paper documents the long-run stock price performance of firms with
   effective Total Quality Management (TQM) programs. The winning of
   quality awards is used as a proxy for effective TQM implementation. We
   compare stock price performance of award winners against various matched
   control groups for a five-year implementation period and a five-year
   postimplementation period. During the implementation period there is no
   difference in the stock price performance, but during the
   postimplementation period award winners significantly outperform firms
   in the various control groups. Depending on the control group used, the
   mean outperformance ranges from 38% to 46%. Our results clearly indicate
   that effective implementation of TQM principles and philosophies leads
   to significant wealth creation. Furthermore, our results should
   alleviate many of the concerns regarding the value of quality award
   systems. Overall, these systems are valuable in terms of recognizing TQM
   firms and promoting awareness of TQM.
TC 182
ZS 4
ZR 0
Z8 1
ZA 0
ZB 1
Z9 186
SN 0025-1909
UT WOS:000167651100002
ER

PT J
AU Kaplan, EH
   Garstka, S
TI March Madness and the office pool
SO MANAGEMENT SCIENCE
VL 47
IS 3
BP 369
EP 382
DI 10.1287/mnsc.47.3.369.9769
PD MAR 2001
PY 2001
AB March brings March Madness, the annual conclusion to the U.S. men's
   college basketball season with two single elimination basketball
   tournaments showcasing the best college teams in the country. Almost as
   mad is the plethora of office pools across the country where the object
   is to pick a priori as many game winners as possible in the tournament.
   More generally, the object in an office pool is to maximize total pool
   points, where different points are awarded for different correct winning
   predictions. We consider the structure of single elimination
   tournaments, and show how to efficiently calculate the mean and the
   variance of the number of correctly predicted wins (or more generally
   the total points earned in an office pool) for a given slate of
   predicted winners. We apply these results to both random and Markov
   tournaments. We then show how to determine optimal office pool
   predictions that maximize the expected number of points earned in the
   pool. Considering various Markov probability models for predicting game
   winners based on regular season performance, professional sports
   rankings, and Las Vegas betting odds, we compare our predictions with
   what actually happened in past NCAA and NIT tournaments. These models
   perform similarly, achieving overall prediction accuracies of about 58%,
   but do not surpass the simple strategy of picking the seeds when the
   goal is to pick as many game winners as possible. For a more
   sophisticated point structure, however, our models do outperform the
   strategy of picking the seeds.
OI Kaplan, Edward/0000-0002-8722-7667
Z8 0
TC 13
ZS 0
ZA 0
ZR 0
ZB 0
Z9 13
SN 0025-1909
UT WOS:000167651100003
ER

PT J
AU Tse, WM
   Li, LK
   Ng, KW
TI Pricing discrete barrier and hindsight options with the tridiagonal
   probability algorithm
SO MANAGEMENT SCIENCE
VL 47
IS 3
BP 383
EP 393
DI 10.1287/mnsc.47.3.383.9775
PD MAR 2001
PY 2001
AB This paper develops an algorithm to calculate the Brownian multivariate
   normal probability subject to any preset error tolerance criteria. The
   algorithm is founded upon the computational simplicity of the
   tridiagonal structure of the inverse of the Brownian correlation matrix.
   Compared with existing pricing technologies without the "barrier too
   close" problem, our calculation method can produce a more accurate and
   efficient analytic evaluation of barrier options monitored at discrete
   instants with well- or ill-behaved barrier levels, or discrete hindsight
   options, for a reasonably large number of monitorings.
RI Ng, Kai Wang/D-3114-2009
ZS 0
ZA 0
TC 15
Z8 0
ZB 0
ZR 0
Z9 15
SN 0025-1909
UT WOS:000167651100004
ER

PT J
AU Shenhar, AJ
TI One size does not fit all projects: Exploring classical contingency
   domains
SO MANAGEMENT SCIENCE
VL 47
IS 3
BP 394
EP 414
DI 10.1287/mnsc.47.3.394.9772
PD MAR 2001
PY 2001
AB Not many authors have attempted to classify projects according to any
   specific scheme, and those who have tried rarely offered extensive
   empirical evidence. From a theoretical perspective, a traditional
   distinction between radical and incremental innovation has often been
   used in the Literature of innovation, and has created the basis for many
   classical contingency studies. Similar concepts, however, did not become
   standard in the literature of projects, and it seems that theory
   development in project management is still in its early years. As a
   result, most project management literature still assumes that all
   projects are fundamentally similar and that "one size fits all." The
   purpose of this exploratory research is to show how different types of
   projects are managed in different ways, and to explore the domain of
   traditional contingency theory in the more modern world of projects.
   This two-step research is using a combination of qualitative and
   quantitative methods and two data sets to suggest a conceptual,
   two-dimensional construct model for the classification of technical
   projects and for the investigation of project contingencies. Within this
   framework, projects are classified into four levels of technological
   uncertainty, and into three levels of system complexity, according to a
   hierarchy of systems and subsystems. The study provides two types of
   implications, For project leadership it shows why and how management
   should adapt a more project-specific style. For theory development, it
   offers a collection of insights that seem relevant to the world of
   projects as temporary organizations, but are, at times, different, from
   classical structural contingency theory paradigms in enduring
   organizations. While still exploratory in nature, this study attempts to
   suggest new inroads to the future study of modern project domains.
ZR 0
ZA 0
ZS 13
Z8 1
ZB 8
TC 377
Z9 389
SN 0025-1909
UT WOS:000167651100005
ER

PT J
AU Tagaras, G
   Vlachos, D
TI A periodic review inventory system with emergency replenishments
SO MANAGEMENT SCIENCE
VL 47
IS 3
BP 415
EP 429
DI 10.1287/mnsc.47.3.415.9770
PD MAR 2001
PY 2001
AB This paper proposes and analyzes a periodic review inventory system with
   two replenishment modes. Regular orders are placed periodically
   following a base stock policy on inventory position, and arrive at the
   stocking location after a deterministic lead time. The location also has
   the option of placing emergency orders, characterized by a shorter lead
   time but higher acquisition cost, in case of imminent stockouts. Thus,
   at some appropriate time in the replenishment cycle, the necessity and
   size of an emergency order is determined according to a base stock
   policy on net stock. The timing of the emergency order is such that this
   order arrives and can be used to satisfy the demand in the time period
   just before the arrival of a regular order, when the likelihood of a
   stockout is highest. An approximate cost model is developed which can
   easily be optimized with respect to the order-up-to parameters. This
   model is used as the basis for a heuristic algorithm, which leads to
   solutions that are very close to the exact optimal solutions determined
   through simulation. It is shown that the proposed system offers
   substantial cost savings relative to a system without the emergency
   replenishment option.
OI Vlachos, Dimitrios/0000-0002-0430-2386
ZR 0
ZB 0
TC 92
ZA 0
Z8 11
ZS 0
Z9 103
SN 0025-1909
UT WOS:000167651100006
ER

PT J
AU Knott, AM
TI The dynamic value of hierarchy
SO MANAGEMENT SCIENCE
VL 47
IS 3
BP 430
EP 448
DI 10.1287/mnsc.47.3.430.9776
PD MAR 2001
PY 2001
AB This study develops a dual-routines view of the dynamic value of
   hierarchy, and tests it against the implicit null hypothesis that
   hierarchy merely provides static advantages over markets. The view holds
   that hierarchical managers perform two roles that create value for firms
   in perpetuity-an administrative role of enforcing operational routine,
   and an entrepreneurial role of executing a metaroutine that continually
   revises operational routine to keep pace with changes in the
   environment. The test consists of a natural experiment comparing the
   behavior and performance of establishments that leave a franchise, "lose
   their hierarchical managers," with those that remain.
   I find support for the view. in the absence of the franchisor,
   establishment behavior drifts from the operational routine, and
   establishments fail to adopt innovation. Both responses lead to
   significant decay in performance. Thus hierarchical managers are
   necessary to actively enforce routine, even after the routine been
   assimilated, and to introduce innovation, even in this unique setting of
   perfect incentives.
RI Knott, Anne Marie/AAD-8455-2019
ZR 1
ZA 0
TC 68
ZS 0
Z8 0
ZB 2
Z9 69
SN 0025-1909
UT WOS:000167651100007
ER

PT J
AU Nelson, BL
   Goldsman, D
TI Comparisons with a standard in simulation experiments
SO MANAGEMENT SCIENCE
VL 47
IS 3
BP 449
EP 463
DI 10.1287/mnsc.47.3.449.9778
PD MAR 2001
PY 2001
AB We consider the problem of comparing a finite number of stochastic
   systems with respect to a single system (designated as the "standard")
   via simulation experiments. The comparison is based on expected
   performance, and the goal is to determine if any system has larger
   expected performance than the standard, and if so to identify the best
   of the alternatives. In this paper we provide two-stage experiment
   design and analysis procedures to solve the problem for a variety of
   scenarios, including those in which we encounter unequal variances
   across systems, as well as those in which we use the variance reduction
   technique of common random numbers and it is appropriate to do so. The
   emphasis is added because in some cases common random numbers can be
   counterproductive when performing comparisons with a standard. We also
   provide methods for estimating the critical constants required by our
   procedures, present a portion of an extensive empirical study, and
   demonstrate one of the procedures via a numerical example.
RI Nelson, Barry L/B-7490-2009
ZB 0
TC 47
ZA 0
ZS 0
Z8 0
ZR 0
Z9 47
SN 0025-1909
UT WOS:000167651100008
ER

PT J
AU Downs, B
   Metters, R
   Semple, J
TI Managing inventory with multiple products, lags in delivery, resource
   constraints, and lost sales: A mathematical programming approach
SO MANAGEMENT SCIENCE
VL 47
IS 3
BP 464
EP 479
DI 10.1287/mnsc.47.3.464.9774
PD MAR 2001
PY 2001
AB This paper develops an order-up-to S inventory model that is designed to
   handle multiple items, resource constraints, lags in delivery, and lost
   sales without sacrificing computational simplicity. Mild conditions are
   shown to ensure that the expected average holding cost and the expected
   average shortage cost are separable convex functions of the order-up-to
   levels. We develop nonparametric estimates of these costs and use them
   in conjunction with Linear programming to produce what is termed the "LP
   policy." The LP policy has two major advantages over traditional
   methods: first, it can be computed in complex environments such as the
   one described above; and second, it does not require an explicit
   functional form of demand, something that is difficult to specify
   accurately in practice. In two numerical experiments designed so that
   optimal policies could be computed, the LP policy fared well, differing
   from the optimal profit by an average of 2.20% and 1.84%, respectively.
   These results compare quite favorably with the errors incurred in
   traditional methods when a correctly specified distribution uses
   estimated parameters. Our findings support the effectiveness of this
   mathematical programming technique for approximating complex, real-world
   inventory control problems.
RI Semple, John/F-8137-2012
Z8 1
TC 38
ZR 0
ZS 0
ZA 0
ZB 0
Z9 39
SN 0025-1909
UT WOS:000167651100009
ER

PT J
AU Drexl, A
   Kimms, A
TI Sequencing JIT mixed-model assembly lines under station-load and
   part-usage constraints
SO MANAGEMENT SCIENCE
VL 47
IS 3
BP 480
EP 491
DI 10.1287/mnsc.47.3.480.9777
PD MAR 2001
PY 2001
AB This paper deals with two most important problems, from both practical
   and theoretical standpoints, arising in sequencing mixed-model assembly
   lines. Such lines have become core components of modern repetitive
   manufacturing, and just-in-time (JIT) manufacturing in particular. One
   problem is to keep the usage rate of all parts fed into the final
   assembly as constant as possible (the "level-scheduling problem"), while
   the other is to keep the Line's workstation loads as constant as
   possible (the "car-sequencing problem"). In this paper the combined
   problem is formulated as a single-integer programming model. The
   LP-relaxation of this model is solved by column-generation techniques.
   The results of an experimental evaluation show that the lower bounds are
   tight.
Z8 5
TC 66
ZS 1
ZR 0
ZA 0
ZB 0
Z9 70
SN 0025-1909
UT WOS:000167651100010
ER

PT J
AU Sobrero, M
   Roberts, EB
TI The trade-off between efficiency and learning in interorganizational
   relationships for product development
SO MANAGEMENT SCIENCE
VL 47
IS 4
BP 493
EP 511
DI 10.1287/mnsc.47.4.493.9828
PD APR 2001
PY 2001
AB his paper analyzes the performance implications of interorganizational
   relationships in the development of technological innovations, focusing
   on the characteristics of the tasks partitioned between a manufacturer
   and its suppliers in the development of new products. We identify two
   critical dimensions: (1) the design scope and (2) the level of task
   interdependency. The design scope dimension characterizes the type of
   problem-solving activities outsourced by the manufacturer. The level of
   task interdependency dimension characterizes the influence of any given
   supplier-manufacturer interaction on other activities within an overall
   innovation process. Data:analyses on 50 supplier-manufacturer
   relationships drawn from three new product development projects show
   that the type of problem-solving activities being partitioned and their
   level of interdependency with the rest of the project are important
   predictors of performance outcomes of the relationship, controlling for
   contractual differences. Further, the analyses demonstrate a clear
   trade-off between short-term efficiency-increasing and longer-term
   learning-enhancing outcomes.
RI Sobrero, Maurizio/E-2532-2013
OI Sobrero, Maurizio/0000-0002-7839-2935
Z8 2
TC 88
ZR 0
ZB 0
ZA 0
ZS 1
Z9 91
SN 0025-1909
UT WOS:000168708600001
ER

PT J
AU Aviv, Y
   Federgruen, A
TI Capacitated multi-item inventory systems with random and seasonally
   fluctuating demands: Implications for postponement strategies
SO MANAGEMENT SCIENCE
VL 47
IS 4
BP 512
EP 531
DI 10.1287/mnsc.47.4.512.9829
PD APR 2001
PY 2001
AB We e address multi-item inventory systems with random and seasonally
   fluctuating and possibly correlated, demands. The items are produced in
   two stages, each with its own lead-time; in the first stage a common
   intermediate product is manufactured. The production volumes in the
   first stage are bounded by given capacity limits. We develop an accurate
   lower bound and close-to-optimal heuristic strategies of simple
   structure. The gap between them, evaluated in an extensive numerical
   study, is on average only 0.45%. We use the model to investigate the
   benefits of various delayed product differentiation (postponement)
   strategies, as well as other strategic questions, including (i) the
   benefits of flexible versus dedicated production facilities; (ii) the
   trade-off between capacity and inventory investments, and (iii) the
   trade-off between capacity investments and service levels.
ZS 0
TC 73
ZA 0
ZB 0
ZR 0
Z8 4
Z9 77
SN 0025-1909
UT WOS:000168708600002
ER

PT J
AU Heiman, A
   McWilliams, B
   Shen, ZH
   Zilberman, D
TI Learning and forgetting: Modeling optimal product sampling over time
SO MANAGEMENT SCIENCE
VL 47
IS 4
BP 532
EP 546
DI 10.1287/mnsc.47.4.532.9832
PD APR 2001
PY 2001
AB Firms use samples to increase the sales of almost all consumable goods,
   including food, health, and cleaning products. Despite its importance,
   sampling remains one of the most under-researched areas. There are no
   theoretical quantitative models of sampling behavior other than the
   pioneering work of Jain et al. (1995), who modeled sampling as an
   important factor in the diffusion of new products.
   In this paper we characterize sampling as having two effects. The first
   is the change in the probability of a consumer purchasing a product
   immediately after having sampled the product. The second is an increase
   in the consumer's cumulative goodwill formation, which results from
   sampling the product. This distinction differentiates our model from
   other models of goodwill, in which firm sales are only a function of the
   existing goodwill level.
   We determine the optimal dynamic sampling effort of a firm and examine
   the factors that affect the sampling decision. We find that although the
   sampling effort will decline over a product's Life cycle, it may
   continue in mature products. Another finding is that when we have a
   positive change in the factors that increase sampling productivity
   steady-state goodwill stock and sales will increase, but equilibrium
   sampling can either increase or decrease. The change in the sampling
   level is indeterminate because, while increased sampling productivity
   means that firms have incentives to increase sampling, the increase in
   the equilibrium goodwill level indirectly reduces the marginal
   productivity of sampling, thus reducing the incentives to sample. We
   discuss managerial implications, and how the model can be used to
   address various circumstances.
RI Heiman, Amir/S-1377-2016
OI Heiman, Amir/0000-0002-8469-5211
Z8 8
TC 60
ZB 0
ZR 1
ZA 0
ZS 1
Z9 69
SN 0025-1909
UT WOS:000168708600003
ER

PT J
AU Juneja, S
   Shahabuddin, P
TI Fast simulation of Markov chains with small transition probabilities
SO MANAGEMENT SCIENCE
VL 47
IS 4
BP 547
EP 562
DI 10.1287/mnsc.47.4.547.9827
PD APR 2001
PY 2001
AB Consider: a-finite-state Markov chain where the transition probabilities
   differ by orders of magnitude. This Markov chain has an "attractor
   state," i.e., from any state of the Markov chain there exists:a sample
   path of significant probability-to the-attractor state. There also
   exists a "rare set," which is accessible from the attractor state only
   by sample paths of very. small probability. The problem is to estimate
   the probability that starting from the attractor state, the Maykov-chain
   hits the rare set before returning to the attractor state. Examples of
   this setting arise in the case of reliability models with highly
   reliable components as well as in the case of-queueing networks with low
   traffic. Importance-sampling is a commonly used simulation technique for
   the fast estimation of rare-event probabilities. It-involves simulating
   the Markov chain under a new probability-measure that emphasizes the
   most likely paths to therare set.-Previous research focused on
   developing importance-sampling schemes fora special case of Markov
   chains that did not include "high-probability cycles." We show, through
   examples that the Markov chains,used to model many commonly encountered
   systems do have high-probability cycles, and existing
   importance-sampling schemes can lead to infinite variance in simulating
   such systems, We then develop the insight that in the:presence. of
   high-probability cycles care should be taken in allocating:the new
   transition probabilities so that the variance accumulated over these
   cycles does not increase without bounds. Based on this observation we
   develop two importance-sampling techniques that have the bounded;
   relative error property, i.e., the simulation run-length required to
   estimate the, rare-event probability to a fixed degree of accuracy
   remains bounded the event of interest becomes more rare.
TC 29
ZS 0
ZR 0
Z8 1
ZA 0
ZB 1
Z9 30
SN 0025-1909
UT WOS:000168708600004
ER

PT J
AU Ittner, CD
   Nagar, V
   Rajan, MV
TI An empirical examination of dynamic quality-based learning models
SO MANAGEMENT SCIENCE
VL 47
IS 4
BP 563
EP 578
DI 10.1287/mnsc.47.4.563.9831
PD APR 2001
PY 2001
AB Using detailed data on defect rates and quality costs from twelve plants
   of a Fortune 500 company, we provide the first direct tests of
   predictions arising from two-sets of dynamic quality-based learning
   models. We find-greater support for quality-based learning models that
   assume learning is a function of both proactive investments in quality
   improvement and autonomous learning-by-doing, than for models-that
   assume learning is a function of reactive investments in quality
   improvement alone. We then extend these two:Sets of models: to examine
   the impact of individual prevention activities and past nonconformance
   expenditures on defect rates. We find that-benefits from different types
   of prevention expenditures vary, and that past nonconformance
   expenditures provide learning opportunities that allow the organization
   to more efficiently cope with future failures,, thereby reducing
   subsequent nonconformance costs. These important implications are absent
   incurrent-quality-based learning models, providing an opportunity for
   future theoretical development.
ZR 0
Z8 2
ZA 0
ZS 1
TC 64
ZB 2
Z9 67
SN 0025-1909
UT WOS:000168708600005
ER

PT J
AU Grahovac, J
   Chakravarty, A
TI Sharing and lateral transshipment of inventory in a supply chain with
   expensive low-demand items
SO MANAGEMENT SCIENCE
VL 47
IS 4
BP 579
EP 594
DI 10.1287/mnsc.47.4.579.9826
PD APR 2001
PY 2001
AB The emergence of carriers that deliver items to geographically dispersed
   destinations quickly rand at a reasonable cost,: combined with the low
   cost of sharing information through networked databases, has opened up
   new opportunities to better manage inventory. We investigate these
   benefits in the context of a supply chain in which a manufacturer
   supplies;expensive, low-demand items to vertically integrated or
   autonomous retailers via one central depot. The manufacturer's lead time
   is assumed to be due to the geographical distance, from the market or a
   combination of low:volumes, high variety,land inflexible production
   processes. We formulate and solve an appropriate mathematical model
   based on one-for-one inventory policies in which a replenishment order
   is placed as soon as the customer withdraws an item. We find that
   sharing and transshipment of items often, but not always, reduces the
   overall costs of holding, shipping, and waiting for inventory.
   Unexpectedly, these cost reductions are sometimes achieved through
   increasing overall inventory levels in the supply chain. Finally while
   sharing of inventory typically: benefits all the participants in
   decentralized supply chains, this is not necessarily the case-sharing
   can hurt the distributor or individual retailers, regardless of their
   relative power: in the supply chain.
ZA 0
TC 94
Z8 12
ZR 0
ZS 0
ZB 0
Z9 106
SN 0025-1909
UT WOS:000168708600006
ER

PT J
AU Jain, N
   Paul, A
TI A generalized model of operations reversal for fashion goods
SO MANAGEMENT SCIENCE
VL 47
IS 4
BP 595
EP 600
DI 10.1287/mnsc.47.4.595.9830
PD APR 2001
PY 2001
AB Operations reversal is a process design principle that involves
   switching two consecutive stages of the manufacturing process to improve
   process performance; In tl;is paper we investigate conditions under
   which operations reversal can be used to reduce the variability-as
   measured by the variance and standard deviation-of production volumes at
   the intermediate stage of the manufacturing process. We:generalize the
   operations reversal model of Lee and Tang (1998) to explicitly
   incorporate two important characteristics of fashion goods markets:
   heterogeneity among customers and unpredictability of customer
   preferences. We also present a new approach to modeling the operations
   reversal problem.
Z8 3
ZR 0
ZB 0
TC 12
ZA 0
ZS 0
Z9 15
SN 0025-1909
UT WOS:000168708600007
ER

PT J
AU Bell, DE
   Fishburn, PC
TI Strong one-switch utility
SO MANAGEMENT SCIENCE
VL 47
IS 4
BP 601
EP 604
DI 10.1287/mnsc.47.4.601.9825
PD APR 2001
PY 2001
AB The linear plus exponential utility function has received increasing
   attention of late as a particularly attractive family for evaluating
   additive gambles;for wealth. In,addition to its ability to reflect
   increasing appreciation for money, risk aversion, and decreasing risk.
   aversion, it is consistent with a risk-return representation in-which
   return is measured by expected value. In this paper we present a new
   condition, strong one-switch, that characterizes the Linear plus
   exponential family.
ZS 0
Z8 0
ZA 0
ZR 0
TC 18
ZB 0
Z9 18
SN 0025-1909
UT WOS:000168708600008
ER

PT J
AU Raghunathan, S
TI Information sharing in a supply chain: A note on its value when demand
   is nonstationary
SO MANAGEMENT SCIENCE
VL 47
IS 4
BP 605
EP 610
DI 10.1287/mnsc.47.4.605.9833
PD APR 2001
PY 2001
AB In a recent paper, Lee, So, and Tang (2000) showed that in a two-level
   supply chain with non-stationary AR(1) end demand, the manufacturer
   benefits significantly when the retailer shares point-of-sale (POS)
   demand data. We show in this paper, analytically and through simulation,
   that the manufacturer's benefit is insignificant when the parameters of
   the AR(1) process are known to both parties, as in Lee, So, and Tang
   (LST). The key-reason for the difference:between our results and those
   of LST is that:LST assume that the manufacturer also uses an AR(1)
   process to forecast the retailer order quantity. However, the
   manufacturer can reduce the variance-of its forecast further by using
   the entire order history to which it has access. Thus, when intelligent
   use of already available internal information (order history) suffices,
   there is no need to invest in interorganizational systems for
   information sharing.
RI Weller, Matt J/E-8421-2010
ZR 0
ZB 0
ZA 0
ZS 0
Z8 23
TC 171
Z9 194
SN 0025-1909
EI 1526-5501
UT WOS:000168708600009
ER

PT J
AU Adner, R
   Levinthal, D
TI Demand heterogeneity and technology evolution: Implications for product
   and process innovation
SO MANAGEMENT SCIENCE
VL 47
IS 5
BP 611
EP 628
DI 10.1287/mnsc.47.5.611.10482
PD MAY 2001
PY 2001
AB The evolution of technology has been a central issue in the strategy and
   organizations Literature. However, the focus of much of this work has
   been on what is essentially the "supply side" of technical change-the
   evolution of firm capabilities. We present a demand-based view of
   technology evolution that is focused on the interaction between
   technology development and the demand environment in which the
   technology is ultimately evaluated. We develop a formal computer
   simulation model that explicitly considers the influence of
   heterogeneity in market demand-the presence of consumers with different
   needs and requirements-on firms' innovation choices. The model is used
   to examine the dynamics of product and process innovation (Utterback and
   Abernathy 1975). The analysis reveals that demand heterogeneity offers
   an alternative to supply-side explanations of the technology Life cycle.
   Further, by considering the implications of decreasing marginal utility
   from performance improvements, the model highlights the role of
   "technologically satisfied" consumers in shaping innovation incentives,
   and suggests a rationale for a new stage in the technology life cycle
   characterized by increasing performance at a stable price. The stage has
   not yet been treated formally in the Literature, but is widely observed,
   most prominently in digital and information-based technologies.
ZB 6
ZR 1
ZA 1
ZS 5
Z8 11
TC 384
Z9 400
SN 0025-1909
EI 1526-5501
UT WOS:000168988900001
ER

PT J
AU Cachon, GP
   Lariviere, MA
TI Contracting to assure supply: How to share demand forecasts in a supply
   chain
SO MANAGEMENT SCIENCE
VL 47
IS 5
BP 629
EP 646
DI 10.1287/mnsc.47.5.629.10486
PD MAY 2001
PY 2001
AB Forecast sharing is studied in a supply chain with a manufacturer that
   faces stochastic demand for a single product and a supplier that is the
   sole source for a critical component. The following sequence of events
   occurs: the manufacturer provides her initial forecast to the supplier
   along with a contract,the supplier constructs-capacity (if he accepts
   the Contract), the manufacturer receives an updated forecast and submits
   a final order. Two contract compliance regimes are considered. If the
   supplier accepts the contract under forced compliance then he has little
   flexibility with respect to his capacity choice; under voluntary
   compliance, however, he maintains substantial flexibility. Optimal
   supply chain performance requires the manufacturer to share her initial
   forecast truthfully, but she has an incentive to inflate her forecast to
   induce the supplier to build more capacity. The supplier is aware of
   this bias, and so may not trust the manufacturer's forecast, harming
   supply chain performance. We study contracts that allow the supply chain
   to share demand forecasts credibly under either compliance regime.
RI Weller, Matt J/E-8421-2010; Lariviere, Martin/AAU-6757-2020
ZR 0
TC 528
ZB 2
Z8 79
ZS 3
ZA 0
Z9 604
SN 0025-1909
UT WOS:000168988900002
ER

PT J
AU Seshadri, S
   Shapira, Z
TI Managerial allocation of time and effort: The effects of interruptions
SO MANAGEMENT SCIENCE
VL 47
IS 5
BP 647
EP 662
DI 10.1287/mnsc.47.5.647.10481
PD MAY 2001
PY 2001
AB Time is one of the more salient constraints on managerial behavior. This
   constraint may be very taxing in high-velocity environments where
   managers have to attend to many;tasks simultaneously. Earlier work by
   Radner (1976) proposed models based on notions of the thermostat or
   "putting out fires" to guide managerial time and effort allocation among
   tasks. We link these ideas to the issue of the level of complexity of
   the tasks to be attended to while alluding to the sequential versus
   parallel modes of processing. We develop a stochastic model to analyze
   the behavior of a manager who has to attend to a few short-term proesses
   while attempting to devote as much time as possible to the pursuit of a
   long-term project. A major aspect of this problem is how the manager
   deals with interruptions. Different rules of attention allocation are
   proposed, and their implications to managerial behavior are discussed.
RI Seshadri, Sridhar/D-6034-2012; Seshadri, Sridhar/AAI-1410-2020
TC 41
Z8 0
ZR 0
ZS 0
ZA 0
ZB 0
Z9 41
SN 0025-1909
UT WOS:000168988900003
ER

PT J
AU Loch, CH
   Terwiesch, C
   Thomke, S
TI Parallel and sequential testing of design alternatives
SO MANAGEMENT SCIENCE
VL 47
IS 5
BP 663
EP 678
DI 10.1287/mnsc.47.5.663.10480
PD MAY 2001
PY 2001
AB An important managerial problem in product design in the,extent to which
   testing activities are carried out in parallel or in series. Parallel
   testing has the advantage of proceeding more rapidly than serial testing
   but does not take advantage of the potential for learning between tests,
   thus resulting in a larger number of tests. We model this trade-off in
   the form of a dynamic program and derive the optimal testing strategy
   (or mix of parallel and serial testing) that minimizes both the to;al
   cost and time of testing. We derive the optimal testing strategy as a
   function of testing cost, prior knowledge, and testing lead time. Using
   information theory to measure the test efficiency, we further show that
   in the case of imperfect testing (due to noise or simulated test
   conditions), the attractiveness of parallel strategies decreases.
   Finally, we analyze the relationship between testing strategies and the
   structure of design hierarchy. We show that a key benefit of modular
   product architecture lies in the reduction of testing cost.
TC 104
ZR 0
ZA 0
ZS 0
ZB 0
Z8 0
Z9 104
SN 0025-1909
EI 1526-5501
UT WOS:000168988900004
ER

PT J
AU Fisher, M
   Ramdas, K
   Zheng, YS
TI Ending inventory valuation in multiperiod production scheduling
SO MANAGEMENT SCIENCE
VL 47
IS 5
BP 679
EP 692
DI 10.1287/mnsc.47.5.679.10485
PD MAY 2001
PY 2001
AB When making lot-sizing decisions, managers often use a model horizon T
   that is much smaller than any reasonable estimate of the firm's future
   horizon. This is done because forecast accuracy deteriorates rapidly for
   longer horizons, while computational burden increases. However, what is
   optimal over the short horizon may be suboptimal over the long run,
   resulting in errors known as end-effects. A common end-effect in
   lot-sizing models is to set end-of-horizon inventory to zero. This
   policy can result in excessive setup costs or stock-outs in the long
   run.
   We present a method to mitigate end-effects in lot sizing by including a
   valuation term V(I-T) for end-of-horizon inventory I-T, in the objective
   function of the short-horizon model. We develop this concept within the
   classical EOQ modeling framework, and then apply it to the dynamic
   lot-sizing problem (DLSP). If demand in each period of the DLSP equals
   the long-run average demand rate, then our procedure induces an optimal
   ordering policy over the short horizon that coincides with the long-run
   optimal ordering policy. We test our procedure empirically against the
   Wagner-Whitin algorithm and the Silver Meal heuristic, under several
   demand patterns, within a rolling horizon framework. With few
   exceptions, our approach significantly outperforms the other approaches
   tested, for modest to long model horizons. We discuss applicability to
   more general lot-sizing problems.
RI ramdas, kamalini/M-9798-2014
ZB 0
Z8 0
ZR 0
TC 37
ZA 0
ZS 0
Z9 37
SN 0025-1909
UT WOS:000168988900005
ER

PT J
AU Chen, FR
   Federgruen, A
   Zheng, YS
TI Coordination mechanisms for a distribution system with one supplier and
   multiple retailers
SO MANAGEMENT SCIENCE
VL 47
IS 5
BP 693
EP 708
DI 10.1287/mnsc.47.5.693.10484
PD MAY 2001
PY 2001
AB We address a fundamental two-echelon distribution system in which the
   sales volumes of the retailers are endogenously determined on the basis
   of known demand functions. Specifically, this paper studies a
   distribution channel where a supplier distributes a single product to
   retailers, who in turn sell the product to consumers. The demand in each
   retail market arrives continuously at a constant rate that is a general
   decreasing function of the retail price in the market. We have
   characterized an optimal strategy, maximizing total systemwide profits
   in a centralized system. We have also shown that the same optimum level
   of channelwide profits can be achieved-in a decentralized system, but
   only if coordination is achieved via periodically charged, fixed fees,
   and a nontraditional discount pricing scheme under which the discount
   given to a retailer is the sum of three discount components based on the
   retailer's (i) annual-sales volume, (ii) order quantity, and (iii) order
   frequency, respectively. Moreover, we show that no (traditional)
   discount scheme, based on order quantities only, suffices to optimize
   channelwide profits when there-are multiple nonidentical retailers. The
   paper also considers a scenario where the channel members fail to
   coordinate their decisions and provides numerical examples that
   illustrate the value of coordination. We extend our results to settings
   in which the retailers' holding cost rates depend on the wholesale
   price.
TC 290
ZB 2
ZS 2
Z8 50
ZA 0
ZR 0
Z9 340
SN 0025-1909
EI 1526-5501
UT WOS:000168988900006
ER

PT J
AU Lim, WS
TI Producer-supplier contracts with incomplete information
SO MANAGEMENT SCIENCE
VL 47
IS 5
BP 709
EP 715
DI 10.1287/mnsc.47.5.709.10479
PD MAY 2001
PY 2001
AB This paper investigates the contract design problem of a producer when
   he purchases parts from a supplier, and there is incomplete information
   regarding the quality of the parts. This is the first game-theoretic
   model of quality control tl;at captures this informational asymmetry. We
   focus on two compensation schemes embedded in the contract, namely,
   price rebate (when inspection is done upon receipt of the parts) and
   warranty. We show that when a full-price rebate is not possible and the
   producer and the supplier have to share the damage costs, an optimal
   contract is such that the:supplier compensates the producer by the same
   amount, regardless of his quality type. However, a supplier with low
   quality is more likely to be offered a contract with an inspection
   scheme, while a supplier with high quality is constrained with a
   warranty scheme. We also show that when the producer need not share the
   cost in exactly one of the compensation schemes, he may still offer the
   other compensation scheme to a supplier type depending on the relative
   costs involved, the maximum compensation cost acceptable by all supplier
   types, and his ex ante beliefs about the quality level of the supplier.
RI Lim, Wei Shi/A-5181-2016
OI Lim, Wei Shi/0000-0002-0275-6747
ZR 0
TC 111
ZB 1
ZS 1
Z8 18
ZA 0
Z9 126
SN 0025-1909
UT WOS:000168988900007
ER

PT J
AU Langer, T
   Weber, M
TI Prospect theory, mental accounting, and differences in aggregated and
   segregated evaluation of lottery portfolios
SO MANAGEMENT SCIENCE
VL 47
IS 5
BP 716
EP 733
DI 10.1287/mnsc.47.5.716.10483
PD MAY 2001
PY 2001
AB If individuals have to evaluate a sequence of lotteries, their judgment
   is influenced by the presentation mode. Experimental studies have found
   significantly higher acceptance rates for a sequence of lotteries if the
   overall distribution was displayed instead of the set of lotteries
   itself. Mental accounting and loss aversion provide an easy and
   intuitive explanation for this phenomenon. Ln this paper we offer an
   explanation that incorporates further evaluation concepts of Prospect
   Theory. Our formal analysis of the difference in aggregated and
   segregated portfolio evaluation demonstrates that the higher
   attractiveness of the aggregated presentation mode is not a general
   phenomenon (as suggested in the Literature) but depends on specific
   parameters of the lotteries. The theoretical findings are supported by
   an experimental study In contrast to the existing evidence and in line
   with our theoretical results, we find for specific types of lotteries an
   even lower acceptance rate if the overall distribution is displayed.
Z8 10
ZA 0
TC 60
ZB 3
ZS 1
ZR 0
Z9 71
SN 0025-1909
UT WOS:000168988900008
ER

PT J
AU Fuloria, PC
   Zenios, SA
TI Outcomes-adjusted reimbursement in a health-care delivery system
SO MANAGEMENT SCIENCE
VL 47
IS 6
BP 735
EP 751
DI 10.1287/mnsc.47.6.735.9816
PD JUN 2001
PY 2001
AB This paper considers a health-care delivery system with two
   noncooperative parties: a purchaser of medical services and a
   specialized provider. A dynamic principal-agent model that captures the
   interaction between the two parties is developed. In this model,
   patients arrive exogenously, receive periodic treatment from the
   provider, suffer costly complications that require hospital care, and
   eventually exit the system in death. The provider chooses the intensity
   of treatment in each period, incurs an associated cost, and is
   reimbursed by the purchaser according to observed patient outcomes. The
   purchaser's problem is to determine a payment system that will induce
   treatment choices maximizing total social welfare. The optimal payment
   system, referred to as the outcomes-adjusted payment system, is
   identified. It consists of a prospective payment per patient and a
   retrospective payment adjustment based on adverse short-term patient
   outcomes. This system induces the most efficient delivery of medical
   services by combining the immediate "threat" of a retrospective payment
   adjustment with the future reward of prospective payments generated by
   surviving patients. A numerical example is provided in the context of
   Medicare's End-Stage Renal Disease program. The example compares the
   optimal system to systems that are currently in place. The results
   suggest that the purchaser can achieve significant gains in patient life
   expectancy by switching to the outcomes-adjusted payment system, but
   this requires accurate information about treatment technology, patient
   characteristics, and provider preferences. The life-expectancy gains do
   not involve increased medical expenditures.
ZB 0
ZA 0
Z8 0
ZS 0
ZR 0
TC 30
Z9 30
SN 0025-1909
UT WOS:000169830600001
ER

PT J
AU Pisano, GP
   Bohmer, RMJ
   Edmondson, AC
TI Organizational differences in rates of learning: Evidence from the
   adoption of minimally invasive cardiac surgery
SO MANAGEMENT SCIENCE
VL 47
IS 6
BP 752
EP 768
DI 10.1287/mnsc.47.6.752.9811
PD JUN 2001
PY 2001
AB This paper examines learning curves in the health care setting to
   determine whether organizations achieve performance improvements from
   cumulative experience at different rates. Although extensive research
   has shown that cumulative experience leads to performance improvement
   across numerous contexts, the question of how much of this improvement
   is due to mere experience and how much is due to collective learning
   processes has received little attention. We argue that organizational
   learning processes may allow some organizations to benefit more than
   others from equivalent levels of experience. We thus propose that
   learning curves can vary across organizations engaged in the same
   "learning task," due to organizational learning effects. To investigate
   this proposition, we investigate cardiac surgery departments
   implementing a new technology for minimally invasive cardiac surgery.
   Data on operative procedure times from a sample of 660 patients who
   underwent the new operation at 16 different institutions are analyzed.
   The results confirm that cumulative experience is a significant
   predictor of learning, and further reveal that the slope of the learning
   curve varies significantly across organizations. Theoretical and
   practical implications of the work are discussed.
TC 296
ZR 0
Z8 0
ZS 5
ZA 0
ZB 10
Z9 299
SN 0025-1909
UT WOS:000169830600002
ER

PT J
AU Bonser, JS
   Wu, SD
TI Procurement planning to maintain both short-term adaptiveness and
   long-term perspective
SO MANAGEMENT SCIENCE
VL 47
IS 6
BP 769
EP 786
DI 10.1287/mnsc.47.6.769.9814
PD JUN 2001
PY 2001
AB We study the fuel procurement problem for electrical utilities under
   uncertain demand and market price. Long-term contractual supply
   commitments are made at a set price with fuel suppliers at the beginning
   of each year. Each month the procurement planner can use fuel from these
   contracts or purchase fuel at the current market price. Motivated by
   practical insights from this market, we propose a two-phase dynamic
   procedure to determine a procurement plan. In the first phase, the
   minimum contract purchases for each month are determined at the
   beginning of the year. In the second phase, given the minimum contract
   purchases, the more detailed procurement decisions are determined at the
   beginning of each month with the most up-to-date information. We perform
   intensive computational experiments that show that this procedure
   produces high-quality solutions comparable to a rolling-horizon
   stochastic-programming heuristic, is easier to maintain and generalize,
   is computationally faster, and is robust to random fluctuations in
   demand requirements, spot market prices, and other sources of
   uncertainty.
Z8 3
ZS 0
TC 43
ZA 0
ZB 0
ZR 0
Z9 45
SN 0025-1909
UT WOS:000169830600003
ER

PT J
AU Nault, BR
   Tyagi, RK
TI Implementable mechanisms to coordinate horizontal alliances
SO MANAGEMENT SCIENCE
VL 47
IS 6
BP 787
EP 799
DI 10.1287/mnsc.47.6.787.9808
PD JUN 2001
PY 2001
AB Unprecedented changes in the economics of interaction, mainly as a
   result of advances in information and telecommunication technologies
   such as the Internet, are causing a shift toward more networked forms of
   organizations such as horizontal alliances - that is, alliances among
   firms in similar businesses that have positive externalities between
   them. Because the success of such horizontal alliances depends crucially
   on aligning individual alliance-member incentives with those of the
   alliance as a whole, it is important to find coordination mechanisms
   that achieve this alignment and are simple-to-implement. In this paper,
   we examine two simple coordination mechanisms for a horizontal alliance
   characterized by the following features: (i) firms in the alliance can
   exert effort only in their "local" markets to increase customer demand
   for the alliance; (ii) customers are mobile and a customer living in a
   given alliance member's local area may have a need to buy from some
   other alliance member; and (iii) the coordination rules followed by the
   alliance determine which firms from a large pool of potential
   member-firms join the alliance, and how much effort each firm joining
   the alliance exerts in its local market. In this horizontal alliance
   setup, we consider the use of two coordination mechanisms: (i) a linear
   transfer of fees between members if demand from one member's local
   customer is served by another member, and (ii) ownership of an equal
   share of the alliance profits generated from a royalty on each member's
   sales. We derive conditions on the distribution of demand externalities
   among alliance members to determine when each coordination mechanism
   should be used separately, and when the mechanisms should be used
   together.
ZS 2
ZR 0
ZB 0
TC 28
ZA 0
Z8 2
Z9 32
SN 0025-1909
UT WOS:000169830600004
ER

PT J
AU Butler, J
   Morrice, DJ
   Mullarkey, PW
TI A multiple attribute utility theory approach to ranking and selection
SO MANAGEMENT SCIENCE
VL 47
IS 6
BP 800
EP 816
DI 10.1287/mnsc.47.6.800.9812
PD JUN 2001
PY 2001
AB Managers of large industrial projects often measure performance by
   multiple attributes. For example, our paper is motivated by the
   simulation of a large industrial project called a land seismic survey,
   in which project performance is based on duration, cost, and resource
   utilization. To address these types of problems, we develop a ranking
   and selection procedure for making comparisons of systems (e.g., project
   configurations) that have multiple performance measures. The procedure
   combines multiple attribute utility theory with statistical ranking and
   selection to select the best configuration from a set of possible
   configurations using the indifference-zone approach. We apply our
   procedure to results generated by the simulator for a land seismic
   survey that has six performance measures, and describe a particular type
   of sensitivity analysis that can be used as a robustness check.
ZB 0
Z8 3
ZA 0
TC 126
ZS 0
ZR 0
Z9 129
SN 0025-1909
EI 1526-5501
UT WOS:000169830600005
ER

PT J
AU Anderson, EG
TI The nonstationary staff-planning problem with business cycle and
   learning effects
SO MANAGEMENT SCIENCE
VL 47
IS 6
BP 817
EP 832
DI 10.1287/mnsc.47.6.817.9815
PD JUN 2001
PY 2001
AB Managing highly skilled employees is extremely complex because of the
   need to balance the costs and time lags associated with their training
   against the need to meet demand as quickly as possible. Unlike previous
   approaches to this problem in the staffing literature, this paper
   develops an optimal staffing policy at the strategic level to cope with
   nonstationary stochastic demand for a staff characterized by
   unproductive apprentice employees and fully productive experienced
   employees. The paper then explores the implications of this policy in
   different industries, using empirical data. Aside from the optimal
   policy, this paper's primary results include: (1) demand volatility
   reduces average productivity, most especially under conditions of low
   (or slightly negative) growth and - nonintuitively - low employee
   turnover or knowledge obsolescence rates; (2) there is a trade-off
   between meeting demand and high productivity; (3) firms with longer
   business cycles should smooth their hiring and firing policies; and (4)
   firms in industries with longer training times should smooth their
   hiring and firing policies. The paper also explores the possible rewards
   from reducing training times and turnover rates. Finally, it discusses
   managerial implications and possible future directions in research.
ZB 0
Z8 0
ZS 0
ZA 0
TC 29
ZR 0
Z9 29
SN 0025-1909
UT WOS:000169830600006
ER

PT J
AU Fischetti, M
   Lodi, A
   Martello, S
   Toth, P
TI A polyhedral approach to simplified crew scheduling and vehicle
   scheduling problems
SO MANAGEMENT SCIENCE
VL 47
IS 6
BP 833
EP 850
DI 10.1287/mnsc.47.6.833.9810
PD JUN 2001
PY 2001
AB Crew and vehicle scheduling are fundamental issues in public transit
   management. Informally, they can be described as the problem of
   determining the optimal duties for a set of crews (e.g., bus drivers) or
   vehicles (e.g., buses) so as to cover a given set of timetabled trips,
   satisfying a number of constraints laid down by the union contract and
   company regulations. We consider the simplified but still NP-hard case
   in which several depots are specified, and limits on both the total time
   between the start and the end of any duty (spread time) and the total
   duty operational time (working time) are imposed. We give a 0-1 linear
   programming formulation based on binary variables associated with trip
   transitions, which applies to both crew and vehicle scheduling. The
   model is enhanced by means of new families of valid inequalities, for
   which exact and heuristic separation procedures are proposed. These
   techniques are embedded into an exact branch-and-cut algorithm, which
   also incorporates heuristic procedures. The performance of two
   implementations of the method (for vehicle scheduling and crew
   scheduling, respectively) are evaluated through computational testing on
   both random and real-world test problems from the literature.
RI Martello, Silvano/D-3117-2011
OI Martello, Silvano/0000-0001-6515-1406
ZA 0
TC 36
Z8 2
ZR 0
ZB 0
ZS 1
Z9 38
SN 0025-1909
UT WOS:000169830600007
ER

PT J
AU Gopalakrishnan, M
   Ding, K
   Bourjolly, JM
   Mohan, S
TI A tabu-search heuristic for the capacitated lot-sizing problem with
   set-up carryover
SO MANAGEMENT SCIENCE
VL 47
IS 6
BP 851
EP 863
DI 10.1287/mnsc.47.6.851.9813
PD JUN 2001
PY 2001
AB This paper presents a tabu-search heuristic for the capacitated
   lot-sizing problem (CLSP) with set-up carryover. This
   production-planning problems allows multiple items to be produced within
   a time period, and setups for items to be carried over from one period
   to the next. Two interrelated decisions, sequencing and lot sizing, are
   present in this problem. Our tabu-search heuristic consists of five
   basic move types - three for the sequencing decisions and two for the
   lot-sizing decisions. We allow infeasible solutions to be generated at a
   penalty during the course of the search. We use several search
   strategies, such as dynamic tabu list, adaptive memory, and
   self-adjusting penalties, to strengthen our heuristic. We also propose a
   lower-bounding procedure to estimate the quality of our heuristic
   solution. We have also modified our heuristic to produce good solutions
   for the CLSP without set-up carryover. The computational study,
   conducted on a set of 540 test problems, indicates that on average our
   heuristic solutions are within 12% of a bound on optimality. In
   addition, for the set of test problems our results indicate an 8%
   reduction in total cost through set-up carryover.
Z8 1
ZB 0
ZS 0
ZR 0
TC 61
ZA 0
Z9 62
SN 0025-1909
UT WOS:000169830600008
ER

PT J
AU Vanderbeck, F
TI A nested decomposition approach to a three-stage, two-dimensional
   cutting-stock problem
SO MANAGEMENT SCIENCE
VL 47
IS 6
BP 864
EP 879
DI 10.1287/mnsc.47.6.864.9809
PD JUN 2001
PY 2001
AB We consider the cutting of rectangular order pieces into stock pieces of
   specified width and length. The cutting process involves three stages of
   orthogonal guillotine cutting: Stock pieces are cut into sections that
   are cut into slits that are cut into order pieces. Restrictions imposed
   on the cutting process make the combinatorial structure of the problem
   more complex, but limit the scope of solution space. The objective of
   the problem is mainly to minimize waste, but our model also accounts for
   other issues such as aging stock pieces, urgent or optional orders, and
   fixed setup costs. Our solution approach involves a nested decomposition
   of the problem and the recursive use of the column-generation technique:
   We use a column-generation formulation of the problem (Gilmore and
   Gomory 1965) and the cutting-pattern-generation subproblem is itself
   solved using a column-generation algorithm. LP-based lower bounds on the
   minimum cost are computed and, by rounding the LP solution, a feasible
   solution and associated upper bound is obtained. This approach could in
   principle be used in a branch-and-bound search to solve the problem to
   optimality. We report computational results for industrial instances.
   The algorithm is being used in industry as a production-planning tool.
ZS 0
ZR 0
Z8 1
ZB 0
ZA 0
TC 56
Z9 57
SN 0025-1909
UT WOS:000169830600009
ER

PT J
AU Corbett, CJ
   DeCroix, GA
TI Shared-savings contracts for indirect materials in supply chains:
   Channel profits and environmental impacts
SO MANAGEMENT SCIENCE
VL 47
IS 7
BP 881
EP 893
DI 10.1287/mnsc.47.7.881.9802
PD JUL 2001
PY 2001
AB There are many materials for which the quantity needed by a firm is at
   best indirectly related to the quantity of final product produced by
   that firm, such as solvents in manufacturing processes or office
   supplies. For any such "indirect" materials, an inescapable incentive
   conflict exists: The buyer wishes to minimize consumption of these
   indirect materials, while the supplier's profits depend on increasing
   volume. Both buyer and supplier can exert effort to reduce consumption,
   hence making the overall supply chain more efficient. However, no
   supplier will voluntarily participate unless contract terms are
   fundamentally revised. This can be done through a variety of
   "shared-savings" contracts, where both parties profit from a consumption
   reduction. This paper analyzes several such contracts currently in use
   for chemicals purchasing. We show that such contracts can always
   increase supply-chain profits but need not lead to reduced consumption.
   We analyze equilibrium effort levels, consumption, and total profits,
   and show how these change with the contract parameters. We find that the
   goals of maximizing joint profits and minimizing consumption are
   generally not aligned. Also, surprisingly, a decrease in a cost
   parameter can lead to a decrease in profits; it may be necessary (but is
   always possible) to renegotiate the shared-savings contract to reap the
   benefits of a cost decrease.
RI corbett, charles j/B-2454-2008
OI corbett, charles j/0000-0003-1814-3977
Z8 21
ZS 0
ZR 0
ZB 4
TC 122
ZA 0
Z9 143
SN 0025-1909
UT WOS:000170475400001
ER

PT J
AU Oliva, R
   Sterman, JD
TI Cutting corners and working overtime: Quality erosion in the service
   industry
SO MANAGEMENT SCIENCE
VL 47
IS 7
BP 894
EP 914
DI 10.1287/mnsc.47.7.894.9807
PD JUL 2001
PY 2001
AB The erosion of service quality throughout the economy is a frequent
   concern in the popular press. The American Customer Satisfaction Index
   for services fell in 2000 to 69.4%, down 5 percentage points from 1994.
   We hypothesize that the characteristics of services-inseparability
   intangibility and labor intensity-interact with management practices to
   bias service providers toward reducing the level of service they
   deliver, often locking entire industries into a vicious cycle of eroding
   service standards. To explore this proposition we develop a formal model
   that integrates the structural elements of service delivery. We use
   econometric estimation, interviews, observations, and archival data to
   calibrate the model for a consumer-lending service center in a major
   bank in the United Kingdom. We find that temporary imbalances between
   service capacity and demand interact with decision rules for effort
   allocation, capacity management, overtime, and quality aspirations to
   yield permanent erosion of the service standards and loss of revenue. We
   explore policies to improve performance and implications for
   organizational design in the service sector.
RI Oliva, Rogelio/A-8542-2008
OI Oliva, Rogelio/0000-0001-7716-1310
ZS 0
ZB 1
Z8 0
ZR 0
ZA 0
TC 221
Z9 221
SN 0025-1909
UT WOS:000170475400002
ER

PT J
AU Ha, AY
TI Optimal pricing that coordinates queues with customer-chosen service
   requirements
SO MANAGEMENT SCIENCE
VL 47
IS 7
BP 915
EP 930
DI 10.1287/mnsc.47.7.915.9806
PD JUL 2001
PY 2001
AB This article considers the problem of coordinating the admission rates
   and service requirements of a multiclass queue when these decisions are
   made on a decentralized basis. The customer classes are characterized by
   different demand patterns, delay costs, and service costs. Customers
   make individual decisions on whether to join the queue and, if so, their
   service requirements. Their class identities and service requirements
   are private information not known to the system manager. We develop a
   two-stage decision framework to analyze the problem and characterize the
   optimal admission rates and service requirements under both centralized
   and decentralized assumptions. We distinguish admission and service
   externality costs that lead to suboptimal performance under
   decentralized control. For a given service discipline, we derive optimal
   class-specific pricing schemes that can coordinate the system when only
   service requirements but not class identities are unobservable. When
   customer class identities are also unobservable, we consider two common
   service disciplines that offer undifferentiated service: processor
   sharing and first-come-first-served. Based on the general framework, for
   the M/G/s processor sharing queue, we show that a single variable fee
   (payment per unit of time in the system) can induce the optimal
   admission rates and service requirements for all customer classes. For
   the M/G/1 first-come-first-served queue, we show that a single pricing
   scheme that is quadratic in time in service can induce the optimal
   admission rates and service requirements for all customer classes. Our
   result demonstrates that, under suitable conditions, simple and
   undifferentiated pricing can coordinate complex queueing systems with
   heterogeneous customer classes.
ZR 0
ZB 0
TC 28
Z8 2
ZS 0
ZA 0
Z9 30
SN 0025-1909
UT WOS:000170475400003
ER

PT J
AU Klausner, A
   Pollak, M
TI Comparative reliability of verdicts
SO MANAGEMENT SCIENCE
VL 47
IS 7
BP 931
EP 948
DI 10.1287/mnsc.47.7.931.9801
PD JUL 2001
PY 2001
AB We consider the problem of evaluating the reliability of a verdict given
   by a panel of judges. Given no information other than the number of
   panelists for and against, we address the question of when is a verdict
   that was obtained by a majority of k(1) vs. j(1) more or less reliable
   than one reached by k(2) vs j(2) We define criteria and investigate
   which verdicts are comparable and which are not. Consequences of this
   study may have bearing on choice of panel size and decision rule for
   decision-making bodies, such as courts, juries, committees, and boards.
   As implied by the above, our perspective is a posterior view of
   reliability though it also entails prior concern regarding how the
   reliability of a verdict will be perceived after being delivered. As an
   example, we apply our results to comparing the reliability of different
   verdicts handed down by the Supreme Court of the State of Israel and
   assessing the option of expanding a hearing on a case from a bench of
   three judges to a larger panel.
Z8 0
ZB 0
ZA 0
ZS 0
ZR 0
TC 1
Z9 1
SN 0025-1909
UT WOS:000170475400004
ER

PT J
AU Davydov, D
   Linetsky, V
TI Pricing and hedging path-dependent options under the CEV process
SO MANAGEMENT SCIENCE
VL 47
IS 7
BP 949
EP 965
DI 10.1287/mnsc.47.7.949.9804
PD JUL 2001
PY 2001
AB Much of the work on path-dependent options assumes that the underlying
   asset price follows geometric Brownian motion with constant volatility
   This paper uses a more general assumption for the asset price process
   that provides a better fit to the empirical observations. We use the
   so-called constant elasticity of variance (CEV) diffusion model where
   the volatility is a function of the underlying asset price. We derive
   analytical formulae for the prices of important types of path-dependent
   options under this assumption. We demonstrate that the prices of
   options, which depend on extrema, such as barrier and lookback options,
   can be much more sensitive to the specification of the underlying price
   process than standard call and put options and show that a financial
   institution that uses the standard geometric Brownian motion assumption
   is exposed to significant pricing and hedging errors when dealing in
   path-dependent options.
RI Linetsky, Vadim/B-7474-2009
ZA 0
Z8 19
ZS 1
ZR 0
TC 193
ZB 1
Z9 211
SN 0025-1909
EI 1526-5501
UT WOS:000170475400005
ER

PT J
AU Corbett, CJ
   Karmarkar, US
TI Competition and structure in serial supply chains with deterministic
   demand
SO MANAGEMENT SCIENCE
VL 47
IS 7
BP 966
EP 978
DI 10.1287/mnsc.47.7.966.9799
PD JUL 2001
PY 2001
AB Supply chains often consist of several tiers, with different numbers of
   firms competing at each tier. A major determinant of the structure of
   supply chains is the cost structure associated with the underlying
   manufacturing process. In this paper, we examine the impact of fixed and
   variable costs on the structure and competitiveness of supply chains
   with a serial structure and price-sensitive linear deterministic demand.
   The entry stage is modeled as a simultaneous game, where the players
   take the outcomes of the subsequent post-entry (Cournot) competition
   into account in making their entry decisions. We derive expressions for
   prices and production quantities as functions of the number of entrants
   at each tier of a multitier chain. We characterize viability and
   stability of supply-chain structures and show, using lattice arguments,
   that there is always an equilibrium structure in pure strategies in the
   entry game. Finally, we examine the effects of vertical integration in
   the two-tier case. Altogether, the paper provides a framework for
   comparing a variety of supply-chain structures and for studying how they
   are affected by cost structures and by the number of entrants throughout
   the chain.
RI corbett, charles j/B-2454-2008
OI corbett, charles j/0000-0003-1814-3977
ZB 4
ZS 1
Z8 11
ZR 0
TC 149
ZA 0
Z9 159
SN 0025-1909
UT WOS:000170475400006
ER

PT J
AU Burnetas, A
   Gilbert, S
TI Future capacity procurements under unknown demand and increasing costs
SO MANAGEMENT SCIENCE
VL 47
IS 7
BP 979
EP 992
DI 10.1287/mnsc.47.7.979.9803
PD JUL 2001
PY 2001
AB In this paper we study a situation in which a broker must manage the
   procurement of a short-life-cycle product. As the broker observes demand
   for the item, she learns about the demand process. However, as is often
   the case in practice, it becomes either more difficult or more expensive
   to procure the item as the selling season advances. Thus, the broker
   must trade off higher procurement costs against the benefit of making
   ordering decisions with better information about demand. Problems of
   this type arise, for example, in the travel industry, where a travel
   agent's cost of procuring airline and hotel reservations increases as
   the date of a vacation package approaches. We develop a newsvendor-like
   characterization of the optimal procurement policy. In a numerical
   analysis, we demonstrate how broker procurements tend to cluster just
   before price increases and how brokers can benefit from explicitly
   considering the effects of information about demand in their ordering
   policies.
RI Burnetas, Apostolos/O-2911-2014
OI Burnetas, Apostolos/0000-0002-9365-9255
ZB 0
Z8 1
ZS 0
ZR 0
ZA 0
TC 27
Z9 28
SN 0025-1909
UT WOS:000170475400007
ER

PT J
AU Belvaux, G
   Wolsey, LA
TI Modelling practical lot-sizing problems as mixed-integer programs
SO MANAGEMENT SCIENCE
VL 47
IS 7
BP 993
EP 1007
DI 10.1287/mnsc.47.7.993.9800
PD JUL 2001
PY 2001
AB In spite of the remarkable improvements in the quality of general
   purpose mixed-integer programming software, the effective solution of a
   variety of lot-sizing problems depends crucially on the development of
   tight formulations for the special problem features occurring in
   practice.
   After reviewing some of the basic preprocessing techniques for handling
   safety stocks and multilevel problems, we discuss a variety of aspects
   arising particularly in small and large bucket (time period) models such
   as start-ups, changeovers, minimum batch sizes, choice of one or two
   set-ups per period, etc. A set of applications is described that
   contains one or more of these special features, and some indicative
   computational results are presented. Finally, to show another technique
   that is useful, a slightly different (supply chain) application is
   presented, for which the a priori addition of some simple mixed-integer
   inequalities, based on aggregation, leads to important improvements in
   the results.
ZS 3
TC 95
Z8 0
ZA 0
ZR 0
ZB 0
Z9 97
SN 0025-1909
UT WOS:000170475400008
ER

PT J
AU Fischetti, M
   Salazar, JJ
TI Solving the cell suppression problem on tabular data with linear
   constraints
SO MANAGEMENT SCIENCE
VL 47
IS 7
BP 1008
EP 1027
DI 10.1287/mnsc.47.7.1008.9805
PD JUL 2001
PY 2001
AB Cell suppression is a widely used technique for protecting sensitive
   information in statistical data presented in tabular form. Previous
   works on the subject mainly concentrate on 2- and 3-dimensional tables
   whose entries are subject to marginal totals. In this paper we address
   the problem of protecting sensitive data in a statistical table whose
   entries are linked by a generic system of linear constraints. This very
   general setting covers, among others, k-dimensional tables with
   marginals as well as the so-called hierarchical and linked tables that
   are very often used nowadays for disseminating statistical data. In
   particular, we address the optimization problem known in the literature
   as the (secondary) Cell Suppression Problem, in which the information
   loss due to suppression has to be minimized. We introduce a new integer
   linear programming model and outline an enumerative algorithm for its
   exact solution. The algorithm can also be used as a heuristic procedure
   to find near-optimal solutions. Extensive computational results on a
   test-bed of 1,160 real-world and randomly generated instances are
   presented, showing the effectiveness of the approach. In particular, we
   were able to solve to proven optimality 4-dimensional tables with
   marginals as well as linked tables of reasonable size (to our knowledge,
   tables of this kind were never solved optimally by previous authors).
RI Gonzalez, Juan Jose Salazar/C-3671-2014
OI Gonzalez, Juan Jose Salazar/0000-0001-5683-0271
ZR 0
TC 32
ZB 1
ZS 0
ZA 0
Z8 0
Z9 32
SN 0025-1909
UT WOS:000170475400009
ER

PT J
AU Natter, M
   Mild, A
   Feurstein, M
   Dorffner, G
   Taudes, A
TI The effect of incentive schemes and organizational arrangements on the
   new product development process
SO MANAGEMENT SCIENCE
VL 47
IS 8
BP 1029
EP 1045
DI 10.1287/mnsc.47.8.1029.10228
PD AUG 2001
PY 2001
AB This paper proposes a new model for studying the new product development
   process in an artificial environment. We show how connectionist models
   can be used to simulate the adaptive nature of agents' learning
   exhibiting similar behavior as practically experienced learning curves.
   We study the impact of incentive schemes (local, hybrid, and global) on
   the new product development process for different types of
   organizations. Sequential organizational structures are compared to two
   different types of team-based organizations, incorporating methods of
   quality function deployment such as the house of quality. A key finding
   of this analysis is that the firms' organizational structure and agents'
   incentive system significantly interact. We show that the house of
   quality is less affected by the incentive scheme than firms using a
   trial and error approach. This becomes an important factor for new
   product success when the agents' performance measures are conflicting.
RI Mild, Andreas/AAE-1523-2020; Dorffner, Georg/AAQ-1455-2020; Dorffner, Georg/
OI Dorffner, Georg/0000-0002-3181-2576
TC 25
ZR 0
ZA 0
ZB 0
Z8 0
ZS 1
Z9 26
SN 0025-1909
UT WOS:000170629600001
ER

PT J
AU Milner, JM
   Pinker, EJ
TI Contingent labor contracting under demand and supply uncertainty
SO MANAGEMENT SCIENCE
VL 47
IS 8
BP 1046
EP 1062
DI 10.1287/mnsc.47.8.1046.10233
PD AUG 2001
PY 2001
AB Firms increasingly use contingent labor to flexibly respond to demand in
   many environments. Labor supply agencies are growing to fill this need.
   As a result, firms and agencies are engaging in long-term contracts for
   labor supply. We develop mathematical models of the interaction between
   firms and labor supply agencies when demand and supply are uncertain. We
   consider two models of labor supply uncertainty, termed productivity and
   availability uncertainty, and study how each affects the nature of the
   contracts formed. These models reflect two major roles played by the
   labor supply agency. In the case of productivity uncertainty we find
   that it is possible to construct a contract that coordinates the firm
   and agency hiring in an optimal way. In contrast, we show that in
   environments characterized by availability uncertainty, optimal
   contracts are not possible. However, there is a large range of contract
   parameters for which both parties would benefit from a contract. We
   analyze these and discuss the trade-offs that should be considered in
   contract negotiation.
RI Pinker, Edieal/A-9253-2008
Z8 4
ZA 0
ZB 0
ZR 1
ZS 0
TC 31
Z9 36
SN 0025-1909
UT WOS:000170629600002
ER

PT J
AU Kouvelis, P
   Axarloglou, K
   Sinha, V
TI Exchange rates and the choice of ownership structure of production
   facilities
SO MANAGEMENT SCIENCE
VL 47
IS 8
BP 1063
EP 1080
DI 10.1287/mnsc.47.8.1063.10227
PD AUG 2001
PY 2001
AB The aim of this research is to study the effects of real exchange rates
   on the long-term ownership strategies of production facilities of firms
   entering foreign markets. Among the strategies considered are exporting
   (EXP), joint ventures with local partners (JV), and wholly owned
   production facilities (WOS) in the foreign country. Our research takes a
   first step in modeling the influence of exchange rates on the choice and
   dynamic adjustment of such strategies. The insights obtained from our
   modeling analysis are then translated into testable hypotheses and
   empirically verified with the use of firm level data from U.S.
   multinational corporations (both at the firm and a more aggregate
   level). An insightful result of our model is the identification of a
   hysteresis phenomenon that characterizes switching behavior between
   strategies in the presence of switchover cost. The magnitude of the
   hysteresis band, which is a measure of the inertia associated with
   keeping the current ownership structure, is affected by a multiplicity
   of factors such as exchange rate volatility and market power of the
   entering firm. Analytical and numerical results on the effects of such
   factors on the hysteresis band are provided. The four testable
   hypotheses generated from our modeling analysis are rigorously tested
   with the use of a multinomial logit model on data obtained from the
   Harvard Multinational Enterprise database, and a data set maintained by
   the Bureau of Economic Analysis, the U.S. Department of Commerce. The
   empirical results strongly support our insights that relatively
   depreciated real exchange rates (i.e., weak home currency) favor (a) the
   JV over the WOS and (b) EXP mode over the WOS or JV Finally, we
   summarize our results into useful guidelines for global production
   managers.
RI Kouvelis, Panos/ABG-2350-2020
ZS 0
ZA 0
Z8 2
ZB 0
TC 44
ZR 0
Z9 46
SN 0025-1909
UT WOS:000170629600003
ER

PT J
AU Atamturk, A
   Hochbaum, DS
TI Capacity acquisition, subcontracting, and lot sizing
SO MANAGEMENT SCIENCE
VL 47
IS 8
BP 1081
EP 1100
DI 10.1287/mnsc.47.8.1081.10232
PD AUG 2001
PY 2001
AB The fundamental question encountered in acquiring capacity to meet
   nonstationary demand over a multiperiod horizon is how to balance the
   trade-off between having insufficient capacity in some periods and
   excess capacity in others. In the former situation, part of the demand
   is subcontracted while, in the latter, capacity that has been paid for
   is rendered idle. Capacity and subcontracting decisions arise in many
   economic activities ranging from production capacity planning in
   semiconductor fabs to leasing communication networks, from
   transportation contracts to staffing of call centers. In this paper, we
   investigate the trade-offs between acquiring capacity, subcontracting,
   production, and holding inventory to satisfy nonstationary demand over a
   finite horizon. We present capacity acquisition models with holding and
   without holding inventory and identify forecast-robust properties of the
   models that restrict the dependence of optimal capacity decisions on the
   demand forecasts. We develop algorithms for numerous practical cost
   structures involving variable and fixed charges and prove that they all
   have polynomial time complexity. For models with inventory, we solve a
   sequence of constant capacity lot-sizing and subcontracting subproblems,
   which is also of independent interest.
TC 82
ZS 1
ZR 0
Z8 12
ZA 0
ZB 0
Z9 94
SN 0025-1909
UT WOS:000170629600004
ER

PT J
AU Godfrey, GA
   Powell, WB
TI An adaptive, distribution-free algorithm for the newsvendor problem with
   censored demands, with applications to inventory and distribution
SO MANAGEMENT SCIENCE
VL 47
IS 8
BP 1101
EP 1112
DI 10.1287/mnsc.47.8.1101.10231
PD AUG 2001
PY 2001
AB We consider the problem of optimizing inventories for problems where the
   demand distribution is unknown, and where it does not necessarily follow
   a standard form such as the normal. We address problems where the
   process of deciding the inventory, and then realizing the demand, occurs
   repeatedly. The only information we use is the amount of inventory left
   over. Rather than attempting to estimate the demand distribution, we
   directly estimate the value function using a technique called the
   Concave, Adaptive Value Estimation (CAVE) algorithm. CAVE constructs a
   sequence of concave piecewise linear approximations using sample
   gradients of the recourse function at different points in the domain.
   Since it is a sampling-based method, CAVE does not require knowledge of
   the underlying sample distribution. The result is a nonlinear
   approximation that is more responsive than traditional linear stochastic
   quasi-gradient methods and more flexible than analytical techniques that
   require distribution information. In addition, we demonstrate
   near-optimal behavior of the CAVE approximation in experiments involving
   two different types of stochastic programs the newsvendor stochastic
   inventory problem and two-stage distribution problems.
RI Powell, Warren/N-8263-2019
ZS 0
ZA 0
Z8 4
TC 102
ZR 0
ZB 0
Z9 105
SN 0025-1909
UT WOS:000170629600005
ER

PT J
AU Vanhoucke, M
   Demeulemeester, E
   Herroelen, W
TI On maximizing the net present value of a project under renewable
   resource constraints
SO MANAGEMENT SCIENCE
VL 47
IS 8
BP 1113
EP 1121
DI 10.1287/mnsc.47.8.1113.10226
PD AUG 2001
PY 2001
AB In this paper we study the resource-constrained project-scheduling
   problem with discounted cash flows. Each activity of this
   resource-constrained project-scheduling problem has certain resource
   requirements and a known deterministic cash flow that can be either
   positive or negative. Deterministic cash flows are assumed to occur over
   the duration of the activities. Progress payments and cash outflows
   occur at the completion of activities. The objective is to schedule the
   activities subject to a fixed deadline to maximize the net present value
   subject to the precedence and resource constraints. With these features
   the financial aspects of project management are taken into account.
   We introduce a depth-first branch-and-bound algorithm that makes use of
   extra precedence relations to resolve a number of resource conflicts and
   a fast recursive search algorithm for the max-npv problem to compute
   upper bounds. The recursive search algorithm exploits the idea that
   positive cash flows should be scheduled as early as possible while
   negative cash flows should be scheduled as late as possible within the
   precedence constraints. The procedure has been coded in Visual C++,
   Version 4.0 under Windows NT, and has been validated on two problem
   sets.
RI Vanhoucke, Mario/D-8647-2015
OI Vanhoucke, Mario/0000-0001-6702-3563
ZA 0
Z8 3
TC 49
ZS 0
ZR 1
ZB 1
Z9 53
SN 0025-1909
EI 1526-5501
UT WOS:000170629600006
ER

PT J
AU Duan, JC
   Gauthier, G
   Simonato, JG
TI Asymptotic distribution of the EMS option price estimator
SO MANAGEMENT SCIENCE
VL 47
IS 8
BP 1122
EP 1132
DI 10.1287/mnsc.47.8.1122.10234
PD AUG 2001
PY 2001
AB Monte Carlo simulation is commonly used for computing prices of
   derivative securities when an analytical solution does not exist.
   Recently, a new simulation technique known as empirical martingale
   simulation (EMS) has been proposed by Duan and Simonato (1998) as a way
   of improving simulation accuracy. EMS has one drawback however. Because
   of the dependency among sample paths created by the EMS adjustment, the
   standard error of the price estimate is not readily available from using
   one simulation sample. In this paper, we develop a scheme to estimate
   the EMS accuracy. The EMS price estimator is first shown to have an
   asymptotically normal distribution. Through a simulation study, we then
   find that the asymptotic normal distribution serves as a good
   approximation for samples consisting of as few as 500 simulation paths.
RI Duan, Jin-Chuan/D-2408-2016
ZB 0
ZS 0
ZR 0
TC 8
Z8 0
Z9 8
SN 0025-1909
UT WOS:000170629600007
ER

PT J
AU Chick, SE
   Inoue, K
TI New procedures to select the best simulated system using common random
   numbers
SO MANAGEMENT SCIENCE
VL 47
IS 8
BP 1133
EP 1149
DI 10.1287/mnsc.47.8.1133.10229
PD AUG 2001
PY 2001
AB Although simulation is widely used to select the best of several
   alternative system designs, and common random numbers is an important
   tool for reducing the computation effort of simulation experiments,
   there are surprisingly few tools available to help a simulation
   practitioner select the best system when common random numbers are
   employed. This paper presents new two-stage procedures that use common
   random numbers to help identify the best simulated system. The
   procedures allow for screening and attempt to allocate additional
   replications to improve the value of information obtained during the
   second stage, rather than determining the number of replications
   required to provide a given probability of correct selection guarantee.
   The procedures allow decision makers to reduce either the expected
   opportunity cost associated with potentially selecting an inferior
   system, or the probability of incorrect selection. A small empirical
   study indicates that the new procedures outperform several procedures
   with respect to several criteria, and identifies potential areas for
   further improvement.
ZA 0
TC 86
Z8 1
ZR 0
ZB 0
ZS 0
Z9 87
SN 0025-1909
EI 1526-5501
UT WOS:000170629600008
ER

PT J
AU Levy, H
   Guttman, I
   Tkatch, I
TI Regression, correlation, and the time interval: Additive-multiplicative
   framework
SO MANAGEMENT SCIENCE
VL 47
IS 8
BP 1150
EP 1159
DI 10.1287/mnsc.47.8.1150.10225
PD AUG 2001
PY 2001
AB Then two random variables are both additive or multiplicative, the
   effect of the way one "slices" the available period to subperiods (time
   intervals) is well documented in the literature. In this paper, we
   investigate the time interval effect when one of the variables is
   additive and one is multiplicative. We prove that the squared
   multiperiod correlation coefficient (rho (2)(n)) decreases monotonically
   as n increases, and approaches zero when n goes n to infinity. However,
   for relevant data corresponding to the U.S. stock market index, when
   shifting from weekly parameters to quarterly parameters the decrease in
   rho (2)(n) is negligible. n The effect on the regression coefficient is
   much more dramatic and even a shift from weekly data to quarterly data
   affects the regression coefficient substantially. The regression slope
   generally approaches zero, minus infinity or plus infinity, as the
   number of periods increases. Montonicity, however, exists only in
   certain cases.
ZA 0
TC 9
Z8 0
ZB 1
ZR 0
ZS 0
Z9 9
SN 0025-1909
UT WOS:000170629600009
ER

PT J
AU Bennell, JA
   Dowsland, KA
TI Hybridising tabu search with optimisation techniques for irregular stock
   cutting
SO MANAGEMENT SCIENCE
VL 47
IS 8
BP 1160
EP 1172
DI 10.1287/mnsc.47.8.1160.10230
PD AUG 2001
PY 2001
AB Sequential meta-heuristic implementations for the irregular
   stock-cutting problem have highlighted a number of common problems. The
   literature suggests a consensus that it is more efficient to allow
   configurations with overlapping pieces in the solution space and to
   penalise these in the evaluation function. However, depending on the
   severity of the penalty this relaxation results in a tendency to
   converge toward infeasible solutions or to seek out feasible solutions
   at the expense of overall quality. A further problem is encountered in
   defining a neighbourhood search strategy that can deal with the infinite
   solution space inherent in the irregular stock-cutting problem. The
   implementation in this paper adopts a hybrid tabu search approach that
   incorporates two very different optimisation routines that utilise
   alternative neighbourhoods to address the described problems.
ZS 1
TC 46
Z8 0
ZR 0
ZB 0
ZA 0
Z9 46
SN 0025-1909
EI 1526-5501
UT WOS:000170629600010
ER

PT J
AU Shane, S
TI Technology regimes and new firm formation
SO MANAGEMENT SCIENCE
VL 47
IS 9
BP 1173
EP 1190
DI 10.1287/mnsc.47.9.1173.9785
PD SEP 2001
PY 2001
AB At least since Schumpeter (1934 and 1942), researchers have been
   interested in identifying the dimensions of technology regimes that
   facilitate new firm formation as a mode of technology exploitation.
   Using data on 1,397 patents assigned to the Massachusetts Institute of
   Technology during the 1980-1996. period, I show that four hypothesized
   dimensions of the technology regime-the age of the technical field, the
   tendency of the market toward segmentation, the effectiveness of
   patents, and the importance of complementary assets in marketing and
   distribution-influence the likelihood that new technology will be
   exploited through firm formation.
ZS 1
Z8 4
ZA 0
ZB 2
TC 170
ZR 0
Z9 175
SN 0025-1909
UT WOS:000171419000001
ER

PT J
AU Conlon, E
   Devaraj, S
   Matta, KF
TI The relationship between initial quality perceptions and maintenance
   behavior: The case of the automotive industry
SO MANAGEMENT SCIENCE
VL 47
IS 9
BP 1191
EP 1202
DI 10.1287/mnsc.47.9.1191.9788
PD SEP 2001
PY 2001
AB W e examine the relationship between quality, represented by consumer
   ratings, and quality-related activities by the customer, represented by
   maintenance activities in the automotive industry. Based on several
   converging theoretical perspectives, we present and test a model
   relating vehicle initial quality ratings to consumers' routine
   maintenance. Three types of data were collected for the study: (1)
   vehicle service records at a local dealership, (2) primary data from a
   survey of vehicle owners, and (3) Consumer Reports data on quality
   ratings and initial purchase prices. The results of a structural
   equation analysis of the proposed model indicate a significant link
   between quality and customers' quality behavior. This link has important
   strategic implications for both automotive manufacturers and
   distributors, particularly as "leasing" becomes more prevalent in the
   industry.
ZB 0
ZA 0
ZR 0
ZS 0
Z8 0
TC 17
Z9 17
SN 0025-1909
EI 1526-5501
UT WOS:000171419000002
ER

PT J
AU Ba, SL
   Stallaert, J
   Whinston, AB
TI Optimal investment in knowledge within a firm using a market mechanism
SO MANAGEMENT SCIENCE
VL 47
IS 9
BP 1203
EP 1219
DI 10.1287/mnsc.47.9.1203.9781
PD SEP 2001
PY 2001
AB There has been an extensive research literature on auctions, but recent
   developments in technology have resulted in new interest in auction
   mechanisms as a practical way of allocating resources. This paper
   presents a new double-auction mechanism to handle resource allocation
   for public goods when complementarity exists.
   The mechanism is placed in the context of an organization's internal
   knowledge investment. Knowledge goods have two distinct Characteristics.
   First, knowledge within an organization can be considered a public good,
   so it is subject to the free-rider problem. Second, knowledge is
   interrelated and interdependent; that is, there is complementarity among
   knowledge components. The value of knowledge often derives from a bundle
   of knowledge components, rather than from its individual pieces. These
   two characteristics present a serious challenge to allocating
   organizational resources for knowledge goods.
   We introduce an internal market in which knowledge providers offer
   knowledge projects and knowledge consumers place bids to acquire them.
   The mechanism is a Groves-Clarke-type double auction that allows bundled
   knowledge goods to be traded so as to recognize complementarities
   between knowledge projects. The market mechanism we propose is incentive
   compatible; i.e., it induces people to reveal their true valuation. In
   addition, it allows trades of knowledge bundles to determine which
   knowledge components are most valuable from the organization's
   viewpoint. Under mild assumptions, the mechanism is a computationally
   tractable solution to operating a market of bundled public goods. We
   further show how "imputed prices" can be calculated for subsets of
   knowledge components and prove that a market mechanism that does not
   allow bundle orders or does not address the free-rider problem yields a
   systematic underinvestment in knowledge.
ZB 0
ZR 1
TC 42
ZS 0
Z8 4
ZA 0
Z9 47
SN 0025-1909
EI 1526-5501
UT WOS:000171419000003
ER

PT J
AU Taylor, TA
TI Channel coordination under price protection, midlife returns, and
   end-of-life returns in dynamic markets
SO MANAGEMENT SCIENCE
VL 47
IS 9
BP 1220
EP 1234
DI 10.1287/mnsc.47.9.1220.9786
PD SEP 2001
PY 2001
AB This paper examines three channel policies that are used in declining
   price environments: Price protection (P) is a mechanism under which the
   manufacturer pays the retailer a credit applying to the retailer's
   unsold inventory when the wholesale price drops during the life cycle;
   midlife returns (M) allow the retailer to return units partway through
   the life cycle at some rebate; and end-of-life returns (E) allow the
   retailer to return unsold units at the end of the life cycle. Under
   declining retail prices, if the wholesale prices and the return rebates
   are set properly, then EM (i.e., midlife and end-of-life returns)
   achieves channel coordination. However, such a policy may not be
   implementable because it may require the manufacturer to be worse off as
   a result of coordination. If P is used in addition to EM and the terms
   are set properly, then PEM guarantees both coordination and a win-win
   outcome. If the retail price is constant over time, then EM is
   sufficient to guarantee both coordination and a win-win outcome.
Z8 14
TC 88
ZR 0
ZS 0
ZB 1
ZA 0
Z9 101
SN 0025-1909
UT WOS:000171419000004
ER

PT J
AU Lauritzen, SL
   Nilsson, D
TI Representing and solving decision problems with limited information
SO MANAGEMENT SCIENCE
VL 47
IS 9
BP 1235
EP 1251
DI 10.1287/mnsc.47.9.1235.9779
PD SEP 2001
PY 2001
AB We introduce the notion of LImited Memory Influence Diagram (LIMID) to
   describe multistage decision problems in which the traditional
   assumption of no forgetting is relaxed. This can be relevant in
   situations with multiple decision makers or when decisions must be
   prescribed under memory constraints, such as in partially observed
   Markov decision processes (POMDPs). We give an algorithm for improving
   any given strategy by local computation of single policy updates and
   investigate conditions for the resulting strategy to be optimal.
RI Lauritzen, Steffen L/L-9314-2014
OI Lauritzen, Steffen L/0000-0001-7176-6212
ZR 0
ZS 0
ZB 3
Z8 2
ZA 0
TC 103
Z9 105
SN 0025-1909
EI 1526-5501
UT WOS:000171419000005
ER

PT J
AU Teo, CP
   Sethuraman, J
   Tan, WP
TI Gale-Shapley stable marriage problem revisited: Strategic issues and
   applications
SO MANAGEMENT SCIENCE
VL 47
IS 9
BP 1252
EP 1267
DI 10.1287/mnsc.47.9.1252.9784
PD SEP 2001
PY 2001
AB We study strategic issues in the Gale-Shapley stable marriage model. Iri
   the first part of the paper, we derive the optimal cheating strategy and
   show that it is not always possible for a woman to recover her
   women-optimal stable partner from the men-optimal stable matching
   mechanism when she can only cheat by permuting her preferences. In fact,
   we show, using simulation, that the chances that a woman can benefit
   from cheating are slim. In the second part of the paper, we consider a
   two-sided matching market found in Singapore. We study the matching
   mechanism used by the Ministry of Education (MOE) in the placement of
   primary six students in secondary schools, and discuss why the current
   method has limited success in accommodating the preferences of the
   students, and the specific needs of the schools (in terms of the "mix"
   of admitted students). Using insights from the first part of the paper,
   we show that stable matching mechanisms are more appropriate in this
   matching market and explain why the strategic behavior of the students
   need not be a major concern.
RI Teo, Chung Piaw/P-8070-2015; Teo, Chung Piaw/
OI Teo, Chung Piaw/0000-0002-0534-6858
ZR 1
ZB 0
TC 52
ZS 0
ZA 0
Z8 18
Z9 71
SN 0025-1909
UT WOS:000171419000006
ER

PT J
AU Toktay, LB
   Wein, LM
TI Analysis of a forecasting-production-inventory system with stationary
   demand
SO MANAGEMENT SCIENCE
VL 47
IS 9
BP 1268
EP 1281
DI 10.1287/mnsc.47.9.1268.9787
PD SEP 2001
PY 2001
AB We consider a production stage that produces a single item in a
   make-to-stock manner. Demand for finished goods is stationary. In each
   time period, an updated vector of demand forecasts over the forecast
   horizon becomes available for use in production decisions. We model the
   sequence of forecast update vectors using the Martingale model of
   forecast evolution developed by Graves et al. (1986, 1998) and Heath and
   Jackson (1994). The production stage is modeled as a single-server,
   discrete-time, continuous-state queue. We focus on a modified base-stock
   policy incorporating forecast information and use an approximate
   analysis rooted in heavy traffic theory and random walk theory to obtain
   a closed-form expression for the (forecast-corrected) base-stock level
   that minimizes the expected steady-state inventory holding and backorder
   costs. This expression, which is shown to be accurate under certain
   conditions in a simulation study, sheds some light on the
   interrelationships among safety stock, stochastic correlated demand,
   inaccurate forecasts, and random and capacitated production in
   forecasting-production-inventory systems.
OI Toktay, L. Beril/0000-0001-7446-8253
ZA 0
ZB 0
Z8 0
ZR 0
ZS 1
TC 76
Z9 77
SN 0025-1909
UT WOS:000171419000007
ER

PT J
AU Balachander, S
TI Warranty signalling and reputation
SO MANAGEMENT SCIENCE
VL 47
IS 9
BP 1282
EP 1289
DI 10.1287/mnsc.47.9.1282.9783
PD SEP 2001
PY 2001
AB In this paper, we present a signalling-based explanation for the
   empirical phenomenon that a longer warranty may be offered by a product
   with lower quality. Our explanation hinges on differences in consumer
   knowledge about reliability of established and newer products. In a
   product market where a new entrant competes with an established product,
   we show that signalling behavior leads to an outcome where the less
   reliable product may carry the longer warranty.
Z8 2
TC 52
ZS 0
ZB 0
ZR 0
ZA 0
Z9 54
SN 0025-1909
UT WOS:000171419000008
ER

PT J
AU Stojkovic, M
   Soumis, F
TI An optimization model for the simultaneous operational flight and pilot
   scheduling problem
SO MANAGEMENT SCIENCE
VL 47
IS 9
BP 1290
EP 1305
DI 10.1287/mnsc.47.9.1290.9780
PD SEP 2001
PY 2001
AB This paper describes and solves the operational pilot scheduling problem
   for one day of operations. The problem consists in simultaneously
   modifying, as necessary, the existing flight departure schedules and
   planned individual work days (duties) while keeping planned aircraft
   itineraries unchanged. It requires the covering of all flights from one
   day of operations with available pilots while minimizing changes in both
   the flight schedule and the next day's planned duties. The newly
   constructed personalized duties must not exceed the maximum duty
   duration. Flight precedence constraints, coming from existing fixed
   aircraft itineraries, must be respected as well. The problem is
   mathematically formulated as an integer nonlinear multicommodity network
   flow model with time windows and additional constraints. To solve the
   problem, a Dantzig-Wolfe decomposition combined with a branch-and-bound
   method has been used. The master problem comprises the flight-covering
   constraints and a new set of flight precedence constraints. Subproblems
   consisting of time-constrained shortest-path problems with linear time
   costs are solved by a specialized dynamic-programming algorithm. The
   proposed optimization approach has been tested on several input data
   sets. All of them have been successfully solved in very short
   computational time.
Z8 0
ZA 0
ZR 0
ZS 0
TC 45
ZB 0
Z9 45
SN 0025-1909
UT WOS:000171419000009
ER

PT J
AU Axsater, S
TI A note on stock replenishment and shipment scheduling for vendor-managed
   inventory systems
SO MANAGEMENT SCIENCE
VL 47
IS 9
BP 1306
EP 1310
DI 10.1287/mnsc.47.9.1306.9782
PD SEP 2001
PY 2001
AB In a recent paper, Cetinkaya and Lee (2000) model integrated inventory
   control and shipment scheduling in connection with vendor-managed
   inventory (VMI). The model is optimized by an approximate technique.
   This note provides a simple procedure for exact optimization, and
   illustrates that the errors when using the suggested approximate
   technique may be very large for certain types of problems. We also
   suggest a new approximation and an adjustment that can be used to
   improve both the original and new heuristic.
ZA 0
ZB 0
TC 40
Z8 6
ZS 0
ZR 0
Z9 46
SN 0025-1909
UT WOS:000171419000010
ER

PT J
AU Lapre, MA
   Van Wassenhove, LN
TI Creating and transferring knowledge for productivity improvement in
   factories
SO MANAGEMENT SCIENCE
VL 47
IS 10
BP 1311
EP 1325
DI 10.1287/mnsc.47.10.1311.10264
PD OCT 2001
PY 2001
AB Can a firm accelerate its learning curve if knowledge about the
   production function is incomplete? This article identifies a production
   line specifically set up to create technological knowledge about its
   production function through scientific experimentation (formal learning)
   as opposed to learning by doing. The organizational structure of this
   line was very successful in creating technological knowledge. Formal
   learning resulted in huge productivity improvements. Replication of this
   organizational structure on three production lines in other plants
   within the same firm fell short of expectations. Formal learning did not
   result in similar productivity improvements. Our research suggests two
   factors that may facilitate creation and transfer of technological
   knowledge: management buy-in and knowledge diversity to solve
   interdepartmental problems.
RI Wang, Charles/B-5565-2011; Lapre, Michael/
OI Wang, Charles/0000-0001-9331-8437; Lapre, Michael/0000-0003-2259-8739
ZA 0
TC 98
ZS 1
ZB 0
Z8 0
ZR 0
Z9 98
SN 0025-1909
UT WOS:000172267400001
ER

PT J
AU Aviv, Y
TI The effect of collaborative forecasting on supply chain performance
SO MANAGEMENT SCIENCE
VL 47
IS 10
BP 1326
EP 1343
DI 10.1287/mnsc.47.10.1326.10260
PD OCT 2001
PY 2001
AB We consider a cooperative, two-stage supply chain consisting of two
   members: a retailer and a supplier. In our first model, called local
   forecasting, each member updates the forecasts of future demands
   periodically, and is able to integrate the adjusted forecasts into his
   replenishment process. Forecast adjustments made at both levels of the
   supply chain can be correlated. The supply chain has a decentralized
   information structure, so that day-to-day inventory and forecast
   information are known locally only. In our second model, named
   collaborative forecasting, the supply chain members jointly maintain and
   update a single forecasting process in the system. Hence, forecasting
   information becomes centralized. Finally, we consider as a benchmark the
   special case in which forecasts are not integrated into the
   replenishment processes at all. We propose a unified framework that
   allows us to study and compare the three types of settings. This study
   comes at a time when various types of collaborative forecasting
   partnerships are being experimented within industry, and when the
   drivers for success or failure of such initiatives are not yet fully
   understood. In addition to providing some managerial insights into
   questions that arise in this context, our set of models is tailored to
   serve as building blocks for future work in this emerging area of
   research.
RI Weller, Matt J/E-8421-2010
ZS 3
Z8 11
ZB 0
ZA 0
TC 280
ZR 0
Z9 291
SN 0025-1909
UT WOS:000172267400002
ER

PT J
AU Gallego, G
   Ozer, O
TI Integrating replenishment decisions with advance demand information
SO MANAGEMENT SCIENCE
VL 47
IS 10
BP 1344
EP 1360
DI 10.1287/mnsc.47.10.1344.10261
PD OCT 2001
PY 2001
AB There is a growing consensus that a portfolio of customers with
   different demand lead times can lead to higher, more regular revenues
   and better capacity utilization. Customers with positive demand lead
   times place orders in advance of their needs, resulting in advance
   demand information. This gives rise to the problem of finding effective
   inventory control policies under advance demand information. We show
   that state-dependent (s, S) and base-stock policies are optimal for
   stochastic inventory systems with and without fixed costs. The state of
   the system reflects our knowledge of advance demand information. We also
   determine conditions under which advance demand information has no
   operational value. A numerical study allows us to obtain additional
   insights and to evaluate strategies to induce advance demand
   information.
RI Gallego, Guillermo/AAK-1549-2020
OI Gallego, Guillermo/0000-0002-9664-3750
Z8 7
TC 154
ZS 0
ZB 0
ZR 0
ZA 0
Z9 161
SN 0025-1909
UT WOS:000172267400003
ER

PT J
AU Ortega, J
TI Job rotation as a learning mechanism
SO MANAGEMENT SCIENCE
VL 47
IS 10
BP 1361
EP 1370
DI 10.1287/mnsc.47.10.1361.10257
PD OCT 2001
PY 2001
AB This article analyzes the costs and benefits of job rotation as a
   mechanism with which the firm can learn about the employees'
   productivities and the profitability of different jobs or activities. I
   compare job rotation to an assignment policy where employees specialize
   in one job along their career. The gains from adopting a job rotation
   policy are larger when there is more prior uncertainty about employees
   and activities. I argue that this firm learning theory fits the existing
   evidence on rotation better than alternative explanations based on
   employee motivation and employee learning.
RI Ortega, Jaime/G-3103-2012
OI Ortega, Jaime/0000-0001-5434-0949
ZS 1
ZB 0
ZR 0
ZA 0
TC 98
Z8 3
Z9 101
SN 0025-1909
UT WOS:000172267400004
ER

PT J
AU Kukreja, A
   Schmidt, CP
   Miller, DM
TI Stocking decisions for low-usage items in a multilocation inventory
   system
SO MANAGEMENT SCIENCE
VL 47
IS 10
BP 1371
EP 1383
DI 10.1287/mnsc.47.10.1371.10263
PD OCT 2001
PY 2001
AB This research shows that organizations with a number of "sister" plants,
   warehouses, or other stocking points can profit from the concept of
   proactive use of transshipments as an element of their inventory control
   policy. For certain types of parts, employing transshipments can
   significantly reduce the total inventory needed throughout the entire
   collection of stocking points. The study is motivated by a real-life
   situation involving a large utility company having 29 power-generating
   plants in five Southeastern states where there are thousands of parts
   that are commonly used at multiple plants.
   At present, each plant operates independently and maintains enough stock
   to meet its own requirements. Transshipments take place between plants
   whenever there is an emergency requirement for a part, but no explicit
   consideration is given to this effect while deciding on stocking levels
   at different plants. In the case we examined, by setting stocking levels
   to explicitly take account of transshipments, total system cost could be
   reduced by about 70% over the company's decentralized policy.
   In general, this work considers a single-echelon, N-location,
   continuous-review inventory system in which complete pooling of stock is
   permitted among the locations. A model is developed for slow-moving,
   expensive, and consumable parts that are common to two or more
   locations. A one-for-one ordering policy and queueing theory allow
   development and solution of a system of equations for the probability
   distribution of net inventory at each location. A heuristic procedure is
   also developed to determine cost-effective stocking levels. Actual data
   from the utility company are used to demonstrate the applicability of
   the model. Savings achieved as a result of pooling are reported.
TC 69
ZB 0
ZR 0
Z8 14
ZA 0
ZS 2
Z9 85
SN 0025-1909
EI 1526-5501
UT WOS:000172267400005
ER

PT J
AU Lee, CY
   Cetinkaya, S
   Wagelmans, APM
TI A dynamic lot-sizing model with demand time windows
SO MANAGEMENT SCIENCE
VL 47
IS 10
BP 1384
EP 1395
PD OCT 2001
PY 2001
AB One of the basic assumptions of the classical dynamic lot-sizing model
   is that the aggregate demand of a given period must be satisfied in that
   period. Under this assumption, if backlogging is not allowed, then the
   demand of a given period cannot be delivered earlier or later than the
   period. If backlogging is allowed, the demand of a given period cannot
   be delivered earlier than the period, but it can be delivered later at
   the expense of a backordering cost. Like most mathematical models, the
   classical dynamic lot-sizing model is a simplified paraphrase of what
   might actually happen in real life. In most real-life applications, the
   customer offers a grace period-we call it a demand time window-during
   which a particular demand can be satisfied with no penalty. That is, in
   association with each demand, the customer specifies an acceptable
   earliest and a latest delivery time. The time interval characterized by
   the earliest and latest delivery dates of a demand represents the
   corresponding time window.
   This paper studies the dynamic lot-sizing problem with demand time
   windows and provides polynomial time algorithms for computing its
   solution. If backlogging is not allowed, the complexity of the proposed
   algorithm is O(T-2) where T is the length of the planning horizon. When
   backlogging is allowed, the complexity of the proposed algorithm is
   O(T-3).
ZS 1
ZR 0
ZB 2
Z8 2
ZA 0
TC 67
Z9 70
SN 0025-1909
UT WOS:000172267400006
ER

PT J
AU Sherali, HD
   Smith, JC
TI Improving discrete model representations via symmetry considerations
SO MANAGEMENT SCIENCE
VL 47
IS 10
BP 1396
EP 1407
DI 10.1287/mnsc.47.10.1396.10265
PD OCT 2001
PY 2001
AB In this paper, we focus on a useful modeling concept that is frequently
   ignored while formulating discrete optimization problems. Very often,
   there exists a natural symmetry inherent in the problem itself that, if
   propagated to the model, can hopelessly mire a branch-and-bound solver
   by burdening it to explore and eliminate such alternative symmetric
   solutions. We discuss three applications where such a symmetry arises: a
   telecommunications network design problem, a noise pollution problem,
   and a machine procurement and operation problem. For each case, we
   identify the indistinguishable objects in the model that create the
   problem symmetry and show how imposing certain decision hierarchies
   within the model significantly enhances its solvability, while using a
   popular modern-day commercial branch-and-cut software (CPLEX 6.5).
ZS 0
ZB 0
Z8 0
ZA 0
ZR 0
TC 128
Z9 128
SN 0025-1909
EI 1526-5501
UT WOS:000172267400007
ER

PT J
AU Kara, BY
   Tansel, BC
TI The latest arrival hub location problem
SO MANAGEMENT SCIENCE
VL 47
IS 10
BP 1408
EP 1420
DI 10.1287/mnsc.47.10.1408.10258
PD OCT 2001
PY 2001
AB The traditionally studied hub location problems in the literature pay
   attention to flight times but not to transient times spent at hubs for
   unloading, loading, and sorting operations. The transient times may
   constitute a significant portion of the total delivery time for cargo
   delivery systems. We focus on the minimization of the arrival time of
   the last arrived item in cargo delivery systems and develop a model that
   correctly computes the arrival times by taking into account both the
   flight times and the transient times. Nonlinear and linear integer
   formulations are given and computational results are provided. The
   effects of delays on the system performance are analyzed.
ZR 0
Z8 1
ZB 0
TC 64
ZS 3
ZA 0
Z9 68
SN 0025-1909
UT WOS:000172267400008
ER

PT J
AU Andradottir, S
   Ayhan, H
   Down, DG
TI Server assignment policies for maximizing the steady-state throughput of
   finite queueing systems
SO MANAGEMENT SCIENCE
VL 47
IS 10
BP 1421
EP 1439
DI 10.1287/mnsc.47.10.1421.10262
PD OCT 2001
PY 2001
AB For a system of finite queues, we study how servers should be assigned
   dynamically to station's in order to obtain optimal (or near-optimal)
   long-run average throughput. We assume that travel times between
   different service facilities are negligible, that each server can work
   on only one job at a time, and that several servers can work together on
   one job. We show that when the service rates depend only on either the
   server or the station (and not both), then all nonidling server
   assignment policies are optimal. Moreover, for a Markovian system with
   two stations in tandem and two servers, we show that the optimal policy
   assigns one server to each station unless that station is blocked or
   starved (in which case the server helps at the other station), and we
   specify the criterion used for assigning servers to stations. Finally,
   we propose a simple server assignment policy for tandem systems in which
   the number of stations equals the number of servers, and we present
   numerical results that show that our policy appears to yield
   near-optimal throughput under general conditions.
ZS 0
ZR 0
TC 77
Z8 0
ZB 0
ZA 0
Z9 77
SN 0025-1909
UT WOS:000172267400009
ER

PT J
AU Nault, BR
   Tyagi, RK
TI Implementable mechanisms to coordinate horizontal alliances (vol 47, pg
   787, 2001)
SO MANAGEMENT SCIENCE
VL 47
IS 10
BP 1440
EP 1440
PD OCT 2001
PY 2001
TC 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 0
SN 0025-1909
UT WOS:000172267400010
ER

PT J
AU Ofek, E
   Sarvary, M
TI Leveraging the customer base: Creating competitive advantage through
   knowledge management
SO MANAGEMENT SCIENCE
VL 47
IS 11
BP 1441
EP 1456
DI 10.1287/mnsc.47.11.1441.10249
PD NOV 2001
PY 2001
AB Professional services firms (e.g., consultants, accounting firms, or
   advertising agencies) generate and sell business solutions to their
   customers. In doing so, they can leverage the cumulative experience
   gained from serving their customer base to either reduce their variable
   costs or increase the quality of their products/services. In other
   words, their "production technology" exhibits some form of increasing
   returns to scale. Growth and globalization, coupled with recent advances
   in information technology, have led many of these firms to introduce
   sophisticated knowledge management (KM) systems in order to create
   sustainable competitive advantage. In this paper, the authors analyze
   how KM is likely to affect competition among such professional services
   firms. In particular, they first explore what type (supply-side versus
   demand-side) of economies of scale are likely to be exploited in KM
   systems. In the former case, KM's role is to reduce the operating costs
   of the firm, while in the latter case, its role is to create added value
   to customers by significantly increasing product quality. Second, the
   authors analyze the competitive dynamics and market structure that
   emerge as a result of firms competing with KM systems. The results shed
   light on the current literature exploring the deployment of KM systems
   by suggesting that in a competitive setting, when firms' ability to
   leverage their customer base is high, KM should lead to quality
   improvement rather than cost reductions. In a dynamic setting, it is
   also shown that when firms use their KM system to improve product
   quality, higher ability to leverage the customer base may actually hurt
   profits and lead to industry shakeout. Beyond normative insights, the
   results also support a number of recent market trends in management
   consulting, including the increased emphasis on knowledge-creating
   activities in modern KM systems, the wave of mergers between consulting
   firms, and the recent emergence of "retail consulting" services.
RI Sarvary, Miklos/C-7197-2010; Wang, Charles/B-5565-2011
OI Wang, Charles/0000-0001-9331-8437
ZS 0
ZA 0
Z8 1
TC 127
ZB 0
ZR 0
Z9 128
SN 0025-1909
UT WOS:000172613100001
ER

PT J
AU Sarkar, S
   Sriram, RS
TI Bayesian models for early warning of bank failures
SO MANAGEMENT SCIENCE
VL 47
IS 11
BP 1457
EP 1475
DI 10.1287/mnsc.47.11.1457.10253
PD NOV 2001
PY 2001
AB he focus of this research is to demonstrate how probabilistic models may
   be used to provide early warnings for bank failures. While prior
   research in the auditing literature has recognized the applicability of
   a Bayesian belief revision framework for many audit tasks, empirical
   evidence has suggested that auditors' cognitive decision processes often
   violate probability axioms. We believe that some of the well-documented
   cognitive limitations of a human auditor can be compensated by an
   automated system. In particular, we demonstrate that a formal belief
   revision scheme can be incorporated into an automated system to provide
   reliable probability estimates for early warning of bank failures. The
   automated system examines financial ratios as predictors of a bank's
   performance and assesses the posterior probability of a banks financial
   health (alternatively, financial distress). We examine two different
   probabilistic models, one that is simpler and makes more assumptions,
   while the other that is somewhat more complex but makes fewer
   assumptions. We find that both models are able to make accurate
   predictions with the help of historical data to estimate the required
   probabilities. In particular, the more complex model is found to be very
   well calibrated in its probability estimates. We posit that such a model
   can serve as a useful decision aid to an auditor's judgment process.
RI zhou, hao/G-4832-2011
ZS 3
Z8 0
TC 69
ZA 0
ZR 0
ZB 0
Z9 72
SN 0025-1909
UT WOS:000172613100002
ER

PT J
AU Feinberg, FM
TI On continuous-time optimal advertising under S-shaped response
SO MANAGEMENT SCIENCE
VL 47
IS 11
BP 1476
EP 1487
DI 10.1287/mnsc.47.11.1476.10246
PD NOV 2001
PY 2001
AB Continuous-time monopolistic models of advertising expenditure that rely
   on strict response concavity have been shown to prescribe eventual
   spending at a constant rate. However, analyses of discrete analogs have
   suggested that S-shaped response (convexity for low expenditure levels)
   may allow for the periodic optima encountered in actual practice.
   Casting the dynamic between advertising and sales in a common format (an
   autonomous, first-order relationship), the present paper explores
   extensions along three dimensions: an S-shaped response function, the
   value of the discount rate, and the possibility of diffusionlike
   response. Supplementing the treatment by Mahajan and Muller (1986), a
   flexible class of S-shaped response models is formulated for which it is
   demonstrated that, in contrast to findings in the literature on
   discretized advertising models, continuous periodic optima cannot be
   supported. Further, a set of conditions on the advertising response
   function are derived, that contains and extends that suggested by
   Sasieni (1971). Collectively, these results both suggest a set of
   baseline properties that reasonable models should possess and cast doubt
   on the ability of first-order models to capture effects of known
   managerial relevance.
RI Feinberg, Fred/ABB-7766-2020
OI Feinberg, Fred/0000-0003-2238-0721
TC 38
ZB 0
ZA 0
Z8 0
ZS 0
ZR 0
Z9 38
SN 0025-1909
UT WOS:000172613100003
ER

PT J
AU Dana, JD
   Petruzzi, NC
TI Note: The newsvendor model with endogenous demand
SO MANAGEMENT SCIENCE
VL 47
IS 11
BP 1488
EP 1497
DI 10.1287/mnsc.47.11.1488.10252
PD NOV 2001
PY 2001
AB This paper considers a firm's price and inventory policy when it faces
   uncertain demand that depends on both price and inventory level. The
   authors extend the classic newsvendor model by assuming that expected
   utility maximizing consumers choose between visiting the firm an
   consuming an exogenous, outside option. The outside option represents
   the utility the consumer forgoes when she chooses to visit the firm
   before-knowing whether or not the product will be available. The authors
   investigate both the case in which the firm's price is exogenous and the
   case in which price is chosen optimally. The paper makes two
   contributions. First, the authors show that the firm holds more
   inventories, provides a higher fill rate, attracts more customers, and
   earns higher profits when it internalizes the effect of its inventory on
   demand. Second, the authors show that in the endogenous price case the
   firm's two-dimensional decision problem can be reduced to two,
   sequential, single-variable optimizations. As a result, the
   endogenous-price case is as easy to solve as the exogenous-price case.
Z8 3
ZS 0
ZA 0
TC 130
ZB 0
ZR 0
Z9 132
SN 0025-1909
UT WOS:000172613100004
ER

PT J
AU Bleichrodt, H
   Pinto, JL
   Wakker, PP
TI Making descriptive use of prospect theory to improve the prescriptive
   use of expected utility
SO MANAGEMENT SCIENCE
VL 47
IS 11
BP 1498
EP 1514
DI 10.1287/mnsc.47.11.1498.10248
PD NOV 2001
PY 2001
AB This paper proposes a quantitative modification of standard utility
   elicitation procedures, such as the probability and certainty
   equivalence methods, to correct for commonly observed violations of
   expected utility. Traditionally, decision analysis assumes expected
   utility not only for the prescriptive purpose of calculating optimal
   decisions but also for the descriptive purpose of eliciting utilities.
   However, descriptive violations of expected utility bias utility
   elicitations. That such biases are effective became clear when
   systematic discrepancies were found between different utility
   elicitation methods that, under expected utility, should have yielded
   identical utilities. As it is not clear how to correct for these biases
   without further knowledge of their size or nature, most utility
   elicitations still calculate utilities by means of the expected utility
   formula. This paper speculates on the biases and their sizes by using
   the quantitative assessments of probability transformation and loss
   aversion suggested by prospect theory. It presents quantitative
   corrections for the probability and certainty equivalence methods. If
   interactive sessions to correct for biases are not possible, then the
   authors propose to use the corrected utilities rather than the
   uncorrected ones in prescriptions of optimal decisions. In an
   experiment, the discrepancies between the probability and certainty
   equivalence methods are removed by the authors' proposal.
RI prades, jose luis pinto/B-7069-2008
OI prades, jose luis pinto/0000-0002-9684-3410
Z8 3
ZR 0
ZS 1
TC 153
ZA 0
ZB 6
Z9 157
SN 0025-1909
UT WOS:000172613100005
ER

PT J
AU Huang, S
   Yang, Y
   Anderson, K
TI A theory of finitely durable goods monopoly with used-goods market and
   transaction costs
SO MANAGEMENT SCIENCE
VL 47
IS 11
BP 1515
EP 1532
DI 10.1287/mnsc.47.11.1515.10250
PD NOV 2001
PY 2001
AB We construct a dynamic game to model a monopoly of finitely durable
   goods. The solution concept is Markov-perfect equilibria with general
   equilibria embedded in every time period. Our model is flexible enough
   to simultaneously explain or accommodate many commonly observed
   phenomena or stylized facts, such as concurrent leasing and selling,
   active secondary markets for used goods, heterogeneous consumers,
   endogenous consumption patterns, depreciation, an infinite time horizon,
   and nontrivial transaction costs. Within our model, consumers have
   incentives to segment themselves into various consumption classes
   according to their willingness to pay, and nontrivial transaction costs
   to sell used goods put strong constraints on consumers' consumption
   sequences in time. As a direct consequence of the finite durability, the
   market power of the monopolist remains intact. Leasing manifests itself
   as a facilitator of price discrimination by debundling the durable good
   into new and used portions that are naturally bundled together under
   outright sales. The concurrent leasing and selling reflects the degree
   of the comparative advantage the monopolist has over consumers in
   disposing used goods. This comparative advantage, which is partially
   exploited by the monopolist and partially shared by the consumers,
   provides a sufficient mechanism to gain Pareto improvement on the
   market.
ZA 1
Z8 2
ZS 0
TC 32
ZR 0
ZB 0
Z9 35
SN 0025-1909
UT WOS:000172613100006
ER

PT J
AU Kleijnen, JPC
   Cheng, RCH
   Bettonvil, B
TI Validation of trace-driven simulation models: Bootstrap tests
SO MANAGEMENT SCIENCE
VL 47
IS 11
BP 1533
EP 1538
DI 10.1287/mnsc.47.11.1533.10255
PD NOV 2001
PY 2001
AB Trace-driven (or correlated inspection) simulation means that the
   simulated and the real systems have some common inputs (say, historical
   arrival times) so that the two systems' outputs are cross-correlated. To
   validate such a simulation, this paper focuses on the difference between
   the average simulated and real responses. To evaluate this validation
   statistic, the paper develops a novel bootstrap technique-based on
   replicated runs. This validation statistic and the bootstrap technique
   are evaluated in extensive Monte Carlo experiments with specific
   single-server queues. These experiments show acceptable Type-I and
   Type-II error probabilities.
RI Kleijnen, Jack/AAL-6469-2020; Kleijnen, Jack/ABB-6455-2020; Kleijnen, jack/
OI Kleijnen, jack/0000-0001-8413-2366
ZS 0
ZB 3
TC 21
ZR 0
ZA 0
Z8 1
Z9 22
SN 0025-1909
EI 1526-5501
UT WOS:000172613100007
ER

PT J
AU Li, L
   Porteus, EL
   Zhang, HT
TI Optimal operating policies for multiplant stochastic manufacturing
   systems in a changing environment
SO MANAGEMENT SCIENCE
VL 47
IS 11
BP 1539
EP 1551
DI 10.1287/mnsc.47.11.1539.10251
PD NOV 2001
PY 2001
AB This paper addresses the horizontal coordination between production
   units located in different countries within a supply chain in a changing
   environment. The model incorporates (1) congestion and delay through
   uncertainties in demand and processing times, (2) a changing production
   cost environment through uncertainty in an environmental state (such as
   the exchange rate), and (3) allowing production to stock. The main
   contribution of the paper is to characterize the optimal production
   policy, assuming no switchover cost, as a barrier-type control policy
   for a series of models. For each plant, there is a barrier function
   defined on the environmental state that gives the total worldwide stock
   level barrier: This plant should be operated if and only if the stock
   level is below this barrier. The authors also show that, in a simple
   setting of two plants in different countries, the barrier functions are
   not always monotone in the exchange rate even when the production costs
   are. The authors present a condition under which the control barriers
   are shown to be monotone. Under this condition and with only two plants,
   it is optimal to follow a primary/secondary plant policy in which, given
   a fixed environmental state, it is optimal to operate both plants when
   stock is low, only the primary plant when stock is moderate, and neither
   when stock is high. Furthermore, the roles of the plants switch as the
   environmental state passes through the equal production cost state. In
   addition, the firm seeks to carry the most stock as a hedge against
   future environmental state moves, when one plant is significantly
   cheaper than the other. The firm seeks to carry the least stock when
   both plants are equally costly to operate.
ZB 0
Z8 5
ZR 0
ZS 0
ZA 0
TC 9
Z9 14
SN 0025-1909
UT WOS:000172613100008
ER

PT J
AU Kornish, LJ
TI Pricing for a durable-goods monopolist under rapid sequential innovation
SO MANAGEMENT SCIENCE
VL 47
IS 11
BP 1552
EP 1561
DI 10.1287/mnsc.47.11.1552.10247
PD NOV 2001
PY 2001
AB A durable-goods monopolist who will be introducing new and improved
   versions of his product must decide how to price his products, keeping
   in mind the relative attractiveness of the current and future products.
   Dhebar (1994) has shown that if technology is changing too quickly and
   the producer cannot credibly commit to future prices and quality, then
   no equilibrium strategy exists. That is, there is no credible strategy
   for the future product that the producer can commit to in the first
   period. We show that an equilibrium pricing strategy exists if the
   monopolist does not offer upgrade pricing, that is, special pricing to
   consumers who have bought an earlier version. The author shows the
   possible purchase patterns in equilibrium and derives the optimal
   pricing strategy.
ZR 0
TC 63
ZA 0
ZB 0
ZS 0
Z8 4
Z9 67
SN 0025-1909
UT WOS:000172613100009
ER

PT J
AU Rajagopalan, S
   Swaminathan, JM
TI A coordinated production planning model with capacity expansion and
   inventory management
SO MANAGEMENT SCIENCE
VL 47
IS 11
BP 1562
EP 1580
DI 10.1287/mnsc.47.11.1562.10254
PD NOV 2001
PY 2001
AB Motivated by a problem faced by a large manufacturer of a consumer
   product, we explore the interaction between production planning and
   capacity acquisition decisions in environments with demand growth. We
   study a firm producing multiple items in a multiperiod environment where
   demand for items is known but varies over time with a long-term growth
   and possible short-term fluctuations. The production equipment is
   characterized by significant changeover time between the production of
   different items. While demand growth is gradual, capacity additions are
   discrete. Therefore, periods immediately following a machine purchase
   are characterized by excess machine capacity. We develop a mathematical
   programming model and an effective solution approach to determine the
   optimal capacity acquisition, production and inventory decisions over
   time. Through a computational study, we show the effectiveness of the
   solution approach in terms of solution quality and investigate the
   impact of product variety, cost of capital, and other important
   parameters on the capacity and inventory decisions. The computational
   results bring out some key insights-increasing product variety may not
   result in excessive inventory and even a substantial increase In set-up
   times or holding costs may not increase the total cost over the horizon
   in a significant manner due to the ability to acquire additional
   capacity We also provide solutions and insights to the real problem that
   motivated this work.
ZR 0
Z8 3
ZA 0
TC 44
ZB 0
ZS 1
Z9 47
SN 0025-1909
UT WOS:000172613100010
ER

PT J
AU Dewan, S
   Mendelson, H
TI Information technology and trader competition in financial markets:
   Endogenous liquidity
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1581
EP 1587
DI 10.1287/mnsc.47.12.1581.10241
PD DEC 2001
PY 2001
AB This note integrates the models of Dewan and Mendelson (1998) (DM) and
   Kyle (1985), extending the DM analysis of time-based competition in
   financial markets to the case of endogenous liquidity. The results
   enable us to examine the link between information technology
   investments, trading strategies, and liquidity.
ZS 0
ZB 0
TC 7
ZR 0
ZA 0
Z8 0
Z9 7
SN 0025-1909
UT WOS:000173374800001
ER

PT J
AU Randall, T
   Ulrich, K
TI Product variety, supply chain structure, and firm performance: Analysis
   of the US bicycle industry
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1588
EP 1604
DI 10.1287/mnsc.47.12.1588.10237
PD DEC 2001
PY 2001
AB Using data from the U.S. bicycle industry, we examine the relation among
   product variety, supply chain structure, and firm performance. Variety
   imposes two types of costs on a supply chain: production costs and
   market mediation costs. Production costs include, among other costs, the
   incremental fixed investments associated with providing additional
   product variants. Market mediation costs arise because of uncertainty in
   product demand created by variety. In the presence of demand
   uncertainty, precisely matching supply with demand is difficult. Market
   mediation costs include the variety-related inventory holding costs,
   product mark-down costs occurring when supply exceeds demand, and the
   costs of lost sales occurring when demand exceeds supply. We analyze
   product variety at the product attribute level, noting that the relative
   impact of variety on production and market mediation costs depends to a
   large extent on the attribute underlying the variety. That is, some
   types of variety incur high production costs and some types of variety
   incur high market mediation costs. We characterize supply chain
   structure by the degree to which production facilities are
   scale-efficient and by the distance of the production facility from the
   target market. We hypothesize that firms with scale-efficient production
   (i.e., high-volume firms) will offer types of variety associated with
   high production costs, and firms with local production will offer types
   of variety associated with high market mediation costs. This hypothesis
   implies that there is a coherent way to match product variety with
   supply chain structure. Empirical results suggest that firms which match
   supply chain structure to the type of product variety they offer
   outperform firms which fail to match such choices.
ZB 0
Z8 1
TC 174
ZA 0
ZS 4
ZR 0
Z9 176
SN 0025-1909
UT WOS:000173374800002
ER

PT J
AU Joglekar, NR
   Yassine, AA
   Eppinger, SD
   Whitney, DE
TI Performance of coupled product development activities with a deadline
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1605
EP 1620
DI 10.1287/mnsc.47.12.1605.10240
PD DEC 2001
PY 2001
AB This paper explores the performance of coupled development activities by
   proposing a performance generation model (PGM). The goal of the PGM is
   to develop insights about optimal strategies (i.e., sequential,
   concurrent, or overlapped) to manage coupled design activities that
   share a fixed amount of engineering resources subject to performance and
   deadline constraints. Model analysis characterizes the solution space
   for the coupled development problem. The solution space is used to
   explore the generation of product performance and the associated dynamic
   forces affecting concurrent development practices. We use these forces
   to explain conditions under which concurrency is a desirable strategy.
Z8 2
TC 62
ZB 0
ZA 0
ZR 0
ZS 0
Z9 64
SN 0025-1909
UT WOS:000173374800003
ER

PT J
AU Makadok, R
   Barney, JB
TI Strategic factor market intelligence: An application of information
   economics to strategy formulation and competitor intelligence
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1621
EP 1638
DI 10.1287/mnsc.47.12.1621.10245
PD DEC 2001
PY 2001
AB This paper develops a model of information-acquisition decisions by
   firms that are competing in a "strategic factor market" (Barney 1986) to
   purchase a scarce resource whose value is unknown and differs across
   firms. The model builds on the argument that more accurate expectations
   about the firm-specific value of resources is, other than luck, the only
   way for firms to obtain the specific resources required for competitive
   advantage. We address the more specific question of what types of
   information firms should gather to accomplish this goal. The model
   generates a series of testable hypotheses about how a firm's optimal mix
   of different types of information is affected by a number of factors,
   including the level of uncertainty about the value of the resource being
   acquired; the rarity, imitability and nonsubstitutability of that
   resource; the level of inscrutability of firms' pre-existing stocks of
   resources; and firms' information-gathering and information-processing
   capacities.
OI Makadok, Richard/0000-0002-0030-9935
ZR 0
TC 157
ZB 0
ZS 1
ZA 1
Z8 1
Z9 160
SN 0025-1909
UT WOS:000173374800004
ER

PT J
AU Shafer, SM
   Nembhard, DA
   Uzumeri, MV
TI The effects of worker learning, forgetting, and heterogeneity on
   assembly line productivity
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1639
EP 1653
DI 10.1287/mnsc.47.12.1639.10236
PD DEC 2001
PY 2001
AB The authors investigate through several simulations how patterns of
   learning and forgetting affect the operating performance of an assembly
   line. A unique aspect of this study is that a distribution of
   learning/forgetting behavior based on an empirical population of workers
   is used rather than assuming the same learning pattern for all
   employees. The paper demonstrates that modeling only central tendency
   and not the variations across workers tends to systematically
   underestimate overall productivity. The data used to estimate the
   parameters for the distribution of learning curves were collected from
   an assembly line that produces car radios.
   Analysis of the models fit to a population of workers reveals that
   higher levels of previous experience are positively correlated with
   higher steady-state productivity levels and negatively correlated with
   the learning rate. To further motivate the study, a conceptual model
   with several factors hypothesized to influence assembly line
   productivity is presented. Among key factors included in the model are
   the rate of worker learning, the size of the worker pool, task tenure,
   and the magnitude of worker forgetting. In controlled computer
   simulation experiments, each of these factors was found to be
   statistically significant, as were a number of the two-way interaction
   terms.
TC 104
Z8 3
ZB 3
ZS 2
ZR 0
ZA 0
Z9 109
SN 0025-1909
UT WOS:000173374800005
ER

PT J
AU Dayanand, N
   Padman, R
TI Project contracts and payment schedules: The client's problem
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1654
EP 1667
DI 10.1287/mnsc.47.12.1654.10242
PD DEC 2001
PY 2001
AB Contractual agreements have assumed significant complexity in recent
   times because of the emergence of strategies like outsourcing and
   partnering in the successful completion of large software development,
   manufacturing, and construction projects. A client and contractor enter
   into an agreement for a project either by bidding or negotiation.
   Effective and efficient bidding, negotiation, and subsequent monitoring
   are hindered by the lack of appropriate decision support tools for the
   management of project finances. Progress payments to the contractor are
   an important issue in project management because of their potential
   impact on project finances and activity schedules. In this paper, we
   consider the problem of simultaneously determining the amount, location,
   and timing of progress payments in projects from a client's perspective.
   We develop three mixed-integer linear programming models, based on some
   practical methods of determining payment schedules from different types
   of project contracts. We discuss properties of the models and draw
   insights about the characteristics of optimal payment schedules obtained
   with each model by an experimental study on a sample of 10 small
   projects. Our analysis shows that, contrary to current practice, the
   client obtains the greatest benefit by scheduling the project for early
   completion such that the payments are not made at regular intervals. It
   is also cost effective for the client to make payments either in the
   early stages of the project or toward the end, even though this causes
   considerable variation in the time gap between payments. We also
   evaluate the impact of the client's preferred payment schedules on the
   contractor's finances and activity schedules, and draw some conclusions
   on the interdependence of payment and project parameters on the
   objectives of both parties entering the contractual agreement.
ZA 0
TC 48
ZR 0
ZB 0
ZS 0
Z8 17
Z9 65
SN 0025-1909
UT WOS:000173374800006
ER

PT J
AU Rudi, N
   Kapur, S
   Pyke, DF
TI A two-location inventory model with transshipment and local decision
   making
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1668
EP 1680
DI 10.1287/mnsc.47.12.1668.10235
PD DEC 2001
PY 2001
AB In situations where a seller has surplus stock and another seller is
   stocked out, it may be desirable to transfer surplus stock from the
   former to the latter. We examine how the possibility of such
   transshipments between two independent locations affects the optimal
   inventory orders at each location. If each location aims to maximize its
   own profits-we call this local decision making-their inventory choices
   will not, in general, maximize joint profits. We find transshipment
   prices which induce the locations to choose inventory levels consistent
   with joint-profit maximization.
RI Rudi, Nils/B-3812-2010
ZB 0
Z8 24
ZR 0
ZA 0
ZS 1
TC 221
Z9 246
SN 0025-1909
UT WOS:000173374800007
ER

PT J
AU Shi, LY
   Olafsson, S
   Chen, Q
TI An optimization framework for product design
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1681
EP 1692
DI 10.1287/mnsc.47.12.1681.10243
PD DEC 2001
PY 2001
AB An important problem in the product design and development process is to
   use the partworths preferences of potential customers to design a new
   product such that market share is maximized. The authors present a new
   optimization framework for this problem, the nested partitions (NP)
   method. This method is globally convergent and may utilize existing
   heuristic methods to speed its convergence. We incorporate several known
   heuristics into this framework and demonstrate through numerical
   experiments that using the NP method results in superior product
   designs. Our numerical results suggest that the new framework is
   particularly useful for designing complex products with many attributes.
RI Shi, Leyuan/I-9951-2014
TC 55
ZS 0
ZA 0
ZB 1
ZR 0
Z8 10
Z9 65
SN 0025-1909
UT WOS:000173374800008
ER

PT J
AU Cvsa, V
   Ritchken, P
TI Pricing claims under GARCH-Level dependent interest rate processes
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1693
EP 1711
DI 10.1287/mnsc.47.12.1693.10238
PD DEC 2001
PY 2001
AB This article considers the pricing of interest-rate-sensitive claims
   when the underlying interest rate is driven by a two-state-variable
   GARCH process. Analytical solutions are established for the case when
   the innovations in the short rate are normal and/or chi-squared random
   variables and the volatility of rates take on a special GARCH form.
   GARCH models that nest level-dependent interest rate models, including
   the Cox, Ingersoll, and Ross model, are also considered. Algorithms are
   provided that permit the efficient pricing of American-style interest
   rate claims under a rather broad array of GARCH-Level dependent
   processes.
TC 3
ZR 0
ZA 0
ZS 0
ZB 0
Z8 0
Z9 3
SN 0025-1909
UT WOS:000173374800009
ER

PT J
AU Kilka, M
   Weber, M
TI What determines the shape of the probability weighting function under
   uncertainty?
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1712
EP 1726
DI 10.1287/mnsc.47.12.1712.10239
PD DEC 2001
PY 2001
AB Decision weights are an important component in recent theories of
   decision making under uncertainty. To better explain these decision
   weights, a two-stage approach has been proposed: First, the probability
   of an event is judged and then this probability is transformed by the
   probability weighting function known from decision making under risk. We
   extend the two-stage approach by allowing the probability weighting
   function to depend on the type of uncertainty. Using this more general
   approach, properties of decision weights can be attributed to properties
   of probability judgments and/or to properties of probability weighting.
   We present an empirical study that shows that it is indeed necessary to
   allow the probability weighting function to be source dependent. The
   analysis includes an examination of properties of the probability
   weighting function under uncertainty that have not been considered yet.
TC 102
ZR 0
ZA 0
ZS 0
ZB 6
Z8 2
Z9 104
SN 0025-1909
UT WOS:000173374800010
ER

PT J
AU Harrington, JE
TI Comment on "Reducing buyer search costs: Implications for electronic
   marketplaces"
SO MANAGEMENT SCIENCE
VL 47
IS 12
BP 1727
EP 1732
DI 10.1287/mnsc.47.12.1727.10244
PD DEC 2001
PY 2001
Z8 0
ZA 0
TC 17
ZS 0
ZB 0
ZR 0
Z9 17
SN 0025-1909
UT WOS:000173374800011
ER

PT J
AU Cohen, WM
   Nelson, RR
   Walsh, JP
TI Links and impacts: The influence of public research on industrial R&D
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP 1
EP 23
DI 10.1287/mnsc.48.1.1.14273
PD JAN 2002
PY 2002
AB In this paper, we use data from the Carnegie Mellon Survey on industrial
   R&D to evaluate for the U.S. manufacturing sector the influence of
   "public" (i.e., university and government R&D lab) research on
   industrial R&D, the role that public research plays in industrial R&D,
   and the pathways through which that effect is exercised. We find that
   public research is critical to industrial R&D in a small number of
   industries and importantly affects industrial R&D across much of the
   manufacturing sector. Contrary to the notion that university research
   largely generates new ideas for industrial R&D projects, the survey
   responses demonstrate that public research both suggests new R&D
   projects and contributes to the completion of existing projects in
   roughly equal measure overall. The results also indicate that the key
   channels through which university research impacts industrial R&D
   include published papers and reports, public conferences and meetings,
   informal information exchange, and consulting. We also find that, after
   controlling for industry, the influence of public research on industrial
   R&D is disproportionately greater for larger firms as well as start-ups.
CT Conference on University Entrepreneurship and Technology Transfer
CY DEC, 2000
CL GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT, ATLANTA, GEORGIA
HO GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT
ZS 29
ZR 4
Z8 22
TC 1130
ZB 33
ZA 1
Z9 1179
SN 0025-1909
UT WOS:000173972400002
ER

PT J
AU Owen-Smith, J
   Riccaboni, M
   Pammolli, F
   Powell, WW
TI A comparison of US and European university-industry relations in the
   life sciences
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP 24
EP 43
DI 10.1287/mnsc.48.1.24.14275
PD JAN 2002
PY 2002
AB We draw on diverse data sets to compare the institutional organization
   of upstream life science research across the United States and Europe.
   Understanding cross-national differences in the organization of
   innovative labor in the life sciences requires attention to the
   structure and evolution of biomedical networks involving public research
   organizations (universities, government laboratories, nonprofit research
   institutes, and research hospitals), science-based biotechnology firms,
   and multinational pharmaceutical corporations. We use network
   visualization methods and correspondence analyses to demonstrate that
   innovative research in biomedicine has its origins in regional clusters
   in the United States and in European nations. But the scientific and
   organizational composition of these regions varies in consequential
   ways. In the United States, public research organizations and small
   firms conduct R&D across multiple therapeutic areas and stages of the
   development process. Ties within and across these regions link small
   firms and diverse public institutions, contributing to the development
   of a robust national network. In contrast, the European story is one of
   regional specialization with a less diverse group of public research
   organizations working in a smaller number of therapeutic areas. European
   institutes develop local connections to small firms working on similar
   scientific problems, while cross-national linkages of European regional
   clusters typically involve large pharmaceutical corporations. We show
   that the roles of large and small firms differ in the United States and
   Europe, arguing that the greater heterogeneity of the U.S. system is
   based on much closer integration of basic science and clinical
   development.
CT Conference on University Entrepreneurship and Technology Transfer
CY DEC, 2000
CL GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT, ATLANTA, GA
HO GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT
RI Powell, Walter W/B-5991-2008; Owen-Smith, Jason/B-3665-2012; Riccaboni, Massimo/D-4102-2009; Pammolli, Fabio/; RICCABONI, Massimo/; Owen-Smith, Jason/
OI Pammolli, Fabio/0000-0001-7056-1303; RICCABONI,
   Massimo/0000-0003-4979-8933; Owen-Smith, Jason/0000-0001-8007-1121
ZB 13
ZR 0
ZA 0
Z8 4
TC 255
ZS 3
Z9 263
SN 0025-1909
EI 1526-5501
UT WOS:000173972400003
ER

PT J
AU Agrawal, A
   Henderson, R
TI Putting patents in context: Exploring knowledge transfer from MIT
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP 44
EP 60
DI 10.1287/mnsc.48.1.44.14279
PD JAN 2002
PY 2002
AB In this paper we explore the degree to which patents are representative
   of the magnitude, direction, and impact of the knowledge spilling out of
   the university by focusing on the Massachusetts Institute of Technology
   (MIT), and in particular, on the Departments of Mechanical and
   Electrical Engineering. Drawing on both qualitative and quantitative
   data, we show that patenting is a minority activity: a majority of the
   faculty in our sample never patent, and publication rates far outstrip
   patenting rates. Most faculty members estimate that patents account for
   less than 10% of the knowledge that transfers from their labs. Our
   results also suggest that in two important ways patenting is not
   representative of the patterns of knowledge generation and transfer from
   MIT: patent volume does not predict publication volume, and those firms
   that cite MIT papers are in general not the same firms as those that
   cite MIT patents. However, patent volume is positively correlated with
   paper citations, suggesting that patent counts may be reasonable
   measures of research impact. We close by speculating on the implications
   of our results for the difficult but important question of whether, in
   this setting, patenting acts as a substitute or a complement to the
   process of fundamental research.
CT Conference on University Entrepreneurship and Technology Transfer
CY DEC, 2000
CL GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT, ATLANTA, GEORGIA
HO GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT
ZR 0
ZA 0
ZB 25
TC 521
ZS 7
Z8 4
Z9 530
SN 0025-1909
UT WOS:000173972400004
ER

PT J
AU Colyvas, J
   Crow, M
   Gelijns, A
   Mazzoleni, R
   Nelson, RR
   Rosenberg, N
   Sampat, BN
TI How do university inventions get into practice?
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP 61
EP 72
DI 10.1287/mnsc.48.1.61.14272
PD JAN 2002
PY 2002
CT Conference on University Entrepreneurship and Technology Transfer
CY DEC, 2000
CL GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT, ATLANTA, GEORGIA
HO GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT
ZS 7
TC 256
ZR 0
ZA 0
ZB 5
Z8 1
Z9 264
SN 0025-1909
UT WOS:000173972400005
ER

PT J
AU Mowery, DC
   Sampat, BN
   Ziedonis, AA
TI Learning to patent: Institutional experience, learning, and the
   characteristics of US university patents after the Bayh-Dole Act,
   1981-1992
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP 73
EP 89
DI 10.1287/mnsc.48.1.73.14278
PD JAN 2002
PY 2002
CT Conference on University Entrepreneurship and Technology Transfer
CY DEC, 2000
CL GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT, ATLANTA, GEORGIA
HO GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT
RI Ziedonis, Arvids/N-4007-2018
OI Ziedonis, Arvids/0000-0001-8340-6820
Z8 0
ZA 0
ZR 0
ZS 6
TC 142
ZB 6
Z9 148
SN 0025-1909
UT WOS:000173972400006
ER

PT J
AU Thursby, JG
   Thursby, MC
TI Who is selling the Ivory Tower? Sources of growth in university
   licensing
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP 90
EP 104
DI 10.1287/mnsc.48.1.90.14271
PD JAN 2002
PY 2002
AB Historically, commercial use of university research has been viewed in
   terms of spillovers. Recently, there has been a dramatic increase in
   technology transfer through licensing as universities attempt to
   appropriate the returns from faculty research. This change has prompted
   concerns regarding the source of this growth-specifically, whether it
   suggests a change in the nature of university research. We develop an
   intermediate input model to examine the extent to which the growth in
   licensing is due to the productivity of observable inputs or driven by a
   change in the propensity of faculty and administrators to engage in
   commercializing university research. We model licensing as a three-stage
   process, each involving multiple inputs. Nonparametric programming
   techniques are applied to survey data from 64 universities to calculate
   total factor productivity (TFP) growth in each stage. To examine the
   sources of TFP growth, the productivity analysis is augmented by survey
   evidence from businesses who license-in university inventions. Results
   suggest that increased licensing is due primarily to an increased
   willingness of faculty and administrators to license and increased
   business reliance on external R&D rather than a shift in faculty
   research.
CT Conference on University Entrepreneurship and Technology Transfer
CY DEC, 2000
CL GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT, ATLANTA, GEORGIA
HO GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT
RI McBee, David J/F-3968-2012
Z8 9
ZR 1
ZS 5
ZB 10
TC 416
ZA 0
Z9 429
SN 0025-1909
UT WOS:000173972400007
ER

PT J
AU Feldman, M
   Feller, I
   Bercovitz, J
   Burton, R
TI Equity and the technology transfer strategies of American research
   universities
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP 105
EP 121
DI 10.1287/mnsc.48.1.105.14276
PD JAN 2002
PY 2002
AB American universities are experimenting with new mechanisms for
   promoting the commercialization of academic research and generating
   revenue from university intellectual property. This paper discusses
   mechanisms available to universities in managing the commercialization
   of intellectual property, considering equity as a technology transfer
   mechanism that offers advantages for both generating revenue and
   aligning the interests of universities, industry and faculty. Employing
   data from a national survey of Carnegie I and Carnegie II institutions,
   we document the recent rise in university equity holdings. We present
   and estimate a model that considers the university's use of equity to be
   a function of behavioral factors related to the university's prior
   experiences with licensing, success relative to other institutions, and
   the organization of the technology transfer office, as well as
   structural characteristics related to university type.
CT Conference on University Entrepreneurship and Technology Transfer
CY DEC, 2000
CL GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT, ATLANTA, GEORGIA
HO GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT
Z8 2
ZR 0
TC 176
ZA 0
ZS 7
ZB 2
Z9 185
SN 0025-1909
UT WOS:000173972400008
ER

PT J
AU Shane, S
TI Selling university technology: Patterns from MIT
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP 122
EP 137
DI 10.1287/mnsc.48.1.122.14281
PD JAN 2002
PY 2002
AB any research universities engage in efforts to license inventions
   developed by university-affiliated inventors. However, no systematic
   explanation of the conditions under which university inventions will be
   licensed or commercialized has been provided. Drawing on transaction
   cost economics, I provide a conceptual framework to explain which
   university inventions are most likely to be licensed, commercialized,
   and generate royalties, and who will undertake that commercialization. I
   test this framework on data on the 1,397 patents assigned to the
   Massachusetts Institute of Technology during the 1980-1996 period. The
   results show that (1) university inventions are more likely to be
   licensed when patents are effective; (2) when patents are effective,
   university technology is generally licensed to noninventors; (3) when
   patents are effective, licensing back to inventors increases the
   likelihood of license termination and reduces the likelihood of
   invention commercialization; and (4) the effectiveness of patents
   increases royalties earned for inventions licensed to noninventors. The
   implications of these findings for innovation management and strategy,
   entrepreneurship, and university technology commercialization are
   discussed.
CT Conference on University Entrepreneurship and Technology Transfer
CY DEC, 2000
CL GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT, ATLANTA, GEORGIA
HO GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT
TC 210
ZA 0
ZB 4
ZR 0
ZS 6
Z8 6
Z9 219
SN 0025-1909
UT WOS:000173972400009
ER

PT J
AU Zucker, LG
   Darby, MR
   Armstrong, JS
TI Commercializing knowledge: University science, knowledge capture, and
   firm performance in biotechnology
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP 138
EP 153
DI 10.1287/mnsc.48.1.138.14274
PD JAN 2002
PY 2002
AB Commercializing knowledge involves transfer from discovering scientists
   to those who will develop it commercially. New codes and formulae
   describing discoveries develop slowly-with little incentive if value is
   low and many competing opportunities if high. Hence new knowledge
   remains naturally excludable and appropriable. Team production allows
   more knowledge capture of tacit, complex discoveries by firm scientists.
   A robust indicator of a firm's tacit knowledge capture (and strong
   predictor of its success) is the number of research articles written
   jointly by firm scientists and discovering, "star" scientists, nearly
   all working at top universities. An operationally attractive
   generalization of our star measure-collaborative research articles
   between firm scientists and top research university
   scientists-replicates the impact on firm success. In panel analyses,
   publications by firm scientists with stars and/or top 112 university
   scientists increase the number and citation rate for firm patents.
   Further, star articles increase these rates significantly more than
   other top 112 university scientists' articles. Cross-sectional analyses
   of products and employment show a similar pattern of positive effects on
   firms' success of collaborations with stars or top university
   scientists, but estimates of differential effects are nonrobust due to
   multicollinearity. Venture capital funding has significant, usually
   positive effects on firm success.
CT Conference on University Entrepreneurship and Technology Transfer
CY DEC, 2000
CL GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT, ATLANTA, GEORGIA
HO GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT
RI McBee, David J/F-3968-2012; Zucker, Lynne G/C-1467-2008; Darby, Michael R/C-1457-2008
OI Zucker, Lynne G/0000-0002-1852-6612; Darby, Michael
   R/0000-0003-4565-2670
Z8 7
ZS 2
TC 511
ZR 3
ZA 1
ZB 10
Z9 524
SN 0025-1909
UT WOS:000173972400010
ER

PT J
AU Shane, S
   Stuart, T
TI Organizational endowments and the performance of university start-ups
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP 154
EP 170
DI 10.1287/mnsc.48.1.154.14280
PD JAN 2002
PY 2002
AB The question of how initial resource endowments-the stocks of resources
   that entrepreneurs contribute to their new ventures at the time of
   founding-affect organizational life chances is one of significant
   interest in organizational ecology, evolutionary theory, and
   entrepreneurship research. Using data on the life histories of all 134
   firms founded to exploit MIT-assigned inventions during the 1980-1996
   period, the study analyzes how resource endowments affect the likelihood
   of three critical outcomes: that new ventures attract venture capital
   financing, experience initial public offerings, and fail. Our analysis
   focuses on the role of founders' social capital as a determinant of
   these outcomes. Event history analyses show that new ventures with
   founders having direct and indirect relationships with venture investors
   are most likely to receive venture funding and are less likely to fail.
   In turn, receiving venture funding is the single most important
   determinant of the likelihood of IPO. We conclude that the social
   capital of company founders represents an important endowment for
   early-stage organizations.
CT Conference on University Entrepreneurship and Technology Transfer
CY DEC, 2000
CL GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT, ATLANTA, GEORGIA
HO GEORGIA INST TECHNOL, DUPREE COLL MANAGEMENT
ZB 2
TC 660
ZS 8
Z8 8
ZR 1
ZA 0
Z9 675
SN 0025-1909
UT WOS:000173972400011
ER

PT J
AU Mowery, DC
   Shane, S
TI Introduction to the special issue on university entrepreneurship and
   technology transfer
SO MANAGEMENT SCIENCE
VL 48
IS 1
BP V
EP IX
DI 10.1287/mnsc.48.1.0.14277
PD JAN 2002
PY 2002
ZB 1
TC 67
Z8 0
ZR 0
ZS 1
ZA 0
Z9 68
SN 0025-1909
UT WOS:000173972400001
ER

PT J
AU King, AA
   Tucci, CL
TI Incumbent entry into new market niches: The role of experience and
   managerial choice in the creation of dynamic capabilities
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP 171
EP 186
DI 10.1287/mnsc.48.2.171.253
PD FEB 2002
PY 2002
AB Increasingly, technological innovation creates markets for new products
   and services. To survive, firms must respond to these new markets. How
   do firms develop the capabilities necessary to succeed in such changing
   conditions? Some suggest that experience with previous entry builds such
   capabilities. Others suggest that capabilities arise from experience
   producing and selling to existing markets. The role of managers is also
   debated. Some argue that experience with existing markets causes
   managers to miss entry opportunities. Others argue that managers enter
   new markets when their firm possesses the experience needed to compete
   effectively.
   In this paper, we explore these issues by investigating entry patterns
   in the disk-drive industry. We investigate the effect of experience in
   existing markets and experience with previous market entry. We find that
   experience in previous markets increased the probability that a firm
   would enter a new market. We show that this experience had greater value
   if the firm entered the new market. We infer that managers chose to
   enter these markets to obtain this increase in value.
RI Tucci, Christopher L/G-6435-2012; King, Andrew A/E-1684-2011
OI Tucci, Christopher L/0000-0001-8733-9530; King, Andrew
   A/0000-0002-3447-5376
Z8 1
ZB 3
ZR 0
ZS 2
TC 303
ZA 0
Z9 307
SN 0025-1909
UT WOS:000174441600004
ER

PT J
AU Ho, TH
   Savin, S
   Terwiesch, C
TI Managing demand and sales dynamics in new product diffusion under supply
   constraint
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP 187
EP 206
DI 10.1287/mnsc.48.2.187.257
PD FEB 2002
PY 2002
AB The Bass diffusion model is a well-known parametric approach to
   estimating new product demand trajectory over time. This paper
   generalizes the Bass model by allowing for a supply constraint. In the
   presence of a supply constraint, potential customers who are not able to
   obtain the new product join the waiting queue, generating backorders.
   and potentially reversing their adoption decision, resulting in lost
   sales. Consequently, they do not generate the positive "word-of-mouth"
   that is typically assumed in the Bass model, leading to significant
   changes in the new product diffusion dynamics.
   We study how a firm should manage its supply processes in a new product
   diffusion environment with backorders and lost sales. We consider a
   make-to-stock production environment and use optimal control theory to
   establish that it is never optimal to delay demand fulfillment. This
   result is interesting because immediate fulfillment may accelerate the
   diffusion process and thereby result in a greater loss of customers in
   the future. Using this result, we derive closed-form expressions for the
   resulting demand and sales dynamics over the product life cycle. We then
   use these expressions to investigate how the firm should determine the
   size of its capacity and the time to market its new product. We show
   that delaying a product launch to build up an initial inventory may be
   optimal and can be used as a substitute for capacity. Also, the optimal
   time to market and capacity increase with the coefficients of innovation
   and imitation in the adoption population. We compare our optimal
   capacity and time to market policies with those resulting from
   exogeneous demand forecasts in order to quantify the value of
   endogenizing demand.
RI Ho, Teck-Hua/D-1630-2013
OI Ho, Teck-Hua/0000-0001-5210-4977
ZS 0
Z8 7
ZR 0
TC 87
ZA 0
ZB 0
Z9 93
SN 0025-1909
UT WOS:000174441600005
ER

PT J
AU Gans, N
TI Customer loyalty and supplier quality competition
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP 207
EP 221
DI 10.1287/mnsc.48.2.207.256
PD FEB 2002
PY 2002
AB We develop a model of customer choice in response to random variation in
   quality The choice model yields closed-form expressions which reflect
   the effect of competing suppliers' service quality on the long-run
   fraction of purchases a customer makes at the various competitors. We
   then use the expressions as the basis of simple normative models for
   suppliers seeking to maximize their long-run average profits. The
   results provide insight into the effect of switching behavior on the
   service levels offered by competing suppliers.
ZB 1
TC 86
Z8 3
ZS 1
ZA 0
ZR 0
Z9 89
SN 0025-1909
UT WOS:000174441600006
ER

PT J
AU Kim, N
   Han, JK
   Srivastava, RK
TI A dynamic IT adoption model for the SOHO market: PC generational
   decisions with technological expectations
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP 222
EP 240
DI 10.1287/mnsc.48.2.222.252
PD FEB 2002
PY 2002
AB The small-office/home-office (SOHO) professionals comprise the fastest
   growing segment in the labor force today. Typically being a one-person
   business based at home, SOHO owners mostly rely on office information
   technology to single handedly run their entire operation. Despite the
   segment's ostensibly growing dependence and influence on the information
   technology (IT) industry, still very little is known about the dynamics
   between SOHO and IT products. With the purpose of addressing this void,
   we investigate the SOHO professionals' adoption patterns of
   multigenerational IT products. Accordingly, we develop and empirically
   estimate an individual SOHO-level initial- and repeat-purchase logit
   model that captures the procurement patterns for successive generations
   of technological products, namely the PC category. Specifically, we find
   that SOHO professionals' procurement choices are influenced by a number
   of salient dimensions (i.e., income, performance, price, interpurchase
   time, network externalities). Furthermore, some SOHO owners are found to
   have a preference for a future (expected) generation (over a currently
   available one), which is explained via their business dispositions
   (i.e., technology orientation, result orientation, search orientation)
   toward accepting technological incertitude.
RI SRIVASTAVA, Rajendra/C-5953-2009; Srivastava, Rajendra K/O-5503-2018; HAN, Jin Kyung/D-2156-2010; KIM, Namwoon/
OI Srivastava, Rajendra K/0000-0002-5236-2375; KIM,
   Namwoon/0000-0001-8884-9241
ZR 0
ZB 0
ZA 0
Z8 0
TC 24
ZS 0
Z9 24
SN 0025-1909
UT WOS:000174441600007
ER

PT J
AU Rajagopalan, S
TI Make to order or make to stock: Model and application
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP 241
EP 256
DI 10.1287/mnsc.48.2.241.255
PD FEB 2002
PY 2002
AB Some firms make all their products to order while others make them to
   stock. There are a number of firms that maintain a middle ground, where
   some items are made to stock and others are made to order. This paper
   was motivated by a consumer product company faced with the decision
   about which items to make to stock and which ones to make to order, and
   the inventory and production policy for the make-to-stock items. The
   production environment is characterized by multiple items, setup times
   between the production of consecutive items, limited capacity, and
   congestion effects. In such an environment, making an item to order
   reduces inventory costs for that item, but might increase the lot size
   and inventory costs for the items made to stock. Also, lead times
   increase because of congestion effects, resulting in higher safety
   stocks for make-to-stock items and lower service levels for
   make-to-order items, thus leading to a complex trade-off. We develop a
   nonlinear, integer programming formulation of the problem. We present an
   efficient heuristic to solve the problem, which was motivated by key
   results for a special case of the problem without congestion effects
   that can be solved optimally. We also develop a lower bound to evaluate
   the performance of the heuristic. A computational study indicates that
   the heuristic performs well. We discuss the application of the model in
   a large firm and the resulting insights. We also provide insights into
   the impact of various problem parameters on the make-to-order versus
   make-to-stock decisions using a computational study. In particular, we
   find that the average number of setups of an item selected for
   make-to-stock production is always less than half the average number of
   setups of the item if it were to be made to order. Also, factors other
   than an item's demand, such as its setup time, processing time, and unit
   holding cost, impact the make-to-order versus make-to-stock decision.
ZA 0
ZR 0
Z8 6
ZB 1
TC 103
ZS 1
Z9 110
SN 0025-1909
UT WOS:000174441600008
ER

PT J
AU Stenbacka, R
   Tombak, M
TI Investment, capital structure, and complementarities between debt and
   new equity
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP 257
EP 272
DI 10.1287/mnsc.48.2.257.260
PD FEB 2002
PY 2002
AB We study simultaneous investment and financing decisions made by
   incumbent owners in the presence of capital market imperfections, We
   present a theory for how the optimal combination of debt and equity
   financing depends on the firm's internal funds. We identify
   complementarities between the two financial instruments. We test these
   predictions empirically with panel data on 3,119 corporations in the
   COMPUSTAT database. Our estimates using instrumental variable techniques
   support our theoretical predictions regarding the link between internal
   funds and capital investments, as well as the interaction effects
   between debt and new equity. We explore implications for managers,
   financiers, and policy makers.
ZB 0
TC 10
ZA 0
Z8 0
ZS 0
ZR 0
Z9 10
SN 0025-1909
UT WOS:000174441600009
ER

PT J
AU Bradley, JR
   Glynn, PW
TI Managing capacity and inventory jointly in manufacturing systems
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP 273
EP 288
DI 10.1287/mnsc.48.2.273.254
PD FEB 2002
PY 2002
AB In this paper, we develop approximations that yield insight into the
   joint optimization of capacity and inventory, and how the optimal
   inventory policy varies with capacity investment in a single-product,
   single-station, make-to-stock manufacturing system in which inventory is
   managed through a base-stock policy. We allow for a correlated demand
   stream as we analyze our models in an asymptotic regime, in which the
   penalty and holding costs are small relative to the cost of capacity
   Although our approximations are asymptotically correct, our Brownian
   approximation is accurate even under moderate traffic intensity.
ZS 1
ZA 0
Z8 1
ZR 0
TC 42
ZB 0
Z9 44
SN 0025-1909
UT WOS:000174441600010
ER

PT J
AU King, A
   Lenox, M
TI Exploring the locus of profitable pollution reduction
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP 289
EP 299
DI 10.1287/mnsc.48.2.289.258
PD FEB 2002
PY 2002
AB In this paper, we explore the locus of profitable pollution reduction.
   We propose that managers underestimate the full value of some means of
   pollution reduction and so under exploit these means. Based on evidence
   from previous studies, we argue that waste prevention often provides
   unexpected innovation offsets, and that onsite waste treatment often
   provides unexpected cost. We use statistical methods to test the
   direction and significance of the relationship between the various means
   of pollution reduction and profitability. We find strong evidence that
   waste prevention leads to financial gain, but we find no evidence that
   firms profit from reducing pollution by other means. Indeed, we find
   evidence that the benefits of waste prevention alone are responsible for
   the observed association between lower emissions and profitability.
RI King, Andrew A/E-1684-2011
OI King, Andrew A/0000-0002-3447-5376
TC 553
ZA 0
Z8 2
ZB 26
ZR 0
ZS 2
Z9 557
SN 0025-1909
EI 1526-5501
UT WOS:000174441600011
ER

PT J
AU Cheung, KL
   Lee, HL
TI The inventory benefit of shipment coordination and stock rebalancing in
   a supply chain
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP 300
EP 306
DI 10.1287/mnsc.48.2.300.251
PD FEB 2002
PY 2002
AB In this paper, we examine two information-based supply-chain efforts
   that are often linked to Vendor-Managed Inventory (VMI) programs.
   Specifically, we consider a supplier serving Multiple retailers located
   in a close proximity. The first effort uses information on the
   retailers' inventory positions to coordinate shipments from the supplier
   to enjoy economies of scale in shipments, such as full truckloads. The
   second effort uses the same information for eventual unloading of the
   shipments to the retailers to rebalance their stocking positions. How
   much benefit do we gain from such initiatives? What are the relative
   benefits of the two initiatives? What are the drivers of such benefits?
   This paper seeks answers to these questions.
Z8 13
ZA 0
ZR 1
TC 120
ZB 0
ZS 0
Z9 133
SN 0025-1909
EI 1526-5501
UT WOS:000174441600012
ER

PT J
AU Reinschmidt, KF
TI Aggregate social discount rate derived from individual discount rates
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP 307
EP 312
DI 10.1287/mnsc.48.2.307.259
PD FEB 2002
PY 2002
AB In the economic evaluation of large public-sector projects, an aggregate
   social discount rate may be used in present worth comparison of
   alternatives. This paper uses the assumptions that individual discount
   rates are constant over time and approximately Normally distributed
   across the affected population, with mean mu and variance sigma(2), to
   derive an aggregate discount function that is exponential in form but
   with time-dependent aggregate discount rate p(t) = mu - sigma(2)t/2,
   where t is the time of occurrence of the cost or benefit. This equation
   agrees with numerical simulations. If sigma(2) > 0, then the aggregate
   discount rate is less than the mean individual discount rate, and use of
   the time-dependent aggregate discount rate p(t) = mu - sigma(2)t/2
   instead of the constant discount factor p(t) = mu would result in larger
   discounted present values for public-sector projects for which the
   benefits lie far in the future. This could mean that public-sector
   investments that would be rejected under the assumption p(t) = mu might
   be justified using the time-dependent aggregate discount rate p(t) = mu
   - sigma(2)t/2.
ZR 0
ZA 0
TC 10
ZS 1
Z8 1
ZB 1
Z9 11
SN 0025-1909
UT WOS:000174441600013
ER

PT J
AU Hopp, WJ
   Lovejoy, WS
   Ulrich, K
TI Editorial objectives - Design and operations management
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP VI
EP VII
PD FEB 2002
PY 2002
AB In recent years the field of operations management has expanded to
   embrace a larger set of problems than that which historically dominated
   our academic literature. There is now an increased presence of upper
   management issues (for example issues of design, investment, and
   coordination) at both the demand and supply end of our research
   activities. In recognition of this, the Manufacturing, Distribution and
   Service Operations department of Management Science will be renamed the
   Design and Operations Management department, with a revised editorial
   mission (below) focused on promoting and addressing these higher level
   issues. The intent is not to discount the importance of further progress
   on more tactical managerial issues, but rather to reduce the overlap
   among the editorial missions of the top INFORMS journals and at the same
   time promote new work in exciting and industrially relevant areas. We
   invite a careful reading of our editorial mission and enthusiastically
   encourage all appropriate contributions.
ZS 0
TC 0
Z8 0
ZA 0
ZB 0
ZR 0
Z9 0
SN 0025-1909
UT WOS:000174441600003
ER

PT J
AU Levinthal, D
TI Editorial objectives - Business strategy
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP V
EP V
PD FEB 2002
PY 2002
ZS 0
ZB 0
ZA 0
Z8 0
TC 0
ZR 0
Z9 0
SN 0025-1909
UT WOS:000174441600002
ER

PT J
AU Ortega, J
TI Job rotation as a learning mechanism (vol 47, pg 1361, 2001)
SO MANAGEMENT SCIENCE
VL 48
IS 2
BP I
EP I
PD FEB 2002
PY 2002
ZR 0
ZB 0
TC 0
Z8 0
ZA 0
ZS 0
Z9 0
SN 0025-1909
UT WOS:000174441600001
ER

PT J
AU Krishnan, V
   Bhattacharya, S
TI Technology selection and commitment in new product development: The role
   of uncertainty and design flexibility
SO MANAGEMENT SCIENCE
VL 48
IS 3
BP 313
EP 327
DI 10.1287/mnsc.48.3.313.7728
PD MAR 2002
PY 2002
AB Selecting the right technologies to incorporate in new products is a
   particularly challenging aspect of new product definition and
   development. While newer advanced technologies may offer improved
   performance, they also make the product development process more risky
   and challenging. In this paper, we focus on the problem of technology
   selection and commitment under uncertainty, a major challenge to firms
   in turbulent environments. We argue that the ''pizza-bin'' approach of
   rejecting prospective technologies outright may not serve firms well
   when the pressure to differentiate products is enormous. After
   motivating the challenges and decisions facing firms using a real-life
   application from Dell Computer Corporation, we formulate a mathematical
   model of a firm that must define its products in the presence of
   technology uncertainty. Specifically, the firm faces two options: (i) a
   proven technology that is known to be viable and (ii) a prospective
   technology that offers superior price to performance results but whose
   viability is not a fully certain outcome. To minimize the impact of
   technology uncertainty, we consider two approaches to design flexibility
   termed parallel path and sufficient design, which allow the firm to
   concurrently develop its products while the technology is being
   validated. Our analysis helps understand appropriateness of the
   different flexible design approaches. We illustrate our model with the
   Dell portable computer example and note the managerial implications of
   our analysis.
RI BHATTACHARYA, Shantanu Hiralal/J-4138-2014; Bhattacharya, Shantanu/
OI Bhattacharya, Shantanu/0000-0001-5027-6505
TC 108
ZS 2
ZR 0
Z8 2
ZA 0
ZB 0
Z9 112
SN 0025-1909
UT WOS:000175081300001
ER

PT J
AU Zenios, SA
TI Optimal control of a paired-kidney exchange program
SO MANAGEMENT SCIENCE
VL 48
IS 3
BP 328
EP 342
DI 10.1287/mnsc.48.3.328.7732
PD MAR 2002
PY 2002
AB Organ exchanges are expected to increase the utilization of living
   donors and to alleviate the critical shortage of organs for
   transplantation. The typical arrangement involves a direct exchange
   between two blood-type incompatible donor-candidate pairs. An alternate
   possibility is an indirect exchange between one such pair and the
   highest priority candidate on the regular waiting list for cadaveric
   organs. This paper focuses on the mix of direct and indirect exchanges
   that maximizes the expected total discounted quality-adjusted life years
   (QALY) of the candidates in the participating pairs. Direct exchanges
   are preferable because the candidate receives a living-donor organ
   instead of the inferior cadaveric organ an indirect exchange provides.
   However, the latter involves a shorter wait. To capture this tradeoff,
   we develop a double-ended queueing model for an exchange system with two
   types of donor-candidate pairs, and obtain an optimal dynamic exchange
   policy by invoking a Brownian approximation. The policy takes the form
   of a two-sided regulator in which new pairs will join the exchange
   system to wait for a direct exchange if and only if the process modeling
   the exchange system is within the regulator's two barriers. In all other
   circumstances, new pairs will participate in an indirect exchange.
   Expressions for the optimal barriers are obtained under a variety of
   assumptions about the objective function, including one of complete
   candidate autonomy. The analysis identifies three design principles that
   will amplify the likelihood of an exchange program's success. First,
   exchange programs must involve the coordinated activities of multiple
   local transplant centers to enjoy the substantial benefits of resource
   pooling. Second, participant wait must be controlled through indirect
   exchanges. Third, the program must respect participants' autonomy and
   weigh that autonomy against the broader goal of maximizing their overall
   welfare.
Z8 2
ZS 0
ZR 0
ZA 0
TC 26
ZB 2
Z9 28
SN 0025-1909
EI 1526-5501
UT WOS:000175081300002
ER

PT J
AU Ding, M
   Eliashberg, J
TI Structuring the new product development pipeline
SO MANAGEMENT SCIENCE
VL 48
IS 3
BP 343
EP 363
DI 10.1287/mnsc.48.3.343.7727
PD MAR 2002
PY 2002
AB dIn many new product development (NPD) situations, the development
   process is characterized by uncertainty, and no single development
   approach will necessarily lead to a successful product. To increase the
   likelihood of having at least one successful product, multiple
   approaches may be simultaneously funded at the various NPD stages. The
   managerial challenge is to construct ex ante an appropriate NPD pipeline
   by choosing the right number of approaches to be funded at each stage.
   This so-called pipeline problem is also present in, among others,
   advertising copy selection and new products test markets problems. We
   describe here a normative model for structuring pipelines for such
   situations. The optimal structure of the pipeline is driven by the cost
   of the development approach, its probability of survival, and the
   expected profitability. We illustrate the workability and implications
   of the model by applying it to some real-world scenarios in the
   pharmaceutical industry, and by comparing its normative pipeline
   recommendations against actual pipelines. Our results suggest that, for
   the cases we studied, firms tend to use narrower pipelines for their new
   drug development than they should, and thereby they underspend on
   research and development. We also present general qualitative insights
   for one- and two-stage NPD optimal pipeline structures.
TC 64
Z8 0
ZS 1
ZA 0
ZR 0
ZB 1
Z9 65
SN 0025-1909
UT WOS:000175081300003
ER

PT J
AU Shane, S
   Cable, D
TI Network ties, reputation, and the financing of new ventures
SO MANAGEMENT SCIENCE
VL 48
IS 3
BP 364
EP 381
DI 10.1287/mnsc.48.3.364.7731
PD MAR 2002
PY 2002
AB Explaining how entrepreneurs overcome information asymmetry between
   themselves and potential investors to obtain financing is an important
   issue for entrepreneurship research. Our premise is that economic
   explanations for venture finance, which do not consider how social ties
   influence this process, are undersocialized and incomplete. However, we
   also argue that organization theoretic arguments, which draw on the
   concept of social obligation, are oversocialized. Drawing on the
   organizational theory literature, and in-depth fieldwork with 50
   high-technology ventures, we examine the effects of direct and indirect
   ties between entrepreneurs and 202 seed-stage investors on venture
   finance decisions. We show that these ties influence the selection of
   ventures to fund through a process of information transfer.
RI Cable, Daniel/C-3579-2014; Kolyaka, Tanya/E-7464-2016; DEL RIO, MIGUEL ANGEL MONTANES/F-2359-2013
OI Kolyaka, Tanya/0000-0001-8595-4396; 
ZA 0
Z8 18
TC 730
ZR 1
ZS 5
ZB 3
Z9 749
SN 0025-1909
UT WOS:000175081300004
ER

PT J
AU Nambisan, S
TI Complementary product integration by high-technology new ventures: The
   role of initial technology strategy
SO MANAGEMENT SCIENCE
VL 48
IS 3
BP 382
EP 398
DI 10.1287/mnsc.48.3.382.7724
PD MAR 2002
PY 2002
AB In this paper, we investigate the relationship between complementary
   product integration and the initial technology strategy of a
   high-technology new venture. With customers placing considerable
   emphasis on cross-product integration, the success of a new venture is
   dependent as much on its ability to integrate its product with relevant
   complementary products as on the core product functionality itself. We
   identify three types of complementary product integration: value-added
   internal, add-on module, and data interface. We argue that the adoption
   of proactive initial technology strategy critically determines the
   ability of a high-technology new venture to rapidly and efficiently
   integrate its product with new and emerging complementary products. More
   specifically, we offer hypotheses that relate initial design and
   development strategies to the number and the type of complementary
   product integrations achieved by a new venture in the initial years. The
   hypotheses are tested using data from a set of U.S.-based software new
   ventures. The results support our arguments and imply the need for
   high-technology new ventures to adopt an explicit complementary product
   focus during initial product design.
RI Nambisan, Satish/AAE-3369-2020
ZR 1
TC 46
ZB 1
Z8 2
ZS 0
ZA 0
Z9 49
SN 0025-1909
UT WOS:000175081300005
ER

PT J
AU Angelus, A
   Porteus, EL
TI Simultaneous capacity and production management of short-life-cycle,
   produce-to-stock goods under stochastic demand
SO MANAGEMENT SCIENCE
VL 48
IS 3
BP 399
EP 413
DI 10.1287/mnsc.48.3.399.7726
PD MAR 2002
PY 2002
AB This paper derives the optimal simultaneous capacity and production plan
   for a short-life-cycle, produce-to-stock good under stochastic demand.
   Capacity can be reduced as well as added, at exogenously set unit
   prices. In both cases studied, with and without carry-over of unsold
   units, a target interval policy is optimal: There is a (usually
   different) target interval for each period such that capacity should be
   changed as little as possible to bring the level available into that
   interval. Our contribution in the case of no carry-over, is a detailed
   characterization of the target intervals, assuming demands increase
   stochastically at the beginning of the life cycle and decrease
   thereafter. In the case of carry-over, we establish the general result
   and show that capacity and inventory are economic substitutes: The
   target intervals decrease in the initial stock level and the optimal
   unconstrained base stock level decreases in the capacity level. In both
   cases, optimal service rates are not necessarily constant over time. A
   numerical example illustrates the results.
RI ANGELUS, Alexandar/D-2215-2010
Z8 4
TC 58
ZR 0
ZS 0
ZB 0
ZA 0
Z9 62
SN 0025-1909
UT WOS:000175081300006
ER

PT J
AU Moinzadeh, K
TI A multi-echelon inventory system with information exchange
SO MANAGEMENT SCIENCE
VL 48
IS 3
BP 414
EP 426
DI 10.1287/mnsc.48.3.414.7730
PD MAR 2002
PY 2002
AB In this paper, we consider a supply-chain model consisting of a single
   product, one supplier, and multiple retailers. Demand at the retailers
   is random, but stationary. Each retailer places her orders to the
   supplier according to the well-known (Q, R) policy. We assume that the
   supplier has online information about the demand, as well as inventory
   activities of the product at each retailer, and uses this information
   when making order/replenishment decisions. We first propose a
   replenishment policy for the supplier, which incorporates information
   about the inventory position of the retailers. Then, we provide an exact
   analysis of the operating measures of such systems. Assuming the
   inventory/replenishment decisions are made centrally for the system, we
   compare the performance of our model with those that do not use
   information in their decision making, namely, systems that use
   installation stock policies via a numerical experiment. Based on our
   numerical results, we identify the parameter settings under which
   information sharing is most beneficial.
Z8 10
ZS 0
ZR 1
ZB 0
ZA 0
TC 122
Z9 133
SN 0025-1909
UT WOS:000175081300007
ER

PT J
AU Korkie, B
   Turtle, HJ
TI A mean-variance analysis of self-financing portfolios
SO MANAGEMENT SCIENCE
VL 48
IS 3
BP 427
EP 443
DI 10.1287/mnsc.48.3.427.7725
PD MAR 2002
PY 2002
AB T his paper develops the analytics and geometry of the investment
   opportunity set (IOS) and the test statistics for self-financing
   portfolios. A self-financing portfolio is a set of long and short
   investments such that the sum of their investment weights, or net
   investment, is zero. This contrasts with a standard portfolio that has
   investment weights summing to one. Examples of self-financing portfolios
   are hedges, overlays, arbitrage portfolios, swaps, and long/short
   portfolios. A standard portfolio plus the IOS of self-financing
   portfolios form a restricted IOS hyperbola with restricted efficient set
   constants that differ from the usual constants. The restrictions affect
   statistical tests of portfolio efficiency, which are developed for the
   self-financing restrictions. As an application, we consider the
   self-financing portfolios formed by Fama and French (1992, 1993, 1995),
   based on market capitalization and value. In contrast to Fama and French
   (1992, 1993, 1995), we find that their restricted IOS is significantly
   different from the unrestricted IOS with the implication that the
   Fama-French tests are misspecified.
RI Turtle, Harry/A-2254-2014
OI Turtle, Harry/0000-0003-0703-9824
Z8 2
ZR 0
ZA 0
TC 15
ZS 0
ZB 0
Z9 17
SN 0025-1909
UT WOS:000175081300008
ER

PT J
AU Oguz, O
TI Generalized column generation for linear programming
SO MANAGEMENT SCIENCE
VL 48
IS 3
BP 444
EP 452
DI 10.1287/mnsc.48.3.444.7729
PD MAR 2002
PY 2002
AB Column generation is a well-known and widely practiced technique for
   solving linear programs with too many variables or constraints to
   include in the initial formulation explicitly. Instead, the required
   column information is generated at each iteration of the simplex
   algorithm. This paper shows that, even if the number of variables is low
   enough for explicit inclusion in the model with the available
   technology, it may still be more efficient to resort to column
   generation for some class of problems.
Z8 0
ZR 0
TC 3
ZB 0
ZA 0
ZS 0
Z9 3
SN 0025-1909
EI 1526-5501
UT WOS:000175081300009
ER

PT J
AU Cyert, RM
   Kang, SH
   Kumar, P
TI Corporate governance, takeovers, and top-management compensation: Theory
   and evidence
SO MANAGEMENT SCIENCE
VL 48
IS 4
BP 453
EP 469
DI 10.1287/mnsc.48.4.453.205
PD APR 2002
PY 2002
AB We examine, both theoretically and empirically, top-management
   compensation in the presence of agency conflicts when shareholders have
   delegated governance responsibilities to a self-interested Board of
   Directors (BOD). We develop a theoretical framework that explicitly
   incorporates the BOD as a strategic player, models the negotiation
   process between the CEO and the BOD in designing CEO compensation, and
   considers the impact of potential takeovers by large shareholders
   monitoring the CEO-BOD negotiations. In equilibrium, internal governance
   by the BOD and external takeover threats by a large shareholder act as
   substitutes in imposing managerial control, especially in constraining
   management's profligacy in awarding equity-based compensation to itself.
   The model emphasizes factors in the design of compensation contracts
   that are rarely considered in the literature, such as equity ownership
   of the largest outside shareholder and the firm's bankruptcy risk. It
   also provides new perspectives on factors that are often considered in
   the literature, such as firm size, firm performance, equity ownership of
   the BOD, and BOD structure. Our empirical tests lend considerable
   support for our theoretical predictions. Equity ownership of the largest
   external shareholder, that of the BOD, and the default risk, are
   strongly negatively related to the size of CEO equity compensation.
   Consistent with the theoretical model, these factors do not
   significantly influence the growth of fixed (or non-performance-related)
   compensation. We also find that the equity ownership of the BOD is more
   important in managerial compensation control than other BOD related
   variables, such as BOD size or the proportion of outside directors.
Z8 1
TC 146
ZB 1
ZR 0
ZA 1
ZS 2
Z9 149
SN 0025-1909
EI 1526-5501
UT WOS:000175529300001
ER

PT J
AU Breen, WJ
   Hodrick, LS
   Korajczyk, RA
TI Predicting equity liquidity
SO MANAGEMENT SCIENCE
VL 48
IS 4
BP 470
EP 483
DI 10.1287/mnsc.48.4.470.210
PD APR 2002
PY 2002
AB In this paper we develop a measure of liquidity price impact, which
   quantifies the change in a firm's stock price associated with its
   observed net trading volume. For a large set of institutional trades we
   compare out-of-sample, characteristic-based estimates of price impact to
   actual price impacts. Predictive predetermined firm characteristics,
   chosen to proxy for the severity of adverse selection in the equity
   market, the non-information-based costs of making a market in the stock,
   and the extent of shareholder heterogeneity, include relative size,
   historical relative trading volume, institutional holdings, and the
   inverse of the stock price. We find numerous aspects of trade execution
   which are significantly related to the price impact forecast error in
   economically plausible ways: For example, the predicted price impact
   overestimates the actual price impact for very large trades, for trades
   executed in a more patient manner, and for trades where the institution
   pays higher commissions.
OI Korajczyk, Robert/0000-0003-2436-2324
Z8 1
TC 56
ZS 1
ZB 0
ZR 0
ZA 0
Z9 58
SN 0025-1909
UT WOS:000175529300002
ER

PT J
AU Kirsch, LJ
   Sambamurthy, V
   Ko, DG
   Purvis, RL
TI Controlling information systems development projects: The view from the
   client
SO MANAGEMENT SCIENCE
VL 48
IS 4
BP 484
EP 498
DI 10.1287/mnsc.48.4.484.204
PD APR 2002
PY 2002
AB Increasingly, business clients are actively leading information systems
   (IS) projects, often in collaboration with IS professionals, and they
   are exercising a greater degree of project control. Control is defined
   as all attempts to motivate individuals to achieve desired objectives,
   and it can be exercised via formal and informal modes. Much of the
   previous research investigating the choice of control mode has focused
   on direct reporting relationships between IS project leaders and their
   superiors in a hierarchical setting. However, the client-IS
   relationships may take on a variety of forms, including both
   hierarchical and lateral settings, Moreover, prior research has found
   that the knowledge of the systems development process is a key
   antecedent of control, yet clients are unlikely to be as knowledgeable
   as IS professionals about this process. It is therefore unclear whether
   prior findings will generalize to the client-IS pair, and the goal of
   this research is to examine the exercise of control across this
   relationship. Data were gathered from a questionnaire survey of 69 pairs
   of clients and IS project leaders. The results are largely consistent
   with prior research on the antecedents of formal control modes, but they
   shed new insight on the choice of informal control modes.
OI Ko, Dong-Gil/0000-0002-1967-0333
Z8 4
TC 205
ZS 2
ZB 0
ZA 0
ZR 0
Z9 211
SN 0025-1909
UT WOS:000175529300003
ER

PT J
AU Song, JS
TI Order-based backorders and their implications in multi-item inventory
   systems
SO MANAGEMENT SCIENCE
VL 48
IS 4
BP 499
EP 516
DI 10.1287/mnsc.48.4.499.207
PD APR 2002
PY 2002
AB In a multi-item inventory system, such as an assemble-to-order
   manufacturing system or an online-retailing system, a customer order
   typically consists of several different items in different amounts. The
   average order-based backorders are the average number of customer orders
   that are not yet completely filled, While this is an important measure
   of customer satisfaction, it has not been widely studied in the
   operations management literature. This is largely because its evaluation
   involves the joint distribution of inventory levels of different items
   and other intricate relations, which is computationally dreadful. Taking
   a novel approach, this paper develops a tractable way of evaluating this
   measure exactly. We also develop easy-to-compute bounds, which require
   the evaluation of item-based backorders only. Numerical experiments
   indicate that the average of the lower and upper bounds is very
   effective.
   The exact results show surprisingly simple structures, which shed light
   on how system parameters affect the performance. Using these results, we
   study several examples to gain managerial insights. Questions addressed
   include: What are the implications of item-based inventory planning
   decisions on the order-based performance? What is the impact of
   introducing common components on inventory and service trade-offs? Would
   order-delivery performance be improved if we restrict the number of
   choices in product configurations?
ZB 1
Z8 5
ZA 1
TC 40
ZS 1
ZR 0
Z9 46
SN 0025-1909
UT WOS:000175529300004
ER

PT J
AU Gupta, D
   Gerchak, Y
TI Quantifying operational synergies in a merger/acquisition
SO MANAGEMENT SCIENCE
VL 48
IS 4
BP 517
EP 533
DI 10.1287/mnsc.48.4.517.209
PD APR 2002
PY 2002
AB Merger and acquisition activity has increased sharply in the last
   decade. It seems useful to have models that can help senior managers of
   bidder firms make informed decisions about the amount of premium, over
   the target's share prices prevailing prior to merger announcement, that
   can be justified on the basis of operational synergies. The goal of this
   article is to capture important parameters from the production side that
   have a bearing on the valuation of the target's shares. We show that the
   production characteristics of both the bidder and the target matter in a
   significant way. For example, if the bidder and target operate in
   independent markets, the bidder has flexible production facilities but
   the target's production facilities are inflexible, then an increase in
   the bidder's demand can make the target less attractive and lower the
   value of operational synergy.
TC 44
Z8 3
ZB 2
ZA 0
ZS 0
ZR 0
Z9 47
SN 0025-1909
UT WOS:000175529300005
ER

PT J
AU Clemons, EK
   Hann, IH
   Hitt, LM
TI Price dispersion and differentiation in online travel: An empirical
   investigation
SO MANAGEMENT SCIENCE
VL 48
IS 4
BP 534
EP 549
DI 10.1287/mnsc.48.4.534
PD APR 2002
PY 2002
AB Previous research has examined whether price dispersion exists in
   theoretically highly efficient Internet markets. However, much of the
   previous work has been focused on industries with low cost and
   undifferentiated products. In this paper, we examine the presence of
   price dispersion and product differentiation using data on the airline
   ticket offerings of online travel agents (OTAs). We find that different
   OTAs offer tickets with substantially different prices and
   characteristics when given the same customer request. Some of this
   variation appears to be due to product differentiation-different OTAs
   specialize by systematically offering different trade-offs between
   ticket price and ticket quality (minimizing the number of connections,
   matching requested departure and return time). However, even after
   accounting for differences in ticket quality ticket prices vary by as
   much as 18% across OTAs. In addition, OTAs return tickets that are
   strictly inferior to the ticket offered by another OTA for the same
   request between 2.2% and 28% of the time. Overall, this suggests the
   presence of both price dispersion and product differentiation in the
   online travel market.
ZA 0
ZR 0
TC 219
ZB 1
Z8 5
ZS 3
Z9 226
SN 0025-1909
EI 1526-5501
UT WOS:000175529300006
ER

PT J
AU Bertsimas, D
   Demir, R
TI An approximate dynamic programming approach to multidimensional knapsack
   problems
SO MANAGEMENT SCIENCE
VL 48
IS 4
BP 550
EP 565
DI 10.1287/mnsc.48.4.550.208
PD APR 2002
PY 2002
AB We present an Approximate Dynamic Programming (ADP) approach for the
   multidimensional knapsack problem (MKP). We approximate the value
   function (a) using parametric and nonparametric methods and (b) using a
   base-heuristic. We propose a new heuristic which adaptively rounds the
   solution of the linear programming relaxation. Our computational study
   suggests: (a) the new heuristic produces high quality solutions fast and
   robustly, (b) state of the art commercial packages like CPLEX require
   significantly larger computational time to achieve the same quality of
   solutions, (c) the ADP approach using the new heuristic competes
   successfully with alternative heuristic methods such as genetic
   algorithms, (d) the ADP approach based on parametric and nonparametric
   approximations, while producing reasonable solutions, is not
   competitive. Overall, this research illustrates that the base-heuristic
   approach is a promising computational approach for MKPs worthy of
   further investigation.
ZS 0
ZA 0
TC 82
ZR 0
Z8 4
ZB 0
Z9 86
SN 0025-1909
UT WOS:000175529300007
ER

PT J
AU Zohar, E
   Mandelbaum, A
   Shimkin, N
TI Adaptive behavior of impatient customers in tele-queues: Theory and
   empirical support
SO MANAGEMENT SCIENCE
VL 48
IS 4
BP 566
EP 583
DI 10.1287/mnsc.48.4.566.211
PD APR 2002
PY 2002
AB We address the modeling and analysis of abandonments from a queue that
   is invisible to its occupants. Such queues arise in remote service
   systems, notably the Internet and telephone call centers; hence, we
   refer to them as tele-queues. A basic premise of this paper is that
   customers adapt their patience (modeled by an abandonment-time
   distribution) to their service expectations, in particular to their
   anticipated waiting time. We present empirical support for that
   hypothesis, and propose an M/M/m-based model that incorporates adaptive
   customer behavior. In our model, customer patience depends on the mean
   waiting time in the queue. We characterize the resulting system
   equilibrium (namely, the operating point in steady state), and establish
   its existence and uniqueness when changes in customer patience are
   bounded by the corresponding changes in their anticipated waiting time.
   The feasibility of multiple system equilibria is illustrated when this
   condition is violated. Finally, a dynamic learning model is proposed
   where customer expectations regarding their waiting time are formed
   through accumulated experience. We demonstrate, via simulation,
   convergence to the theoretically anticipated equilibrium, while
   addressing certain issues related to censored-sampling that arise
   because of abandonments.
ZS 3
ZR 0
ZA 0
Z8 3
ZB 0
TC 80
Z9 86
SN 0025-1909
EI 1526-5501
UT WOS:000175529300008
ER

PT J
AU Chiang, WC
   Kouvelis, P
   Urban, TL
TI Incorporating workflow interference in facility layout design: The
   quartic assignment problem
SO MANAGEMENT SCIENCE
VL 48
IS 4
BP 584
EP 590
DI 10.1287/mnsc.48.4.584.206
PD APR 2002
PY 2002
AB Although many authors have noted the importance of minimizing workflow
   interference in facility layout design, traditional layout research
   tends to focus on minimizing the distance-based transportation cost.
   This paper formalizes the concept of workflow interference from a
   facility layout perspective. A model, formulated as a quartic assignment
   problem, is developed that explicitly considers the interference of
   workflow. Optimal and heuristic solution methodologies are developed and
   evaluated.
RI Kouvelis, Panos/ABG-2350-2020
ZS 1
ZA 0
Z8 0
TC 7
ZR 0
ZB 0
Z9 8
SN 0025-1909
UT WOS:000175529300009
ER

PT J
AU Zantek, PF
   Wright, GP
   Plante, RD
TI Process and product improvement in manufacturing systems with correlated
   stages
SO MANAGEMENT SCIENCE
VL 48
IS 5
BP 591
EP 606
DI 10.1287/mnsc.48.5.591.7804
PD MAY 2002
PY 2002
AB Manufacturing systems typically contain processing and assembly stages
   whose output quality is significantly affected by the output quality of
   preceding stages in the system. This study offers and empirically
   validates a procedure for (1) measuring the effect of each stage's
   performance on the output quality of subsequent stages including the
   quality of the final product, and (2) identifying stages in a
   manufacturing system where management should concentrate investments in
   process quality improvement. Our proposed procedure builds on the
   precedence ordering of the stages in the system and uses the information
   provided by correlations between the product quality measurements across
   stages.
   The starting point of our procedure is a computer executable network
   representation of the statistical relationships between the product
   quality measurements; execution automatically converts the network to a
   simultaneous-equations model and estimates the model parameters by the
   method of least squares. The parameter estimates are used to measure and
   rank the impact of each stage's performance on variability in
   intermediate stage and final product quality. We extend our work by
   presenting an economic model, which uses these results, to guide
   management in deciding on the amount of investment in process quality
   improvement for each stage.
   We report some of the findings from an extensive empirical validation of
   our procedure using circuit board production line data from a major
   electronics manufacturer. The empirical evidence presented here
   highlights the importance of accounting for quality linkages across
   stages in (a) identifying the sources of variation in product quality
   and (b) allocating investments in process quality improvement.
OI Zantek, Paul/0000-0001-8171-1901
TC 57
ZB 0
Z8 6
ZR 0
ZA 0
ZS 0
Z9 63
SN 0025-1909
UT WOS:000175935400001
ER

PT J
AU Treharne, JT
   Sox, CR
TI Adaptive inventory control for nonstationary demand and partial
   information
SO MANAGEMENT SCIENCE
VL 48
IS 5
BP 607
EP 624
DI 10.1287/mnsc.48.5.607.7807
PD MAY 2002
PY 2002
AB This paper examines several different policies for an inventory control
   problem in which the demand process is nonstationary and partially
   observed. The probability distribution for the demand in each period is
   determined by the state of a Markov chain, the core process. However,
   the state of this core process is not directly observed, only the actual
   demand is observed by the decision maker. Given this demand process, the
   inventory control problem is a composite-state, partially observed
   Markov decision process (POMDP), which is an appropriate model for a
   number of dynamic demand problems. In practice, managers often use
   certainty equivalent control (CEC) policies to solve such a problem.
   However, this paper presents results that demonstrate that there are
   other practical control policies that almost always provide much better
   solutions for this problem than the CEC policies commonly used in
   practice. The computational results also indicate how specific problem
   characteristics influence the performance of each of the alternative
   policies.
ZS 1
ZR 0
ZA 0
TC 52
Z8 2
ZB 0
Z9 53
SN 0025-1909
UT WOS:000175935400002
ER

PT J
AU Ben-Ameur, H
   Breton, M
   L'Ecuyer, P
TI A dynamic programming procedure for pricing American-style Asian options
SO MANAGEMENT SCIENCE
VL 48
IS 5
BP 625
EP 643
DI 10.1287/mnsc.48.5.625.7803
PD MAY 2002
PY 2002
AB Pricing European-style Asian options based on the arithmetic average,
   under the Black and Scholes model, involves estimating an integral (a
   mathematical expectation) for which no easily computable analytical
   solution is available. Pricing their American-style counterparts, which
   provide early exercise opportunities, poses the additional difficulty of
   solving a dynamic optimization problem to determine the optimal exercise
   strategy. A procedure for pricing American-style Asian options of the
   Bermudan flavor, based on dynamic programming combined with
   finite-element piecewise-polynomial approximation of the value function,
   is developed here. A convergence proof is provided. Numerical
   experiments illustrate the consistency and efficiency of the procedure.
   Theoretical properties of the value function and of the optimal exercise
   strategy are also established.
RI L'Ecuyer, Pierre/O-6577-2019; Breton, Michele/
OI L'Ecuyer, Pierre/0000-0002-3184-0796; Breton,
   Michele/0000-0001-8264-8350
Z8 1
ZA 0
ZR 0
ZS 0
ZB 0
TC 24
Z9 25
SN 0025-1909
EI 1526-5501
UT WOS:000175935400003
ER

PT J
AU Gavirneni, S
TI Information flows in capacitated supply chains with fixed ordering costs
SO MANAGEMENT SCIENCE
VL 48
IS 5
BP 644
EP 651
DI 10.1287/mnsc.48.5.644.7806
PD MAY 2002
PY 2002
AB Many organizations have only recently recognized that sharing
   information with other members in their supply chain can lead to
   significant reduction in the total costs. Usually these information
   flows are incorporated into existing operating policies at the various
   parties. In this paper we argue that, in some cases, it may be necessary
   to change the way the supply chain is managed to make complete use of
   the information flows. We support this argument by analyzing a supply
   chain containing a capacitated supplier and a retailer facing i.i.d.
   demands. In addition there are fixed ordering costs between the retailer
   and the supplier. In this setting, we consider two models: (1) the
   retailer is using the optimal (s, S) policy and providing the supplier
   information about her inventory levels; and (2) the retailer, still
   sharing information on her inventory levels, orders in a period only if
   by the previous period the cumulative end-customer demand since she last
   ordered was greater than delta. Thus, in Model 1, information sharing is
   used to supplement existing policies; while, in Model 2, we have
   redefined operating policies to make better use of the information
   flows. We will show, via a detailed computational study, that the total
   supply chain costs of Model 2 are 10.4% lower, on the average, than that
   of Model 1. We noticed that this reduction in costs is higher at higher
   capacities, higher supplier penalty costs, lower retailer penalty costs,
   moderate values of set-up cost, and at lower end-customer demand
   variances.
Z8 7
TC 101
ZB 0
ZS 1
ZA 0
ZR 0
Z9 108
SN 0025-1909
EI 1526-5501
UT WOS:000175935400004
ER

PT J
AU Grosfeld-Nir, A
   Gerchak, Y
TI Multistage production to order with rework capability
SO MANAGEMENT SCIENCE
VL 48
IS 5
BP 652
EP 664
DI 10.1287/mnsc.48.5.652.7802
PD MAY 2002
PY 2002
AB This study considers multistage production systems where defective units
   can be reworked repeatedly at every stage. Production, as well as
   rework, is in lots requiring set-up and variable production costs, and
   orders need to be filled in their entirety. The yield of each stage is
   uncertain, so several production runs may need to be attempted until the
   quantity of finished products is sufficient. The trade-off at each stage
   is between using small lots, possibly necessitating repeated rework
   set-ups and large lots, which may result in costly overproduction.
   Multistage manufacturing facilities with rework capabilities are quite
   common in practice, but their optimal operation when orders have to be
   met in full has been virtually unexplored. We, show that a multistage
   system where only one of the stages requires a setup (a
   "single-bottleneck system") can be reduced to a single-stage system.
   Moreover, if it is possible to arrange the operations in any order, we
   prove that it is best to make the "bottleneck" the first stage of the
   system. We also develop recursive algorithms for solving two- and
   three-stage systems, where all stages require set-ups, optimally,
   Generalizations to systems where rework yields and costs differ from
   those of initial processing are also discussed.
TC 40
Z8 0
ZS 0
ZR 0
ZB 2
ZA 0
Z9 40
SN 0025-1909
UT WOS:000175935400005
ER

PT J
AU Gotoh, J
   Konno, H
TI Bounding option prices by semidefinite programming: A cutting plane
   algorithm
SO MANAGEMENT SCIENCE
VL 48
IS 5
BP 665
EP 678
DI 10.1287/mnsc.48.5.665.7801
PD MAY 2002
PY 2002
AB In a recent article, Bertsimas and Popescu showed that a tight upper
   bound on a European-type call option price, given the first n moments of
   the distribution of the underlying security price, can be obtained by
   solving an associated semidefinite programming problem (SDP). The
   purpose of this paper is to improve and extend their results. We will
   show that a tight lower bound can be calculated by solving another SDP.
   Also, we will show that these problems can be solved very quickly by a
   newly developed cutting plane algorithm when n is less than six or
   seven.
RI Gotoh, Jun-ya/D-4290-2011; Gotoh, Jun-ya/
OI Gotoh, Jun-ya/0000-0002-0097-7298
ZB 0
Z8 0
ZR 0
TC 11
ZA 0
ZS 0
Z9 11
SN 0025-1909
UT WOS:000175935400006
ER

PT J
AU Benjaafar, S
TI Modeling and analysis of congestion in the design of facility layouts
SO MANAGEMENT SCIENCE
VL 48
IS 5
BP 679
EP 704
DI 10.1287/mnsc.48.5.679.7800
PD MAY 2002
PY 2002
AB Reducing manufacturing lead times and minimizing work-in-process (WIP)
   inventories are the cornerstones of popular manufacturing strategies
   such as Lean, Quick Response, and Just-in-Time Manufacturing. In this
   paper, we present a model that captures the relationship between
   facility layout and congestion-related measures of performance. We use
   the model to introduce a formulation of the facility layout design
   problem where the objective is to minimize work-in-process (WIP). In
   contrast to some recent research, we show that layouts obtained using a
   WIP-based formulation can be very different from those obtained using
   the conventional quadratic assignment problem (QAP) formulation. For
   example, we show that a QAP-optimal layout can be WIP-infeasible.
   Similarly, we show that two QAP-optimal layouts can have vastly
   different WIP values. In general, we show that WIP is not monotonic in
   material-handling travel distances. This leads to a number of surprising
   results. For instance, we show that it is possible to reduce overall
   distances between departments but increase WIP. Furthermore, we find
   that the relative desirability of a layout can be affected by changes in
   material-handling capacity even when travel distances remain the same.
   We examine the effect of various system parameters on the difference in
   WIP between QAP- and WIP-optimal layouts. We find that although there
   are conditions under which the difference in WIP is significant, there
   are those under which both layouts are WIP-equivalent.
ZS 1
ZB 0
ZA 0
Z8 0
ZR 0
TC 62
Z9 62
SN 0025-1909
UT WOS:000175935400007
ER

PT J
AU Xue, M
   Harker, PT
TI Note: Ranking DMUs with infeasible super-efficiency DEA models
SO MANAGEMENT SCIENCE
VL 48
IS 5
BP 705
EP 710
DI 10.1287/mnsc.48.5.705.7805
PD MAY 2002
PY 2002
AB It has been suggested in the data envelopment analysis (DEA) literature
   that it is impossible to obtain a full ranking of decision-making units
   (DMUs) when infeasible subproblems arise in the so-called
   super-efficiency IDEA models under different returns to scale (RTS)
   assumptions other than constant returns to scale (CRS) and consequently
   the application of the super-efficiency DEA models under different RTS
   conditions other than CRS should be restricted. The implications of the
   infeasibility in super-efficiency IDEA models with respect to the
   efficiency ranking of the DMUs is explored. Based on the analysis, we
   show that it is still possible to obtain the full ranking of the entire
   observation set when infeasibilities arise in super-efficiency IDEA
   models.
RI Harker, Patrick T/A-9467-2013
OI Harker, Patrick T/0000-0003-0659-3102
TC 58
ZA 0
Z8 4
ZR 0
ZS 0
ZB 1
Z9 62
SN 0025-1909
UT WOS:000175935400008
ER

PT J
AU Smith, K
   Dickhaut, J
   McCabe, K
   Pardo, JV
TI Neuronal substrates for choice under ambiguity, risk, gains, and losses
SO MANAGEMENT SCIENCE
VL 48
IS 6
BP 711
EP 718
DI 10.1287/mnsc.48.6.711.194
PD JUN 2002
PY 2002
AB Economic forces shape the behavior of individuals and institutions.
   Forces affecting individual behavior are attitudes about payoffs (gains
   and losses) and beliefs about outcomes (risk and ambiguity). Under risk,
   the likelihoods of alternative outcomes are fully known. Under
   ambiguity, these likelihoods are unknown. In our experiment, payoffs and
   outcomes were manipulated independently during a classical choice task
   as brain activity was measured with positron emission tomography (PET).
   Here, we show that attitudes about payoffs and beliefs about the
   likelihood of outcomes exhibit interaction effects both behaviorally and
   neurally. Participants are risk averse in gains and risk-seeking in
   losses; they are ambiguity-seeking in neither gains nor losses. Two
   neural substrates for choice surfaced in the interaction between
   attitudes and beliefs: a dorsomedial neocortical system and a
   ventromedial system. This finding reveals that the brain does not honor
   a prevalent assumption of economics-the independence of the evaluations
   of payoffs and outcomes. The demonstration of a relationship between
   brain activity and observed economic choice attests to the feasibility
   of a neuroeconomic decision science.
OI McCabe, Kevin/0000-0003-0544-157X
TC 87
ZS 0
Z8 3
ZA 3
ZR 0
ZB 24
Z9 93
SN 0025-1909
UT WOS:000176630700001
ER

PT J
AU Lee, H
   Whang, S
TI The impact of the secondary market on the supply chain
SO MANAGEMENT SCIENCE
VL 48
IS 6
BP 719
EP 731
DI 10.1287/mnsc.48.6.719.189
PD JUN 2002
PY 2002
AB This paper investigates the impacts of a secondary market where
   resellers can buy and sell excess inventories. We develop a two-period
   model with a single manufacturer and many resellers. At the beginning of
   the first period resellers order and receive products from the
   manufacturer, but at the beginning of the second period, they can trade
   inventories among themselves in the secondary market. We endogenously
   derive the optimal decisions for the resellers, along with the
   equilibrium market price of the secondary market. The secondary market
   creates two interdependent effects-a quantity effect (sales by the
   manufacturer) and an allocation effect (supply chain performance). The
   former is indeterminate; i.e., the total sales volume for the
   manufacturer may increase or decrease, depending on the critical
   fractile, The latter is always positive; i.e., the secondary market
   always improves allocative efficiency. The sum of the effects is also
   unclear-the welfare of the supply chain may or may not increase as a
   result of the secondary market. Lastly, we study potential strategies
   for the manufacturer to increase sales in the presence of the secondary
   market.
TC 107
ZB 0
ZA 0
Z8 25
ZR 0
ZS 0
Z9 132
SN 0025-1909
UT WOS:000176630700002
ER

PT J
AU Hitt, LM
   Frei, FX
TI Do better customers utilize electronic distribution channels? The case
   of PC banking
SO MANAGEMENT SCIENCE
VL 48
IS 6
BP 732
EP 748
DI 10.1287/mnsc.48.6.732.188
PD JUN 2002
PY 2002
AB Many service firms are pursuing electronic distribution strategies to
   augment existing physical infrastructure for product and service
   delivery. But little systematic study has been made for whether and how
   characteristics or behaviors might differ between customers who use
   electronic delivery systems and those who use traditional channels. We
   explore these differences by comparing customers who utilize
   personal-computer-based home banking (PC banking) to other bank
   customers. Case studies and detailed customer data from four
   institutions suggest that PC banking customers are apparently more
   profitable, principally due to unobservable characteristics extant
   before the adoption of PC banking. Demographic characteristics and
   changes in customer behavior following adoption of PC banking account
   for only a small fraction of overall differences. It also appears that
   retention is marginally higher for customers of the online channel.
TC 105
ZA 0
ZR 0
Z8 0
ZB 0
ZS 1
Z9 106
SN 0025-1909
UT WOS:000176630700003
ER

PT J
AU Garfinkel, R
   Gopal, R
   Goes, P
TI Privacy protection of binary confidential data against deterministic,
   stochastic, and insider threat
SO MANAGEMENT SCIENCE
VL 48
IS 6
BP 749
EP 764
DI 10.1287/mnsc.48.6.749.193
PD JUN 2002
PY 2002
AB A practical model and an associated method are developed for providing
   consistent, deterministically correct responses to ad-hoc queries to a
   database containing a field of binary confidential data. COUNT queries,
   i.e., the number of selected subjects whose confidential datum is
   positive, are to be answered. Exact answers may allow users to determine
   an individual's confidential information. Instead, the proposed
   technique gives responses in the form of a number plus a guarantee so
   that the user can determine an interval that is sure to contain the
   exact answer. At the same time, the method is also able to provide both
   deterministic and stochastic protection of the confidential data to the
   subjects of the database. Insider threat is defined precisely and a
   simple option for defense against it is given. Computational results on
   a simulated database are very encouraging in that most queries are
   answered with tight intervals, and that the quality of the responses
   improves with the number of subjects identified by the query. Thus the
   results are very appropriate for the very large databases prevalent in
   business and governmental organizations. The technique is very efficient
   in terms of both time and storage requirements, and is readily scalable
   and implementable.
RI Gopal, Ram/M-9077-2019
OI Gopal, Ram/0000-0003-4241-9355
ZS 0
TC 30
ZB 0
ZR 0
ZA 0
Z8 0
Z9 30
SN 0025-1909
UT WOS:000176630700004
ER

PT J
AU Pieters, R
   Warlop, L
   Wedel, M
TI Breaking through the clutter: Benefits of advertisement originality and
   familiarity for brand attention and memory
SO MANAGEMENT SCIENCE
VL 48
IS 6
BP 765
EP 781
DI 10.1287/mnsc.48.6.765.192
PD JUN 2002
PY 2002
AB Rising levels of advertising competition have made it increasingly
   difficult to attract and hold consumers' attention and to establish
   strong memory traces for the advertised brand. A common communication
   strategy to break through this competitive clutter is to increase ad
   originality However, ad originality may have detrimental effects when
   consumers pay more attention to the ad at the expense of the advertised
   brand. Moreover, the positive effects of originality may quickly wane
   when the ad becomes familiar. Surprisingly, no research to date has
   examined such brand attention and memory effects of ad originality and
   familiarity The current study aims to fill this void. We use a
   stochastic model of the influence that ad originality and familiarity
   have on consumers' eye fixations to the key elements of
   advertisements-brand, text, and pictorial-and how the information
   extracted during eye fixations promotes memory for the advertised brand.
   The model explicitly accounts for heterogeneity due to consumers and
   advertisements. Infrared eye tracking was applied to collect eye
   fixation data from 119 consumers who paged through two general-audience
   magazines containing 58 full-page advertisements. Memory for the
   advertised brands was assessed with an indirect memory task. The model
   was estimated using Markov Chain Monte Carlo (MCMC) methods. In support
   of our hypotheses, original advertisements drew more attention to the
   advertised brand. More importantly however, advertisements that were
   both original and familiar attracted the largest amount of attention to
   the advertised brand, which improved subsequent brand memory. In
   addition, original and familiar ads were found to promote brand memory
   directly. Implications of these findings for communication and media
   planning strategy are discussed.
Z8 12
ZS 1
ZA 1
TC 179
ZB 6
ZR 0
Z9 192
SN 0025-1909
EI 1526-5501
UT WOS:000176630700005
ER

PT J
AU Barker, VL
   Mueller, GC
TI CEO characteristics and firm R&D spending
SO MANAGEMENT SCIENCE
VL 48
IS 6
BP 782
EP 801
DI 10.1287/mnsc.48.6.782.187
PD JUN 2002
PY 2002
AB Over the past fifteen years, a number of studies have examined the
   determinants of firm R&D spending. These studies, however, almost
   invariably focus on the role of firm or external ownership
   characteristics in predicting R&D spending while overlooking the
   attributes of the top managers involved in allocating corporate
   resources. In this study, we change that focus by empirically examining
   how R&D spending as compared to industry competitors varies at firms
   based on the characteristics of their CEOs. Using a sample of publicly
   traded firms, we find that CEO characteristics explain a significant
   proportion of the sample variance in firm R&D spending even when
   corporate strategy, ownership structure, and other firm-level attributes
   are controlled. In terms of individual CEO characteristics, we find that
   R&D spending is greater at firms where CEOs are younger, have greater
   wealth invested in firm stock and significant career experience in
   marketing and/or engineering/R&D. In contrast to existing theory we find
   that the amount of a CEO's formal education had no significant
   association with R&D spending once a CEO has attained a college degree.
   However, significant R&D spending increases are found at firms where
   CEOs have advanced science-related degrees. From subgroup analyses, we
   further find that CEO effects on relative R&D spending increase with
   longer CEO tenure implying that CEOs, over time, may mold R&D spending
   to suit their own preferences. From these results, we make implications
   for both research on determinants of R&D spending and managerial
   practice.
CT 60th Annual Meeting of the Academy-of-Management
CY AUG   07, 2000
CL TORONTO, CANADA
SP Acad Management
TC 444
ZA 0
ZS 5
Z8 9
ZR 0
ZB 1
Z9 458
SN 0025-1909
UT WOS:000176630700006
ER

PT J
AU Bleichrodt, H
   Schmidt, U
TI A context-dependent model of the gambling effect
SO MANAGEMENT SCIENCE
VL 48
IS 6
BP 802
EP 812
DI 10.1287/mnsc.48.6.802.190
PD JUN 2002
PY 2002
AB This paper presents a context-dependent theory of decision under risk.
   The relevant contextual factor is the presence of a riskless lottery in
   a preference comparison. The theory only deviates from expected utility
   if the set of options contains both riskless and risky lotteries, The
   main motivation for the theory is to explain the gambling effect.
   Contrary to previous theories of the gambling effect, the present theory
   is consistent with stochastic dominance. It can, however, violate
   transitivity. The theory allows for a decomposition of the interaction
   between risk aversion and gambling aversion and thereby extends the
   classical Arrow-Pratt measure of risk aversion.
ZS 0
ZB 0
TC 15
Z8 1
ZA 0
ZR 0
Z9 16
SN 0025-1909
UT WOS:000176630700007
ER

PT J
AU Christ, D
   Avi-Itzhak, B
TI Strategic equilibrium for a pair of competing servers with convex cost
   and balking
SO MANAGEMENT SCIENCE
VL 48
IS 6
BP 813
EP 820
DI 10.1287/mnsc.48.6.813.191
PD JUN 2002
PY 2002
AB A two-person game is formulated for a queuing situation involving a pair
   of exponential servers competing for arriving customers. The servers
   have identical characteristics except for their service rates. Each
   server is free to select its own service rate. The objective of each
   server is to select a service rate that will maximize its own profit.
   Arrivals are Poisson. The probability that an arriving customer enters
   the queue is allowed to depend on the queue length at the time of
   arrival. The proportion of arrivals to a given server is shown to be
   strictly concave in the server's own service rate and decreasing in the
   other service rate. Furthermore, we show that when the cost function is
   convex and increasing, there exists a unique pure strategy Nash
   equilibrium point for the resulting game.
ZB 0
Z8 1
ZS 0
ZR 0
TC 9
Z9 10
SN 0025-1909
UT WOS:000176630700008
ER

PT J
AU von Hippel, E
   Katz, R
TI Shifting innovation to users via toolkits
SO MANAGEMENT SCIENCE
VL 48
IS 7
BP 821
EP 833
DI 10.1287/mnsc.48.7.821.2817
PD JUL 2002
PY 2002
AB In the traditional new product development process, manufacturers first
   explore user needs and then develop responsive products. Developing an
   accurate understanding of a user need is not simple or fast or cheap,
   however. As a result, the traditional approach is coming under
   increasing strain as user needs change more rapidly, and as firms
   increasingly seek, to serve "markets of one."
   Toolkits for user's innovation is an emerging alternative approach in
   which manufacturers actually abandon the attempt to understand user
   needs in detail in favor of transferring, need-related aspects of
   product and service development to users. Experience in fields where.
   the toolkit approach has been pioneered show custom products being
   developed much more quickly and at a lower cost. In this paper we
   explore toolkits for user innovation and explain why and how they work.
RI Gofman, Alex/A-3095-2010
ZR 1
ZA 1
TC 484
Z8 3
ZB 5
ZS 5
Z9 492
SN 0025-1909
UT WOS:000177388800001
ER

PT J
AU McGahan, AM
   Porter, ME
TI What do we know about variance in accounting profitability?
SO MANAGEMENT SCIENCE
VL 48
IS 7
BP 834
EP 851
DI 10.1287/mnsc.48.7.834.2816
PD JUL 2002
PY 2002
AB In this paper, we analyze the variance of accounting profitability among
   a broad cross-section of firms in the American economy from 1981 to
   1994. The purpose of the analysis is to identify the importance of year,
   industry, corporate-parent, and business-specific effects on accounting
   profitability among operating businesses across sectors. The findings
   indicate that industry and corporate-parent effects are important and
   related to one another. As expected, business-specific effects, which
   arise from competitive positioning and other factors, have a large
   influence on performance. The analysis reconciles the results of
   previous studies by exploring differences in method and data. We also
   identify the broad contributions and limitations of the research, and
   suggest avenues for further study. New approaches are necessary to
   generate significant insights about the relationships between industry,
   corporate-parent, and business influences on firm profitability.
ZS 13
ZA 0
Z8 1
ZR 0
TC 179
ZB 1
Z9 192
SN 0025-1909
UT WOS:000177388800002
ER

PT J
AU Harris, M
   Raviv, A
TI Organization design
SO MANAGEMENT SCIENCE
VL 48
IS 7
BP 852
EP 865
DI 10.1287/mnsc.48.7.852.2821
PD JUL 2002
PY 2002
AB This paper attempts to explain organization structure based on optimal
   coordination of interactions among activities. The main idea is that
   each manager is capable of detecting and coordinating interactions only
   within his limited area of expertise. Only the CEO can coordinate
   companywide interactions. The optimal design of the organization trades
   off the costs and benefits of various configurations of managers. Our
   results consist of classifying the characteristics of activities and
   managerial costs that lead to the matrix organization, the functional
   hierarchy, the divisional hierarchy, or a flat hierarchy. We also
   investigate the effect of changing the costs of various managers on the
   nature of the optimal organization, including the extent of
   centralization.
ZB 0
Z8 4
TC 77
ZR 0
ZA 0
ZS 2
Z9 82
SN 0025-1909
UT WOS:000177388800003
ER

PT J
AU David, JS
   Hwang, YC
   Pei, BKW
   Reneau, JH
TI The performance effects of congruence between product competitive
   strategies and purchasing management design
SO MANAGEMENT SCIENCE
VL 48
IS 7
BP 866
EP 885
DI 10.1287/mnsc.48.7.866.2819
PD JUL 2002
PY 2002
AB The objective of this study is to examine a performance contingency
   effect between product competitive strategy and organization design
   using an archival approach. Specifically, this study examines a sample
   of 194 firms from 20 industries based on the data collected by Center
   for Advanced Purchasing Studies (CAPS) in its benchmarking surveys
   between 1989-1994 and links the benchmarking data to the COMPUSTAT
   (Standard & Poor's) financial data of these firms. The results of the
   study reveal a contingency relationship among product competitive
   strategies, purchasing design characteristics, and overall firm
   financial performance (return on assets). Specifically, the nature of
   this contingency relationship suggests that a firm's product competitive
   strategy must be enabled with a complementary design in purchasing
   management to promote firm performance. Given the growing practice of
   benchmarking at the functional level, this study also examines whether
   or not a firm achieving a congruency in product strategy and design will
   necessarily enjoy higher operational efficiency at the purchasing
   management level. The results show that this is true only under specific
   conditions. The implications of the preceding findings are discussed
   accordingly.
OI David, Julie Smith/0000-0003-4607-4921
TC 64
Z8 7
ZB 1
ZR 0
ZA 0
ZS 1
Z9 72
SN 0025-1909
UT WOS:000177388800004
ER

PT J
AU Arya, A
   Glover, J
   Routledge, BR
TI Project assignment rights and incentives for eliciting ideas
SO MANAGEMENT SCIENCE
VL 48
IS 7
BP 886
EP 899
DI 10.1287/mnsc.48.7.886.2822
PD JUL 2002
PY 2002
AB In this paper, we study an incentive problem that arises between a
   principal and two agents because they value a real option differently.
   The real option in our model is a timing option. The agents have limited
   capacity to undertake projects, and each agent's capacity can be filled
   now or later. Because the principal cares about capacity in the
   aggregate but each agent cares only about his own capacity, the agents
   assign a higher value to the option to wait. As a result, agents
   sometimes withhold ideas from the principal. We show that
   decentralization can be a solution to this problem. Delegating
   assignment rights to an agent reduces the option value of waiting for
   the other agent sufficiently that he is willing to reveal his ideas.
ZA 0
ZR 0
ZS 0
ZB 0
TC 5
Z8 0
Z9 5
SN 0025-1909
UT WOS:000177388800005
ER

PT J
AU Siggelkow, N
TI Misperceiving interactions among complements and substitutes:
   Organizational consequences
SO MANAGEMENT SCIENCE
VL 48
IS 7
BP 900
EP 916
DI 10.1287/mnsc.48.7.900.2820
PD JUL 2002
PY 2002
AB Systems composed of activity choices that interact in nonsimple ways can
   allow firms to create and sustain a competitive advantage. However, in
   complex systems, decision makers may not always have a precise
   understanding of the exact strength of the interaction between
   activities. Likewise, incentive and accounting systems may lead decision
   makers to ignore or misperceive interactions. This paper studies
   formally the consequences of misperceiving interaction effects between
   activity choices. Our results suggest that misperceptions with respect
   to complements are more costly than with respect to substitutes. As a
   result, firms should optimally invest more to gather information about
   interactions among complementary activities-e.g., concerning network
   effects-than about interactions among substitute activities. Similarly,
   the use of division-based incentive schemes appears to be more advisable
   for divisions whose products are substitutes than for divisions that
   produce complements. It is further shown that system fragility is not
   necessarily positively correlated with the strength of the interaction
   between choices. While systems of complements become increasingly
   fragile as the strength of interaction increases, systems of substitutes
   can become increasingly stable.
TC 117
ZB 1
ZR 0
ZA 0
Z8 0
ZS 0
Z9 117
SN 0025-1909
UT WOS:000177388800006
ER

PT J
AU Detemple, J
   Tian, WD
TI The valuation of American options for a class of diffusion processes
SO MANAGEMENT SCIENCE
VL 48
IS 7
BP 917
EP 937
DI 10.1287/mnsc.48.7.917.2815
PD JUL 2002
PY 2002
AB W e present an integral equation approach for the valuation of
   American-style derivatives when the underlying asset price follows a
   general diffusion process and the interest rate is stochastic. Our
   contribution is fourfold. First, we show that the exercise region is
   determined by a single exercise boundary under very general conditions
   on the interest rate and the dividend yield. Second, based on this
   result, We derive a recursive integral equation for the exercise
   boundary and provide a parametric representation of the American option
   price: Third, we apply the results to models with stochastic volatility
   or stochastk interest rate, and to American bond options in one-factor
   models: For the cases studied, explicit parametric valuation formulas
   are obtained. Finally, we extend esults on American capped options to
   general diffusion prices. Numerical schemes based on approximations of
   the optimal stopping time (such as approximations based on a lower
   bound, or on a combination of lower and upper bounds) are shown to be
   valid in this context.
RI Detemple, Jerome B/E-5013-2013
OI Detemple, Jerome B/0000-0003-1173-6374
ZS 2
TC 38
ZA 0
Z8 5
ZR 0
ZB 0
Z9 44
SN 0025-1909
EI 1526-5501
UT WOS:000177388800007
ER

PT J
AU Gerwin, D
   Barrowman, NJ
TI An evaluation of research on Integrated Product Development
SO MANAGEMENT SCIENCE
VL 48
IS 7
BP 938
EP 953
DI 10.1287/mnsc.48.7.938.2818
PD JUL 2002
PY 2002
AB Integrated Product Development (IPD) creates overlap and interaction
   between activities in the new product development process and, because
   this increases the need to coordinate, compensates through other aspects
   of the new product development process (e.g., integrated tools), product
   definitions (e.g., incremental development), organizational context
   (e.g., reduced task specialization), and teaming (e.g., cross-functional
   teams). Since IPD has become an important new standard for managing new
   product development, this paper's general aim is to evaluate the
   research that has been conducted on it. Our three specific objectives
   include first critiquing the IPD literature by identifying problems with
   empirical research and recommending solutions. There are concerns about
   the overall approach, conceptualizing and operationalizing IPD
   characteristics, and selecting performance objectives. Second, we
   conduct a meta-analysis to evaluate relationships between specific IPD
   characteristics and project performance. We indicate where relationships
   do or do not exist and identify variables that may moderate these
   relationships. Third, we offer suggestions for extending IPD research
   into studies of (a) the hierarchy of teams working on a project, (b) one
   company managing a portfolio of projects over time, and (c) two or more
   firms collaborating in a strategic alliance.
ZS 2
ZA 0
Z8 4
ZR 0
TC 187
ZB 2
Z9 193
SN 0025-1909
UT WOS:000177388800008
ER

PT J
AU Anderson, ET
TI Sharing the wealth: When should firms treat customers as partners?
SO MANAGEMENT SCIENCE
VL 48
IS 8
BP 955
EP 971
DI 10.1287/mnsc.48.8.955.170
PD AUG 2002
PY 2002
AB Marketers often stress the importance of treating customers as partners.
   A fundamental premise of this perspective is that all parties can be
   weakly better off if they work together to increase joint surplus and
   reach Pareto-efficient agreements. For marketing managers, this implies
   organizing marketing activities in a manner that maximizes total
   surplus. This logic is theoretically sound when agreements between
   partners are limitless and costless. In most consumer marketing contexts
   (business-to-consumer), this is typically not true. The question I ask
   is should one still expect firms to partner with consumers and reach
   Pareto-efficient agreements? In this paper, I use the example of a
   firm's choice of product configuration to demonstrate two effects.
   First, I show that a firm may configure a product in a manner that
   reduces total surplus but increases firm profits. Second, one might
   conjecture that increased competition would eliminate this effect, but I
   show that in a duopoly firm profits may be increasing in the cost of
   product completion. This second result suggests that firms may prefer to
   remain inefficient and/or stifle innovations. Both results violate a
   fundamental premise of partnering-that firms and consumers should work
   together to increase total surplus and reach Pareto-efficient
   agreements. The model illustrates that Pareto-efficient agreements are
   less likely to occur if negotiation with individual partners is
   infeasible or costly, such as in business-to-consumer contexts. Consumer
   marketers in one-to-many marketing environments should be wary of
   treating customers as partners because Pareto-efficient agreements may
   not be optimal for their firm.
ZA 0
Z8 0
ZR 1
TC 18
ZB 0
ZS 0
Z9 19
SN 0025-1909
UT WOS:000177887400001
ER

PT J
AU Amaldoss, W
   Jain, S
TI David vs. Goliath: An analysis of asymmetric mixed-strategy games and
   experimental evidence
SO MANAGEMENT SCIENCE
VL 48
IS 8
BP 972
EP 991
DI 10.1287/mnsc.48.8.972.165
PD AUG 2002
PY 2002
AB Mixed strategies are widely used to model strategic situations in
   diverse fields such as economics, marketing, political science, and
   biology. However, some of the implications of asymmetric mixed-strategy
   solutions are counterintuitive. We develop a stylized model of patent
   race to examine some of these implications. In our model two firms
   compete to develop a product and obtain a patent. However, one firm
   values the patent more because of its market advantages, such as brand
   reputation and distribution network. Contrary to some intuition, we find
   that the firm that values the patent less is likely to invest more
   aggressively in developing the product and will also win the patent more
   often. We argue that the reason for these counterintuitive results is
   inherent in the very concept of mixed strategy solution. In a laboratory
   test, we examine whether subjects' behavior conforms to the equilibrium
   predictions. We find that the aggregate behavior of our subjects is
   consistent with the game-theoretic predictions. With the help of the
   experience-weighted attraction (EWA) learning model proposed by Camerer
   and Ho (1999), we show that adaptive learning can account for the
   investment behavior of our subjects. We find that the EWA learning model
   tracks the investment decisions of our subjects well, whether we hold
   out trials or an entire group of subjects.
Z8 0
TC 24
ZS 0
ZB 0
ZA 0
ZR 0
Z9 24
SN 0025-1909
UT WOS:000177887400002
ER

PT J
AU Taylor, TA
TI Supply chain coordination under channel rebates with sales effort
   effects
SO MANAGEMENT SCIENCE
VL 48
IS 8
BP 992
EP 1007
DI 10.1287/mnsc.48.8.992.168
PD AUG 2002
PY 2002
AB A channel rebate is a payment from a manufacturer to a retailer based on
   retailer sales to end consumers. Two common forms of channel rebates are
   linear rebates, in which the rebate is paid for each unit sold, and
   target rebates, in which the rebate is paid for each unit sold beyond a
   specified target level. When demand is not influenced by sales effort, a
   properly designed target rebate achieves channel coordination and a
   win-win outcome. Coordination cannot be achieved by a linear rebate in a
   way that is implementable. When demand is influenced by retailer sales
   effort, a properly designed target rebate and returns contract achieves
   coordination and a win-win outcome. Other contracts, such as linear
   rebate and returns or target rebate alone, cannot achieve coordination
   in a way that is implementable. Contrary to the view expressed in the
   literature that accepting returns weakens incentives for retailer sales
   effort, we find that the provision of returns strengthens incentives for
   effort.
RI Pavlov, Valery/F-9591-2019
OI Pavlov, Valery/0000-0001-8190-0526
TC 534
ZB 7
ZA 0
Z8 145
ZS 3
ZR 1
Z9 680
SN 0025-1909
UT WOS:000177887400003
ER

PT J
AU Pich, MT
   Loch, CH
   De Meyer, A
TI On uncertainty, ambiguity, and complexity in project management
SO MANAGEMENT SCIENCE
VL 48
IS 8
BP 1008
EP 1023
DI 10.1287/mnsc.48.8.1008.163
PD AUG 2002
PY 2002
AB This article develops a model of a project as a payoff function that
   depends on the state of the world and the choice of a sequence of
   actions. A causal mapping, which may be incompletely known by the
   project team, represents the impact of possible actions on the states of
   the world. An underlying probability space represents available
   information about the state of the world. Interactions among actions and
   states of the world determine the complexity of the payoff function.
   Activities are endogenous, in that they are the result of a policy that
   maximizes the expected project payoff.
   A key concept is the adequacy of the available information about states
   of the world and action effects. We express uncertainty, ambiguity and
   complexity in terms of information adequacy. We identify three
   fundamental project management strategies: instructionism, learning, and
   selectionism. We show that classic project management methods emphasize
   adequate information and instructionism, and demonstrate how modern
   methods fit into the three fundamental strategies. The appropriate
   strategy is contingent on the type of uncertainty present and the
   complexity of the project payoff function. Our model establishes a
   rigorous language that allows the project manager to judge the adequacy
   of the available project information at the outset, choose an
   appropriate combination of strategies, and set a supporting project
   infrastructure-that is, systems for planning, coordination and
   incentives, and monitoring.
RI DE MEYER, Arnoud/E-8653-2013; De Meyer, Arnoud/
OI De Meyer, Arnoud/0000-0001-8047-1002
ZR 0
Z8 9
ZB 6
TC 398
ZS 9
ZA 0
Z9 412
SN 0025-1909
EI 1526-5501
UT WOS:000177887400004
ER

PT J
AU Agarwal, R
   Bayus, BL
TI The market evolution and sales takeoff of product innovations
SO MANAGEMENT SCIENCE
VL 48
IS 8
BP 1024
EP 1041
DI 10.1287/mnsc.48.8.1024.167
PD AUG 2002
PY 2002
AB In contrast to the prevailing supply-side explanation that price
   decreases are the key driver of a sales takeoff, we argue that outward
   shifting supply and demand curves lead to market takeoff. Our
   fundamental idea is that sales in new markets are initially low because
   the first commercialized forms of new innovations are primitive. Then,
   as new firms enter, actual and perceived product quality improves (and
   prices possibly drop), which leads to a takeoff in sales. To provide
   empirical evidence for this explanation, we explore the relationship
   between takeoff times, price decreases, and firm entry for a sample of
   consumer and industrial product innovations commercialized in the United
   States over the past 150 years. Based on a proportional hazards analysis
   of takeoff times, we find that new firm entry dominates other factors in
   explaining observed sales takeoff times. We interpret these results as
   supporting the idea that demand shifts during the early evolution of a
   new market due to nonprice factors is the key driver of a sales takeoff.
ZR 0
ZB 1
ZS 0
Z8 1
ZA 0
TC 182
Z9 182
SN 0025-1909
UT WOS:000177887400005
ER

PT J
AU Lilien, GL
   Morrison, PD
   Searls, K
   Sonnack, M
   von Hippel, E
TI Performance assessment of the lead user idea-generation process for new
   product development
SO MANAGEMENT SCIENCE
VL 48
IS 8
BP 1042
EP 1059
DI 10.1287/mnsc.48.8.1042.171
PD AUG 2002
PY 2002
AB Traditional idea generation techniques based on customer input usually
   collect information on new product needs from a random or typical set of
   customers. The "lead user process" takes a different approach. It
   collects information about both needs and solutions from users at the
   leading edges of the target market, as well as from users in other
   markets that face similar problems in a more extreme form. This paper
   reports on a natural experiment conducted within the 3M Company on the
   effect of the lead user (LU) idea-gene ration process relative to more
   traditional methods. 3M is known for its innovation capabilities-and we
   find that the LU process appears to improve upon those capabilities.
   Annual sales of LU product ideas generated by the average LU project at
   3M are conservatively projected to be $146 million after five years-more
   than eight times higher than forecast sales for the average
   contemporaneously conducted "traditional" project. Each funded LU
   project is projected to create a new major product line for a 3M
   division. As a direct result, divisions funding LU project ideas are
   projecting their highest rate of major product line generation in the
   past 50 years.
ZA 0
TC 411
ZB 3
ZR 0
Z8 12
ZS 5
Z9 428
SN 0025-1909
UT WOS:000177887400006
ER

PT J
AU Solow, D
   Vairaktarakis, G
   Piderit, SK
   Tsai, MC
TI Managerial insights into the effects of interactions on replacing
   members of a team
SO MANAGEMENT SCIENCE
VL 48
IS 8
BP 1060
EP 1073
DI 10.1287/mnsc.48.8.1060.164
PD AUG 2002
PY 2002
AB A mathematical model is presented for studying the effects of
   interactions among team members on the process of replacing members of a
   team in an organization. The model provides the ability to control the
   number of members that interact with each individual on the team.
   Through the use of analysis and computer simulations, it is shown how
   the amount of interaction affects the tradeoff between the expected
   performance and the number of replacements and interviews needed to find
   a good team using various replacement policies. New managerial insights
   into this process-such as the fact that it is not necessarily optimal to
   replace the worst-performing team member-are provided.
OI Tsai, Ming-Chi/0000-0002-0560-7819
Z8 2
ZS 0
ZB 1
ZA 0
ZR 0
TC 13
Z9 15
SN 0025-1909
EI 1526-5501
UT WOS:000177887400007
ER

PT J
AU Leshno, M
   Levy, H
TI Preferred by "all" and preferred by "most" decision makers: Almost
   stochastic dominance
SO MANAGEMENT SCIENCE
VL 48
IS 8
BP 1074
EP 1085
DI 10.1287/mnsc.48.8.1074.169
PD AUG 2002
PY 2002
AB While "most" decision makers may prefer one uncertain prospect over
   another, stochastic dominance rules as well as other investment
   criteria, will not reveal this preference due to some extreme utility
   functions in the case of even a very small violation of these rules.
   Such strict rules relate to "all" utility functions in a given class
   including extreme ones which presumably rarely represents investors'
   preference. In this paper we establish almost stochastic dominance (ASD)
   rules which formally reveal a preference for "most" decision makers, but
   not for "all" of them. The ASD rules reveal that choices which probably
   conform with "most" decision makers also solve some debates, e.g.,
   showing, as practitioners claim, an ASD preference for a higher
   proportion of stocks in the portfolio as the investment horizon
   increases, a conclusion which is not implied by the well-known
   stochastic dominance rules.
ZS 2
ZB 5
TC 133
ZR 0
Z8 2
ZA 0
Z9 135
SN 0025-1909
UT WOS:000177887400008
ER

PT J
AU Kou, SG
TI A jump-diffusion model for option pricing
SO MANAGEMENT SCIENCE
VL 48
IS 8
BP 1086
EP 1101
DI 10.1287/mnsc.48.8.1086.166
PD AUG 2002
PY 2002
AB Brownian motion and normal distribution have been widely used in the
   Black-Scholes option-pricing framework to model the return of assets.
   However, two puzzles emerge from many empirical investigations: the
   leptokurtic feature that the return distribution of assets may have a
   higher peak and two (asymmetric) heavier tails than those of the normal
   distribution, and an empirical phenomenon called "volatility smile" in
   option markets. To incorporate both of them and to strike a balance
   between reality and tractability, this paper proposes, for the purpose
   of option pricing, a double exponential jump-diffusion model. In
   particular, the model is simple enough to produce analytical solutions
   for a variety of option-pricing problems, including call and put
   options, interest rate derivatives, and path-dependent options.
   Equilibrium analysis and a psychological interpretation of the model are
   also presented.
Z8 67
TC 795
ZR 1
ZA 0
ZS 1
ZB 5
Z9 855
SN 0025-1909
EI 1526-5501
UT WOS:000177887400009
ER

PT J
AU Gatignon, H
   Tushman, ML
   Smith, W
   Anderson, P
TI A structural approach to assessing innovation: Construct development of
   innovation locus, type, and characteristics
SO MANAGEMENT SCIENCE
VL 48
IS 9
BP 1103
EP 1122
DI 10.1287/mnsc.48.9.1103.174
PD SEP 2002
PY 2002
AB We take a structural approach to assessing innovation. We develop a
   comprehensive set of measures to assess an innovation's locus, type, and
   characteristics. We find that the concepts of competence destroying and
   competence enhancing are composed of two distinct constructs that,
   although correlated, separately characterize an innovation: new
   competence acquisition and competence enhancement/destruction. We
   develop scales to measure these constructs and show that new competence
   acquisition and competence enhancing/destroying are different from other
   innovation characteristics including core/peripheral and
   incremental/radical, as well as architectural and generational
   innovation types. We show that innovations can be evaluated
   distinctively on these various dimensions with generally small
   correlations between them. We estimate the impact these different
   innovation characteristics and types have on time to introduction and
   perceived commercial success. Our results indicate the importance of
   taking a structural approach to describing innovations and to the
   differential importance of innovation locus, type, and characteristics
   on innovation outcomes. Our results also raise intriguing questions
   regarding the locus of competence acquisition (internal vs. external)
   and both innovation outcomes.
RI Anderson, Philip/B-4364-2010; Gatignon, Hubert A/B-1853-2010; Smith, Wendy K/H-9575-2013
TC 448
ZS 7
ZB 2
Z8 5
ZA 1
ZR 0
Z9 458
SN 0025-1909
EI 1526-5501
UT WOS:000178515300001
ER

PT J
AU Jain, S
   Kannan, PK
TI Pricing of information products on online servers: Issues, models, and
   analysis
SO MANAGEMENT SCIENCE
VL 48
IS 9
BP 1123
EP 1142
DI 10.1287/mnsc.48.9.1123.178
PD SEP 2002
PY 2002
AB Online information servers that provide access to diverse databases
   where users can search for, browse through, and download the information
   they need have been rapidly increasing in number in the past few years.
   Online vendors have traditionally charged users for information on the
   based on the length of the time they were connected to the databases.
   With hardware and software advances, many online servers have recently
   started changing their pricing strategies to search-based and/or
   subscription-fee pricing. This paper examines the various issues
   involved in pricing these information products, and presents an economic
   approach to analyze conditions under which the various pricing schemes
   may prove optimal for the online servers. Our results show that the
   variation in consumer expertise and valuation of information affects the
   choice of a pricing strategy by the server. We present general
   conditions under which subscription-fee pricing is optimal even when
   consumer demand is inelastic. We also find that, given the cost
   structures characterizing the market, undifferentiated online servers
   can compete and coexist in the market each making positive profits. We
   show that in a competitive setting an increase in costs of online
   servers can sometimes benefit them by enabling them to differentiate
   themselves. Our results offer insights into the trends in pricing
   strategies and may provide an explanation as to why many servers may
   persist with connect-time strategies.
RI Kannan, Pallassana K/D-8192-2011
TC 53
ZR 0
Z8 5
ZS 0
ZA 0
ZB 0
Z9 58
SN 0025-1909
UT WOS:000178515300002
ER

PT J
AU Shaffer, G
   Zhang, ZJ
TI Competitive one-to-one promotions
SO MANAGEMENT SCIENCE
VL 48
IS 9
BP 1143
EP 1160
DI 10.1287/mnsc.48.9.1143.172
PD SEP 2002
PY 2002
AB One-to-one promotions are possible when consumers are individually
   addressable and firms know something about each customer's preferences.
   We explore the competitive effects of one-to-one promotions in a model
   with two competing firms where the firms differ in size and consumers
   have heterogeneous brand loyalty. We find that one-to-one promotions
   always lead to an increase in price competition (average prices in the
   market decrease). However, we also find that one-to-one promotions
   affect market shares. This market-share effect may outweigh the effect
   of lower prices, benefiting the firm whose market share increases. Our
   results suggest that of two firms, the firm with the higher-quality
   product may gain from one-to-one promotions. Our model also has
   implications for the phenomenon of customer churn, where consumers
   switch to a less preferred brand due to targeted promotional incentives.
   We show that churning can arise optimally from firms pursuing a
   profit-maximizing strategy. Instead of trying to minimize it, the
   optimal way to manage customer churn is to engage in both offensive and
   defensive promotions with the relative mix depending on the marginal
   cost of targeting.
ZS 0
Z8 4
ZA 0
ZB 0
TC 132
ZR 0
Z9 136
SN 0025-1909
UT WOS:000178515300003
ER

PT J
AU Archibald, TW
   Thomas, LC
   Betts, JM
   Johnston, RB
TI Should start-up companies be cautious? Inventory policies which maximise
   survival probabilities
SO MANAGEMENT SCIENCE
VL 48
IS 9
BP 1161
EP 1174
DI 10.1287/mnsc.48.9.1161.176
PD SEP 2002
PY 2002
AB New start-up companies, which are considered to be a vital ingredient in
   a successful economy, have a different objective than established
   companies: They want to maximise their chance of long-term survival. We
   examine the implications for their operating decisions of this different
   criterion by considering an abstraction of the inventory problem faced
   by a start-up manufacturing company. The problem is modelled under two
   criteria as a Markov decision process; the characteristics of the
   optimal policies under the two criteria are compared. It is shown that
   although the start-up company should be more conservative in its
   component purchasing strategy than if it were a well-established
   company, it should not be too conservative. Nor is its strategy monotone
   in the amount of capital it has available. The models are extended to
   allow for interest on investment and inflation.
RI Thomas, Lyn/B-3326-2014; Betts, John/; Archibald, Thomas/
OI Thomas, Lyn/0000-0002-3727-4772; Betts, John/0000-0002-2715-104X;
   Archibald, Thomas/0000-0002-3132-7909
Z8 8
ZB 0
ZA 0
ZS 0
ZR 0
TC 58
Z9 66
SN 0025-1909
UT WOS:000178515300004
ER

PT J
AU Bohlmann, JD
   Golder, PN
   Mitra, D
TI Deconstructing the pioneer's advantage: Examining vintage effects and
   consumer valuations of quality and variety
SO MANAGEMENT SCIENCE
VL 48
IS 9
BP 1175
EP 1195
DI 10.1287/mnsc.48.9.1175.175
PD SEP 2002
PY 2002
AB Several studies have demonstrated an order-of-entry effect on market
   share, suggesting that pioneers outperform later entrants. However,
   other research has pointed out the limitations of these studies and
   found evidence that many pioneers fail or have low market share. Given
   this background, the purpose of this research is to understand the
   conditions under which pioneers are more likely and also less likely to
   have an advantage. We propose a game-theoretic model that includes
   important sources of pioneer advantages as well as disadvantages.
   Specifically, we incorporate a pioneer advantage due to preemption in
   markets with heterogeneous tastes. In addition, we incorporate a
   potential pioneer disadvantage due to technology vintage effects, where
   later entrants utilizing improved technology can have lower costs and
   higher quality. The model allows us to evaluate the extent of vintage
   effects necessary to overcome a pioneer's advantage. Key relationships
   are found between the magnitude of the pioneer advantage or disadvantage
   and consumer valuations of product attributes (e.g., variety and
   quality). We empirically validate the model with vintage effect data in
   36 product categories, and measures of consumer valuations of product
   variety and quality for 12 of these 36 categories. The results show that
   pioneers do better in product categories where variety is more important
   and worse in categories where product quality is more important.
   Pioneers in categories with high vintage effects are shown to have lower
   market shares and higher failure rates. Similar results appear when
   analyzing persistence of market leadership over time, further validating
   our model's major implications. We also present two case studies that
   illustrate key elements of the model.
OI Bohlmann, Jonathan/0000-0003-1534-7085
ZR 0
Z8 3
ZB 0
TC 86
ZS 0
ZA 0
Z9 89
SN 0025-1909
UT WOS:000178515300005
ER

PT J
AU Li, LD
TI Information sharing in a supply chain with horizontal competition
SO MANAGEMENT SCIENCE
VL 48
IS 9
BP 1196
EP 1212
DI 10.1287/mnsc.48.9.1196.177
PD SEP 2002
PY 2002
AB This paper examines the incentives for firms to share information
   vertically in a two-level supply chain in which there are an upstream
   firm (a manufacturer) and many downstream firms (retailers). The
   retailers are engaged in a Cournot competition and are endowed with some
   private information. Vertical information sharing has two effects:
   "direct effect" due to the changes in strategy by the parties involved
   in sharing the information and "indirect effect" (or "leakage effect")
   due to the changes in strategy by other competing firms (who may infer
   the information from the actions of the informed parties). Both changes
   would affect the profitability of the firms. We show that the leakage
   effect discourages the retailers from sharing their demand information
   with the manufacturer while encouraging them to share their cost
   information. On the other hand, the direct effect always discourages the
   retailers from sharing their information. When voluntary information
   sharing is not possible, we identify conditions under which information
   can be traded and show how price should be determined to facilitate such
   information exchange. We also examine the impact of vertical information
   sharing on the total supply chain profits and social benefits.
RI Weller, Matt J/E-8421-2010
Z8 68
TC 315
ZA 0
ZB 4
ZS 0
ZR 0
Z9 381
SN 0025-1909
EI 1526-5501
UT WOS:000178515300006
ER

PT J
AU Thonemann, UW
   Brown, AO
   Hausman, WH
TI Easy quantification of improved spare parts inventory policies
SO MANAGEMENT SCIENCE
VL 48
IS 9
BP 1213
EP 1225
DI 10.1287/mnsc.48.9.1213.173
PD SEP 2002
PY 2002
AB This paper presents approximate analytical models to quantify the
   expected improvement in inventory investment when using a system
   approach to control inventory as opposed to a simpler item approach. A
   system approach ensures that a demand-weighted average fill rate is
   achieved at low inventory investment by assigning low fill rates to
   parts with high costs and high fill rates to parts with low costs. An
   item approach does not vary fill rates by parts but assigns identical
   fill rates to all parts. Using single-parameter functional
   representations of the skewness of unit costs and average demand across
   all parts in the system, simple approximate analytical expressions for
   the required inventory investment are derived for both approaches. The
   accuracy of the approximations is validated using data from a
   distribution center for computer spare parts. For these data, the
   solutions obtained by the approximations are very close to the exact
   values. The results show that inventory investments can be well
   approximated as a function of only a few cost and demand parameters.
   These expressions can be used to determine the percentage reduction in
   inventory investment for a particular target demand-weighted average
   fill rate when the superior system approach is used instead of the item
   approach. For increased ease of use, the percentage reduction in
   inventory when using a system as opposed to an item approach is computed
   over a range of realistic values for the key parameters of the model and
   a quadratic expression is fitted to the data. This fitted expression
   provides rough guidelines for the anticipated improvement with very
   limited data needed, prior to detailed modeling or implementation.
RI Thonemann, Ulrich W/C-4344-2008
OI Thonemann, Ulrich W/0000-0002-3507-9498
Z8 0
ZB 0
ZS 0
ZA 0
TC 31
ZR 0
Z9 31
SN 0025-1909
UT WOS:000178515300007
ER

PT J
AU Loch, CH
   Kavadias, S
TI Dynamic portfolio selection of NPD programs using marginal returns
SO MANAGEMENT SCIENCE
VL 48
IS 10
BP 1227
EP 1241
DI 10.1287/mnsc.48.10.1227.275
PD OCT 2002
PY 2002
AB Selecting. program portfolios within a budget constraint is, an
   important challenge in the management of, new product development (NPD).
   Optimal portfolios are difficult to define because of the combinatorial.
   complexity of project combinations. However, at the aggregate level of
   the strategic allocation of resources across product lines, investment
   in, a program is not an all-or-nothing decision, but can be adjusted,.
   resulting in a higher or lower program benefit (e.g., higher or lower
   quality). In some cases, resources can be adjusted even for individual
   projects.
   With this insight, one can use marginal analysis to optimally allocate
   the scarce budget. This article develops a dynamic model of resource
   allocation, taking into account multiple interacting factors, such as
   independent or correlated, uncertain market payoffs that change over,
   time, increasing or decreasing returns from the NPD investment,
   carry-over of the investment benefit over multiple periods, and
   interactions across market segments.. We characterize optimal policies
   in closed form and derive qualitative decision rules for managers.
ZR 0
ZS 2
Z8 6
TC 122
ZA 0
ZB 1
Z9 127
SN 0025-1909
UT WOS:000179232800001
ER

PT J
AU Chintagunta, PK
   Bonfrer, A
   Song, I
TI Investigating them effects of store-brand introduction on retailer
   demand and pricing behavior
SO MANAGEMENT SCIENCE
VL 48
IS 10
BP 1242
EP 1267
DI 10.1287/mnsc.48.10.1242.274
PD OCT 2002
PY 2002
AB Researchers have recently been interested in studying the drivers of
   store-brand success as well as factors that motivate retailers to
   introduce store brands. In this paper, we study the effects of the
   introduction of a store-brand into a particular product category.
   Specifically, we are interested in the effect of store-brand
   introduction on the demand as well as on the supply side. On the demand
   side, we investigate the changes in preferences for the national brands
   and price elasticities in the category. On the supply side, we study the
   effects of the new entrant on the interactions between the national
   brand manufacturers and the retailer introducing the store brand,
   including how these interactions influence the retailer's pricing
   behavior. In doing so, we are also able to test whether the observed
   data are consistent with some of the commonly used assumptions regarding
   retailer pricing behavior. For the demand specification we use a random
   coefficients logit model that allows for consumer heterogeneity. The
   model parameters are estimated using aggregate data while explicitly
   accounting for endogeneity in retail prices.
   Our empirical results obtained from the oats product category based on
   store-level data from a multistore retail chain indicate that the
   store-brand introduction generates notable changes within the category
   The store-brand introduction coincides with an increase in the
   retailer's margins for the national brand. We find that the preferences
   for the national brand are relatively unaffected, by the introduction of
   the store-brand. While consumers are, in general, more price sensitive
   (in terms of elasticities) than they were prior to store-brand
   introduction, a statistical test of the differences in mean price
   elasticities across stores and between the two regimes fails to reject
   the hypothesis of no change in these elasticities. Elasticities in
   specific stores however, do increase after the store brand is
   introduced. We also find that there is considerable heterogeneity in the
   preferences for the store-brand. On the supply side, we test several
   forms of manufacturer-retailer interactions to identify retailer pricing
   behavior most consistent with the data. Our results indicate that the
   data reject several, commonly imposed, forms of interactions. In
   examining the nature of manufacturer interactions with the retailer, we
   find-that the manufacturer of the national brand appears to take a
   softer stance in its interactions with the retailer subsequent to
   store-brand entry. This finding is consistent with academic research and
   with articles in the popular press which suggest that the store brand
   enhances the retailer's bargaining ability vis-A-vis the manufacturers
   of the national brands. We also provide results from a second product
   category (frozen pasta) that are largely consistent with those found in
   the oats category.
RI Chintagunta, Pradeep K/A-4764-2017; BONFRER, Andre/D-2158-2010; Chintagunta, Pradeep/
OI Chintagunta, Pradeep/0000-0003-2854-5216
ZB 1
Z8 0
ZA 0
ZR 0
TC 88
ZS 2
Z9 89
SN 0025-1909
UT WOS:000179232800002
ER

PT J
AU Gjerde, KAP
   Slotnick, SA
   Sobel, MJ
TI New product innovation with multiple features and technology constraints
SO MANAGEMENT SCIENCE
VL 48
IS 10
BP 1268
EP 1284
PD OCT 2002
PY 2002
AB We model a firm's decisions about product innovation, focusing on the
   extent to which features should be improved or changed in the succession
   of models that comprise a life cycle. We show that the structure of the
   internal and external environment in which a firm operates suggests when
   to innovate to the technology frontier. The criterion is maximization of
   the expected present value of profits during the life cycle.
   Computational studies complement the theoretical results and lead to
   insights about when to bundle innovations across features. The
   formalization was influenced by extensive interviews with managers in a
   high-technology firm that dominates its industry.
RI Sobel, Matthew J/C-2649-2015
OI Sobel, Matthew J/0000-0002-9729-3756
Z8 1
ZR 1
ZB 0
TC 47
ZA 0
ZS 0
Z9 48
SN 0025-1909
UT WOS:000179232800003
ER

PT J
AU Mezias, SJ
   Chen, YR
   Murphy, PR
TI Aspiration-level adaptation in an American financial services
   organization: A field study
SO MANAGEMENT SCIENCE
VL 48
IS 10
BP 1285
EP 1300
DI 10.1287/mnsc.48.10.1285.277
PD OCT 2002
PY 2002
AB Using field data from an American financial services organization, we
   examined the effects of three important variables in Cyert and March's
   (1963) initial conceptualization. of the aspiration-level adaptation
   process: The previous aspiration level, performance feedback, and social
   comparison. Past findings obtained in controlled contexts (Glynn et al.
   1991; Lant 1992) have provided empirical support for the attainment
   discrepancy model (Lewin et al. 1944), which includes variables of the
   previous aspiration level and attainment discrepancy (i.e., performance
   feedback). We replicated these findings in the field: The effects of the
   previous aspiration level and attainment discrepancy on the current
   aspiration levels were significant and positive. In addition, we
   investigated the effect of social comparison using a variable based on
   the difference between the performance of the focal unit and the
   performance of comparable others (Greve 1998). Based on the assumption
   that decision makers. in organizations will expect to observe similar
   performance levels among those in the same comparison group (Wood 1989),
   we posited that the effect of social comparison would be negative,
   reflecting managerial efforts to reduce performance discrepancies among
   similar units. The empirical results supported the prediction from this
   reasoning. We conclude by discussing implications of our findings for
   theory and research in organizational learning and the behavioral theory
   of the firm.
ZA 0
Z8 1
ZS 0
TC 100
ZR 0
ZB 1
Z9 101
SN 0025-1909
UT WOS:000179232800004
ER

PT J
AU Mukhopadhyay, T
   Kekre, S
TI Strategic and operational benefits of electronic integration in B2B
   procurement processes
SO MANAGEMENT SCIENCE
VL 48
IS 10
BP 1301
EP 1313
DI 10.1287/mnsc.48.10.1301.273
PD OCT 2002
PY 2002
AB Our goal is to assess the strategic and, operational benefits of
   electronic integration for industrial procurement. We conduct a field
   study with an industrial supplier and examine the drivers of performance
   of the procurement process. Our research quantifies both the operational
   and strategic impacts of electronic integration in a B2B procurement
   environment for a supplier. Additionally, we show that the customer also
   obtains substantial benefits from efficient procurement transaction
   processing. We isolate the performance impact of technology choice and
   ordering processes on both the trading partners. A significant finding
   is that the supplier derives large strategic benefits when the customer
   initiates the system-and the supplier enhances the system's
   capabilities. With respect to operational benefits, we find that when
   suppliers have advanced electronic linkages, the order-processing system
   significantly increases benefits to both parties.
OI Mukhopadhyay, Tridas/0000-0001-6691-9595
TC 213
Z8 6
ZR 0
ZS 1
ZB 0
ZA 0
Z9 220
SN 0025-1909
UT WOS:000179232800005
ER

PT J
AU Cachon, GP
   Harker, PT
TI Competition and outsourcing with scale economies
SO MANAGEMENT SCIENCE
VL 48
IS 10
BP 1314
EP 1333
DI 10.1287/mnsc.48.10.1314.271
PD OCT 2002
PY 2002
AB Scale economies are commonplace in operations, yet because of analytical
   challenges, relatively little is, known about how firms should compete
   in their presence. This paper presents a model of competition between
   two firms that face scale economies; (i.e., each firm's cost per unit of
   demand is decreasing in demand). A general framework is used, which
   incorporates competition between two service providers with price- and
   time-sensitive demand (a queuing game), And competition between two
   retailers with fixed-ordering costs and price-sensitive consumers (an
   Economic Order Quantity game). Reasonably general conditions are
   provided under which there exists at most one equilibrium, with both
   firms participating in the market. We demonstrate, in the context of the
   queuing game, that the lower cost firm in equilibrium may have a higher
   market share and a higher price, an enviable situation. We also allow
   each firm to outsource their production process to a supplier. Even if
   the supplier's technology is no better, than the firms' technology
   and,the supplier is required to establish dedicated capacity (so the
   suppliers; scale can be no greater than either firm's scale), we show
   that the firms strictly prefer to outsource. We conclude that scale
   economies provide a strong motivation for outsourcing that has not
   previously been identified in the literature.
RI Harker, Patrick T/A-9467-2013
OI Harker, Patrick T/0000-0003-0659-3102
ZB 0
ZR 0
ZA 1
TC 256
Z8 16
ZS 1
Z9 272
SN 0025-1909
UT WOS:000179232800006
ER

PT J
AU Levy, M
   Levy, H
TI Prospect theory: Much ado about nothing?
SO MANAGEMENT SCIENCE
VL 48
IS 10
BP 1334
EP 1349
DI 10.1287/mnsc.48.10.1334.276
PD OCT 2002
PY 2002
AB Prospet theory is a paradigm challenging the expected utility paradigm.
   One of the fundamental components of prospect theory is the S-shaped
   value function. The value function is mainly justified by experimental
   investigation of the certainty equivalents of prospects confined either
   to the negative or to the positive domain, but not of mixed prospects,
   which characterize most actual investments. We conduct an experimental
   study with mixed prospects, using, for the first time, recently
   developed investment criteria called Prospect Stochastic Dominance (PSD)
   and Markowitz Stochastic Dominance (MSD). We reject the S-shaped value
   function, showing that at least 62%-76% of the subjects cannot be
   characterized by such preferences. We find support for the Markowitz
   utility function, which is a reversed S-shaped function-exactly the
   opposite of the prospect theory value function. It is possible that the
   previous results supporting the S-shaped value function are distorted
   because the prospects had only positive or only negative outcomes,
   presenting hypothetical situations which individuals do not usually
   face, and which are certainly not common in financial markets.
ZR 0
ZB 1
ZS 0
ZA 0
TC 115
Z8 8
Z9 123
SN 0025-1909
UT WOS:000179232800007
ER

PT J
AU Jedidi, K
   Zhang, ZJ
TI Augmenting conjoint analysis to estimate consumer reservation price
SO MANAGEMENT SCIENCE
VL 48
IS 10
BP 1350
EP 1368
DI 10.1287/mnsc.48.10.1350.272
PD OCT 2002
PY 2002
AB Consumer reservation price is a key concept in marketing and economics.
   Theoretically, this concept has been instrumental in studying consumer
   purchase decisions, competitive pricing strategies, and welfare
   economics. Managerially, knowledge of consumer reservation prices is
   critical for implementing many pricing tactics such as bundling, target
   promotions, nonlinear pricing, and one-to-one pricing, and for assessing
   the impact of marketing strategy on demand. Despite the practical and
   theoretical importance of this concept, its measurement at the
   individual level in a practical setting proves elusive.
   We propose a conjoint-based approach to estimate consumer-level
   reservation prices. This approach integrates the preference estimation
   of traditional conjoint with the economic theory of consumer choice.
   This integration augments the capability of traditional conjoint such
   that consumers' reservation prices for a product can be derived directly
   from the individual-level estimates of conjoint coefficients. With this
   augmentation, we can model a consumer's decision of not only which
   product to buy, but also whether to buy at all in a category. Thus, we
   can simulate simultaneously three effects that a change in price or the
   introduction of a new product may generate in a market: the customer
   switching effect, the cannibalization effect, and the market expansion
   effect. We show in a pilot application how this approach can aid product
   and pricing decisions. We also demonstrate the predictive validity of
   our approach using data from a commercial study of automobile batteries.
Z8 2
TC 88
ZA 0
ZB 1
ZS 0
ZR 0
Z9 90
SN 0025-1909
UT WOS:000179232800008
ER

PT J
AU Lovejoy, WS
   Li, Y
TI Hospital operating room capacity expansion
SO MANAGEMENT SCIENCE
VL 48
IS 11
BP 1369
EP 1387
DI 10.1287/mnsc.48.11.1369.266
PD NOV 2002
PY 2002
AB A large midwestern hospital is expecting an increase in, surgical
   caseload: New operating, room (OR) capacity can be had by building new
   ORs or extending the working hours in the current ORs. The choice among
   these options is complicated by the fact that patients; surgeons and,
   surgical staff, and hospital administrators are all important
   stakeholders in: the health service operation, and each has different
   priorities. This. paper investigates the trade-offs among three
   performance criteria (wait to get on schedule, scheduled procedure
   start-tune reliability; and hospital profits), which are of particular
   importance to the different constituencies. The objective is to
   determine how the hospital can best expand its capacity, acknowledging
   the key role that each constituency plays in that objective. En route,
   the paper presents supporting analysis for process improvements and
   suggestions for. optimal participation-inducing staff contracts for
   extending OR hours-of operation.
ZS 0
ZR 0
TC 39
ZB 2
Z8 0
ZA 0
Z9 39
SN 0025-1909
EI 1526-5501
UT WOS:000179624200001
ER

PT J
AU Vulcano, G
   van Ryzin, G
   Maglaras, C
TI Optimal dynamic auctions for revenue management
SO MANAGEMENT SCIENCE
VL 48
IS 11
BP 1388
EP 1407
DI 10.1287/mnsc.48.11.1388.269
PD NOV 2002
PY 2002
AB We analyze a dynamic auction, in which a seller, with C units to sell
   faces a sequence of buyers separated into T time periods. Each group of
   buyers has independent, private values for a single unit. Buyers compete
   directly against each other within a period, as in a traditional
   auction, and indirectly with buyers in other periods through the
   opportunity cost of capacity assessed by the seller. The number of
   buyers in each period, as well as the individual buyers' valuations, are
   random. The model is a variation of the traditional singleleg,
   multiperiod revenue management problem, in which consumers act
   strategically and bid for units of a fixed capacity over time.
   For this setting, we prove that dynamic variants of the first-price and
   second-price auction mechanisms maximize the seller's expected revenue.
   We also show explicitly how to compute and implement these optimal
   auctions. The optimal auctions are then compared to a traditional
   revenue management mechanism-in which list prices are used in each
   period together with capacity controls-and, to a simple auction
   heuristic that consists of allocating units to each period and running a
   sequence of standard, multiunit auctions with fixed reserve prices in
   each period. The traditional revenue management mechanism is proven to
   be optimal in the limiting cases when there is at most one buyer per
   period, when capacity is not constraining, and asymptotically when the
   number of buyers and the capacity increases. The optimal auction
   significantly outperforms both suboptimal mechanisms when there are a
   moderate number of periods, capacity is constrained, and. the total
   volume of sales is not too large. The benefit also increases when
   variability in the dispersion in buyers' valuations or in the number of
   buyers per period increases.
RI Vulcano, Gustavo/K-3250-2016
OI Vulcano, Gustavo/0000-0003-0083-4737
ZR 0
ZS 0
TC 85
ZB 0
Z8 4
ZA 0
Z9 89
SN 0025-1909
EI 1526-5501
UT WOS:000179624200002
ER

PT J
AU Gittell, JH
TI Coordinating mechanisms in care provider groups: Relational coordination
   as a mediator and input uncertainty as a moderator of performance
   effects
SO MANAGEMENT SCIENCE
VL 48
IS 11
BP 1408
EP 1426
PD NOV 2002
PY 2002
AB This paper proposes a model of how coordinating mechanisms work, and
   tests it in the context of patient care. Consistent with organization
   design theory, the performance effects of boundary spanners and team
   meetings were mediated by relational coordination, a communication- and
   relationship-intensive form of coordination. Contrary to organization.
   design theory, however, the performance effects of routines were also
   mediated :by relational coordination. Rather than serving as a
   replacement for interactions, as anticipated by organization design
   theory, routines work by enhancing interactions among participants.
   Likewise, all three coordinating mechanisms, including routines, were
   found to be increasingly effective under conditions of uncertainty.
ZR 0
Z8 2
TC 392
ZB 15
ZA 0
ZS 2
Z9 394
SN 0025-1909
EI 1526-5501
UT WOS:000179624200003
ER

PT J
AU Ang, S
   Slaughter, S
   Ng, KY
TI Human capital and institutional determinants of information technology
   compensation: Modeling multilevel and cross-level interactions
SO MANAGEMENT SCIENCE
VL 48
IS 11
BP 1427
EP 1445
DI 10.1287/mnsc.48.11.1427.264
PD NOV 2002
PY 2002
AB Compensation is critical in attracting and retaining information
   technology (IT) professionals. However, there has been very little
   research on IT compensation. Juxtaposing theories of compensation that
   focus on human capital endowments and labor market segmentation, we
   hypothesize multilevel and cross-level determinants of compensation. We
   use hierarchical linear modeling to analyze archival salary data for
   1,576 IT professionals across 39 institutions. Results indicate that
   compensation is directly determined by human capital endowments of
   education and experience. Institutional differentials do not directly
   drive compensation, but instead moderate the relationship of human
   capital endowments to compensation. Large institutions pay more than
   small institutions to IT professionals with more education, while small
   institutions pay more than large institutions to IT professionals with
   less education. Not-for-profit institutions pay more than for-profits to
   IT professionals with more or IT-specific education. Further,
   information-intensive institutions pay more than
   noninformation-intensive institutions to IT professionals with more or
   IT-specific education. We interpret these results in the context of
   institutional rigidity, core competencies, and labor shortages in the IT
   labor market.
ZS 0
TC 113
Z8 1
ZA 0
ZB 0
ZR 0
Z9 113
SN 0025-1909
UT WOS:000179624200004
ER

PT J
AU Chan, LMA
   Muriel, A
   Shen, ZJM
   Simchi-Levi, D
   Teo, CP
TI Effective zero-inventory-ordering policies for the single-warehouse
   multiretailer problem with piecewise linear cost structures
SO MANAGEMENT SCIENCE
VL 48
IS 11
BP 1446
EP 1460
PD NOV 2002
PY 2002
AB We analyze the problem faced by companies that rely on TL (Truckload)
   and LTL (Less than Truckload) carriers for the distribution of products
   across their supply chain. Our goal is to design simple inventory
   policies and transportation strategies to satisfy time-varying demands
   over a finite horizon, while minimizing systemwide cost by taking
   advantage of quantity discounts in the transportation cost structures.
   For this purpose, we study the cost effectiveness of restricting the
   inventory policies to the class of zero-inventory-ordering (ZIO)
   policies in a single-warehouse multiretailer scenario in which the
   warehouse serves as a cross-dock facility. In particular, we demonstrate
   that there exists a ZIO inventory policy whose total inventory and
   transportation cost is no more than 4/3 (5.6/4.6 if transportation costs
   are stationary) times the optimal cost. However, finding the best ZIO
   policy is an NP-hard problem as well. Thus, we propose two algorithms to
   find an effective ZIO policy: An exact algorithm whose running time is
   polynomial for any fixed number of retailers, and a
   linear-programming-based heuristic whose effectiveness is demonstrated
   in a series of computational experiments. Finally, we extend the
   worst-case results developed in this paper to systems in which the
   warehouse does hold inventory.
RI Teo, Chung Piaw/P-8070-2015; Teo, Chung Piaw/
OI Teo, Chung Piaw/0000-0002-0534-6858
ZS 0
Z8 4
ZA 0
ZB 0
TC 96
ZR 0
Z9 100
SN 0025-1909
EI 1526-5501
UT WOS:000179624200005
ER

PT J
AU Burton, RM
   Lauridsen, J
   Obel, B
TI Return on assets loss from situational and contingency misfits
SO MANAGEMENT SCIENCE
VL 48
IS 11
BP 1461
EP 1485
DI 10.1287/mnsc.48.11.1461.262
PD NOV 2002
PY 2002
AB We develop a rule-based contingency misfit model and related hypotheses
   to test empirically the Burton and Obel (1998) multicontingency model
   forstrategic organizational design: The model is a set of "if-then"
   misfit rules, in which misfits lead to a loss in performance; they are
   complements to the strategy and organizational contingency theory fit
   rules. Using data from 224 small- and medium-sized Danish firms, misfits
   are categorized, and; identified: Then, performance hypotheses, are
   developed. and tested using. regression models. We confirm the
   hypotheses that firms with situational misfits or contingency misfits,
   or both,, incur performance losses in return on assets compared with
   firms with no misfits. Contrary to our hypotheses;; we did not find that
   additional misfits lead to increased performance loss. Our results
   suggest that just one misfit of any kind may significantly compromise
   performance. These results yield a deeper understanding of
   organizational contingency theory, as well as implications for the
   rule-based fit-misfit organizational design model.
OI Lauridsen, Jorgen T./0000-0001-9889-6236; Obel,
   Borge/0000-0003-1283-5489
ZB 0
ZR 0
TC 80
ZS 0
ZA 0
Z8 0
Z9 80
SN 0025-1909
UT WOS:000179624200006
ER

PT J
AU de Vericourt, F
   Karaesmen, F
   Dallery, Y
TI Optimal stock allocation for a capacitated supply system
SO MANAGEMENT SCIENCE
VL 48
IS 11
BP 1486
EP 1501
PD NOV 2002
PY 2002
AB We consider a capacitated supply system that produces a single item that
   is demanded by several classes of customers. Each customer class may
   have a different backorder cost, so stock allocation arises as a key
   decision problem. We model the supply system as a multicustomer
   make-to-stock queue. Using dynamic programming, we show that the optimal
   allocation policy has a simple and intuitive structure. In addition, we
   present an efficient algorithm to compute the parameters of this optimal
   allocation policy. Finally, for. a typical supply chain design problem,
   we illustrate that ignoring the stock allocation dimension-a frequently
   encountered simplifying assumption-can lead to incorrect managerial
   decisions.
OI Karaesmen, Fikri/0000-0003-3851-6232
ZR 0
ZB 0
ZS 0
Z8 0
ZA 0
TC 146
Z9 146
SN 0025-1909
UT WOS:000179624200007
ER

PT J
AU Kim, K
   Chhajed, D
TI Product design with multiple quality-type attributes
SO MANAGEMENT SCIENCE
VL 48
IS 11
BP 1502
EP 1511
DI 10.1287/mnsc.48.11.1502.265
PD NOV 2002
PY 2002
AB We consider a product line design problem with multiple attributes for a
   monopolist serving a market with two customer segments. Products are
   designed with quality-type attributes for which more is always better
   than less. By considering multiple attributes, we derive a measure of
   multidimensional customer preference and offer insights into the optimal
   product design. When customers' preferences exhibit different orders in
   different attributes, our results show that products are differentiated
   horizontally where no one product is better than the other with respect
   to all attributes, and that there exists a region where the first-best
   solution for the monopolist is feasible despite the problem of
   cannibalization. Furthermore, single-product offering strategies are
   never optimal, so pooling of customer segments or reduction of the
   number of segments served will not occur.
Z8 4
ZS 0
ZR 0
TC 60
ZA 0
ZB 0
Z9 64
SN 0025-1909
UT WOS:000179624200008
ER

PT J
AU Klaassen, P
TI Comment on "generating scenario trees for multistage decision problems"
SO MANAGEMENT SCIENCE
VL 48
IS 11
BP 1512
EP 1516
DI 10.1287/mnsc.48.11.1512.261
PD NOV 2002
PY 2002
AB In models of decision making under uncertainty; one typically has to
   approximate the uncertainties by a limited number of discrete outcomes.
   Hoyland and Wallace (2001) formulate a nonlinear programming problem to
   generate such a limited number of discrete outcomes while satisfying
   specified statistical properties. They have developed and employed..
   this method for a stochastic multistage asset-allocation problem. When
   the method is applied to such financial optimization problems under
   uncertainty, we argue here that it does not suffice to match statistical
   properties. To obtain realistic outcomes, the.(limited) description : of
   the uncertainty in such models should also exclude arbitrage
   opportunities, and thereby, be consistent with financial asset pricing
   theory. We illustrate that the method proposed by Hoyland and Wallace
   can result in arbitrage opportunities in the scenario tree if only
   statistical properties are imposed. We show how one can check ex post
   for the presence of arbitrage opportunities in a scenario tree by
   checking, for the existence of solutions to sets of linear equations.
   Arbitrage opportunities can also be precluded ex ante. in the scenario
   tree. by adding constraints to the nonlinear programming problem of
   Hoyland and Wallace.
Z8 6
ZS 0
ZB 0
ZR 0
TC 39
ZA 0
Z9 44
SN 0025-1909
UT WOS:000179624200009
ER

PT J
AU Ingram, P
   Simons, T
TI The transfer of experience in groups of organizations: Implications for
   performance and competition
SO MANAGEMENT SCIENCE
VL 48
IS 12
BP 1517
EP 1533
DI 10.1287/mnsc.48.12.1517.437
PD DEC 2002
PY 2002
AB Groups of organizations are pervasive, although there is little
   systematic knowledge about how they affect their members. We examine one
   dimension of the operation of organization groups, the transfer of
   experience. Our Fore,argument is that organization groups may create
   benefits for their members, but problems-for those outside the group.
   Within the group they can facilitate the transfer of experience among
   their members by creating mechanisms for communication, incentives for
   helping, and by promoting, understanding. The predicted pattern of
   experience transfer should improve performance of those within the
   group, but also has implications for those outside it. Experience
   accumulated, in one organization group strengthens the competitiveness
   of its organizations, and thereby harms competitors outside the group.
   Thus, organization groups are fundamental both for the functioning of
   their members and the competitive dynamics of their industries. Our
   longitudinal analysis of the profitability of kibbutz agriculture
   supports both these claims. Between 1954 and 1965 (the years of this
   study), almost all kibbutzim were part of organization groups. Kibbutzim
   became more profitable as a function of the experience of others in
   their group was reduced, however, as a function of experience of others
   outside. their Their profitability group.
CT 59th Annual Meeting of the Academy-of-Management
CY AUG, 1999
CL CHICAGO, IL
SP Acad Management
Z8 0
ZB 1
ZS 3
ZA 0
TC 77
ZR 0
Z9 80
SN 0025-1909
EI 1526-5501
UT WOS:000180206500001
ER

PT J
AU Chung, W
   Alcacer, J
TI Knowledge seeking and location choice of foreign direct investment in
   the United States
SO MANAGEMENT SCIENCE
VL 48
IS 12
BP 1534
EP 1554
DI 10.1287/mnsc.48.12.1534.440
PD DEC 2002
PY 2002
AB To what extent do firms go abroad to access technology available in
   other locations? This paper examines whether and when state technical
   capabilities attract foreign investment in manufacturing from.
   1987-1993. We find that on average state R&D intensity does not attract
   foreign direct investment. Most investing firms are in lower-tech
   industries and locate in low R&D intensity states, suggesting little
   interest in state technical capabilities. In contrast, we find that
   firms in research-intensive industries are more likely to locate in
   states with high R&D intensity. Foreign firms in the pharmaceutical
   industry value state R&D intensity the most, at a level twice that of
   firms in the semiconductor industry, and four times that of electronics
   firms. Interestingly, not only firms from technically lagging nations,
   but also some firms from technically leading nations are attracted to
   R&D intensive states. This suggests that beyond catching up, firms use
   knowledge-seeking investments also to source technical diversity.
ZB 0
ZS 1
Z8 3
ZA 0
ZR 0
TC 296
Z9 300
SN 0025-1909
UT WOS:000180206500002
ER

PT J
AU Anderson, RM
   Hobbs, BF
TI Using a Bayesian approach to quantify scale compatibility bias
SO MANAGEMENT SCIENCE
VL 48
IS 12
BP 1555
EP 1568
DI 10.1287/mnsc.48.12.1555.444
PD DEC 2002
PY 2002
AB his paper proposes a new analytical framework to quantify and correct
   for scale compatibility bias in the assessment of trade-off weights in
   multiattribute value analysis. The procedure is demonstrated with an
   application to a fisheries management problem. Tradeoff judgments are
   elicited from a group of fisheries experts with management
   responsibility in the Lake Erie basin. Then we use a Bayesian method to
   compute posterior probability distributing of attribute weights. In
   computing the Bayesian weights, our measurement model assumes that the
   weight ratios produced by each respondent's judgments are subject to
   random error and an unknown scale compatibility bias. Ratios are
   log-transformed and analyzed by a Bayesian linear model with a
   noninformative prior distribution. Posterior distributions are then
   developed for the weights and the bias. We estimate the compatibility
   bias for each person and, in most cases, it is found to be large and in
   the predicted direction, suggesting the importance of its consideration
   in deriving trade-off weights. In addition, the Bayesian framework is
   shown to be useful for quantifying the value of additional information
   about multiattribute weights. Finally, a simple heuristic procedure for
   assessing the, weights appears to be effective in eliminating the bias.
RI Hobbs, Benjamin/A-3291-2010
ZR 0
ZB 0
TC 11
ZS 0
ZA 0
Z8 0
Z9 11
SN 0025-1909
UT WOS:000180206500003
ER

PT J
AU Steiger, NM
   Wilson, JR
TI An improved batch means procedure for simulation output analysis
SO MANAGEMENT SCIENCE
VL 48
IS 12
BP 1569
EP 1586
DI 10.1287/mnsc.48.12.1569.438
PD DEC 2002
PY 2002
AB We formulate and evaluate the Automated Simulation Analysis Procedure
   (ASAP), an algorithm for steady-state simulation output analysis based
   on the method of nonoverlapping batch means (NOBM). ASAP delivers a
   confidence interval for an expected response that is centered on the
   sample mean of a portion of a simulation-generated time series and
   satisfies a user-specified absolute or relative precision requirement.
   ASAP operates as follows: The batch size is progressively increased
   until either (a) the batch means pass the von Neumann test for
   independence, and then ASAP delivers a classical NOBM confidence
   interval; or (b) the batch means pass the Shapiro-Wilk test for
   multivariate normality, and then ASAP delivers a correlation-adjusted
   confidence interval. The latter adjustment is based on an inverted
   Cornish-Fisher expansion for the classical NOBM t-ratio, where the terms
   of the expansion are estimated via an autoregressive-moving average time
   series model of the batch means. After determining the batch size and
   confidence-interval type, ASAP sequentially increases the number of
   batches until the precision requirement is satisfied. An extensive
   experimental study demonstrates the performance improvements achieved by
   ASAP versus well-known batch means procedures, especially in
   confidence-interval coverage probability.
Z8 2
ZA 0
ZB 0
ZS 0
ZR 1
TC 25
Z9 28
SN 0025-1909
UT WOS:000180206500004
ER

PT J
AU Wolsey, LA
TI Solving multi-item lot-sizing problems with an MIP solver using
   classification and reformulation
SO MANAGEMENT SCIENCE
VL 48
IS 12
BP 1587
EP 1602
DI 10.1287/mnsc.48.12.1587.442
PD DEC 2002
PY 2002
AB Based on research on the polyhedral structure of lot-sizing models over
   the last 20 years, we claim that there is a nontrivial fraction of
   practical lot-sizing problems that can now be solved by nonspecialists
   just by taking an appropriate a priori reformulation of the problem, and
   then feeding the resulting formulation into a commercial mixed-integer
   programming solver.
   This claim uses the fact that many multi-item problems decompose
   naturally into a set of single-item problems with linking constraints,
   and that there is now a large body of knowledge about single-item
   problems. To put this knowledge to use, we propose a classification of
   lot-sizing problems (in large part single-item) and then indicate in a
   set of tables, what is known about a particular problem class and how
   useful it might be. Specifically, we indicate for each class (i) whether
   a tight extended. formulation is known, and its size; (ii) whether one
   or more families of valid inequalities are known defining the convex
   hull of solutions, and the complexity of the corresponding separation
   algorithms; and (iii) the complexity of the corresponding optimization
   algorithms (which would be useful if a column generation or Lagrangian
   relaxation approach was envisaged).
   Three distinct multi-item lot-sizing instances are then presented to
   demonstrate the approach, and comparative computational results are
   presented. Finally, we also use the classification to point out what
   appear to be some of the important open questions and challenges.
ZS 3
Z8 0
ZR 0
ZA 0
ZB 1
TC 78
Z9 81
SN 0025-1909
UT WOS:000180206500005
ER

PT J
AU Erlebach, T
   Kellerer, H
   Pferschy, U
TI Approximating multiobjective knapsack problems
SO MANAGEMENT SCIENCE
VL 48
IS 12
BP 1603
EP 1612
DI 10.1287/mnsc.48.12.1603.445
PD DEC 2002
PY 2002
AB For multiobjective optimization problems, it is meaningful to compute a
   set of solutions covering all possible trade-offs between the different
   objectives. The multiobjective knapsack problem is a generalization of
   the classical knapsack problem in which each item has several profit
   values. For this problem, efficient algorithms for computing a provably
   good approximation to the set of all nondominated feasible solutions,
   the Pareto frontier, are studied.
   For the multiobjective one-dimensional knapsack problem, a practical
   fully polynomial time approximation scheme (FPTAS) is derived. It is
   based on a new approach to the single objective knapsack problem using a
   partition of the profit space into intervals of exponentially increasing
   length. For the multiobjective m-dimensional knapsack problem, the first
   known polynomial-time approximation scheme (PTAS), based on linear
   programming, is presented.
RI Pferschy, Ulrich/D-2182-2012; Erlebach, Thomas/
OI Pferschy, Ulrich/0000-0001-8881-1497; Erlebach,
   Thomas/0000-0002-4470-5868
ZA 0
Z8 0
ZB 0
ZS 0
ZR 0
TC 62
Z9 62
SN 0025-1909
EI 1526-5501
UT WOS:000180206500006
ER

PT J
AU Sarathy, R
   Muralidhar, K
   Parsa, R
TI Perturbing nonnormal confidential attributes: The copula approach
SO MANAGEMENT SCIENCE
VL 48
IS 12
BP 1613
EP 1627
DI 10.1287/mnsc.48.12.1613.439
PD DEC 2002
PY 2002
AB Protecting confidential, numerical data in databases from. disclosure is
   an important issue both for commercial organizations as well as
   data-gathering and disseminating organizations (such as the Census
   Bureau). Prior studies have shown that perturbation methods are
   effective in protecting such confidential data from snoopers.
   Perturbation methods have to provide legitimate users. with accurate
   (unbiased) information, and also provide adequate security against
   disclosure of confidential information to snoopers. For databases
   described by nonnormal multivariate distributions, existing perturbation
   methods do not provide unbiased characteristics. In this study, we
   develop a copula-based perturbation method capable of maintaining the
   marginal distribution of perturbed attributes to be the same before and
   after perturbation. In addition, this method also preserves the rank
   order correlation between the confidential and nonconfidential
   attributes, thereby maintaining monotonic relationships between
   attributes. The method proposed in this study provides a high level of
   protection, against inferential disclosure. An investigation of the new
   perturbation method for simulated databases shows that the method
   performs effectively The methodology presented in this study represents
   a significant step toward improving the practical. applicability of data
   perturbation methods.
RI Muralidhar, Krishnamurty/A-7618-2009; Sarathy, Rathindra/
OI Sarathy, Rathindra/0000-0001-7352-2676
Z8 0
TC 28
ZB 1
ZS 0
ZR 1
ZA 0
Z9 28
SN 0025-1909
EI 1526-5501
UT WOS:000180206500007
ER

PT J
AU Masuda, Y
   Whang, S
TI Capacity management in decentralized networks
SO MANAGEMENT SCIENCE
VL 48
IS 12
BP 1628
EP 1634
DI 10.1287/mnsc.48.12.1628.446
PD DEC 2002
PY 2002
AB Bottleneck analysis is a useful tool in capacity planning for centrally
   controlled network systems. However, under a decentralized network where
   individual users are allowed to select their own routes, straightforward
   application of bottleneck analysis does not necessarily yield an optimal
   performance. It may even hurt the system performance-an aspect of
   Braess's paradox. We investigate the capacity expansion problem for a
   decentralized system with general network topology. To this end, we
   first discuss the short-run problem and show that the, externality
   pricing solves the joint problem of demand and routing control. We then
   study the capacity expansion/reduction problem for decentralized systems
   that may or may not be optimally controlled in the short run.
RI Masuda, Yasushi/A-7426-2008
OI Masuda, Yasushi/0000-0001-7557-7478
ZR 0
ZB 0
Z8 0
ZS 0
ZA 0
TC 10
Z9 10
SN 0025-1909
UT WOS:000180206500008
ER

PT J
AU Cetinkaya, S
   Parlar, M
TI Note: Optimality conditions for an (s,S) policy with proportional and
   lump-sum penalty costs
SO MANAGEMENT SCIENCE
VL 48
IS 12
BP 1635
EP 1639
PD DEC 2002
PY 2002
AB We consider the optimality of the (s, S) policy for a periodic-review
   stochastic inventory problem with two types of shortage costs. The
   'problem may arise in a rush-order application at a bank branch where
   the emergency provision costs during a foreign currency stockout are
   represented by proportional and lump-sum penalties. Aneja and Noori
   (1987) analyzed this problem and presented a set of conditions for the
   convexity of a particular function and made a claim about the
   K-convexity of another function to prove the optimality of the (s, S)
   policy. We show that because the function that is claimed to be K-convex
   is actually concave over a subset of its domain, Aneja and Noori'
   arguments cannot be used to prove the optimality of the (s, S) policy.
   However, we argue that Aneja and Noori's problem is equivalent to the
   typical lost-sales problem, and using this equivalence, we find a simple
   convexity. condition that assures the optimality of the (s, S) policy.
Z8 0
ZR 0
ZS 0
ZA 0
TC 5
ZB 0
Z9 5
SN 0025-1909
UT WOS:000180206500009
ER

PT J
AU Greenleaf, EA
   Ma, J
   Qiu, WH
   Rao, AG
   Sinha, AR
TI Note on "guarantees in auctions: The auction house as negotiator and
   managerial decision maker"
SO MANAGEMENT SCIENCE
VL 48
IS 12
BP 1640
EP 1644
DI 10.1287/mnsc.48.12.1640.441
PD DEC 2002
PY 2002
AB In this note,(1) we identify two errors in Greenleaf, Rao, and Sinha's
   (1993) analysis of negotiation of guarantees in auctions. This note
   provides a high-level but self-contained summary of the revised results.
   We find that, in contrast with the earlier claim, guaranteed auctions
   lead to-greater total expected revenue than conventional auctions. The
   ability to bargain over guarantee values and commissions certainly
   benefits sellers but may hurt the profits of auction houses. We relate
   these results to recent events in auction markets.
RI Greenleaf, Eric A/A-6552-2008
ZS 0
TC 5
ZA 0
Z8 1
ZB 0
ZR 0
Z9 6
SN 0025-1909
UT WOS:000180206500010
ER

PT J
AU Chiang, WYK
   Chhajed, D
   Hess, JD
TI Direct-marketing, indirect profits: A strategic analysis of dual-channel
   supply-chain design
SO MANAGEMENT SCIENCE
VL 49
IS 1
BP 1
EP 20
DI 10.1287/mnsc.49.1.1.12749
PD JAN 2003
PY 2003
AB The advent of e-commerce has prompted many-manufacturers to redesign
   their traditional channel structures by engaging in direct sales. The
   model conceptualizes the impact-of customer acceptance of a direct
   channel, the degree to which customers accept a direct channel as a
   substitute for. shopping at a traditional store, on supply-chain design.
   The customer acceptance of a direct channel can be strong enough that an
   indepent manufacturer Would open a direct channel to, compete with its
   own retailers. Here, direct marketing is used for strategic channel
   control purposes even though it is inefficient on its own and,
   surprisingly, it can profit the manufacturer even when so direct sales
   occur. Specifically, we construct a price-setting game between a
   manufacturer and its independent retailer. Direct marketing, which
   indirectly increases the flow of profits through the retail channel,
   helps the manufacturer improve overall Profitability by reducing the
   degree of inefficient price double marginalization. While operated by
   the manufacturer to constrain the retailer's pricing behavior, the
   direct channel may-not always be detrimental to the retailer because it
   will be accompanied by a wholesale price reduction. This combination of
   manufacturer pull and push can benefit the retailer in equilibrium.
   Finally, we show that the mere threat of introducing the direct channel
   can increase the manufacturer's negotiated share of cooperative profits
   even if price efficiency is obtained by using other business practices.
RI CHIANG, Wei-yu Kevin/K-1019-2015
OI CHIANG, Wei-yu Kevin/0000-0003-4806-7485
Z8 207
TC 761
ZA 0
ZS 2
ZB 8
ZR 0
Z9 958
SN 0025-1909
UT WOS:000182094000002
ER

PT J
AU Ahuja, MK
   Galletta, DF
   Carley, KM
TI Individual centrality and performance in virtual R&D groups: An
   empirical study
SO MANAGEMENT SCIENCE
VL 49
IS 1
BP 21
EP 38
DI 10.1287/mnsc.49.1.21.12756
PD JAN 2003
PY 2003
AB Communication technologies support virtual R&D groups by enabling
   immediate and frequent interaction of their geographically-distributed
   members. Performance of members in such groups has yet to be studied
   longitudinally. A model proposes not only direct effects of. functional
   role, status, and communication role on individual performance, but also
   indirect effects through individual centrality. Social network analysis
   was performed on e-mail samples from two time periods separated by four
   years. Analysis revealed both direct and indirect effects as
   hypothesized; however, the indirect effects were more consistent in both
   time periods, The clearest findings were that centrality mediates the
   effects of functional role, status., and communication role on
   individual performance. Interestingly, centrality was a stronger direct
   predictor of performance than the individual characteristics considered
   in this study. The study illustrates the usefulness of accounting for
   network effects for better understanding individual performance in
   virtual groups.
OI Galletta, Dennis/0000-0003-0442-5500; Carley, Kathleen
   M./0000-0002-6356-0238
ZR 0
ZS 0
Z8 5
TC 239
ZA 0
ZB 3
Z9 244
SN 0025-1909
EI 1526-5501
UT WOS:000182094000003
ER

PT J
AU Schilling, MA
   Vidal, P
   Ployhart, RE
   Marangoni, A
TI Learning by doing something else: Variation, relatedness, and the
   learning curve
SO MANAGEMENT SCIENCE
VL 49
IS 1
BP 39
EP 56
DI 10.1287/mnsc.49.1.39.12750
PD JAN 2003
PY 2003
AB Many organizational learning studies have an implicit assumption that
   the learning rate is maximized through specialization: the more an
   individual or organization focuses on a particular task, the faster it
   will improve. However, through contrasting the various learning process
   theories described in the research on organizational, group, and
   individual learning, we develop a set of competing hypotheses that
   suggest some degree of variation might improve the learning rate.
   Furthermore, such comparison yields competing arguments about how
   related or unrelated such task variation should be to improve the
   learning rate. This research uses an experimental study to answer the
   following research questions: Is the learning rate maximized through
   specialization? Or does variation, related or unrelated, enhance the
   learning process? We find that the learning rate under conditions of
   related variation is significantly greater than under conditions of
   specialization or unrelated variation, indicating the possibility of
   synergy between related learning efforts consistent with an implicit
   learning or insight effect. We find no significant differences in the
   rates of learning under the conditions of specialization and unrelated
   variation. These results yield important implications for how work
   should be organized, and for future research into the learning process.
RI Schilling, Melissa A/A-2385-2008; Ployhart, Robert/Y-3347-2019
ZB 3
ZA 0
Z8 2
TC 208
ZR 1
ZS 3
Z9 213
SN 0025-1909
UT WOS:000182094000004
ER

PT J
AU Schwartz, ES
   Zozaya-Gorostiza, C
TI Investment under uncertainty in information technology: Acquisition and
   development projects
SO MANAGEMENT SCIENCE
VL 49
IS 1
BP 57
EP 70
DI 10.1287/mnsc.49.1.57.12753
PD JAN 2003
PY 2003
AB In this paper, we develop two models for the valuation-of information
   technology (IT) investment projects using the real options approach. The
   IT investment projects discussed in this paper are categorized into
   development and acquisition projects, depending upon the time it takes
   to start benefiting from the IT asset once the decision to invest has
   been taken. The models account for uncertainty both in the costs and
   benefits associated with the investment opportunity. Our stochastic cost
   function for IT development projects incorporates the technical and
   input cost uncertainties of Pindyck's model (1993), but also considers
   the fact that the investment costs of some IT projects might change even
   if no investment takes place. In contrast to other models in the real
   options literature in which benefits are summarized in the underlying
   asset value, our model for IT acquisition projects represents these
   benefits as a stream of stochastic cash flows.
TC 101
ZA 0
ZR 0
Z8 8
ZS 1
ZB 0
Z9 110
SN 0025-1909
EI 1526-5501
UT WOS:000182094000005
ER

PT J
AU Rothkopf, MH
   Harstad, RM
   Fu, YH
TI Is subsidizing inefficient bidders actually costly?
SO MANAGEMENT SCIENCE
VL 49
IS 1
BP 71
EP 84
DI 10.1287/mnsc.49.1.71.12748
PD JAN 2003
PY 2003
AB A widespread practice, particularly in public-sector procurement and
   dispersal, is to subsidize a class of competitors believed to be at an
   economic disadvantage. Arguments for such policies vary, but they
   typically assume that benefits of subsidization must be large enough to
   outweigh a presumed economic cost of the subsidy. When disadvantaged
   competitors compete in auctions, the subsidy serves to. make them more
   competitive rivals. Other bidders rationally respond by bidding more
   aggressively. We consider a model of procurement auctions and show that
   a policy of subsidizing inefficient competitors can lower expected
   project cost and also enhance economic efficiency. Some subsidy is
   generally better than no subsidy for-a wide range of parameters.
Z8 0
ZA 0
ZR 1
ZB 0
ZS 0
TC 30
Z9 31
SN 0025-1909
EI 1526-5501
UT WOS:000182094000006
ER

PT J
AU Bapna, R
   Goes, P
   Gupta, A
TI Analysis and design of business-to-consumer online auctions
SO MANAGEMENT SCIENCE
VL 49
IS 1
BP 85
EP 101
DI 10.1287/mnsc.49.1.85.12754
PD JAN 2003
PY 2003
AB Business-to-consumer online auctions form an important element in the
   portfolio of mercantile processes that facilitate electronic commerce
   activity. Much of traditional auction.. theory has focused on analyzing
   single-item auctions in isolation from the market context in which they
   take place. We demonstrate the weakness of such approaches in online
   settings where a majority of auctions are multiunit in nature. Rather
   than pursuing a classical approach and assuming knowledge of the
   distribution of consumers' valuations, we emphasize the largely ignored
   discrete and sequential nature of such auctions. We derive a general
   expression that characterizes the multiple equilibria that can arise in
   such auctions and segregate these into desirable and undesirable
   categories. Our analytical and empirical results,, obtained by tracking
   real-world online auctions, indicate that bid increment is an important
   factor amongst the control factors that online auctioneers can
   manipulate and control. We show that consumer bidding strategies in such
   auctions-are not-uniform and that the level of bide increment chosen
   influences them. With a motive of providing concrete strategic
   directions to online auctioneers, we derive an absolute upper bound for
   the bid increment. Based on the theoretical upper bound we propose a
   heuristic decision rule for setting the bid increment. Empirical
   evidence lends support to the hypothesis that setting a bid increment
   higher than that suggested by the heuristic decision rule has a negative
   impact on the auctioneer's revenue.
RI Gupta, Alok/AAF-4281-2020
OI Gupta, Alok/0000-0002-2097-1643
ZS 0
ZR 0
TC 96
Z8 0
ZA 0
ZB 0
Z9 96
SN 0025-1909
UT WOS:000182094000007
ER

PT J
AU Delquie, P
TI Optimal conflict in preference assessment
SO MANAGEMENT SCIENCE
VL 49
IS 1
BP 102
EP 115
DI 10.1287/mnsc.49.1.102.12751
PD JAN 2003
PY 2003
AB Conflict arises in decision making when the choice alternatives present
   strong advantages and disadvantages over one another, that is, when the
   trade-offs involved are large. Conflict affects human response to
   choice, in particular, it increases decision difficulty and response
   unreliability. On the other hand, larger trade-offs, i.e., higher
   conflict, reveal more information about an individual's preferences and
   mitigate the influence of measurement unreliability on preference model
   estimation. This suggests, somewhat counterintuitively, that there may
   exist some optimal level of conflict for efficient measurement of
   preferences. How to determine this level? This issue is examined from
   behavioral and analytical angles. We outline a general analysis of the
   interaction between trade-off size and modeling accuracy, and
   demonstrate its application on a simple example. The kind of analysis
   developed here can be conveniently implemented in a computer
   spreadsheet, and would be especially valuable when large amounts of
   preference data are to be collected, as in consumer preference studies,
   experimental research, and contingent valuation surveys.
ZB 0
ZS 0
ZA 0
Z8 1
TC 14
ZR 0
Z9 15
SN 0025-1909
UT WOS:000182094000008
ER

PT J
AU Brandts, J
   Charness, G
TI Truth or consequences: An experiment
SO MANAGEMENT SCIENCE
VL 49
IS 1
BP 116
EP 130
DI 10.1287/mnsc.49.1.116.12755
PD JAN 2003
PY 2003
AB This paper presents evidence that the willingness to punish an unfair
   action is sensitive to whether this action was preceded by a deceptive
   message. One player first senda a message indicating an intended play,
   which is either favorable or unfavorable to the other player in the
   game. After the message, the sender, and the receiver play a
   simultaneous 2 x 2 game, in which the sender may or may not play
   according to his message. Outcome cells may, hence, be reached following
   true or false messages. In the third stage, the receiver may (at a cost)
   punish or reward, depending on which cell of the simultaneous game has
   been reached. We test whether receivers' rates of monetary sacrifice
   depend on the process by which an outcome is reached. We study two
   decision-elicitation methods: the strategy and the direct response
   methods. For each method, deception more than doubles the punishment
   rate as a response to an action that is unfavorable to the receiver. We
   also find evidence that 17-25% of all participants choose to reward a
   favorable action choice made by the sender, even though doing so leaves
   one at a payoff disadvantage. Our results reflect on current economic
   models of utility and have implications for organizational
   decision-making behavior.
OI Brandts, Jordi/0000-0001-9082-9258
ZS 0
ZB 2
ZR 0
Z8 0
ZA 0
TC 93
Z9 93
SN 0025-1909
EI 1526-5501
UT WOS:000182094000009
ER

PT J
AU Heikkinen, VP
TI Timber harvesting as a part of the portfolio management: A multiperiod
   stochastic optimisation approach
SO MANAGEMENT SCIENCE
VL 49
IS 1
BP 131
EP 142
DI 10.1287/mnsc.49.1.131.12752
PD JAN 2003
PY 2003
AB A multiperiod stochastic optimization model is formulated for a land
   owner who can speculate between investing harvesting income in financial
   assets and postponing harvesting. This paper demonstrates the benefits
   from using a multiperiod model, the effects of cointegration on optimal
   portfolio, and the differences between the timber harvesting model and
   the standard financial portfolio optimisation model. The demonstrations
   are made partly by using a real Finnish forest and price data, and
   partly by using artificial data. In the real data example, the system is
   demonstrated using a case where it is assumed that the land owner has
   several mature forest stands, which can be harvested at any time during
   the next 3 years. Investment alternatives are stocks, government bonds,
   and bank deposits. The forestry returns were defined as a sum of
   exponential physical growth and stumpage price return. The chosen
   definition of forestry returns makes the model very useful, for example,
   when speculating on what speed of physical growth is needed to make
   forestry a competitive investment alternative when both returns and
   risks are considered.
ZR 0
Z8 2
ZB 7
ZA 0
TC 10
ZS 0
Z9 13
SN 0025-1909
UT WOS:000182094000010
ER

PT J
AU Hopp, WJ
TI From the editor
SO MANAGEMENT SCIENCE
VL 49
IS 1
BP V
EP VII
PD JAN 2003
PY 2003
ZB 0
Z8 0
ZS 0
ZR 0
TC 1
Z9 1
SN 0025-1909
UT WOS:000182094000001
ER

PT J
AU Lee, J
TI Innovation and strategic divergence: An empirical study of the US
   pharmaceutical industry from 1920 to 1960
SO MANAGEMENT SCIENCE
VL 49
IS 2
BP 143
EP 159
DI 10.1287/mnsc.49.2.143.12745
PD FEB 2003
PY 2003
AB Today, firms employing two distinct survival strategies-(l) innovation
   and (2) imitation-coexist in the U.S. pharmaceutical industry. History
   indicates that this intraindustry heterogeneity did not exist prior to
   1940. This study empirically investigates the origin of this strategic
   divergence by focusing on changes in firms' R&D inputs and outputs. It
   finds that some U.S. pharmaceutical firms responded to the opportunity
   presented by the discovery of antibiotics in the 1940s by investing more
   in R&D, while many others did not. Over time, the innovators dominated
   in developing new drugs, and the gap between innovators and imitators
   steadily increased. These findings also shed light on "the genesis of
   strategic groups," a phenomenon that is not yet well understood.
TC 34
ZR 0
ZS 1
ZB 0
Z8 2
ZA 0
Z9 36
SN 0025-1909
UT WOS:000182128000001
ER

PT J
AU Raghu, TS
   Sen, PK
   Rao, HR
TI Relative performance of incentive mechanisms: Computational modeling and
   simulation of delegated investment decisions
SO MANAGEMENT SCIENCE
VL 49
IS 2
BP 160
EP 178
DI 10.1287/mnsc.49.2.160.12742
PD FEB 2003
PY 2003
AB This paper evaluates the relative performances of several well-known and
   widely-used incentive mechanisms under controlled experimental
   conditions. The scenario utilized is a delegated investment setting
   where effort and risk aversions contribute to moral hazard among fund
   managers. Analytical intractability of the problem requires a
   computational modeling approach to simulate comparative solutions for
   specific contracts under different parametric settings. Through a
   simulation exercise, we consider multiple agents who decide their
   investment strategy over several consecutive periods. Agents learn about
   estimation and market uncertainty through repeated realizations of
   investment returns. In each sequence of periods, a number of different
   incentive mechanisms based on the agent's communication and/or outcome
   are considered. Results of the computational experiments are presented.
   Our results overwhelmingly show the efficacy of the incentive contracts
   in improving the welfare of the investors. In the presence of an
   estimation risk, when agents learn from their past performances, the
   market volatility interacts with the estimation risk that makes
   risk-sharing arrangements such as limited liability overly important.
   Paying the agent to assume the risk may no longer lead to the best
   performance incentives.
RI Sen, Pradyot/I-7030-2013
OI Sen, Pradyot/0000-0003-4446-2613
TC 12
ZS 0
ZB 0
ZR 0
Z8 2
ZA 0
Z9 14
SN 0025-1909
UT WOS:000182128000002
ER

PT J
AU Lee, J
   Boatwright, P
   Kamakura, WA
TI A Bayesian model for prelaunch sales forecasting of recorded music
SO MANAGEMENT SCIENCE
VL 49
IS 2
BP 179
EP 196
DI 10.1287/mnsc.49.2.179.12744
PD FEB 2003
PY 2003
AB In a situation where several hundred new music albums are released each
   month, producing sales forecasts in a reliable and consistent manner is
   a rather difficult and cumbersome task. The purpose of this study is to
   obtain sales forecasts for a new album before it is introduced. We
   develop a hierarchical Bayesian model based on a logistic diffusion
   process. It allows for the generalization of various adoption patterns
   out of discrete data and can be applied in a situation where the
   eventual number of adopters is unknown. Using sales of previous albums
   along with information known prior to the launch of a new album, the
   model constructs informed priors, yielding prelaunch sales forecasts,
   which are out-of-sample predictions. In the context of new product
   forecasting before introduction, the information we have is limited to
   the relevant background characteristics of a new album. Knowing only the
   general attributes of a new album, the meta-analytic approach proposed
   here provides an informed prior on the dynamics of duration, the effects
   of marketing variables, and the unknown market potential. As new data
   become available, weekly sales forecasts and market size (number of
   eventual adopters) are revised and updated. We illustrate our approach
   using weekly sales data of albums that appeared in Billboard's Top 200
   albums chart from January 1994 to December 1995.
ZA 0
Z8 2
ZS 0
TC 44
ZB 0
ZR 0
Z9 46
SN 0025-1909
UT WOS:000182128000003
ER

PT J
AU Bayus, BL
   Erickson, G
   Jacobson, R
TI The financial rewards of new product introductions in the personal
   computer industry
SO MANAGEMENT SCIENCE
VL 49
IS 2
BP 197
EP 210
DI 10.1287/mnsc.49.2.197.12741
PD FEB 2003
PY 2003
AB Based on data from firms in the personal computer industry, we study the
   effect of new product introductions on three key drivers of firm value:
   profit rate, profit-rate persistence, and firm size as reflected in
   asset growth. Consistent with our theoretical development, we find that
   new product introductions influence profit rate and size; however, we
   find no effect on profit-rate persistence. Interestingly, we also find
   that the effect of new product introductions on profit rate stems from a
   reduction in selling and general administrative expenditure intensity
   rather than through an increase in gross operating return. Notably,
   firms decrease their advertising intensity in the wake of a new product
   introduction. Firm profitability in this industry apparently benefits
   from new product introductions because new products need less marketing
   support than older products.
ZS 3
TC 129
ZB 0
ZA 0
Z8 4
ZR 0
Z9 136
SN 0025-1909
UT WOS:000182128000004
ER

PT J
AU Nerkar, A
TI Old is gold? The value of temporal exploration in the creation of new
   knowledge
SO MANAGEMENT SCIENCE
VL 49
IS 2
BP 211
EP 229
DI 10.1287/mnsc.49.2.211.12747
PD FEB 2003
PY 2003
AB In this paper, knowledge creation is considered as a path-dependent
   evolutionary process that involves recombining knowledge spread over
   time. The findings of the paper suggest that a balance in combining
   current knowledge with the knowledge available across large time spans
   is an important factor that explains the impact of new knowledge. These
   ideas are empirically tested using patent data from the pharmaceutical
   industry. Results from the analysis offer support for the hypotheses
   developed in the paper
ZS 4
ZR 0
TC 269
ZB 13
ZA 0
Z8 17
Z9 290
SN 0025-1909
EI 1526-5501
UT WOS:000182128000005
ER

PT J
AU Jin, X
   Fu, MC
   Xiong, XP
TI Probabilistic error bounds for simulation quantile estimators
SO MANAGEMENT SCIENCE
VL 49
IS 2
BP 230
EP 246
DI 10.1287/mnsc.49.2.230.12743
PD FEB 2003
PY 2003
AB Quantile estimation has become increasingly important, particularly in
   the financial industry, where value at risk (VaR) has emerged as a
   standard measurement tool for controlling portfolio risk. In this paper,
   we analyze the probability that a simulation-based quantile estimator
   fails to lie in a prespecified neighborhood of the true quantile. First,
   we show that this error probability converges to zero exponentially fast
   with sample size for negatively dependent sampling. Then we consider
   stratified quantile estimators and show that the error probability for
   these estimators can be guaranteed to be 0 with sufficiently large, but
   finite, sample size. These estimators, however, require sample sizes
   that grow exponentially in the problem dimension. Numerical experiments
   on a simple VaR example illustrate the potential for variance reduction.
RI Fu, Michael C/N-4098-2013
OI Fu, Michael C/0000-0003-2105-4932
ZR 0
ZS 0
ZA 0
Z8 0
ZB 0
TC 26
Z9 26
SN 0025-1909
UT WOS:000182128000006
ER

PT J
AU Axsater, S
TI Note: Optimal policies for serial inventory systems under fill rate
   constraints
SO MANAGEMENT SCIENCE
VL 49
IS 2
BP 247
EP 253
PD FEB 2003
PY 2003
AB A continuous review serial production/distribution system with discrete
   compound Poisson demand for the end product is considered. Unmet demand
   is back-ordered. Production/transportation times are constant. All
   deliveries from one stage to the next must be multiples of given batch
   sizes. We consider the problem of minimizing the holding costs under a
   fill rate constraint. Using recent results by Chen (2000), we show that
   under a set of restricted but plausible assumptions, the optimal policy
   is an echelon stock multistage (R, nQ) policy with one of the reorder
   points varying over time. We provide a simple procedure for the
   determination of the optimal policy.
Z8 0
ZB 0
TC 19
ZS 0
ZR 0
ZA 0
Z9 19
SN 0025-1909
UT WOS:000182128000007
ER

PT J
AU Ozer, O
TI Replenishment strategies for distribution systems under advance demand
   information
SO MANAGEMENT SCIENCE
VL 49
IS 3
BP 255
EP 272
PD MAR 2003
PY 2003
AB Customers with positive demand lead times place orders in advance of
   their needs. A portfolio of customers with different demand lead times
   gives rise to what we call advance demand information. We develop
   effective inventory policies for a distribution system to account for
   this information. In particular, we study a centralized system with one
   warehouse serving multiple retailers under advance demand information.
   The inventory manager replenishes the warehouse from an outside
   supplier: Units arriving to the warehouse are allocated to the
   retailers. To control this system, we develop a lower bound and proposed
   a close-to-optimal heuristic for which the optimality gap is on average
   1.92%. We also provide a closed-form solution to approximate the
   system-wide inventory level. Using this explicit solution, the model and
   the heuristic, we investigate (1) the benefit of advance demand
   information, and its impact on allocation decisions, (2) the joint role
   of risk pooling and advance demand information, and (3) the system
   performance with respect to supplier and retailer lead times. We
   illustrate how advance demand information can be a substitute for lead
   times and inventory, and how it enhances the outcome of delayed
   differentiation.
OI Ozer, Ozalp/0000-0001-5552-0968
Z8 3
ZR 0
ZA 0
ZB 1
TC 80
ZS 1
Z9 83
SN 0025-1909
UT WOS:000181969400001
ER

PT J
AU Devaraj, S
   Kohli, R
TI Performance impacts of information technology: Is actual usage the
   missing link?
SO MANAGEMENT SCIENCE
VL 49
IS 3
BP 273
EP 289
DI 10.1287/mnsc.49.3.273.12736
PD MAR 2003
PY 2003
AB The relationship between investment in information technology (IT) and
   its effect on organizational performance continues to interest academics
   and practitioners. In many cases, due to the nature of the research
   design employed, this stream of research has been unable to identify the
   impact of individual technologies on organizational performance. This
   study posits that the driver of IT impact is not the investment in the
   technology, but the actual usage of the technology. This proposition is
   tested in a longitudinal setting of a healthcare system comprising eight
   hospitals.
   Monthly data for a three-year period on various financial and
   nonfinancial measures of hospital performance and technology usage were
   analyzed. The data analysis provides evidence for the technology
   usage-performance link after controlling for various external factors.
   Technology usage was positively and significantly associated with
   measures of hospital revenue and quality, and this effect occurred after
   time lags. The analysis was triangulated using three measures of
   technology usage. The general support for the principal proposition of
   this paper that "actual usage" may be a key variable in explaining the
   impact of technology on performance suggests that omission of this
   variable may be a missing link in IT payoff analyses.
ZA 2
ZS 4
Z8 8
ZB 9
ZR 0
TC 606
Z9 618
SN 0025-1909
EI 1526-5501
UT WOS:000181969400002
ER

PT J
AU Rivkin, JW
   Siggelkow, N
TI Balancing search and stability: Interdependencies among elements of
   organizational design
SO MANAGEMENT SCIENCE
VL 49
IS 3
BP 290
EP 311
DI 10.1287/mnsc.49.3.290.12740
PD MAR 2003
PY 2003
AB We examine how and why elements of organizational design depend on one
   another. An agent-based simulation allows us to model three design
   elements and two contextual variables that have rarely been analyzed
   jointly: a vertical hierarchy that reviews proposals from subordinates,
   an incentive system that rewards subordinates for departmental or
   firm-wide performance, the decomposition of an organization's many
   decisions into departments, the underlying pattern of interactions among
   decisions, and limits on the ability of managers to process information.
   Interdependencies arise among these features because of a basic, general
   tension. To be successful, an organization must broadly search for good
   sets of decisions, but it must also stabilize around good decisions once
   discovered. An effective organization balances search and stability. We
   identify sets of design elements that encourage broad search and others
   that promote stability. The adoption of elements that encourage broad
   search typically raises the marginal benefit of other elements that
   provide offsetting stability. Hence, the need to balance search and
   stability generates interdependencies among the design elements. We pay
   special attention to interdependencies that involve the vertical
   hierarchy. Our findings confirm :many aspects of conventional wisdom
   about vertical hierarchies, but challenge or put boundary conditions on
   others. We place limits, for instance, on the received wisdom that
   firm-wide incentives and capable subordinates make top-level oversight
   less valuable. We also identify circumstances in which vertical
   hierarchies can lead to inferior long-term performance.
ZS 0
Z8 12
ZA 0
ZR 0
TC 376
ZB 5
Z9 387
SN 0025-1909
EI 1526-5501
UT WOS:000181969400003
ER

PT J
AU Baesens, B
   Setiono, R
   Mues, C
   Vanthienen, J
TI Using neural network rule extraction and decision tables for credit-risk
   evaluation
SO MANAGEMENT SCIENCE
VL 49
IS 3
BP 312
EP 329
DI 10.1287/mnsc.49.3.312.12739
PD MAR 2003
PY 2003
AB Credit-risk evaluation is a very challenging and important management
   science problem in the domain of financial analysis. Many classification
   methods have been suggested in the literature to tackle this problem.
   Neural networks, especially, have received a lot of attention because of
   their universal approximation property. However, a major drawback
   associated with the use of neural networks for decision making is their
   lack of explanation capability. While they can achieve a high predictive
   accuracy rate, the reasoning behind how they reach their decisions is
   not readily available. In this paper, we present the results from
   analysing three real-life credit-risk data sets using neural network
   rule extraction techniques. Clarifying the neural network decisions by
   explanatory rules that capture the learned knowledge embedded in the
   networks can help the credit-risk manager in explaining why a particular
   applicant is classified. as either bad or good. Furthermore, we also
   discuss how these rules can be visualized as a decision table in a
   compact and intuitive graphical format that facilitates easy
   consultation. It is concluded that neural network rule extraction and
   decision tables are powerful management tools that allow us to build
   advanced and user-friendly decision-support systems for credit-risk
   evaluation.
RI Vanthienen, Jan/L-5375-2019; Vanthienen, Jan J/A-1668-2018; Vanthienen, Jan/P-7425-2019; Mues, Christophe/
OI Vanthienen, Jan J/0000-0002-3867-7055; Vanthienen,
   Jan/0000-0002-3867-7055; Mues, Christophe/0000-0002-6289-5490
ZS 4
Z8 10
ZR 0
TC 230
ZB 4
ZA 0
Z9 243
SN 0025-1909
UT WOS:000181969400004
ER

PT J
AU Mohring, RH
   Schulz, AS
   Stork, F
   Uetz, M
TI Solving project scheduling problems by minimum cut computations
SO MANAGEMENT SCIENCE
VL 49
IS 3
BP 330
EP 350
PD MAR 2003
PY 2003
AB In project scheduling, a set of precedence-constrained jobs has to be
   scheduled so as to minimize a given objective. In resource-constrained
   project scheduling, the jobs additionally compete for scarce resources.
   Due to its universality, the latter problem has a variety of
   applications in manufacturing, production planning, project management,
   and elsewhere. It is one of the most intractable problems in operations
   research, and has therefore become a popular playground for the latest
   optimization techniques, including virtually all local search paradigms.
   We show that a somewhat more classical mathematical programming approach
   leads to both competitive feasible solutions and strong lower bounds,
   within reasonable computation times. The basic ingredients of our
   approach are the Lagrangian relaxation of a time-indexed integer
   programming formulation and relaxation-based list scheduling, enriched
   with a useful idea from recent approximation algorithms for machine
   scheduling problems. The efficiency of the algorithm results from the
   insight that the relaxed problem can be solved by computing a minimum
   cut in an appropriately defined directed graph. Our computational study
   covers different types of resource-constrained project scheduling
   problems, based on several notoriously hard test sets, including
   practical problem instances from chemical production planning.
Z8 4
ZA 0
ZR 1
TC 111
ZS 0
ZB 2
Z9 115
SN 0025-1909
UT WOS:000181969400005
ER

EF