FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU BORDLEY, R
   HAZEN, GB
TI SSB AND WEIGHTED LINEAR UTILITY AS EXPECTED UTILITY WITH SUSPICION
SO MANAGEMENT SCIENCE
VL 37
IS 4
BP 396
EP 408
DI 10.1287/mnsc.37.4.396
PD APR 1991
PY 1991
AB We show that a "suspicious" subjective expected utility (SEU) maximizer,
   i.e., one who treats potential consequences of states as information
   useful in assessing the probability of those states, may under
   reasonable circumstances act as though he were maximizing either
   weighted linear utility, or skew-symmetric bilinear (SSB) utility.  SEU
   with suspicion, therefore, explains at least as many empirical
   violations of SEU theory as do these and similar models.  We give
   examples to illustrate how several important types of SEU violations may
   seem to arise when suspicion is present.
RI Hazen, Gordon/B-7463-2009
ZS 0
ZB 0
Z8 0
ZR 0
TC 12
Z9 12
SN 0025-1909
UT WOS:A1991FM18400002
ER

PT J
AU CAMPBELL, GM
   MABERT, VA
TI CYCLICAL SCHEDULES FOR CAPACITATED LOT SIZING WITH DYNAMIC DEMANDS
SO MANAGEMENT SCIENCE
VL 37
IS 4
BP 409
EP 427
DI 10.1287/mnsc.37.4.409
PD APR 1991
PY 1991
AB Cyclical scheduling, where the time between production periods for each
   item is constant, offers simplicity and ease of control compared with
   noncyclical scheduling, where production periods are irregularly spaced.
   However, when demands are dynamic, flexibility in the spacing of
   production periods permits noncyclical scheduling to result in lower
   total costs.  This study investigates the additional cost of cyclical
   scheduling.
   We focus upon the capacitated lot sizing problem (CLSP), which deals
   with planning production on a single, capacitated machine serving
   multiple items with dynamic demands.  To establish cyclical schedules, a
   mathematical programming model is developed along with a heuristic
   solution technique and a Lagrangian-based lower bounding procedure.  For
   problems solved in this study, differences between solution costs and
   lower bounds average less than 1%.
   Experiments are performed to evaluate the heuristic technique and to
   compare cyclical schedules with noncyclical ones.  For comparison
   purposes, a noncyclical heuristic and problem sets from the literature
   are used.  New problems based upon operating data from Ford Motor
   Company are also generated and solved.  In this study, cyclical
   schedules average 4.4% higher in cost than, noncyclical ones. 
   Coefficient of demand variation most seriously influences differences in
   costs.  Other significant factors include capacity utilization, setup
   time, time between orders, and number of items.
Z8 0
ZB 0
ZR 0
TC 30
ZA 0
ZS 0
Z9 30
SN 0025-1909
UT WOS:A1991FM18400003
ER

PT J
AU RAMASESH, RV
   ORD, JK
   HAYYA, JC
   PAN, A
TI SOLE VERSUS DUAL SOURCING IN STOCHASTIC LEAD-TIME (S, Q) INVENTORY
   MODELS
SO MANAGEMENT SCIENCE
VL 37
IS 4
BP 428
EP 443
DI 10.1287/mnsc.37.4.428
PD APR 1991
PY 1991
AB When supply lead times are uncertain, the simultaneous procurement from
   two sources offers savings in inventory holding and shortage costs. 
   Economics are achieved if these savings outweigh the increase in
   ordering costs.  In this paper we analyze dual sourcing in the context
   of the "reorder point, order quantity" inventory model with constant
   demand and stochastic lead times and compare it with single sourcing. 
   Two cases are studied, using the uniform and the exponential
   distributions, which may be thought of as two extreme ways of
   representing stochastic lead times.  In our two-vendor model, the order
   quantity is split equally between the two vendors and the split orders
   are placed simultaneously when the inventory position reaches the
   reorder level.  A comparison of the total expected costs suggests that
   when the uncertainty in the lead times is high and the ordering costs
   are low, dual sourcing could be cost effective.
ZB 1
ZA 0
ZR 0
ZS 0
Z8 6
TC 152
Z9 157
SN 0025-1909
UT WOS:A1991FM18400004
ER

PT J
AU SARKAR, D
   ZANGWILL, WI
TI VARIANCE EFFECTS IN CYCLIC PRODUCTION SYSTEMS
SO MANAGEMENT SCIENCE
VL 37
IS 4
BP 444
EP 453
DI 10.1287/mnsc.37.4.444
PD APR 1991
PY 1991
AB Utilizing a cyclic queue system, this paper investigates the effect of
   variance on a multi-item production facility.  The variance of setup
   time, service rate and arrival rate is shown to have a powerful and
   sometimes paradoxical influence.  Reduction in setup time, for example,
   is usually presumed to reduce inventory.  We demonstrate that inventory
   can blow up if setup time is cut.  Another paradoxical effect of
   variance is on processing rate.  Speeding up the processing rate should
   reduce the material waiting to be processed.  Again we show that the
   opposite can hold.  Other properties of variance are examined, such as
   its relationship to KAIZEN and Just-In-Time production practices, and
   especially its property of impairing capacity.
ZS 0
ZA 0
ZB 0
ZR 1
Z8 0
TC 39
Z9 40
SN 0025-1909
UT WOS:A1991FM18400005
ER

PT J
AU SCHWEITZER, PJ
   SEIDMANN, A
TI OPTIMIZING PROCESSING RATES FOR FLEXIBLE MANUFACTURING SYSTEMS
SO MANAGEMENT SCIENCE
VL 37
IS 4
BP 454
EP 466
DI 10.1287/mnsc.37.4.454
PD APR 1991
PY 1991
AB This paper introduces the generic concept of processing rates as
   decision variables in Flexible Manufacturing Systems (FMS's).  The
   objective is to determine the minimum cost processing rates given the
   FMS throughout target, the work-in-process level, part routes,
   transporter delays, and the variable capacity cost function for each
   machine.  A nonlinear Mean Value Analysis queueing network optimization
   methodology is developed to control bottlenecks and queue lengths as the
   processing rates are varied.  This methodology further provides the
   average and marginal unit production costs along with necessary and
   sufficient feasibility conditions for the FMS throughput targets. 
   Industrial sample data is then used to illustrate the solution of the
   optimal tool speed problem in a metal-cutting FMS.  Considerable cost
   savings are demonstrated using the proposed methodology in contrast with
   the conventional one-machine optimization models.  Several economic
   insights regarding the issues of capacity allocation for FMS's, and a
   generalization of the square root capacity allocation rule for closed
   networks of queues, are also presented.
TC 69
ZS 0
ZR 0
ZA 0
ZB 1
Z8 1
Z9 70
SN 0025-1909
UT WOS:A1991FM18400006
ER

PT J
AU MANDELL, MB
TI MODELING EFFECTIVENESS-EQUITY TRADE-OFFS IN PUBLIC-SERVICE DELIVERY
   SYSTEMS
SO MANAGEMENT SCIENCE
VL 37
IS 4
BP 467
EP 482
DI 10.1287/mnsc.37.4.467
PD APR 1991
PY 1991
AB Distributional equity is a particularly salient objective in public
   sector decision making in general, and decision making concerning the
   delivery of public services such as education, libraries, sanitation,
   and public safety in particular.  In this paper two related bicriteria
   mathematical programming models are developed for identifying the
   trade-offs between overall output (effectiveness) and equity that result
   from alternative allocations of service resources among different
   service delivery sites (branches).  The models developed here
   incorporate equity in a more satisfactory manner than have previous
   efforts.  An illustrative application of the models to the allocation of
   new books among the branches of a public library system is presented.
ZB 0
ZA 0
ZS 0
ZR 0
Z8 4
TC 71
Z9 74
SN 0025-1909
UT WOS:A1991FM18400007
ER

PT J
AU HENNART, JF
TI THE TRANSACTION COSTS THEORY OF JOINT VENTURES - AN EMPIRICAL-STUDY OF
   JAPANESE SUBSIDIARIES IN THE UNITED-STATES
SO MANAGEMENT SCIENCE
VL 37
IS 4
BP 483
EP 497
DI 10.1287/mnsc.37.4.483
PD APR 1991
PY 1991
AB This paper offers the first large sample empirical study of the factors
   which influence the choice of Japanese firms between full or partial
   ownership of their U.S. manufacturing subsidiaries.  It studies for the
   first time the ownership policies of investors of a single home country
   in a single host country, thus keeping variations within home and host
   countries constant.  One methodological improvement over previous
   studies is the use as independent variables of the relevant
   characteristics of the investing firms.  These had been proxied in
   previous studies by data on U.S. industries entered.
   The results suggest that the degree of ownership taken by Japanese
   manufacturing investors in their American subsidiaries is driven by the
   same general transaction costs variables that determine the choices made
   by the U.S. counterparts:  Japanese parents joint venture when they need
   to combine with other firms intermediate inputs which are subject to
   high market transaction costs.  An intriguing result, however, is the
   lack of significance of two variables which, in the U.S. case, strongly
   push towards full control of foreign subsidiaries.  In this study
   neither the Japanese parent's R&D nor its advertising intensities had
   any significant impact on their ownership policies.
ZB 2
ZS 7
ZR 1
TC 541
ZA 0
Z8 15
Z9 562
SN 0025-1909
UT WOS:A1991FM18400008
ER

PT J
AU BUNN, D
   WRIGHT, G
TI INTERACTION OF JUDGMENTAL AND STATISTICAL FORECASTING METHODS - ISSUES
   AND ANALYSIS
SO MANAGEMENT SCIENCE
VL 37
IS 5
BP 501
EP 518
DI 10.1287/mnsc.37.5.501
PD MAY 1991
PY 1991
AB This paper reviews several of the current controversies in the relative
   value of judgemental and statistical forecasting methods.  Where expert,
   informed judgemental forecasts are being used, a critical analysis of
   the evidence suggests that their quality is higher than many researchers
   have previously asserted, and circumstances favourable to this are
   identified.  The issue of the interaction of judgemental and statistical
   method is, however, identified as a more worthwhile line of inquiry, and
   research in this area is reviewed, differentiating approaches aimed at
   synthesising both of these inputs.
RI Bunn, Derek W/P-5247-2016; Wright, George/D-8927-2012
ZB 2
Z8 1
TC 117
ZS 2
ZA 0
ZR 0
Z9 119
SN 0025-1909
UT WOS:A1991FP77200001
ER

PT J
AU KONNO, H
   YAMAZAKI, H
TI MEAN-ABSOLUTE DEVIATION PORTFOLIO OPTIMIZATION MODEL AND ITS
   APPLICATIONS TO TOKYO STOCK-MARKET
SO MANAGEMENT SCIENCE
VL 37
IS 5
BP 519
EP 531
DI 10.1287/mnsc.37.5.519
PD MAY 1991
PY 1991
AB The purpose of this paper is to demonstrate that a portfolio
   optimization model using the L1 risk (mean absolute deviation risk)
   function can remove most of the difficulties associated with the
   classical Markowitz's model while maintaining its advantages over
   equilibrium models.  In particular, the L1 risk model leads to a linear
   program instead of a quadratic program, so that a large-scale
   optimization problem consisting of more than 1,000 stocks may be solved
   on a real time basis.  Numerical experiments using the historical data
   of NIKKEI 225 stocks show that the L1 risk model generates a portfolio
   quite similar to that of the Markowitz's model within a fraction of time
   required to solve the latter.
ZS 6
Z8 66
ZR 1
ZB 12
ZA 0
TC 715
Z9 786
SN 0025-1909
UT WOS:A1991FP77200002
ER

PT J
AU AMIT, R
   LIVNAT, J
   ZAROWIN, P
TI ACCOUNTING IMPLICATIONS OF CORPORATE DIVERSIFICATION
SO MANAGEMENT SCIENCE
VL 37
IS 5
BP 532
EP 545
DI 10.1287/mnsc.37.5.532
PD MAY 1991
PY 1991
AB This study investigates the direct effects of corporate diversification
   on accounting reports, and the implications of these effects for
   accounting research.  The study shows that firms which diversify into
   unrelated areas of business devote a larger proportion of their capital
   investments to acquisitions and are, therefore, characterized by smaller
   differences between replacement-cost and historical-cost values of
   assets than undiversified firms.  The implications of these findings, as
   well as other operating characteristics of diversified firms, for the
   following areas of accounting research are subsequently examined.
   (1) Inflation-adjusted data.  Inflation-adjusted data of diversified
   firms have less incremental information content (beyond historical-cost)
   than those of undiversified firms.
   (2) Earnings Response Coefficients.  Diversified firms have stronger
   market associations with earnings changes, and their earnings are more
   persistent.
   (3) Selection of accounting methods.  Diversified firms select, ceteris
   paribus, more liberal accounting methods than their undiversified
   counterparts.
TC 2
ZB 0
ZA 0
Z8 0
ZR 0
ZS 0
Z9 2
SN 0025-1909
UT WOS:A1991FP77200003
ER

PT J
AU DEGROOT, MH
   MORTERA, J
TI OPTIMAL LINEAR OPINION POOLS
SO MANAGEMENT SCIENCE
VL 37
IS 5
BP 546
EP 558
DI 10.1287/mnsc.37.5.546
PD MAY 1991
PY 1991
AB Consider a decision problem involving a group of m Bayesians in which
   each member reports his/her posterior distribution for some random
   variable theta.  The individuals all share a common prior distribution
   for theta and a common loss function, but form their posterior
   distributions based on different data sets.  A single distribution of
   theta must be chosen by combining the individual posterior distributions
   in some type of opinion pool.  In this paper, the optimal pool is
   presented when the data observed by the different members of the group
   are conditionally independent given theta.  When the data are not
   conditionally independent, the optimal weights to be used in a linear
   opinion pool are determined for problems involving quadratic loss
   functions and arbitrary distributions for theta and the data. 
   Properties of the optimal procedure are developed and some examples are
   discussed.
Z8 0
ZR 0
ZA 0
ZS 0
TC 12
ZB 0
Z9 12
SN 0025-1909
UT WOS:A1991FP77200004
ER

PT J
AU YOUNG, SC
   SMITH, JQ
TI DERIVING AND ANALYZING OPTIMAL STRATEGIES IN BAYESIAN MODELS OF GAMES
SO MANAGEMENT SCIENCE
VL 37
IS 5
BP 559
EP 571
DI 10.1287/mnsc.37.5.559
PD MAY 1991
PY 1991
AB Wilson (1986) gives a backwards induction algorithm for sequentially
   obtaining the optimal next move in a repeated Bayesian game.  In this
   paper we show how to identify the form of an optimal solution of such a
   game by a graphical procedure.  By means of the Prisoner's Dilemma game,
   we illustrate how Wilson's algorithm can be enhanced using the derived
   analytic form of the solution to produce an explicit optimal strategy. 
   We can then determine not only how P1 should play on all subsequent
   moves of the game, but also use ideas of Bayes rationality to discuss
   whether a given model of P2's reactions is realistic.
ZR 0
ZA 0
Z8 0
ZB 0
ZS 0
TC 1
Z9 1
SN 0025-1909
UT WOS:A1991FP77200005
ER

PT J
AU YANO, CA
   RACHAMADUGU, R
TI SEQUENCING TO MINIMIZE WORK OVERLOAD IN ASSEMBLY LINES WITH PRODUCT
   OPTIONS
SO MANAGEMENT SCIENCE
VL 37
IS 5
BP 572
EP 586
DI 10.1287/mnsc.37.5.572
PD MAY 1991
PY 1991
AB We address the problem of sequencing jobs, each of which is
   characterized by one of a large number of possible combinations of
   customer-specified options, on a paced assembly line.  These problems
   arise frequently in the automotive industry.  One job must be launched
   into the system at equal time intervals, where the time interval (or
   cycle time) is prespecified.  The problem is to sequence the jobs to
   maximize the total amount of work completed, or equivalently, to
   minimize the total amount of incomplete work (or work overload).
   Since there is a large number of option combinations, each job is almost
   unique.  This fact precludes the use of existing mixed model assembly
   line sequencing techniques.  We first consider the sequencing problem
   for a single station which can perform two different sets of operations.
   We characterize the optimal solution for this problem and use the
   results as the basis for a heuristic procedure for multiple stations. 
   Computational results with data from a major automobile company are
   reported.
ZS 0
TC 144
ZA 0
Z8 6
ZR 0
ZB 0
Z9 150
SN 0025-1909
UT WOS:A1991FP77200006
ER

PT J
AU MATSUO, H
   SHANG, JS
   SULLIVAN, RS
TI A CRANE SCHEDULING PROBLEM IN A COMPUTER-INTEGRATED MANUFACTURING
   ENVIRONMENT
SO MANAGEMENT SCIENCE
VL 37
IS 5
BP 587
EP 606
DI 10.1287/mnsc.37.5.587
PD MAY 1991
PY 1991
AB This paper addresses a crane scheduling and machine layout problem in a
   Computer Integrated Manufacturing (CIM) Environment.  A single crame is
   used to move all the Work-in-Process (WIP) in the system.  The overall
   system objective is to maximize the yield rate subject to the flow time
   limit of the WIP.  We formalize the problem, and analytically and
   empirically show that cyclic scheduling provides a near optimal
   solution, which is superior to dispatching rules.  First, we illustrate
   the optimality and benefits of cyclic scheduling in a simple
   environment.  Then, for multiple-product problems, we show that for a
   given sequence, finding the minimum cycle time becomes the maximum cost
   circular network flow problem in a graph.  Based on the insights
   developed, a heuristic for sequencing product types in a cycle is
   derived that approximately minimizes the cycle time over all sequences. 
   Finally, computational experiments are reported and various assertions
   made in the paper are empirically verified.
Z8 1
ZB 0
ZS 0
ZR 0
TC 33
ZA 0
Z9 34
SN 0025-1909
UT WOS:A1991FP77200007
ER

PT J
AU OLIVA, TA
TI INFORMATION AND PROFITABILITY ESTIMATES - MODELING THE FIRMS DECISION TO
   ADOPT A NEW TECHNOLOGY
SO MANAGEMENT SCIENCE
VL 37
IS 5
BP 607
EP 623
DI 10.1287/mnsc.37.5.607
PD MAY 1991
PY 1991
AB This paper uses a response surface based on catastrophe theory to
   examine the interaction of information and profitability estimates on
   the firm's adoption of a new technology or innovation.  As such, the
   paper builds on the conceptual ideas behind McCardle's (1985) work.  An
   illustrative example using simulated data is presented to indicate how
   one might operationalize the key constructs for the purpose of
   estimating the model.
ZR 0
ZA 0
TC 21
ZB 0
ZS 0
Z8 0
Z9 21
SN 0025-1909
UT WOS:A1991FP77200008
ER

PT J
AU WHITT, W
TI THE EFFICIENCY OF ONE LONG-RUN VERSUS INDEPENDENT REPLICATIONS IN
   STEADY-STATE SIMULATION
SO MANAGEMENT SCIENCE
VL 37
IS 6
BP 645
EP 666
DI 10.1287/mnsc.37.6.645
PD JUN 1991
PY 1991
AB We evaluate the efficiency of one long run versus independent
   replications in steady-state discrete-event simulation, assuming that an
   initial portion of each replication will be deleted to allow the process
   to approach steady state.  We provide supporting evidence in favor of
   one long run, but we also show that multiple replications can be more
   efficient.  The advantage of one long run increases if the amount
   deleted increases or if the covariance function decreases more quickly
   (assuming it is nonnegative and decreasing).  Thus, assuming that the
   amount deleted depends on the way the process approaches steady state,
   one long run tends to be efficient when the covariance function decays
   rapidly compared to the rate the process approaches steady state.  We
   also discuss ways to determine the initial portion to delete.  We
   consider the case of an exponential covariance function in detail, and
   use it as a basis for approximations.  We also consider the M/G/infinity
   queueing model and reflected Brownian motion, the latter as an
   approximation for the G/G/1 queueing model.  For these models starting
   at the origin, one long run is efficient, but a moderate number of
   independent replications is essentially equally efficient.  In agreement
   with Kelton and Law (1984), for such examples our analysis only rules
   out many replications of very short runs.
RI Whitt, Ward/D-5337-2013
OI Whitt, Ward/0000-0003-4298-9964
Z8 0
ZB 0
TC 39
ZA 0
ZS 0
ZR 0
Z9 39
SN 0025-1909
UT WOS:A1991FX70100002
ER

PT J
AU SRINIVASAN, MM
TI NONDETERMINISTIC POLLING SYSTEMS
SO MANAGEMENT SCIENCE
VL 37
IS 6
BP 667
EP 681
DI 10.1287/mnsc.37.6.667
PD JUN 1991
PY 1991
AB A nondeterministic polling system is considered in which a single server
   serves a number of stations.  The service discipline at each station is,
   consistently, either nonexhaustive, semiexhaustive, gated, or
   exhaustive.  If the server polls a station i which uses either the
   nonexhaustive or the semiexhaustive service discipline, then the next
   station polled is station j with probability p(ij) if there was service
   at station i.  The service time at station i is a random variable which
   may depend on the station polled next.  If no service is performed at
   station i, then the next station polled is station j with probability
   e(ij).  The time to switch between stations i and j is a random variable
   which may depend on whether service was performed at station i or not.
   If the server polls a station i that follows either the exhaustive
   service discipline or the gated service discipline, then the next
   station polled is station j with probability p(ij) regardless of whether
   there was service at station i or not.
   Cycle times and stability conditions are derived for this system, and
   Conservation Laws are obtained which express a weighted sum of the mean
   waiting times in terms of known data parameters.  For systems with a mix
   of exhaustive and gated service stations, we show how the individual
   mean waiting times can be obtained.
TC 21
ZR 1
ZS 0
ZB 0
ZA 0
Z8 0
Z9 22
SN 0025-1909
UT WOS:A1991FX70100003
ER

PT J
AU MONTREUIL, B
   VENKATADRI, U
TI STRATEGIC INTERPOLATIVE DESIGN OF DYNAMIC MANUFACTURING SYSTEMS LAYOUTS
SO MANAGEMENT SCIENCE
VL 37
IS 6
BP 682
EP 694
DI 10.1287/mnsc.37.6.682
PD JUN 1991
PY 1991
AB This paper presents a proactive strategic methodology for designing
   dynamic layouts for the expansion (or decline) phase of manufacturing
   systems.  The methodology first estimates probable scenarios of the
   system requirements at its maturity level, strategically designs mature
   layouts given the set of scenarios, then tactically interpolates
   intermediate layouts, backward to the initial facilities plan.
   For manufacturing systems with rigid facilities, the paper provides a
   linear programming model sustaining this proactive strategic
   methodology.  The model efficiently generates optimal layouts for all
   intermediate expansion phases given a goal layout for the final mature
   phase of the expansion plan, the phased cell sets, the phased flow and
   relationships sets, and various design constraints, for an array of
   objectives.
ZA 0
ZS 0
ZB 0
Z8 1
ZR 0
TC 46
Z9 47
SN 0025-1909
UT WOS:A1991FX70100004
ER

PT J
AU GAVISH, B
   PIRKUL, H
TI ALGORITHMS FOR THE MULTI-RESOURCE GENERALIZED ASSIGNMENT PROBLEM
SO MANAGEMENT SCIENCE
VL 37
IS 6
BP 695
EP 713
DI 10.1287/mnsc.37.6.695
PD JUN 1991
PY 1991
AB The multi-resource generalized assignment problem is encountered when a
   set of tasks have to be assigned to a set of agents in a way that
   permits assignment of multiple tasks to an agent subject to the
   availability of a set of multiple resources consumed by that agent. 
   This problem differs from the generalized assignment problem in that an
   agent consumes not just one but a variety of resources in performing the
   tasks assigned to him.
   This paper develops effective solution procedures for the multi-resource
   generalized assignment problem.  Various relaxations of the problem are
   studied and theoretical relations among these relaxations are pointed
   out.  Rules for reducing problem size are discussed and are shown to be
   effective through computational experiments.  Heuristic solution
   procedures and an efficient branch and bound procedure are developed. 
   Results of computational experiments testing these procedures are
   reported.
ZS 0
ZA 0
Z8 1
ZB 0
TC 74
ZR 0
Z9 74
SN 0025-1909
UT WOS:A1991FX70100005
ER

PT J
AU GORDON, KJ
   GORDON, RF
   KUROSE, JF
   MACNAIR, EA
TI AN EXTENSIBLE VISUAL ENVIRONMENT FOR CONSTRUCTION AND ANALYSIS OF
   HIERARCHICALLY-STRUCTURED MODELS OF RESOURCE CONTENTION SYSTEMS
SO MANAGEMENT SCIENCE
VL 37
IS 6
BP 714
EP 732
DI 10.1287/mnsc.37.6.714
PD JUN 1991
PY 1991
AB The development of models for evaluating the performance of resource
   contention systems, such as manufacturing systems, computer systems, and
   communication networks, is often a difficult and complex task.  This
   modeling effort can be dramatically reduced by the use of appropriate
   software tools.  The Research Queueing Package Modeling Environment
   (RESQME) provides a graphical environment for constructing, solving, and
   analyzing the results of extended queueing network models of resource
   contention systems.  It supports a rich underlying modeling paradigm
   previously developed in the Research Queueing Package (RESQ) and
   provides a single integrated graphical interface throughout all tasks of
   the modeling lifecycle.  In this paper we present a brief overview of
   RESQME and then focus on two of its most important features:  the
   construction and analysis of hierarchically-structured models and the
   ability to extend and customize the RESQME environment for
   domain-specific modeling via the use of user-defined modeling elements. 
   A manufacturing model is developed in order to illustrate these
   capabilities.
ZB 0
ZA 0
ZR 0
TC 3
Z8 0
ZS 0
Z9 3
SN 0025-1909
UT WOS:A1991FX70100006
ER

PT J
AU ALI, AI
   COOK, WD
   SEIFORD, LM
TI STRICT VS WEAK ORDINAL RELATIONS FOR MULTIPLIERS IN DATA ENVELOPMENT
   ANALYSIS
SO MANAGEMENT SCIENCE
VL 37
IS 6
BP 733
EP 738
DI 10.1287/mnsc.37.6.733
PD JUN 1991
PY 1991
AB In a recent paper, Golany (1988) proposes an interesting extension of
   Data Envelopment Analysis to the situation where ordinal relations among
   weights corresponding to certain dimensions exist. However, the
   development of the extended model contains mathematical errors and the
   proposed equivalence is incorrect.
   We establish the correct model equivalence and prove that weak ordinal
   relations require a nonstandard DEA model. We also show that the case of
   strict ordinal relations can be handled with the standard DEA model.
   These results hold for the CCR, BCC, additive, and multiplicative models
   and for relations involving both input and output multipliers.
ZA 0
ZR 0
TC 36
ZS 0
Z8 2
ZB 1
Z9 38
SN 0025-1909
EI 1526-5501
UT WOS:A1991FX70100007
ER

PT J
AU CARRILLO, MJ
TI EXTENSIONS OF PALM THEOREM - A REVIEW
SO MANAGEMENT SCIENCE
VL 37
IS 6
BP 739
EP 744
DI 10.1287/mnsc.37.6.739
PD JUN 1991
PY 1991
AB This note reviews the transient behavior the M/G/infinity queue with
   nonhomogeneous Poisson or compound Poisson input and nonstationary
   service distribution.  In the case of nonhomogeneous Poisson input, the
   number of customers in the queueing system over time turns out to have a
   Poisson distribution.  The generality of the nonhomogeneity /
   nonstationarity assumptions and the ease of use of the resulting Poisson
   distribution broaden the area of applications for Poisson models.  These
   results have found use in modeling multi-echelon repair systems in
   situations where the number of arrivals or number in service has a
   variance-to-mean ratio of unity (the Poisson case) or greater than
   unity.
Z8 1
ZA 0
ZS 0
ZB 0
TC 17
ZR 0
Z9 18
SN 0025-1909
UT WOS:A1991FX70100008
ER

PT J
AU LEVY, H
TI THE MEAN-COEFFICIENT-OF-VARIATION RULE - THE LOGNORMAL CASE
SO MANAGEMENT SCIENCE
VL 37
IS 6
BP 745
EP 747
DI 10.1287/mnsc.37.6.745
PD JUN 1991
PY 1991
AB The mean-variance (M-V) rule may lead to paradoxical results which may
   be resolved by employing the mean coefficient of variation (M-C) rule. 
   It is shown that the M-C rule constitutes an optimal decision rule for
   lognormal distributions.
ZB 0
ZR 0
ZS 0
TC 5
Z8 0
Z9 5
SN 0025-1909
UT WOS:A1991FX70100009
ER

PT J
AU POWERS, K
   HANSSENS, DM
   HSER, YI
   ANGLIN, MD
TI MEASURING THE LONG-TERM EFFECTS OF PUBLIC-POLICY - THE CASE OF NARCOTICS
   USE AND PROPERTY CRIME
SO MANAGEMENT SCIENCE
VL 37
IS 6
BP 627
EP 644
DI 10.1287/mnsc.37.6.627
PD JUN 1991
PY 1991
AB The effects of treatment and legal supervision on narcotics use and
   criminal activities were assessed by applying newly developed
   time-series methods that disentangle the long-term (permanent) and the
   short-term (temporary) effects of intervention. A multivariate systems
   approach was used to characterize the dynamic interplay of several
   related behaviors at a group level over a long period of time. Five
   variables-abstinence from narcotics use, daily narcotics use (or
   addiction), property crime, methadone maintenance treatment, and legal
   supervision-were derived by aggregating information from over 600
   narcotic addiction histories averaging 12 years in length. Because of
   the long assessment period, age was also included as a control variable.
   Overall, the system dynamics among the variables were characterized by
   long-term rather than short-term relationships. Neither methadone
   maintenance nor legal supervision had short-term effects on narcotics
   use or property crime. Methadone maintenance treatment demonstrated
   long-term benefits by reducing narcotics use and criminal activities.
   Legal supervision, on the other hand, did not reduce either narcotics
   use or property crime in the long run. Instead, there was a positive
   long-term relationship in which a higher level of legal supervision was
   related to higher levels of narcotics use and criminal activity. This
   latter finding is consistent with the observation that either narcotics
   use or criminal activity is likely to bring addicts to the attention of
   the legal system. However, these addicts, as a group, did not directly
   respond to legal supervision by changing their narcotics use or crime
   involvement except perhaps through coerced treatment. The paper explores
   the policy implications of these findings.
RI Hanssens, Dominique M/D-4922-2011
ZR 0
ZS 0
Z8 0
ZB 1
ZA 0
TC 20
Z9 20
SN 0025-1909
EI 1526-5501
UT WOS:A1991FX70100001
ER

PT J
AU FISHBURN, PC
   SARIN, RK
TI DISPERSIVE EQUITY AND SOCIAL RISK
SO MANAGEMENT SCIENCE
VL 37
IS 7
BP 751
EP 769
DI 10.1287/mnsc.37.7.751
PD JUL 1991
PY 1991
AB Dispersive equity is concerned with the impact of life-threatening risks
   from alternative policy decisions on homogeneous groups in a population.
   It is not addressed to the disutility of various numbers of fatalities
   that might occur, but rather to how fatalities are distributed over the
   groups.  Although dispersive equity has long been recognized as an
   important component of some policy decisions, it has received little
   formal treatment within the matrix of salient factors for such
   decisions.  Our purpose is to advance its formal development.
   This is done within a formulation based on probability distributions
   over potential fatality sets.  The formulation gives rise to four
   distinct but not independent equity concepts:  individual risk equity,
   group risk equity, dispersive equity, and social outcome equity.  Each
   of these is analyzed, but special attention is given to dispersive
   equity.  The paper also comments on relationships between total equity
   and its four components, and between total equity and the disutility of
   various numbers of fatalities.
ZS 0
Z8 0
TC 17
ZA 0
ZB 0
ZR 0
Z9 17
SN 0025-1909
UT WOS:A1991GD93300001
ER

PT J
AU PRELEC, D
   LOEWENSTEIN, G
TI DECISION-MAKING OVER TIME AND UNDER UNCERTAINTY - A COMMON APPROACH
SO MANAGEMENT SCIENCE
VL 37
IS 7
BP 770
EP 786
DI 10.1287/mnsc.37.7.770
PD JUL 1991
PY 1991
AB This paper considers a number of parallels between risky and
   intertemporal choice.  We begin by demonstrating a one-to-one
   correspondence between the behavioral violations of the respective
   normative theories for the two domains (i.e., expected utility and
   discounted utility models).  We argue that such violations (or
   preference reversals) are broadly consistent with three propositions
   about the weight that an attribute receives in both types of
   multiattribute choice.  Specifically, it appears that:  (1) if we add a
   constant to all values of an attribute, then that attribute becomes less
   important; (2) if we proportionately increase all values of an
   attribute, or if we change the sign of an attribute, from positive to
   negative, then that attribute becomes more important.  The generality of
   these propositions, as well as the constraints they would impose on
   separable representations of multiattribute preferences, is discussed.
RI Loewenstein, George/G-7616-2014
OI Loewenstein, George/0000-0003-2790-0474
Z8 13
ZS 5
TC 304
ZB 59
ZA 0
ZR 0
Z9 320
SN 0025-1909
UT WOS:A1991GD93300002
ER

PT J
AU PARASKEVOPOULOS, D
   KARAKITSOS, E
   RUSTEM, B
TI ROBUST CAPACITY PLANNING UNDER UNCERTAINTY
SO MANAGEMENT SCIENCE
VL 37
IS 7
BP 787
EP 800
DI 10.1287/mnsc.37.7.787
PD JUL 1991
PY 1991
AB The existence of uncertainty influences the investment, production and
   pricing decision of firms.  Therefore, capacity expansion models need to
   take into account uncertainty.  This uncertainty may arise because of
   errors in the specification, statistical estimation of relationships and
   in the assumptions of exogenous variables.  One such example is demand
   uncertainty.  In this paper, a cautious capacity planning approach is
   described for solving problems in which robustness to likely errors is
   needed.  The aim is to cast the problem in a deterministic framework and
   thereby avoid the complexities inherent in nonlinear stochastic
   formulations.  We adopt a robust approach and minimize an augmented
   objective function that penalises the sensitivity of the objective
   function to various types of uncertainty.  The robust or sensitivity
   approach is compared with Friedenfelds' equivalent deterministic demand
   method.  Using numerical results from a large nonlinear programming
   capacity planning model, it is shown that as caution against demand
   uncertainty increases, the variance of the total objective function
   (profit) decreases.  The cost of such robustness is a deterioration in
   the deterministic risky performance.  This method is also applied to an
   industry simulation model in order to assess the effect of uncertainty
   in market demand on optimal capacity expansion and capacity utilisation.
TC 70
Z8 5
ZA 0
ZB 0
ZR 0
ZS 0
Z9 75
SN 0025-1909
UT WOS:A1991GD93300003
ER

PT J
AU SALOMON, M
   KROON, LG
   KUIK, R
   VANWASSENHOVE, LN
TI SOME EXTENSIONS OF THE DISCRETE LOTSIZING AND SCHEDULING PROBLEM
SO MANAGEMENT SCIENCE
VL 37
IS 7
BP 801
EP 812
DI 10.1287/mnsc.37.7.801
PD JUL 1991
PY 1991
AB In this paper the Discrete Lotsizing and Scheduling Problem (DLSP) is
   considered.  DLSP relates to capacitated lotsizing as well as to job
   scheduling problems and is concerned with determining a feasible
   production schedule with minimal total costs in a single-stage
   manufacturing process.  This involves the sequencing and sizing of
   production lots for a number of different items over a discrete and
   finite planning horizon.  Feasibility of production schedules is subject
   to production quantities being within bounds set by capacity.
   A problem classification for DLSP is introduced and results on
   computational complexity are derived for a number of single and parallel
   machine problems.  Furthermore, efficient algorithms are discussed for
   solving special single and parallel machine variants of DLSP.
TC 64
ZR 0
Z8 1
ZB 0
ZA 0
ZS 0
Z9 65
SN 0025-1909
UT WOS:A1991GD93300004
ER

PT J
AU SRINIVASAN, MM
   LEE, HS
TI RANDOM REVIEW PRODUCTION INVENTORY SYSTEMS WITH COMPOUND POISSON DEMANDS
   AND ARBITRARY PROCESSING TIMES
SO MANAGEMENT SCIENCE
VL 37
IS 7
BP 813
EP 833
DI 10.1287/mnsc.37.7.813
PD JUL 1991
PY 1991
AB A production/inventory system is considered in which a single production
   facility produces items of a given type.  The demand for the item is
   assumed to arrive according to a compound Poisson process.  The time
   required to produce an item is assumed to follow an arbitrary
   distribution.  An (s, S) policy is considered in which production stops
   at the instant that the inventory level is raised to S and production
   resumes at an inspection point when the inventory level is observed to
   have dropped to or below s for the first time.  The time interval
   between two successive inspection points during a nonproduction period
   is a random variable which follows an arbitrary distribution.
   Under a cost structure which includes a set-up cost, a linear holding
   cost and a linear backorder cost, an expression for the expected cost
   per unit time is obtained for given control values.  The operating cost
   during a cycle is shown to be convex in S for a given value of S-s.  For
   the continuous review simple Poisson demand system, as well as some
   other special cases of the system considered here, it is shown that the
   expected cost per unit time is unimodal.  Based on these properties, a
   procedure to find the optimal (s, S) policy is presented.
ZA 0
Z8 0
ZR 0
ZB 0
ZS 0
TC 14
Z9 14
SN 0025-1909
UT WOS:A1991GD93300005
ER

PT J
AU WEIN, LM
TI DUE-DATE SETTING AND PRIORITY SEQUENCING IN A MULTICLASS M/G/1 QUEUE
SO MANAGEMENT SCIENCE
VL 37
IS 7
BP 834
EP 850
DI 10.1287/mnsc.37.7.834
PD JUL 1991
PY 1991
AB The problem of simultaneous due-date setting and priority sequencing is
   analyzed in the setting of a multiclass M/G/1 queueing system.  The
   objective is to minimize the weighted average due-date lead time
   (due-date minus arrival date) of jobs subject to a constraint on either
   the fraction of tardy jobs or the average job tardiness.  Several
   parametric and nonparametric due-date setting policies are proposed that
   depend on the class of arriving job, the state of the queueing system at
   the time of the job's arrival, and the sequencing policy (the weighted
   shortest expected processing time rule) that is used.  In a simulation
   experiment performed on a two-class M/M/1 system, these policies
   outperformed traditional due-date setting policies, and due-date setting
   had a larger impact on performance than priority sequencing.
ZA 0
ZR 0
Z8 0
ZS 0
ZB 0
TC 94
Z9 94
SN 0025-1909
UT WOS:A1991GD93300006
ER

PT J
AU SEGEV, A
   FANG, WP
TI OPTIMAL UPDATE POLICIES FOR DISTRIBUTED MATERIALIZED VIEWS
SO MANAGEMENT SCIENCE
VL 37
IS 7
BP 851
EP 870
DI 10.1287/mnsc.37.7.851
PD JUL 1991
PY 1991
AB In this paper we present an analysis of the problem of determining
   optimal policies for updating distributed materialized views.  We
   demonstrate the general application of materialized views, and define
   the concept of materialized view currency and allow a query to specify
   its currency requirement.  We also allow a materialized view to be
   updated from either a base relation or another materialized view.  This
   flexibility provides an opportunity for further reduction in the cost of
   maintaining distributed materialized views.  We model the problem of
   optimal update policies to capture currency and policy constraints,
   replicated data, and various view update policies.  The optimization
   incorporates a minimum-cost objective function as well as user's
   response time constraints.
ZR 0
ZS 0
Z8 1
ZA 0
ZB 0
TC 18
Z9 19
SN 0025-1909
UT WOS:A1991GD93300007
ER

PT J
AU ORAL, M
   KETTANI, O
   LANG, P
TI A METHODOLOGY FOR COLLECTIVE EVALUATION AND SELECTION OF INDUSTRIAL
   RESEARCH-AND-DEVELOPMENT PROJECTS
SO MANAGEMENT SCIENCE
VL 37
IS 7
BP 871
EP 885
DI 10.1287/mnsc.37.7.871
PD JUL 1991
PY 1991
AB This paper proposes a methodology for evaluating and selecting R&D
   projects in a collective decision setting, especially useful at
   sectorial and national levels.  It consists of two major phases: 
   Evaluation and Selection.  The evaluation process repeately uses
   mathematical programming models to determine the "relative values" of a
   given R&D project from the viewpoint of the other R&D projects.  The
   selection process of R&D projects is based on these "relative values"
   and is done through a model-based outranking method.
   The salient features of the methodology developed are its ability to (1)
   permit the evaluation of an R&D project from the viewpoint of the other
   R&D projects without at first imposing a uniform evaluation scheme, and
   (2) maximize the level of consensus as to which projects should not be
   retained in the R&D Program being funded, thus minimizing the level of
   possible resentment in those organizations or departments whose projects
   are not included in the R&D Program.
   Also discussed in this paper is an application of the methodology to
   evaluate and select major R&D projects in the iron and steel industry of
   Turkey.
ZB 5
ZR 0
ZA 0
Z8 8
ZS 0
TC 160
Z9 168
SN 0025-1909
UT WOS:A1991GD93300008
ER

PT J
AU LEEMIS, LM
TI NONPARAMETRIC-ESTIMATION OF THE CUMULATIVE INTENSITY FUNCTION FOR A
   NONHOMOGENEOUS POISSON-PROCESS
SO MANAGEMENT SCIENCE
VL 37
IS 7
BP 886
EP 900
DI 10.1287/mnsc.37.7.886
PD JUL 1991
PY 1991
AB A nonparametric technique for estimating the cumulative intensity
   function of a nonhomogeneous Poisson process from one or more
   realizations is developed.  This technique does not require any
   arbitrary parameters from the modeler, and the estimated cumulative
   intensity function can be used to generate a point process for Monte
   Carlo simulation by inversion.  Three examples are given.
ZB 1
TC 67
ZS 2
Z8 1
ZA 0
ZR 0
Z9 69
SN 0025-1909
UT WOS:A1991GD93300009
ER

PT J
AU INMAN, RR
   BULFIN, RL
TI SEQUENCING JIT MIXED-MODEL ASSEMBLY LINES
SO MANAGEMENT SCIENCE
VL 37
IS 7
BP 901
EP 904
DI 10.1287/mnsc.37.7.901
PD JUL 1991
PY 1991
AB We provide a new formulation and solution procedure to sequence a mixed
   model just-in-time (JIT) assembly system.  Mixed model JIT assembly
   systems are a fundamental part of the well-known "Toyota Production
   System."  The underlying idea in sequencing these systems is to maintain
   a constant usage rate of all parts on the line.  We give a polynomial
   algorithm to determine the optimal sequence for an objective function
   that is mathematically different, but intuitively similar to the
   objective functions of previous researchers.  Furthermore, a
   computational study indicates that the new algorithm is robust in that
   its sequences are as good as those generated by other algorithms when
   evaluated with respect to traditional objectives, but are found 200
   times faster.
ZR 0
ZS 0
ZA 0
TC 85
Z8 3
ZB 0
Z9 88
SN 0025-1909
UT WOS:A1991GD93300010
ER

PT J
AU FEDERGRUEN, A
   TZUR, M
TI A SIMPLE FORWARD ALGORITHM TO SOLVE GENERAL DYNAMIC LOT SIZING MODELS
   WITH N PERIODS IN 0(N LOG N) OR 0(N) TIME
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 909
EP 925
DI 10.1287/mnsc.37.8.909
PD AUG 1991
PY 1991
AB This paper is concerned with the general dynamic lot size model, or
   (generalized) Wagner-Whitin model.  Let n denote the number of periods
   into which the planning horizon is divided.  We describe a simple
   forward algorithm which solves the general model in 0(n log n) time and
   0(n) space, as opposed to the well-known shortest path algorithm
   advocated over the last 30 years with 0(n2) time.
   A linear, i.e., 0(n)-time and space algorithm is obtained for two
   important special cases:  (a) models without speculative motives for
   carrying stock, i.e., where in each interval of time the per unit order
   cost increases by less than the cost of carrying a unit in stock; (b)
   models with non-decreasing setup costs.
   We also derive conditions for the existence of monotone optimal policies
   and relate these to known (planning horizon and other) results from the
   literature.
RI Tzur, Michal/L-1474-2019
ZA 0
ZS 1
TC 240
ZR 0
Z8 9
ZB 0
Z9 248
SN 0025-1909
UT WOS:A1991GE85700001
ER

PT J
AU POOLE, MS
   HOLMES, M
   DESANCTIS, G
TI CONFLICT-MANAGEMENT IN A COMPUTER-SUPPORTED MEETING ENVIRONMENT
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 926
EP 953
DI 10.1287/mnsc.37.8.926
PD AUG 1991
PY 1991
AB Computer systems to support decision-making, planning, and negotiation
   in groups have the potential for wide-ranging application.  However,
   knowledge of their effects is sparse, particularly for difficult
   situations such as group conflict.  This study reports a laboratory
   experiment to examine how a general purpose group decision support
   system (GDSS) influenced conflict management in small groups making a
   budget allocation decision.  The study tests a model that posits that
   GDSS impacts on conflict outcomes are mediated by group interaction
   processes, particularly how the GDSS enters into group interaction.  The
   model posits seven potential impacts-some positive and some
   negative-that GDSS technology might have on conflict interaction
   processes.  The impacts do not automatically occur, but depend on the
   nature of the GDSS and how the group applies it.  Hence, a given GDSS
   might result only in a subset of the seven impacts.  Among other things,
   the model predicts that the particular combination of GDSS impacts that
   materializes differs across groups and that the balance of these
   impacts, positive or negative, determines positive or negative conflict
   outcomes.
   Groups using a particular GDSS, the Software Aided Meeting Management
   (SAMM) system, were compared to groups using a manual version of the
   same decision structures built into SAMM and to unsupported groups. 
   Results indicated that there were differences in the level of conflict
   in SAMM-supported versus manually-supported and unsupported groups, and
   in conflict management behaviors adopted by the different conditions. 
   Moreover, there were differences in the impacts of SAMM for different
   groups, and there is some evidence that these contributed to consensus
   change.  Overall, the theoretical model was supported by the study. 
   This model and approach used in this study seem useful for designing
   future studies concerning the impacts of computer technology on group
   judgement and choice.
RI Holmes, Michael E./AAD-3507-2020
ZB 1
Z8 1
ZR 0
TC 111
ZA 0
ZS 0
Z9 112
SN 0025-1909
UT WOS:A1991GE85700002
ER

PT J
AU MONTGOMERY, CA
   WERNERFELT, B
TI SOURCES OF SUPERIOR PERFORMANCE - MARKET SHARE VERSUS INDUSTRY EFFECTS
   IN THE UNITED-STATES BREWING INDUSTRY
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 954
EP 959
DI 10.1287/mnsc.37.8.954
PD AUG 1991
PY 1991
AB Using financial measures of performance we investigate the sources of
   value creation in the U.S. brewing industry between 1969 and 1979.  We
   find that market share gains in this industry at this time are not
   correlated with changes in value and that the performance of individual
   leading firms is highly correlated.  Our interpretation is that the
   success of market share building strategies depends critically on
   specific industry conditions.  Specifically, in the absence of
   fundamental shifts in the relative resource positions of individual
   firms, share gains may come at too high a price.  In addition, the
   research shows that intra-industry correlations in returns may result
   from excessive competition rather than collusion.
TC 24
Z8 0
ZA 0
ZS 1
ZR 0
ZB 0
Z9 25
SN 0025-1909
UT WOS:A1991GE85700003
ER

PT J
AU DOMICH, PD
   HOFFMAN, KL
   JACKSON, RHF
   MCCLAIN, MA
TI LOCATING TAX FACILITIES - A GRAPHICS-BASED MICROCOMPUTER OPTIMIZATION
   MODEL
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 960
EP 979
DI 10.1287/mnsc.37.8.960
PD AUG 1991
PY 1991
AB This paper presents a mathematical model that selects locations for
   Internal Revenue Service Posts-of-Duty.  The system is
   microcomputer-based and uses menus and graphically displayed zip code
   maps of IRS districts for interactive inputs and solution outputs.  The
   mathematical model used for this problem is the uncapacitated, fixed
   charge, location-allocation model which minimizes travel and facility
   costs, given a specified level of activity.  A greedy-interchange
   heuristic is used to obtain "good" solutions to the problem and is
   coupled with a lagrangian-relaxation technique providing a measure of
   how far from optimality the current solution can be.  An example with
   Florida data illustrates the use of the model.
TC 12
ZS 0
Z8 0
ZB 0
ZR 0
ZA 0
Z9 12
SN 0025-1909
UT WOS:A1991GE85700004
ER

PT J
AU BEST, MJ
   GRAUER, RR
TI SENSITIVITY ANALYSIS FOR MEAN-VARIANCE PORTFOLIO PROBLEMS
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 980
EP 989
DI 10.1287/mnsc.37.8.980
PD AUG 1991
PY 1991
AB This paper shows how to perform sensitivity analysis for Mean-Variance
   (MV) portfolio problems using a general form of parametric quadratic
   programming.  The analysis allows an investor to examine how parametric
   changes in either the means or the right-hand side of the constraints
   affect the composition, mean, and variance of the optimal portfolio. 
   The optimal portfolio and associated multipliers are piecewise linear
   functions of the changes in either the means or the right-hand side of
   the constraints.  The parametric parts of the solution show the rates of
   substitution of securities in the optimal portfolio, while the
   parametric parts of the multipliers show the rates at which constraints
   are either tightening or loosening.  Furthermore, the parametric parts
   of the solution and multipliers change in different intervals when
   constraints become active or inactive.  The optimal MV paths for
   sensitivity analyses are piecewise parabolic, as in traditional MV
   analysis.  However, the optimal paths may contain negatively sloping
   segments and are characterized by types of kinks, i.e., points of
   nondifferentiability, not found in MV analysis.
TC 71
ZB 0
ZS 0
Z8 0
ZR 0
ZA 0
Z9 71
SN 0025-1909
UT WOS:A1991GE85700005
ER

PT J
AU GUTIERREZ, GJ
   KOUVELIS, P
TI PARKINSON LAW AND ITS IMPLICATIONS FOR PROJECT-MANAGEMENT
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 990
EP 1001
DI 10.1287/mnsc.37.8.990
PD AUG 1991
PY 1991
AB Critical path models concerning project management (i.e. PERT/CPM) fail
   to account for work force behavioral effects on the expected project
   completion time.  In this paper, we provide a modelling framework for
   project management activities, that ultimately accounts for expected
   worker behavior under Parkinson's Law.  A stochastic activity completion
   time model is used to formally state Parkinson's Law.  The developed
   model helps to examine the effects of information release policies on
   subcontractors of project activities, and to develop managerial policies
   for setting appropriate deadlines for series or parallel project
   activities.
RI Kouvelis, Panos/ABG-2350-2020
ZR 0
ZS 1
ZB 0
ZA 0
TC 54
Z8 1
Z9 56
SN 0025-1909
UT WOS:A1991GE85700006
ER

PT J
AU WEIN, LM
   OU, JH
TI THE IMPACT OF PROCESSING TIME KNOWLEDGE ON DYNAMIC JOB-SHOP SCHEDULING
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 1002
EP 1014
DI 10.1287/mnsc.37.8.1002
PD AUG 1991
PY 1991
AB The goal of this paper is to determine if the results for dynamic
   job-shop scheduling problems are affected by the assumptions made with
   regard to the processing time distributions and the scheduler's
   knowledge of the processing times.  Three dynamic job-shop scheduling
   problems (including a two-station version of Conway et al.'s 1967
   nine-station symmetric shop) are tested under seven different scenarios,
   one deterministic and six stochastic, using computer simulation.  The
   deterministic scenario, where the processing times are exponential and
   observed by the scheduler, has been considered in many simulation
   studies, including Conway et al.'s.  The six stochastic scenarios
   include the case where the processing times are exponential and only the
   mean is known by the scheduler, and five different cases where the
   machines are subject to unpredictable failures.  Two policies were
   tested, the shortest expected processing time (SEPT) rule, and a rule
   derived from a Brownian analysis of the corresponding queueing network
   scheduling problem.  Although the SEPT rule performed well in the
   deterministic scenario, it was easily outperformed by the Brownian
   policies in the six stochastic scenarios for all three problems.  Thus,
   the results from simulation studies of dynamic, deterministic job-shop
   scheduling problems may not carry over to the more realistic setting
   where there is unpredictable variability.
ZR 0
TC 6
ZA 0
ZB 0
ZS 0
Z8 0
Z9 6
SN 0025-1909
UT WOS:A1991GE85700007
ER

PT J
AU SPEARMAN, ML
TI AN ANALYTIC CONGESTION MODEL FOR CLOSED PRODUCTION SYSTEMS WITH IFR
   PROCESSING TIMES
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 1015
EP 1029
DI 10.1287/mnsc.37.8.1015
PD AUG 1991
PY 1991
AB We present an analytic model relating the mean cycle time or throughput
   as a function of the number of jobs in a closed production system
   composed of a tandem network of queues having exponential and/or IFR
   processing times.  This model exhibits macroscopic behavior that is
   predicted by results from queueing theory and involves three meaningful
   parameters:  the bottleneck rate and the "raw process" time that can be
   determined from first moment data; and a dimensionless congestion
   coefficient that is typically obtained from a single WIP/average cycle
   time observation (e.g., simulation).
   The derivation of the model is based on observations of the behavior of
   the relation between mean cycle time and WIP.  This "engineering"
   approach is different from a purely "probabilistic" one in that we do
   not consider the distribution of processing times at individual station.
   We compare the accuracy of the model in predicting mean cycle times to
   other techniques such as mean value analysis and simulation.
TC 25
ZR 0
Z8 0
ZS 0
ZB 0
Z9 25
SN 0025-1909
UT WOS:A1991GE85700008
ER

PT J
AU HARVEY, CM
TI MODELS OF TRADEOFFS IN A HIERARCHICAL STRUCTURE OF OBJECTIVES
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 1030
EP 1042
DI 10.1287/mnsc.37.8.1030
PD AUG 1991
PY 1991
AB Multiattribute utility models and cost-benefit models often arrange the
   objectives into a hierarchical structure in order to identify
   appropriate subobjectives and to select appropriate attributes to
   measure the subobjectives.  This paper discusses nonadditive models that
   use the hierarchical structure in order to examine issues of tradeoffs
   that models in present use are not able to include.  The models are
   sufficiently structured so that they can be applied by procedures that
   are similar to those available for other prescriptive models of
   preferences.
Z8 0
ZB 0
ZA 0
TC 1
ZR 0
ZS 0
Z9 1
SN 0025-1909
UT WOS:A1991GE85700009
ER

PT J
AU CALABRESE, JM
   HAUSMAN, WH
TI SIMULTANEOUS DETERMINATION OF LOT SIZES AND ROUTING MIX IN JOB SHOPS
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 1043
EP 1057
DI 10.1287/mnsc.37.8.1043
PD AUG 1991
PY 1991
AB Flexibility and versatility of batch production job shops has increased
   in the last 25 years through the use of multi-purpose numerically
   controlled (NC) machine tools; these computer controlled machines can
   perform a wide variety of different operations.  In recent years, even
   greater flexibility has been achieved by flexible manufacturing systems,
   where groups of NC machines are linked by automated material handling
   devices and controlled by computer.  In such shops, a batch of product
   may have several possible alternative routes that it may follow through
   the shop.  A number of researchers have shown that determining the
   proper mix of routes for each product can have a significant effect on
   shop throughput and work-in-process inventory.  Other researchers have
   found that the lot sizing decision also affects these performance
   measures.  The primary thrust of this paper is to develop a model to
   explore the interaction between routing and lot sizing decisions in a
   multi-machine, multi-work center job shop.  A heuristic is developed for
   simultaneously determining lot sizes and routing mix in problems of
   practical size, and numerical examples are provided in order to
   illustrate the solution method.  The examples show that there can be
   considerable potential for performance improvement by simultaneous
   consideration of routing and lot sizing.
ZA 0
ZR 0
ZB 0
ZS 0
TC 12
Z8 0
Z9 12
SN 0025-1909
UT WOS:A1991GE85700010
ER

PT J
AU PARK, JS
   PETERS, MH
   TANG, K
TI OPTIMAL INSPECTION POLICY IN SEQUENTIAL SCREENING
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 1058
EP 1061
DI 10.1287/mnsc.37.8.1058
PD AUG 1991
PY 1991
AB Under sequential screening, a production lot is inspected item-by-item;
   the decision is made after inspecting each item whether to inspect
   another item or to reject the remainder of the lot; and thus uninspected
   items are never accepted.  This screening process is a special case of
   the sequential sampling considered in Wortham and Wilson (1971).  The
   process is formulated as an optimal stopping problem using a Bayesian
   approach.  Based on an analysis of the structural properties of the
   optimal policy, a backward-recursive optimal algorithm, which is more
   efficient than the existing algorithm for optimal sequential sampling,
   is developed.
OI TANG, KWEI/0000-0002-1777-6476
TC 7
Z8 0
ZB 0
ZR 0
ZS 0
ZA 0
Z9 7
SN 0025-1909
UT WOS:A1991GE85700011
ER

PT J
AU LARSON, RC
TI ADDITION
SO MANAGEMENT SCIENCE
VL 37
IS 8
BP 1062
EP 1062
DI 10.1287/mnsc.37.8.1062
PD AUG 1991
PY 1991
AB A simple modification of one equation in Larson (1990) reduces the
   computational complexity of the algorithm for the Queue Inference Engine
   (QIE) from O(N5) to O(N3), where N is the number of customers queued
   during a congestion period.
ZB 0
ZS 0
ZR 0
Z8 0
TC 4
Z9 4
SN 0025-1909
UT WOS:A1991GE85700012
ER

PT J
AU BUCHANAN, JL
   KEELER, EB
   ROLPH, JE
   HOLMER, MR
TI SIMULATING HEALTH EXPENDITURES UNDER ALTERNATIVE INSURANCE PLANS
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1067
EP 1090
DI 10.1287/mnsc.37.9.1067
PD SEP 1991
PY 1991
AB A simulation model that estimates individual health care spending as a
   function of the structure of indemnity-type insurance plans is
   presented.  The behavioral models that from the basis for this work were
   developed as part of RAND's Health Insurance Experiment, (HIE), a
   randomized clinical trial.  The randomized design and statistical
   methods provided estimates of the effects of insurance on use,
   uncontaminated by sickness or selection effects.  The demand for medical
   care was modelled using episodes of treatment.  Within the simulation,
   episodes occur independently and randomly through time according to a
   Poisson process with rates depending on individual characteristics and
   insurance.  Empirical results from the HIE indicate that insurance
   primarily affects individual decisions to seek treatment (episode
   frequency), but has only minimal effects on episode costs.  The response
   to changes in price (insurance) is modelled as a Bernoulli censoring
   process on episode frequency.  The model is used to address issues on
   the effective design of insurance plans.
ZA 0
TC 26
ZR 0
ZB 0
ZS 0
Z8 0
Z9 26
SN 0025-1909
UT WOS:A1991GJ91700001
ER

PT J
AU SINHA, DK
   CUSUMANO, MA
TI COMPLEMENTARY RESOURCES AND COOPERATIVE RESEARCH - A MODEL OF RESEARCH
   JOINT VENTURES AMONG COMPETITORS
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1091
EP 1106
DI 10.1287/mnsc.37.9.1091
PD SEP 1991
PY 1991
AB We present a model of research joint ventures in which if firms have
   highly complementary skills and resources then they prefer to cooperate
   in areas where the technology is highly appropriable, as in applied
   research. The model also indicates that large firms have a greater
   incentive to cooperate because they are better positioned to capture the
   benefits of a research venture. These findings seem to explain why
   cooperative research among rival firms in Japan has been applied rather
   than basic and conducted frequently among large companies. But firms
   prefer as small a partner as possible to limit the sharing of research
   results, creating a tension that may make cooperative efforts among
   rivals difficult to manage. For this reason, cooperation with
   organizations, such as universities or nonprofit institutions, may be a
   viable alternative for firms looking for complementary skills and
   resources.
Z8 1
ZS 0
ZA 0
ZR 0
TC 51
ZB 1
Z9 52
SN 0025-1909
EI 1526-5501
UT WOS:A1991GJ91700002
ER

PT J
AU BENSON, PG
   SARAPH, JV
   SCHROEDER, RG
TI THE EFFECTS OF ORGANIZATIONAL CONTEXT ON QUALITY MANAGEMENT - AN
   EMPIRICAL-INVESTIGATION
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1107
EP 1124
DI 10.1287/mnsc.37.9.1107
PD SEP 1991
PY 1991
AB While the quality literature abounds with prescriptions for how quality
   should be managed, no one has proposed an organization-theory
   explanation for how quality is managed in organizations.  This paper
   proposes a system-structural model of quality management that relates
   organizational quality context, actual quality management, ideal quality
   management, and quality performance.  The relationships between
   organizational quality context and actual and ideal quality management
   are investigated using data collected from 152 managers from 77 business
   units of 20 manufacturing and service companies.  A previously reported
   instrument is used to measure managers' perceptions of ideal and actual
   quality management in terms of eight critical factors including
   product/service design, training, employee relations, and top management
   leadership.  Several measures are used to characterize organizational
   quality context including company type, company size, degree of
   competition, and corporate support for quality.  The results indicate
   that organizational quality context influences managers' perceptions of
   both ideal and actual quality management.  This suggests that knowledge
   of organizational quality context is useful for explaining and
   predicting quality management practice.  Important contextual variables
   are corporate support for quality, past quality performance, managerial
   knowledge, and the extent of external quality demands.
ZA 0
ZR 0
ZS 0
Z8 0
TC 186
ZB 2
Z9 186
SN 0025-1909
UT WOS:A1991GJ91700003
ER

PT J
AU BARD, JF
   BEJJANI, WA
TI DESIGNING TELECOMMUNICATIONS NETWORKS FOR THE RESELLER MARKET
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1125
EP 1146
DI 10.1287/mnsc.37.9.1125
PD SEP 1991
PY 1991
AB This paper presents an algorithm for minimizing the monthly cost of
   telecommunications networks characterized by multichannel queues with
   forced balking and hierarchical routing plans.  The problem is of major
   interest to resellers of long distance services and corporate network
   managers who lease their lines from AT&T and Other Common Carriers.  The
   algorithm can be used to select the most economical combination of lines
   to meet a desired grade of service, set here to an average blockage rate
   of 1% during the busy hour.
   Because of the nonlinearities involved, the problem is formulated as a
   dynamic program and solved with forward recursion.  The Erlang loss
   formula is used to determine blockage in the case of Poisson arrivals,
   while Wilkinson's equivalent random theory is adopted when the input
   traffic is peaked.  Model validation is achieved with a SLAM II
   simulation.
   The algorithm is applied to the network of National Telecommunications
   of Austin, which consists of 5 hierarchical levels and 52 candidate
   nodes, and carries about 2.3 million minutes of monthly traffic. 
   Current services range from FX connections to Specialized WATS.  The
   results indicate that cost reductions of over 18%, or $30,000 per month,
   can be achieved by periodically adjusting trunk group sizes to match the
   forecast demand.
ZB 0
Z8 0
ZS 0
ZR 0
TC 3
Z9 3
SN 0025-1909
UT WOS:A1991GJ91700004
ER

PT J
AU LIEBERMAN, ER
TI SOVIET MULTIOBJECTIVE MATHEMATICAL-PROGRAMMING METHODS - AN OVERVIEW
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1147
EP 1165
DI 10.1287/mnsc.37.9.1147
PD SEP 1991
PY 1991
AB Over the past 20-30 years multi-objective mathematical programming
   (MOMP) has emerged as an increasingly active area of research in the
   fields of management science, operations research, applied mathematics,
   and engineering.  Despite the intensity of interest, however, earlier
   surveys of MOMP methods have all but ignored Soviet work in this area. 
   Published in unfamiliar journals and often available only in Russian,
   the Soviet research has remained virtually unknown outside of the USSR
   and Eastern Europe.  This has been particularly unfortunate given the
   extent, importance, and originality of much of the Soviet research.  The
   current article attempts to correct this situation by providing a
   comprehensive, yet nontechnical, overview of Soviet MOMP methods.  Using
   a taxonomy similar to ones that have been applied to Western MOMP
   techniques, the article categorizes the Soviet methods based on when
   they involve a decision maker in the solution process-a priori,
   progressively, a posteriori, or never-and what kind of information the
   decision maker provides.  In all, 17 methods are analyzed with
   particular attention given to their distinctive features and to the
   issues of computational feasibility and burden on the decision maker. 
   The article concludes with observations on the overall character of
   Soviet MOMP research, comparing the general directions in Soviet and
   Western research.
TC 14
ZS 0
ZB 0
ZR 0
ZA 0
Z8 0
Z9 14
SN 0025-1909
UT WOS:A1991GJ91700005
ER

PT J
AU PORTEUS, EL
   WHANG, S
TI ON MANUFACTURING MARKETING INCENTIVES
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1166
EP 1181
DI 10.1287/mnsc.37.9.1166
PD SEP 1991
PY 1991
AB Stereotypically, marketing is mainly concerned about satisfying
   customers and manufacturing is mainly interested in factory efficiency. 
   Using the principal-agent (agency) paradigm, which assumes that the
   marketing and manufacturing managers of the firm will act in their
   self-interest, we seek incentive plans that will induce those managers
   to act so that the owner of the firm can attain as much as possible of
   the residual returns.  One optimal incentive plan can be interpreted as
   follows:  The owner subcontracts to pay the manufacturing manager a
   fixed rate for all capacity he delivers.  Each marketing manager
   receives all of the returns from his product.  In turn, all managers pay
   a fixed fee to the owner.  Under this plan, the marketing managers will
   often complain about the stock level decisions, even though these levels
   are announced in advance.  Under a revised plan, the owner can eliminate
   such complaints by delegating the stocking decisions to the respective
   marketing managers, without any loss.  This plan is interpreted as
   requiring the owner to make a futures market for manufacturing capacity,
   paying the manufacturing manager the expected marginal value for each
   unit of capacity delivered, receiving the realized marginal value from
   the marketing managers, and losing money on average in the process.
ZB 0
ZR 0
ZS 0
ZA 0
Z8 6
TC 101
Z9 107
SN 0025-1909
UT WOS:A1991GJ91700006
ER

PT J
AU NELSON, RD
   POPE, RD
TI BOOTSTRAPPED INSIGHTS INTO EMPIRICAL APPLICATIONS OF
   STOCHASTIC-DOMINANCE
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1182
EP 1194
DI 10.1287/mnsc.37.9.1182
PD SEP 1991
PY 1991
AB Bootstrapping a very versatile statistical technique, significantly
   amplifies the understanding and success of empirical applications of
   stochastic dominance.  Its ability to calculate the standard deviations
   of order statistics reveals the uncertainty of the critical estimates of
   the tails of cumulative density functions.  Understanding this
   uncertainty reveals why a wide variety of tail shapes all cause a
   notable loss in power for stochastic dominance tests.  Simulations show
   that the smoothing inherent in bootstrapping can significantly increase
   the power of the tests when dominance exists in the population.
ZR 0
ZB 0
ZS 0
TC 16
ZA 0
Z8 0
Z9 16
SN 0025-1909
UT WOS:A1991GJ91700007
ER

PT J
AU CARRAWAY, RL
   SCHMIDT, RL
TI AN IMPROVED DISCRETE DYNAMIC-PROGRAMMING ALGORITHM FOR ALLOCATING
   RESOURCES AMONG INTERDEPENDENT PROJECTS
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1195
EP 1200
DI 10.1287/mnsc.37.9.1195
PD SEP 1991
PY 1991
AB Nemhauser and Ullmann (1969) proposed a discrete dynamic programming
   (DP) approach for several variations of the basic capital allocation
   model, including one in which the returns and resource consumption of
   projects are interdependent.  For this case, we augment their DP
   approach with a branch-and-bound strategy as suggested in Morin and
   Marsten (1976).  Computational results demonstrate that this enhancement
   significantly reduces required computation time and effectively removes
   any limit on the number of nonzero interaction terms allowed.  We also
   demonstrate that our approach compares favorably to an alternative
   implicit enumeration approach proposed by Hansen (1972).
RI Schmidt, Robert L/B-8483-2013
OI Schmidt, Robert L/0000-0003-4414-0139
ZS 0
TC 29
ZA 0
Z8 2
ZR 0
ZB 0
Z9 30
SN 0025-1909
UT WOS:A1991GJ91700008
ER

PT J
AU LEACHMAN, RC
   XIONG, ZK
   GASCON, A
   PARK, K
TI NOTE - AN IMPROVEMENT TO THE DYNAMIC CYCLE LENGTHS HEURISTIC FOR
   SCHEDULING THE MULTIITEM, SINGLE-MACHINE
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1201
EP 1205
DI 10.1287/mnsc.37.9.1201
PD SEP 1991
PY 1991
AB A heuristic scheduling policy for multi-item, single-machine scheduling
   systems facing stochastic, time-varying demands was previously
   introduced by Leachman and Gascon.  In this technical note we provide an
   improvement to the calculations of the policy.  Simulation tests of the
   revised version of the policy indicate that the improvements maintain or
   enhance customer service while reducing total inventory and setup costs
   on the order of 1-7%.
ZR 0
ZS 0
ZB 0
TC 16
ZA 0
Z8 0
Z9 16
SN 0025-1909
UT WOS:A1991GJ91700009
ER

PT J
AU BROMILEY, P
TI PARADOX OR AT LEAST VARIANCE FOUND - A COMMENT ON MEAN-VARIANCE
   APPROACHES TO RISK-RETURN RELATIONSHIPS IN STRATEGY - PARADOX LOST
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1206
EP 1210
DI 10.1287/mnsc.37.9.1206
PD SEP 1991
PY 1991
AB In general the problem is that the computed mean-variance relationship
   for a period of time cannot be identified in distinction to the effects
   of shifts in the relationship over time-without additional information
   or assumptions. Thus, using a mean-variance approach to risk-return
   relationships means that statements about the nature of the
   mean-variance association cannot be confirmed in a nontrival fashion
   within the empirical system nor generalized to any other time
   period-including subperiods.
ZB 0
ZA 0
ZR 0
TC 20
ZS 0
Z8 0
Z9 20
SN 0025-1909
EI 1526-5501
UT WOS:A1991GJ91700010
ER

PT J
AU RUEFLI, TW
TI PARADOX LOST BECOMES DILEMMA FOUND - REPLY
SO MANAGEMENT SCIENCE
VL 37
IS 9
BP 1210
EP 1215
DI 10.1287/mnsc.37.9.1210
PD SEP 1991
PY 1991
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 18
Z9 18
SN 0025-1909
EI 1526-5501
UT WOS:A1991GJ91700011
ER

PT J
AU CHATTERJEE, K
   KERSTEN, G
   SHAKUN, MF
TI INTRODUCTION TO THE FOCUSED ISSUE ON GROUP DECISION AND NEGOTIATION
SO MANAGEMENT SCIENCE
VL 37
IS 10
BP 1219
EP 1220
DI 10.1287/mnsc.37.10.1219
PD OCT 1991
PY 1991
RI Kersten, Gregory/AAE-9142-2020
OI Kersten, Gregory/0000-0001-8045-1941
ZA 0
ZB 0
Z8 0
TC 3
ZS 0
ZR 0
Z9 3
SN 0025-1909
UT WOS:A1991GN69500001
ER

PT J
AU CRAMTON, PC
TI DYNAMIC BARGAINING WITH TRANSACTION COSTS
SO MANAGEMENT SCIENCE
VL 37
IS 10
BP 1221
EP 1233
DI 10.1287/mnsc.37.10.1221
PD OCT 1991
PY 1991
AB A buyer and seller alternate making offers until an offer is accepted or
   someone terminates negotiations. The seller's valuation is common
   knowledge, but the buyer's valuation is known only by the buyer.
   Impatience to reach an agreement comes from two sources: the traders
   discount future payoffs and there are transaction costs of bargaining.
   Equilibrium behavior involves either immediate trade, delayed trade, or
   immediate termination, depending on the size of the gains from trade and
   the relative bargaining costs. This contrasts with the pure discounting
   model where termination never occurs, and the pure transaction cost
   model where delayed trade never occurs.
ZR 0
TC 31
Z8 0
ZA 0
ZB 0
ZS 0
Z9 31
SN 0025-1909
UT WOS:A1991GN69500002
ER

PT J
AU SAMUELSON, WF
TI FINAL-OFFER ARBITRATION UNDER INCOMPLETE INFORMATION
SO MANAGEMENT SCIENCE
VL 37
IS 10
BP 1234
EP 1247
DI 10.1287/mnsc.37.10.1234
PD OCT 1991
PY 1991
AB In recent years, final-offer arbitration (FOA) has become an
   increasingly frequent means of resolving labor disputes in the private
   and public sectors. The present paper models FOA when each disputant has
   private information bearing on the true value of the case. The model
   characterizes the disputants' equilibrium offer behavior and examines
   arbitration performance. The main conclusion is that FOA outcomes are
   crudely responsive to the underlying merits of the case. In its favor,
   FOA can be expected to be less costly to administer than arbitration
   procedures that attempt to extract perfect information.
Z8 0
TC 15
ZB 0
ZS 0
ZR 0
Z9 15
SN 0025-1909
UT WOS:A1991GN69500003
ER

PT J
AU SYCARA, KP
TI PROBLEM RESTRUCTURING IN NEGOTIATION
SO MANAGEMENT SCIENCE
VL 37
IS 10
BP 1248
EP 1268
DI 10.1287/mnsc.37.10.1248
PD OCT 1991
PY 1991
AB To achieve movement towards a negotiated settlement, it is often
   necessary to restructure the problem under negotiation. Problem
   restructuring can lead to changed perception of the issues by the
   parties, thus breaking deadlocks and increasing the parties' willingness
   to compromise. We present a framework and mechanisms for problem
   restructuring based on the goals and goal relationships of the
   negotiating parties as well as means of manipulating the parties'
   utility estimates. In addition, previous negotiations are a source of
   heuristic advice in the restructuring task. The restructuring approach
   has been implemented in the PERSUADER, a computer program that acts as a
   labor mediator in labor management disputes. To achieve its task, the
   PERSUADER negotiates separately with each party, company and union, to
   guide them in reaching agreement.
TC 81
ZS 0
ZA 0
Z8 2
ZB 0
ZR 0
Z9 83
SN 0025-1909
UT WOS:A1991GN69500004
ER

PT J
AU KERSTEN, GE
   MICHALOWSKI, W
   SZPAKOWICZ, S
   KOPERCZAK, Z
TI RESTRUCTURABLE REPRESENTATIONS OF NEGOTIATION
SO MANAGEMENT SCIENCE
VL 37
IS 10
BP 1269
EP 1290
DI 10.1287/mnsc.37.10.1269
PD OCT 1991
PY 1991
AB The paper introduces restructurable modelling of negotiation aimed at
   supporting decision situations with an evolving structure. The
   theoretical framework of such models is presented by means of a
   rule-based formalism. This framework encompasses both qualitative and
   quantitative models, and the use of multiple procedures for solving the
   negotiation problem, adjusting the solution, and restructuring the
   problem representation. A hypothetical example of a house purchase is
   given to illustrate the discussion. The implications of the study for
   future directions of research on negotiation modelling and support are
   presented.
RI Kersten, Gregory/AAE-9142-2020
OI Kersten, Gregory/0000-0001-8045-1941
Z8 0
ZR 0
TC 39
ZA 0
ZS 1
ZB 0
Z9 40
SN 0025-1909
UT WOS:A1991GN69500005
ER

PT J
AU SHAKUN, MF
TI AIRLINE BUYOUT - EVOLUTIONARY SYSTEMS-DESIGN AND PROBLEM RESTRUCTURING
   IN GROUP DECISION AND NEGOTIATION
SO MANAGEMENT SCIENCE
VL 37
IS 10
BP 1291
EP 1303
DI 10.1287/mnsc.37.10.1291
PD OCT 1991
PY 1991
AB We discuss problem restructuring involving evolution of the problem
   representation in group decision and negotiation support systems. We
   develop the evolutionary systems design (ESD) approach to restructuring
   involving a heuristic controls/goals/values referral process and other
   domain-independent methodological knowledge, such as constraint
   relaxation, contingency planning, coalition formation and flexible goal
   target. These ideas are applied to multiple problem restructuring in a
   scenario motivated by labor-management negotiations and buyout in the
   airline industry, in particular, a composite of negotiations at Eastern
   Airlines, TWA and UAL.
ZR 0
Z8 0
TC 32
ZS 0
ZB 0
ZA 0
Z9 32
SN 0025-1909
UT WOS:A1991GN69500006
ER

PT J
AU MUMPOWER, JL
TI THE JUDGMENT POLICIES OF NEGOTIATORS AND THE STRUCTURE OF NEGOTIATION
   PROBLEMS
SO MANAGEMENT SCIENCE
VL 37
IS 10
BP 1304
EP 1324
DI 10.1287/mnsc.37.10.1304
PD OCT 1991
PY 1991
AB The structure of negotiation problems refers to characteristics of their
   feasible settlement spaces and efficient frontiers. These
   characteristics are determined by the joint distribution of negotiators'
   utilities across possible settlements. Variations in negotiators'
   judgment policies (i.e., how they judge the utility of potential
   settlements) may result in distinctly different negotiation problem
   structures. Depending on the structure of the negotiation problem,
   settlements that are efficient, maximize joint utility, and minimize
   inequality are sometimes possible, sometimes not. When such settlements
   are possible, different strategies may be necessary to reach them. They
   sometimes can be reached only by a "compromise" strategy in which the
   disputants split their differences on each issue, sometimes only by a
   "horsetrading" strategy involving trade-offs among extreme values on
   issues, sometimes by either, and sometimes by neither strategy.
   Settlements on the efficient frontier that yield equal utility to both
   negotiators will sometimes leave both relatively well satisfied,
   sometimes not. When equal-valued settlements yield low levels of
   utility, negotiators are likely to feel dissatisfied and may presume
   that the other negotiator must be comparatively better satisfied. Even
   seemingly simple negotiation problems often pose a high degree of
   cognitive complexity. In the face of uncertainty about the nature of the
   problem structure, negotiators may resort to simple bargaining tactics
   (e.g., incrementally offering concessions on the issue for which the
   marginal rate of loss of utility is least). For many commonly
   encountered problem structures, such tactics lead toward satisfactory
   settlements, but not always. Analyses of the judgment policies of
   negotiators and resultant negotiation problem structures will contribute
   to better understanding of negotiation processes and help to inform the
   design of negotiation support systems.
Z8 0
ZR 0
ZS 0
ZA 0
ZB 0
TC 57
Z9 57
SN 0025-1909
UT WOS:A1991GN69500007
ER

PT J
AU NUNAMAKER, JF
   DENNIS, AR
   VALACICH, JS
   VOGEL, DR
TI INFORMATION TECHNOLOGY FOR NEGOTIATING GROUPS - GENERATING OPTIONS FOR
   MUTUAL GAIN
SO MANAGEMENT SCIENCE
VL 37
IS 10
BP 1325
EP 1346
DI 10.1287/mnsc.37.10.1325
PD OCT 1991
PY 1991
AB The study of negotiating groups, whether distributive between competing
   parties (i.e. "win-lose") or integrative between essentially friendly
   parties from the same organization (i.e., "win-win"), remains important.
   While much previous research in this area has focused on key analytical
   issues such as evaluating proposed options, much less research has
   addressed the equally important initial stage of negotiation: generating
   options for mutual gain. In general, groups do this poorly, as there are
   many obstacles that inhibit successful option generation. Recent
   advances in computer technology provide additional approaches that can
   be used to support option generation as one component in an overall
   Negotiation Support System. This paper presents an integrated series of
   laboratory and field studies that investigated various aspects of
   computer-supported option generation for groups that meet at the same
   place and time. The use of anonymity to separate personalities from the
   issues and promote more objective evaluation was found to improve option
   generation in some circumstances, particularly those with increased
   criticalness and/or power differences among the participants. Larger
   groups were found to be more effective than smaller groups, several
   smaller groups combined, and nominal groups. We present several
   implications for theory development and system design and use, as well
   as a tentative model for computer-supported group option generation.
ZR 0
ZA 0
Z8 1
ZS 0
TC 91
ZB 0
Z9 92
SN 0025-1909
UT WOS:A1991GN69500008
ER

PT J
AU RAO, VS
   JARVENPAA, SL
TI COMPUTER SUPPORT OF GROUPS - THEORY-BASED MODELS FOR GDSS RESEARCH
SO MANAGEMENT SCIENCE
VL 37
IS 10
BP 1347
EP 1362
DI 10.1287/mnsc.37.10.1347
PD OCT 1991
PY 1991
AB Empirical research in the area of computer support of groups is
   characterized by inconsistent results across studies. This paper
   attempts to reconcile the inconsistencies by linking the ad hoc
   reasoning in the studies to existing theories of communication, minority
   influence and human information processing. Contingency models are then
   presented based on the theories discussed. The paper concludes by
   discussing the linkages between the current work and other recently
   published integrations of empirical GDSS research and theories of GDSS.
   1
CT 22ND HAWAII INTERNATIONAL CONF ON SYSTEM SCIENCES
CY JAN, 1989
CL HI
ZS 0
Z8 1
ZR 0
TC 70
ZB 0
ZA 0
Z9 71
SN 0025-1909
UT WOS:A1991GN69500009
ER

PT J
AU MARCELLUS, RL
   DADA, M
TI INTERACTIVE PROCESS QUALITY IMPROVEMENT
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1365
EP 1376
DI 10.1287/mnsc.37.11.1365
PD NOV 1991
PY 1991
AB An ongoing production process produces defective parts at random
   intervals.  Each defective part provides a learning opportunity which
   the decision maker may use to improve the process by investing resources
   to identify and remove the causes of the defective.  For various cost
   criteria, it is optimal to invest in learning until the probability of
   producing a defective becomes sufficiently small.  This policy has
   economic interpretations in terms of marginal benefits.  In addition,
   the optimal policy for expected discounted present cost has an
   interpretation in terms of tradeoffs between "cost of failure" and "cost
   of prevention".  The shape of the tradeoff curve gives insight into the
   controversy between the traditional and zero defects views towards cost
   of quality.
ZR 0
ZA 0
ZS 0
Z8 0
ZB 0
TC 40
Z9 40
SN 0025-1909
UT WOS:A1991GV22000001
ER

PT J
AU RANGAN, VK
   JAIKUMAR, R
TI INTEGRATING DISTRIBUTION STRATEGY AND TACTICS - A MODEL AND AN
   APPLICATION
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1377
EP 1389
DI 10.1287/mnsc.37.11.1377
PD NOV 1991
PY 1991
AB Designing distribution systems requires two decisions, one strategic
   (i.e., the number of levels between the producer and the customer) and
   the other tactical (i.e., channel management policies such as trade
   discounts and rebates).  While the modeling literature focuses on one or
   the other, evidence from the field indicates that the two decisions are
   in fact interactive.  In this paper, we develop and then apply an
   integrated model that solves the strategic issue of channel levels and
   the tactical issue of price rebates simultaneously.
ZR 0
ZS 0
TC 17
Z8 0
ZA 0
ZB 0
Z9 17
SN 0025-1909
UT WOS:A1991GV22000002
ER

PT J
AU BRADEN, DJ
   FREIMER, M
TI INFORMATIONAL DYNAMICS OF CENSORED OBSERVATIONS
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1390
EP 1404
DI 10.1287/mnsc.37.11.1390
PD NOV 1991
PY 1991
AB The analysis of stochastic models is often greatly complicated if there
   are censored observations of the random variables.  This paper
   characterizes families of distributions which help keep tractable the
   analysis of such models.  Our primary motivation is to provide guidance
   to practitioners in the selection of distributions:  If a modeler feels
   that no member of the families we characterize is a reasonable
   approximation, then he will almost surely encounter serious analytic and
   computational problems if his data include censored observations.
   We characterize a family of distributions for which there exist
   fixed-dimensional sufficient statistics of purely censored observations.
   We also characterize an important subset of this family, appropriate for
   situations where data include both censored and exact observations.  We
   derive the corresponding predictive distributions using arbitrary priors
   and present some general results relating stochastic dominance among
   predictive distributions to the parameters of the prior.  We also
   analyze the cases of discrete and mixed random variables.
ZS 0
Z8 3
TC 36
ZB 0
ZA 0
ZR 0
Z9 39
SN 0025-1909
UT WOS:A1991GV22000003
ER

PT J
AU OVIATT, BM
   BAUERSCHMIDT, AD
TI BUSINESS RISK AND RETURN - A TEST OF SIMULTANEOUS RELATIONSHIPS
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1405
EP 1423
DI 10.1287/mnsc.37.11.1405
PD NOV 1991
PY 1991
AB Bowman (1980) found an unexpected and paradoxical negative relationship
   between risk and return in many firms, and, for about a decade, various
   researchers have attempted to explain the paradox. This article
   summarizes some of those explanations, and shows that industry
   conditions and business strategies are likely to influence both risk and
   return. The relationships are depicted in a simultaneous model where
   business return, risk, and debt are endogenously determined.
   The model is tested with 132 nondiversified firms in 8 disparate
   industries. OLS estimates of the parameters of the model show the
   risk-return relationship to be significantly negative, as many past
   researchers have found. However, 3SLS estimates of the parameters of the
   simultaneous model reveal no significant relationship between risk and
   return. The tentative conclusion is that many of the studies in the line
   of research concerned with Bowman's (1980) paradox may have used an
   improperly specified model, and that when a more realistic simultaneous
   model is used, return and risk are shown to be influenced by various
   industry conditions and business strategies, but not by each other.
ZR 0
TC 27
ZB 0
Z8 1
ZS 1
ZA 0
Z9 28
SN 0025-1909
EI 1526-5501
UT WOS:A1991GV22000004
ER

PT J
AU DAMERDJI, H
TI STRONG CONSISTENCY AND OTHER PROPERTIES OF THE SPECTRAL VARIANCE
   ESTIMATOR
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1424
EP 1440
DI 10.1287/mnsc.37.11.1424
PD NOV 1991
PY 1991
AB Consistent estimation of the variance parameter of a stochastic process
   allows construction, under certain conditions, of a confidence interval
   for the mean of the process.  If the variance estimator is strongly
   consistent, fixed-width confidence interval construction is valid for
   large samples.  It has long been known that the spectral variance
   estimator of steady-state simulation output analysis is consistent in
   the mean-square sense.  Here, we provide strong consistency of this
   estimator, thereby justifying fixed-width confidence interval
   construction for the spectral method.  A characterization of spectral
   density function estimators is also introduced.  This characterization
   provides insight into the relation between spectral methods and
   overlapping batch means-type variance estimators.  Finally, some of the
   mathematical conditions provide qualitative insight into the relation
   between the process correlation and certain parameters of spectral
   methods.
Z8 0
TC 23
ZB 1
ZR 0
ZA 0
ZS 0
Z9 23
SN 0025-1909
UT WOS:A1991GV22000005
ER

PT J
AU EASTON, FF
   ROSSIN, DF
TI SUFFICIENT WORKING SUBSETS FOR THE TOUR SCHEDULING PROBLEM
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1441
EP 1451
DI 10.1287/mnsc.37.11.1441
PD NOV 1991
PY 1991
AB Mathematical programs to schedule service employees at minimum cost
   represent each feasible schedule, or tour, with an integer variable.  In
   some service organizations, policies governing employee scheduling
   practices may permit millions of different tours.  A common heuristic
   strategy is to reformulate the problem from a small working subset of
   the feasible tours.  Solution quality depends on the number and types of
   schedules included in the model.
   This paper describes a working subset heuristic based on column
   generation.  The method is general and can accommodate a mix of full-
   and part-time employees.  Experiments revealed its formulations had
   objective values indistinguishable from those of models using all
   feasible tours, and significantly lower than those generated by
   alternative working subset procedures.
Z8 1
TC 55
ZR 0
ZS 0
ZB 0
Z9 56
SN 0025-1909
UT WOS:A1991GV22000006
ER

PT J
AU ELIASHBERG, J
   STEINBERG, R
TI COMPETITIVE STRATEGIES FOR 2 FIRMS WITH ASYMMETRIC PRODUCTION COST
   STRUCTURES
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1452
EP 1473
DI 10.1287/mnsc.37.11.1452
PD NOV 1991
PY 1991
AB We model joint production-marketing strategies for two firms with
   asymmetric production cost structures in competition. The first firm,
   called the "Production-smoother," faces a convex production cost and a
   linear inventory holding cost. The second firm, called the
   "Order-taker," faces a linear production cost and holds no inventory.
   Each firm is assumed to vary continuously over time both its production
   rate and its price in view of an unstable "surge" pattern of demand. The
   underlying theoretical motivation is to investigate the temporal nature
   of the equilibrium policies of two competing firms, one operating at or
   near capacity (the Production-smoother), and one operating significantly
   below capacity (the Order-taker).
   We characterize and compare the equilibrium strategies of the two
   competing firms. Among our results, we show that if the duopolistic
   Production-smoother finds it optimal to hold inventory, then he will
   begin the season by building up inventory, continue by drawing down
   inventory until it reaches zero, and conclude by following a "zero
   inventory" policy until the end of the season. This result, which is
   robust with respect to the market structure, is compared with a
   monopolistic Production-smoother policy. We also show that due to the
   "coupling" effect between the two competing firms, the time at which the
   Production-smoother begins his zero inventory policy is also critical
   for the Order-taker who divides his production and pricing strategies
   into two parts determined by the Production-smoother's zero inventory
   point. Numerical examples that illustrate certain aspects of our
   analyses are provided as well.
ZA 0
ZR 0
TC 27
ZS 0
ZB 0
Z8 0
Z9 27
SN 0025-1909
EI 1526-5501
UT WOS:A1991GV22000007
ER

PT J
AU LIPPMAN, SA
   MCCARDLE, KF
TI UNCERTAIN SEARCH - A MODEL OF SEARCH AMONG TECHNOLOGIES OF UNCERTAIN
   VALUES
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1474
EP 1490
DI 10.1287/mnsc.37.11.1474
PD NOV 1991
PY 1991
AB In the standard search problem there is an infinite pool of items whose
   distribution of values is known.  A decision maker draws an item from
   the pool, observes its value, and decides whether to keep it or to draw
   another item.  He can keep only one item, and he seeks the item with the
   largest value.  In the standard uncertainty resolution problem there is
   only one item, and the value of that item remains uncertain even after
   it is drawn.  The decision maker sequentially collects observations on
   the value of the item and decides whether to keep the item, discard the
   item, or take another observation.  Uncertain search marries the
   sequential drawing from a pool of items from the search literature with
   the unknown value of a drawn item from the uncertainty resolution
   literature.  Presented in the context of technology adoption, it
   considers drawing from a pool of new technologies whose values remain
   unknown even after being drawn.  The decision maker sequentially
   purchases information in order to Bayesianly update the prior
   distribution of the technology's value.  After each observation, the
   decision maker either adopts the technology (and hence quits searching),
   takes another costly observation, rejects the technology and quits
   searching, or rejects the technology and draws the next technology from
   the pool for observation.  The solution to this uncertain search problem
   is surprisingly simple:  solve the version of the uncertainty resolution
   problem in which the return to rejecting the technology is replaced by
   an exit value.  Then use successive approximation to find a fixed point:
   an exit value that equals the expected value of the uncertainty
   resolution problem.
ZB 0
ZR 0
ZA 0
TC 26
ZS 0
Z8 0
Z9 26
SN 0025-1909
UT WOS:A1991GV22000008
ER

PT J
AU BELENKY, V
   BELOSTOTSKY, A
TI ON OPTIMIZATION OF THE PROCESS OF DATA IMPROVEMENT
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1491
EP 1495
DI 10.1287/mnsc.37.11.1491
PD NOV 1991
PY 1991
TC 0
ZR 0
ZA 0
ZB 0
ZS 0
Z8 0
Z9 0
SN 0025-1909
UT WOS:A1991GV22000009
ER

PT J
AU HALL, RW
TI ONE-WAREHOUSE MULTIPLE RETAILER SYSTEMS WITH VEHICLE-ROUTING COSTS -
   COMMENT
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1496
EP 1497
DI 10.1287/mnsc.37.11.1496
PD NOV 1991
PY 1991
ZA 0
Z8 2
ZS 1
ZR 0
ZB 0
TC 20
Z9 23
SN 0025-1909
UT WOS:A1991GV22000010
ER

PT J
AU ANILY, S
   FEDERGRUEN, A
TI COMMENTS ON ONE-WAREHOUSE MULTIPLE RETAILER SYSTEMS WITH VEHICLE-ROUTING
   COSTS - REJOINDER
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1497
EP 1499
DI 10.1287/mnsc.37.11.1497
PD NOV 1991
PY 1991
TC 32
ZA 0
ZB 0
ZS 1
Z8 2
ZR 0
Z9 35
SN 0025-1909
UT WOS:A1991GV22000011
ER

PT J
AU SWANSON, EB
   FULLER, MK
   NIDUMOLU, S
   RAMILLER, N
   WARD, SG
TI ILLUSIVE EFFECTS ON THE DIFFUSION OF AN INNOVATION - A COMMENT
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1500
EP 1502
DI 10.1287/mnsc.37.11.1500
PD NOV 1991
PY 1991
TC 3
ZB 0
Z8 0
ZS 0
ZA 0
ZR 0
Z9 3
SN 0025-1909
UT WOS:A1991GV22000012
ER

PT J
AU NILAKANTA, S
   SCAMELL, RW
TI THE EFFECTS OF INFORMATION-SOURCES AND COMMUNICATION CHANNELS ON THE
   DIFFUSION OF AN INNOVATION
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1503
EP 1506
DI 10.1287/mnsc.37.11.1503
PD NOV 1991
PY 1991
AB Swanson et al.'s comment, "Illusive Effects on the Diffusion of an
   Innovation:  A Comment," (Swanson et al. 1991, this issue) contains two
   major criticisms of our paper (Nilakanta and Scamell, 1990), "Effects of
   Information Sources and Communication Channels on Diffusion of
   Innovation in a Data Base Development Environment:"  (1) the
   significance and interpretations of the results and (2) the legitimacy
   of certain measures that appear in the questionnaire contained in the
   appendix (pp. 34-38).  The purpose of this comment is to address these
   criticisms.
ZB 0
TC 0
ZA 0
Z8 0
ZS 0
ZR 0
Z9 0
SN 0025-1909
UT WOS:A1991GV22000013
ER

PT J
AU GUTIERREZ, GJ
TI CORRECTION
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1507
EP 1507
PD NOV 1991
PY 1991
ZB 0
ZS 0
TC 3
ZR 0
Z8 0
Z9 3
SN 0025-1909
UT WOS:A1991GV22000014
ER

PT J
AU SCHWENK, CR
TI CORRECTION
SO MANAGEMENT SCIENCE
VL 37
IS 11
BP 1508
EP 1508
PD NOV 1991
PY 1991
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
Z9 0
SN 0025-1909
UT WOS:A1991GV22000015
ER

PT J
AU GEOFFRION, AM
TI FW/SM - A PROTOTYPE STRUCTURED MODELING ENVIRONMENT
SO MANAGEMENT SCIENCE
VL 37
IS 12
BP 1513
EP 1538
DI 10.1287/mnsc.37.12.1513
PD DEC 1991
PY 1991
AB A research prototype implementation has been evolving for several years
   in parallel with the vision, theory, language, and applicative aspects
   of structured modeling. The objective of this article is to describe the
   capabilities of this implementation as it now stands, and to comment on
   how it contributes toward fulfilling a previously published agenda for
   the development of a new generation of modeling environments. The
   intended audience is all modeling system designers and evaluators,
   including those who do not happen to take a structured modeling
   approach.
ZB 1
TC 33
ZS 0
ZA 0
ZR 0
Z8 2
Z9 35
SN 0025-1909
UT WOS:A1991HB10900001
ER

PT J
AU SRINIVASAN, K
TI MULTIPLE MARKET ENTRY, COST SIGNALING AND ENTRY DETERRENCE
SO MANAGEMENT SCIENCE
VL 37
IS 12
BP 1539
EP 1555
DI 10.1287/mnsc.37.12.1539
PD DEC 1991
PY 1991
AB A low-cost incumbent may limit price to informatively signal her cost to
   an uncertain potential entrant, and therefore deter entry. We enrich
   this model by investigating the strategic pricing behavior of the
   incumbent when she operates in multiple markets. We demonstrate that the
   low-cost incumbent's ability to separate from a ghost high-cost type is
   enhanced when she combines her signalling effort across markets, instead
   of independent signalling in each market. we show that, in the combined
   least-cost signalling, the low-cost incumbent limit prices in each
   market. In an attempt to minimize dissipative but informative signalling
   costs, the low-cost incumbent may enter unprofitable markets, but exit
   after credible separation.
Z8 0
TC 29
ZR 0
ZA 0
ZS 0
ZB 0
Z9 29
SN 0025-1909
EI 1526-5501
UT WOS:A1991HB10900002
ER

PT J
AU BASSOK, Y
   AKELLA, R
TI ORDERING AND PRODUCTION DECISIONS WITH SUPPLY QUALITY AND DEMAND
   UNCERTAINTY
SO MANAGEMENT SCIENCE
VL 37
IS 12
BP 1556
EP 1574
DI 10.1287/mnsc.37.12.1556
PD DEC 1991
PY 1991
AB In this paper, we solve a production planning problem that has a direct
   bearing on the cost to a facility of vendor quality and reliability.
   This solution is also an important first step in solving the multi-plant
   coordination problem.
   We consider a manufacturing facility with one critical raw material, and
   one or more products whose demand needs to be met. It is assumed that
   demand for finished goods and the arrival process for raw material are
   stochastic. We calculate simultaneously the optimal production level,
   and the raw material order quantity which minimize the total expected
   cost subject to capacity and release level constraints. The results
   obtained by our model (the integrated model) show that the production
   level should be no larger than the production level obtained by solving
   the traditional (nonintegrated) models, and that major savings are
   obtained by solving the integrated model. We are also able to
   characterize and evaluate the cost of reliable supplies of raw material.
   In addition we solve the above problem in the presence of capacity
   constraints. A procedure which allocates capacity to different products
   is presented.
TC 39
ZB 0
ZS 0
ZA 0
Z8 1
ZR 0
Z9 40
SN 0025-1909
UT WOS:A1991HB10900003
ER

PT J
AU SCHERVISH, MJ
   SEIDENFELD, T
   KADANE, JB
TI SHARED PREFERENCES AND STATE-DEPENDENT UTILITIES
SO MANAGEMENT SCIENCE
VL 37
IS 12
BP 1575
EP 1589
DI 10.1287/mnsc.37.12.1575
PD DEC 1991
PY 1991
AB This investigation combines two questions for expected utility theory:
   1. When do the shared preferences among expected utility maximizers
   conform to the dictates of expected utility? 2. What is the impact on
   expected utility theory of allowing preferences for prizes to be
   state-dependent?
   Our Principal conclusion (Theorem 4) establishes very restrictive
   necessary and sufficient conditions for the existence of a Pareto,
   Bayesian compromise of preferences between two Bayesian agents, even
   when utilities are permitted to be state-dependent and identifiable.
   This finding extends our earlier result (Theorem 2, 1989a) which applies
   provided that all utilities are state-independent. A subsidiary theme is
   a decision theoretic analysis of common rules for "pooling" expert
   probabilities.
   Against the backdrop of "horse lottery" theory (Anscombe and Aumann
   1963) and subject to a weak Pareto rule, we show, generally, that there
   is no Bayesian compromise between two Bayesian agents even when
   state-dependent utilities are entertained in an identifiable way. The
   word "identifiable" is important because, if state-dependence is
   permitted merely by dropping the Anscombe-Aumann axiom (Axiom 4 here)
   for "state-independenoe," though a continuum of possible Bayesian
   compromises emerges, also it leads to an extreme underdetermination of
   an agent's personal probability and utility given the agent's
   preferences. Instead, when state-dependence is monitored through (our
   version of) the approach of Karni, Schmeidler, and Vind (1983), the
   general impossibility of a Bayesian, Pareto compromise in preferences
   reappears.
ZS 0
TC 12
ZR 0
ZB 1
Z8 0
ZA 0
Z9 12
SN 0025-1909
UT WOS:A1991HB10900004
ER

PT J
AU DREXL, A
TI SCHEDULING OF PROJECT NETWORKS BY JOB ASSIGNMENT
SO MANAGEMENT SCIENCE
VL 37
IS 12
BP 1590
EP 1602
DI 10.1287/mnsc.37.12.1590
PD DEC 1991
PY 1991
AB A recurring problem in project management involves the allocation of
   scarce resources to the individual jobs comprising the project. In many
   situations such as audit scheduling, the resources correspond to
   individuals (skilled labour). This naturally leads to an assignment type
   project scheduling problem, i.e. a project has to be processed by
   assigning one of several individuals (resources) to each job. In this
   paper we consider the nonpreemptive variant of a resource-constrained
   project job-assignment problem, where job durations as well as costs
   depend upon the assigned resource. Regarding precedence relations as
   well as release dates and deadlines, the question arises, to which jobs
   resources should be assigned in order to minimize overall costs. For
   solving this time-resource-cost-tradeoff problem we present a hybrid
   brand and bound/dynamic programming algorithm with a (rather efficient
   Monte Carlo type) heuristic upper bounding technique as well as various
   relaxation procedures for determining lower bounds. Computational
   results are presented as well.
Z8 6
TC 94
ZS 0
ZR 0
ZA 0
ZB 1
Z9 100
SN 0025-1909
EI 1526-5501
UT WOS:A1991HB10900005
ER

PT J
AU BORCHERDING, K
   EPPEL, T
   VONWINTERFELDT, D
TI COMPARISON OF WEIGHTING JUDGMENTS IN MULTIATTRIBUTE UTILITY MEASUREMENT
SO MANAGEMENT SCIENCE
VL 37
IS 12
BP 1603
EP 1619
DI 10.1287/mnsc.37.12.1603
PD DEC 1991
PY 1991
AB This paper compares four weighting methods in multiattribute utility
   measurement: the ratio method, the swing weighting method, the tradeoff
   method and the pricing out method. 200 subjects used these methods to
   weight attributes for evaluating nuclear waste repository sites in the
   United States. The weighting methods were compared with respect to their
   internal consistency, convergent validity, and external validity.
   Internal consistency was measured by the degree to which ordinal and
   cardinal or ratio responses agreed within the same weighting method.
   Convergent validity was measured by the degree of agreement between the
   weights elicited with different methods. External validity was
   determined by the degree to which weights elicited in this experiment
   agreed with weights that were elicited with managers of the Department
   of Energy. In terms of internal consistency, the tradeoff method fared
   worst. In terms of convergent validity, the pricing out method turned
   out to be an outlier. In terms of external validity, the pricing out
   method showed the best results. While the ratio and swing methods are
   quite consistent and show a fair amount of convergent validity, their
   external validity problems cast doubt on their usefulness. The main
   recommendation for applications is to improve the internal consistency
   of the tradeoff method by careful interactive elicitation and to use it
   in conjunction with the pricing out method to enhance its external
   validity.
ZR 0
ZB 5
ZA 0
ZS 2
Z8 0
TC 122
Z9 123
SN 0025-1909
UT WOS:A1991HB10900006
ER

PT J
AU RAY, SC
TI RESOURCE-USE EFFICIENCY IN PUBLIC-SCHOOLS - A STUDY OF CONNECTICUT DATA
SO MANAGEMENT SCIENCE
VL 37
IS 12
BP 1620
EP 1628
DI 10.1287/mnsc.37.12.1620
PD DEC 1991
PY 1991
AB This study combines Data Envelopment Analysis (DEA) with regression
   modelling to estimate relative efficiency in the public school districts
   of Connecticut. Factors affecting achievements are classified as school
   inputs and other socio-economic factors. DEA is performed with the
   school inputs only. Efficiency measures obtained from DEA are
   subsequently related to the socio-economic factors in a regression model
   with a one-sided disturbance term. The findings suggest that while
   productivity of school inputs varies considerably across districts this
   can be ascribed to a large extent to differences in the socio-economic
   background of the communities served. Variation in managerial efficiency
   is much less than what is implied by the DEA results.
RI Figueiredo, Otavio H S/K-4777-2015
ZS 12
ZA 0
TC 174
ZB 3
ZR 0
Z8 3
Z9 188
SN 0025-1909
UT WOS:A1991HB10900007
ER

PT J
AU LEI, L
   WANG, TJ
TI THE MINIMUM COMMON-CYCLE ALGORITHM FOR CYCLIC SCHEDULING OF 2 MATERIAL
   HANDLING HOISTS WITH TIME WINDOW CONSTRAINTS
SO MANAGEMENT SCIENCE
VL 37
IS 12
BP 1629
EP 1639
DI 10.1287/mnsc.37.12.1629
PD DEC 1991
PY 1991
AB The problem of cyclic scheduling of two hoists is defined as follows.
   There are N + 1 workstations, S0, S1, ..., S(N), and two identical
   hoists that move jobs between stations. Jobs are identical and each job
   has to visit all stations in the order that stations are numbered. It is
   assumed that the hoist traveling times between stations are given
   constants. Each station can hold one job at a time, and each job must
   remain at station S(i) for a period of at least a(i) and at most b(i)
   time units. Both a(i) and b(i), i = 2, ..., N, are given constants.
   Define mi, 0 less-than-or-equal-to i less-than-or-equal-to N, to be a
   move of a job from S(i) to S(i + 1). A cyclic schedule determines the
   order of N + 1 moves, {m(i), i = 0, 1, ..., N}, an assignment of these
   moves to hoists, and the start time of the moves in a cycle. The problem
   is to find a cyclic schedule that minimizes the total time (the cycle
   time) to complete all the N + 1 moves.
   Previous approaches toward solving cyclic hoist scheduling problems have
   been limited to single-hoist cases In this paper, we propose a heuristic
   algorithm that finds schedules for systems with two hoists, and discuss
   an extension to the problem with more than two hoists. The algorithm
   uses a partitioning approach by which a system is partitioned into two
   sets of contiguous workstations and each hoist is assigned to a set. A
   sequence of alternative partitions is evaluated. For each partition, two
   single-hoist subproblems are formed and the optimal (minimal) cycle time
   for each subproblem is independently computed. The two optimal
   single-hoist schedules are then coupled and refined into a feasible
   two-hoist schedule with a common-cycle time for both hoists. The best of
   the generated schedules, that results in the minimum common-cycle time
   among the different partitions, is given as the final solution.
   Computational experience with both randomly generated problems and a
   benchmark problem arising from a real system is discussed.
ZR 0
ZS 0
TC 78
ZA 0
Z8 8
ZB 0
Z9 86
SN 0025-1909
UT WOS:A1991HB10900008
ER

PT J
AU KAMRAD, B
   RITCHKEN, P
TI MULTINOMIAL APPROXIMATING MODELS FOR OPTIONS WITH K-STATE VARIABLES
SO MANAGEMENT SCIENCE
VL 37
IS 12
BP 1640
EP 1652
DI 10.1287/mnsc.37.12.1640
PD DEC 1991
PY 1991
AB Contingent claims whose values depend on multiple sources of uncertainty
   arise in many financial contracts and in the analysis of real projects.
   Unfortunately closed form solutions for these options are rare and
   numerical methods can be computationally expensive. This article extends
   the literature on multinomial approximating models. Specifically, new
   multinomial models are presented that include as special cases existing
   models. The more general models are shown to be computationally more
   efficient.
RI KAMRAD, BARDIA -/A-3057-2008
ZA 0
TC 113
ZB 0
ZR 1
Z8 2
ZS 1
Z9 116
SN 0025-1909
UT WOS:A1991HB10900009
ER

PT B
AU HOJATI, M
BE Rosenbloom, ES
TI APPROXIMATE SOLUTIONS TO DIRECTED NETWORK SYNTHESIS PROBLEM
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 1
EP 6
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
ZS 0
ZA 0
TC 0
ZR 0
ZB 0
Z8 0
Z9 0
UT WOS:A1992BX39A00001
ER

PT B
AU YEH, MH
   YE, YS
   TUO, GZ
BE Rosenbloom, ES
TI CROP INSURANCE PREMIUM RATES AND DISCOUNTS UNDER ALTERNATIVE YIELD
   DISTRIBUTION
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 7
EP 13
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
Z8 0
ZB 0
ZR 0
ZS 0
TC 0
Z9 0
UT WOS:A1992BX39A00002
ER

PT B
AU MARTEL, JM
   AZONDEKON, SH
BE Rosenbloom, ES
TI FUZZY PREFERENCE RELATIONS IN MULTICRITERION ANALYSIS WITH IMPRECISION
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 14
EP 22
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
ZR 0
ZB 0
Z8 0
ZS 0
TC 0
Z9 0
UT WOS:A1992BX39A00003
ER

PT B
AU LAWLESS, A
   BHATT, SK
BE Rosenbloom, ES
TI MULTIPLE OBJECTIVE DECISION-MAKING IN MEDIUM VOLTAGE CURRENT TRANSFORMER
   DESIGN
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 23
EP 33
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
ZA 0
ZR 0
TC 0
ZS 0
ZB 0
Z8 0
Z9 0
UT WOS:A1992BX39A00004
ER

PT B
AU WANG, SH
   ARCHER, NP
BE Rosenbloom, ES
TI A NEURAL NETWORK APPROACH TO ULTRAFUZZY REPRESENTATION OF THE
   UNCERTAINTY IN MULTIPLE PERSON DECISIONS
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 34
EP 43
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
ZB 0
ZR 0
ZS 0
Z8 0
ZA 0
TC 0
Z9 0
UT WOS:A1992BX39A00005
ER

PT B
AU ROSENBLOOM, ES
   SHIU, ESW
BE Rosenbloom, ES
TI A LINEAR-PROGRAMMING APPROACH TO BOND PORTFOLIO MANAGEMENT WITH
   BORROWING
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 44
EP 49
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
ZB 0
Z8 0
ZR 0
TC 0
ZS 0
Z9 0
UT WOS:A1992BX39A00006
ER

PT B
AU BECTOR, CR
   HAWALESHKA, O
   GILL, A
BE Rosenbloom, ES
TI A LOT SIZING INVENTORY PROBLEM WITH VARIABLE DEMAND RATE UNDER BOTH
   CRISP AND FUZZY ENVIRONMENTS
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 50
EP 61
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
ZB 0
TC 0
Z8 0
ZS 0
ZR 0
Z9 0
UT WOS:A1992BX39A00007
ER

PT B
AU SCHONER, B
BE Rosenbloom, ES
TI CORRECTING THE ANALYTIC HIERARCHY PROCESS
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 62
EP 68
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
TC 0
ZA 0
ZS 0
Z8 0
ZB 0
ZR 0
Z9 0
UT WOS:A1992BX39A00008
ER

PT B
AU KOPLYAY, T
   KOH, J
   ROJASESQUIVEL, A
BE Rosenbloom, ES
TI EXECUTIVE-COMPENSATION IN CANADA - A SURVEY OF CANADIAN PRACTICES AND
   HOW THEY COMPARE WITH UNITED-STATES RESULTS
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 69
EP 79
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
ZB 0
ZR 0
TC 0
ZS 0
Z8 0
Z9 0
UT WOS:A1992BX39A00009
ER

PT B
AU YEH, MH
   SHI, HG
BE Rosenbloom, ES
TI CHINA IMPORT DEMAND FOR WHEAT
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 80
EP 86
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
ZB 0
Z8 0
ZS 0
TC 0
ZA 0
ZR 0
Z9 0
UT WOS:A1992BX39A00010
ER

PT B
AU LI, YH
BE Rosenbloom, ES
TI REAL-TIME SCHEDULING ON A TRANSIT BUS ROUTE - A 0-1
   STOCHASTIC-PROGRAMMING MODEL
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 87
EP 96
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
Z8 0
ZA 0
TC 0
ZS 0
ZB 0
ZR 0
Z9 0
UT WOS:A1992BX39A00011
ER

PT B
AU SINGH, C
   HUSAIN, I
BE Rosenbloom, ES
TI DUALITY FOR A CLASS OF NONDIFFERENTIABLE CONTINUOUS-TIME MULTIOBJECTIVE
   PROGRAMMING-PROBLEMS WITH INVEXITY
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 97
EP 114
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
Z8 0
ZB 0
ZR 0
TC 0
ZS 0
Z9 0
UT WOS:A1992BX39A00012
ER

PT B
AU BECTOR, CR
   SUNEJA, SK
   GUPTA, S
BE Rosenbloom, ES
TI UNIVEX FUNCTIONS AND UNIVEX NONLINEAR-PROGRAMMING
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 115
EP 124
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
Z8 0
ZR 0
ZS 0
ZB 0
TC 0
Z9 0
UT WOS:A1992BX39A00013
ER

PT B
AU SUNEJA, SK
   KAUL, RN
BE Rosenbloom, ES
TI GENERALIZED NONSMOOTH INVEX PROGRAMS - OPTIMIZATION AND DUALITY
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 125
EP 131
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
ZS 0
ZB 0
ZR 0
TC 0
Z8 0
Z9 0
UT WOS:A1992BX39A00014
ER

PT B
AU SIM, LSM
   CHENG, TCE
BE Rosenbloom, ES
TI A MODEL TO ASSESS THE RESERVATION PRICES OF AN INTERMEDIATE
   RESEARCH-AND-DEVELOPMENT RESULT AND PATENT REWARD
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 132
EP 142
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
RI Cheng, T. C. E./D-5688-2015
ZB 0
TC 0
ZA 0
ZS 0
ZR 0
Z8 0
Z9 0
UT WOS:A1992BX39A00015
ER

PT B
AU SEAH, E
BE Rosenbloom, ES
TI AN INTEGER PROGRAMMING FORMULATION FOR THE NEUTRALITY OF GRAPH PROBLEM
SO ASAC 92, VOL 13, NO 12, 1992: MANAGEMENT SCIENCE
BP 143
EP 147
PD 1992
PY 1992
CT 1992 ANNUAL CONF OF THE MANAGEMENT SCIENCE INTEREST GROUP OF THE
   ADMINISTRATIVE SCIENCES ASSOC OF CANADA
CY JUN 06-09, 1992
CL QUEBEC CITY, CANADA
SP ADM SCI ASSOC CANADA
Z8 0
TC 0
ZB 0
ZR 0
ZS 0
Z9 0
UT WOS:A1992BX39A00016
ER

PT J
AU LIANG, TP
TI A COMPOSITE APPROACH TO INDUCING KNOWLEDGE FOR EXPERT SYSTEMS-DESIGN
SO MANAGEMENT SCIENCE
VL 38
IS 1
BP 1
EP 17
DI 10.1287/mnsc.38.1.1
PD JAN 1992
PY 1992
AB Knowledge acquisition is a bottleneck for expert system design.  One way
   to overcome this bottleneck is to induce expert system rules from sample
   data.  This paper presents a new induction approach called CRIS.  The
   key notion employed in CRIS is that nominal and nonnominal attributes
   have different characteristics and hence should be analyzed differently.
   In the beginning of the paper, the benefits of this approach are
   described.  Next, the basic elements of the CRIS approach are discussed
   and illustrated.  This is followed by a series of empirical comparisons
   of the predictive validity of CRIS versus two entropy-based induction
   methods (ACLS and PLSI), statistical discriminant analysis, and the
   backpropagation method in neural networks.  These comparisons all
   indicate that CRIS has higher predictive validity.  The implications of
   the findings for expert systems design are discussed in the conclusion
   of the paper.
Z8 0
ZS 0
ZB 0
ZA 0
TC 31
ZR 0
Z9 31
SN 0025-1909
UT WOS:A1992HE22700001
ER

PT J
AU SEBENIUS, JK
TI NEGOTIATION ANALYSIS - A CHARACTERIZATION AND REVIEW
SO MANAGEMENT SCIENCE
VL 38
IS 1
BP 18
EP 38
DI 10.1287/mnsc.38.1.18
PD JAN 1992
PY 1992
AB "Negotiation analysis" seeks to develop prescriptive theory and useful
   advice for negotiators and third parties.  It generally emphasizes the
   parties' underlying interests (as distinct from the issues on the table
   and the positions taken), alternatives to negotiated agreement,
   approaches to productively manage the inherent tension between
   competitive actions to "claim" value individually and cooperative ones
   to "create" value jointly, as well as efforts to change perceptions of
   the game itself.  Since advice to one side does not necessarily presume
   the full game-theoretic rationality of the other side (s), negotiation
   analysts often draw on the findings of behavioral decision analysts and
   economists.   Further, this approach does not generally assume that all
   the elements of the "game" are common knowledge.  Thus, the negotiation
   analytic approach tends to de-emphasize the application of
   game-theoretic solution concepts or efforts to find unique equilibrium
   outcomes.  Instead, to evaluate possible strategies and tactics,
   negotiation analysts generally focus on changes in perceptions of the
   "zone of possible agreement" and the (subjective) distribution of
   possible negotiated outcomes conditional on various actions.  This
   approach is especially sensitive to potentially unrealized joint gains. 
   It has been used to develop prescriptive advice for the simplest
   bilateral negotiations between monolithic parties, for negotiations
   through agents or with linked "internal" and "external" aspects, for
   negotiations in hierarchies and networks, as well as for more complex
   coalitional interactions.
ZS 1
Z8 2
TC 178
ZR 0
ZB 3
ZA 0
Z9 181
SN 0025-1909
UT WOS:A1992HE22700002
ER

PT J
AU HOFFMANN, TR
TI EUREKA - A HYBRID SYSTEM FOR ASSEMBLY LINE BALANCING
SO MANAGEMENT SCIENCE
VL 38
IS 1
BP 39
EP 47
DI 10.1287/mnsc.38.1.39
PD JAN 1992
PY 1992
AB Numerous methods have been proposed for solution of the simple assembly
   line balancing (SALB) problem.  This paper describes a branch and bound
   algorithm which in many cases is faster than the well-known Hoffmann
   heuristic technique to which it is related.  It introduces a simple
   bounding rule which uses the concept of the "theoretical" minimum slack
   time to achieve rapid solutions.  It is combined with the Hoffmann
   heuristic to develop an even more effective system for solving SALB
   problems.  Timing results are given for a standard set of problems found
   in the literature.  Since that set was solved in such a very short time,
   more challenging as well as more typical problems are explored and
   timing results presented.  Benchmarking of the procedure is easier since
   implementation is on an eight-megahertz IBM AT with a math coprocessor,
   using the standard IBM PC Professional FORTRAN compiler.
ZA 0
ZR 0
ZS 0
ZB 1
Z8 3
TC 94
Z9 97
SN 0025-1909
UT WOS:A1992HE22700003
ER

PT J
AU GERCHAK, Y
   FULLER, JD
TI OPTIMAL VALUE DECLARATION IN BUY SELL SITUATIONS
SO MANAGEMENT SCIENCE
VL 38
IS 1
BP 48
EP 56
DI 10.1287/mnsc.38.1.48
PD JAN 1992
PY 1992
AB Buy-Sell "Shotgun" clauses call for a partner who wishes to discontinue
   a partnership to declare a value for the business, and for the other
   partner to then buy her out or sell to her at this value.  The resulting
   decision model for an expected utility maximizing individual, who is
   uncertain of the business' valuation by the partner, is analyzed.  This
   model is also applicable to a "divide and choose" fair division method,
   as well as some historical tax/customs schemes, and is more general than
   comparable bidding/auctions models.  After showing that the optimal
   declaration is always between the declarer's valuation and the fractile
   of the subjective distribution corresponding to the share owned, we show
   that the optimal declaration is always increasing in the valuation, and
   for a risk-neutral declarer also increasing in the share owned.  We
   prove that the more risk-averse the declarer, the closer is the optimal
   declaration to the valuation, and the higher the probability that the
   partner who values the business more will end up owning it.  Finally, we
   relate the optimal declaration to the degree of uncertainty concerning
   the partner's valuation.
ZB 0
ZR 0
ZS 0
Z8 0
TC 4
Z9 4
SN 0025-1909
UT WOS:A1992HE22700004
ER

PT J
AU KAROLYI, GA
TI PREDICTING RISK - SOME NEW GENERALIZATIONS
SO MANAGEMENT SCIENCE
VL 38
IS 1
BP 57
EP 74
DI 10.1287/mnsc.38.1.57
PD JAN 1992
PY 1992
AB Existing adjustment techniques for forecasting systematic risk of
   individual firms have been based on relatively uniformative prior
   knowledge about the cross-sectional distribution of risk estimates. 
   This study introduces prior information in the form of size and
   industry-based cross-sectional distributions of risk estimates.  Such
   information is incorporated into forecasts using familiar and
   generalized adjustment techniques, the latter being based on recently
   developed multiple shrinkage methods.  Improved forecast performance
   results.
ZR 0
ZA 0
ZS 0
Z8 0
ZB 0
TC 15
Z9 15
SN 0025-1909
UT WOS:A1992HE22700005
ER

PT J
AU CHOI, SC
   DESARBO, WS
   HARKER, PT
TI A NUMERICAL APPROACH TO DERIVING LONG-RUN EQUILIBRIUM SOLUTIONS IN
   SPATIAL POSITIONING MODELS
SO MANAGEMENT SCIENCE
VL 38
IS 1
BP 75
EP 86
DI 10.1287/mnsc.38.1.75
PD JAN 1992
PY 1992
AB Choi, DeSarbo and Harker (1990) have recently proposed a numerical
   methodology for optimal product positioning and pricing under the
   assumption that the incumbents react only with price changes in the
   short run.  The current note extends this methodology to include
   incumbents' long-run strategy of competitive product repositioning, in
   addition to price reactions.  This note also introduces the notion of
   product relocation cost to the equilibrium analysis, and applies the
   concept of (full and partial) adjustment processes toward an equilibrium
   to model various strategic behavior of firms.  This methodology is
   illustrated using an existing set of data collected for a major
   telecommunication equipment manufacturer.
RI Harker, Patrick T/A-9467-2013
OI Harker, Patrick T/0000-0003-0659-3102
ZB 0
ZR 0
ZA 0
Z8 0
ZS 0
TC 20
Z9 20
SN 0025-1909
UT WOS:A1992HE22700006
ER

PT J
AU ZHENG, YS
TI ON PROPERTIES OF STOCHASTIC INVENTORY SYSTEMS
SO MANAGEMENT SCIENCE
VL 38
IS 1
BP 87
EP 103
DI 10.1287/mnsc.38.1.87
PD JAN 1992
PY 1992
AB For most order quantity/reorder point inventory systems, the stochastic
   model, which specifies the demands as stochastic processes, is often
   more accurate than its deterministic counterpart- the EOQ model. 
   However, the application of the stochastic model has been limited
   because of the absence of insightful analytical results on the model.
   This paper analyzes the stochastic order quantity/reorder point model in
   comparison with a corresponding deterministic EOQ model.  Based on
   simple optimality conditions for the control variables derived in the
   paper, a sensitivity analysis is carried out, and a number of basic
   qualitative properties are established for the optimal control
   parameters.  Our main results include the following:  (1) in contrast to
   the deterministic EOQ model, the controllable costs of the stochastic
   model due to selection of the order quantity (assuming the reorder point
   is chosen optimally for every order quantity) are actually smaller,
   while the total costs are clearly larger; the optimal order quantity is
   larger, but the difference is relatively small when the quantity is
   large; the cost performance is even less sensitive to choices of the
   order quantity; (2) the relative increase of the costs incurred by using
   the quantity determined by the EOQ instead of the optimal from the
   stochastic model is no more than 1/8, and vanishes when the ordering
   costs are significant relative to other costs.
ZR 0
TC 168
ZS 0
ZA 0
ZB 1
Z8 7
Z9 175
SN 0025-1909
UT WOS:A1992HE22700007
ER

PT J
AU GROENEVELT, H
   PINTELON, L
   SEIDMANN, A
TI PRODUCTION LOT SIZING WITH MACHINE BREAKDOWNS
SO MANAGEMENT SCIENCE
VL 38
IS 1
BP 104
EP 123
DI 10.1287/mnsc.38.1.104
PD JAN 1992
PY 1992
AB Economic lot sizing and batching models often assume reliable
   manufacturing facilities.  In this research, we focus on the effects of
   machine breakdowns and corrective maintenance on the economic lot sizing
   decisions.  Two production control policies are proposed for coping with
   these stochastic interferences.  The first policy assumes that
   production of the interrupted lots is not resumed after a breakdown. 
   Instead, the on-hand inventory is depleted before a new cycle is
   initiated.  Under the second policy studied here, production is
   immediately resumed after a breakdown, if the current on-hand inventory
   is below a certain threshold level.  It is shown that this control
   structure is optimal among all stationary policies.  We show that under
   both policies the optimal lot sizes will always be bigger than the ones
   in a corresponding deterministic case, and that the optimal lot size
   increases with the failure rate.  We also provide exact optimal and
   closed form approximate lot sizing formulas and derive tight bounds on
   the average cost per unit time for the approximations.  In addition, we
   present various structural properties for these policies and operational
   insights relevant to such management decisions as machine replacement or
   maintenance schedules.
RI pintelon, liliane/S-3769-2016
OI pintelon, liliane/0000-0003-4298-1583
Z8 8
ZS 0
ZA 0
TC 196
ZR 0
ZB 3
Z9 204
SN 0025-1909
UT WOS:A1992HE22700008
ER

PT J
AU WEBSTER, S
TI NEW BOUNDS FOR THE IDENTICAL PARALLEL PROCESSOR WEIGHTED FLOW TIME
   PROBLEM
SO MANAGEMENT SCIENCE
VL 38
IS 1
BP 124
EP 136
DI 10.1287/mnsc.38.1.124
PD JAN 1992
PY 1992
AB In 1964, Eastman, Even, and Isaacs (EEI) presented a polynomial time
   lower bound for the NP-hard problem of scheduling n jobs on m available
   and identical processors to minimize weighted flow time.  A general
   bound, of which the EEI bound is a special case, is proposed.  Four new
   bounds for the identical processor problem are given.  All of the new
   bounds can be applied to problems with variable processor ready times. 
   The EEI bound is limited to problems where all processors are initially
   available at the same time.  Two of the four new bounds are shown to
   dominate the EEI bound.  The two other bounds are found to be effective
   for a particular problem class.
   Two polynomial time lower bounds for problems with nonidentical
   processors are introduced.  One bound is applicable to the uniform
   processor problem; the other bound can be applied to the general
   processor problem.  No bounds have previously been proposed for these
   problems.
ZR 0
TC 24
ZS 0
Z8 2
ZB 0
Z9 25
SN 0025-1909
UT WOS:A1992HE22700009
ER

PT J
AU YAMAZAKI, G
   SAKASEGAWA, H
   SHANTHIKUMAR, JG
TI ON OPTIMAL ARRANGEMENT OF STATIONS IN A TANDEM QUEUING SYSTEM WITH
   BLOCKING
SO MANAGEMENT SCIENCE
VL 38
IS 1
BP 137
EP 153
DI 10.1287/mnsc.38.1.137
PD JAN 1992
PY 1992
AB We consider tandem queueing networks with no waiting spaces and address
   the issue of ordering the stations so that the throughput (i.e., the
   departure rate) is maximized.  Based on some theoretical and extensive
   empirical results, we propose two rules for ordering the stations.  The
   first rule recommends arranging the two worst stations (according to our
   ordering) to the first and last stages.  Numerical results show that
   this rule almost always agrees with the optimal ordering of stations. 
   In cases where this rule does not agree with the optimal ordering,
   numerical results show that this rule leads to station arrangements that
   are near optimal.  In addition, numerical results also indicate that the
   first rule is the most important one to achieve a near optimal
   throughput.  The second rule arranges the remaining stations according
   to the so-called "bowl phenomenon."  Numerical results illustrate that
   an optimal arrangement of stations need not exhibit the "bowl
   phenomenon," but the differences in the throughput between the optimal
   and the one obtained by the second rule are always very small (less than
   0.5%).
RI Shanthikumar, George/L-4837-2019
ZB 0
Z8 0
ZS 0
ZR 0
ZA 0
TC 29
Z9 29
SN 0025-1909
UT WOS:A1992HE22700010
ER

PT J
AU CAPON, N
   FARLEY, JU
   LEHMANN, DR
   HULBERT, JM
TI PROFILES OF PRODUCT INNOVATORS AMONG LARGE UNITED-STATES MANUFACTURERS
SO MANAGEMENT SCIENCE
VL 38
IS 2
BP 157
EP 169
DI 10.1287/mnsc.38.2.157
PD FEB 1992
PY 1992
AB This paper identifies four groups among 113 Fortune 500 manufacturers
   that approach innovation quite differently.  The groups are based on 27
   measured elements of corporate environment, corporate strategy, and
   formal and informal organization.  Both product innovation and financial
   performance differ significantly over the groups, and a group of 42
   firms that invest heavily in innovation perform best financially.  A
   smaller group of firms that are not innovative but which follow a
   strategy of acquisition perform nearly as well financially.  Firms
   focusing research resources on process innovation perform poorly,
   although process research complements product research among the
   effective innovators.  Particularly important for explaining both
   product innovation and financial performance of these firms are salient
   combinations of classic elements of good environment, good strategy and
   good organization-strong positions in growing markets, investment in
   research and development, open and creative organizational structures
   and supportive organizational climates.
Z8 6
ZA 0
TC 200
ZS 1
ZB 1
ZR 0
Z9 207
SN 0025-1909
UT WOS:A1992HL33800001
ER

PT J
AU KLEIJNEN, JPC
   ANNINK, B
TI VECTOR COMPUTERS, MONTE-CARLO SIMULATION AND REGRESSION-ANALYSIS - AN
   INTRODUCTION
SO MANAGEMENT SCIENCE
VL 38
IS 2
BP 170
EP 181
DI 10.1287/mnsc.38.2.170
PD FEB 1992
PY 1992
AB Vector computers provide a new tool for management scientists.  The
   application of that tool requires thinking in vector mode.  This mode is
   examined in the context of Monte Carlo experiments with regression
   models; these regression models may serve as metamodels in simulation
   experiments.  The vector mode needs to exploit a specific dimension of
   the Monte Carlo experiment, namely the replicates of that experiment. 
   Taking advantage of the machine architecture gives a code that computes
   Ordinary Least Squares estimates on a Cyber 205 in only 2% of the time
   needed on a Vax 8700.  For Generalized Least Squares estimates, however,
   the code runs slower on the Cyber 205 than on the VAX, if the regression
   model is small; for large models the CYBER 205 runs much faster.
RI Kleijnen, Jack/AAL-6469-2020; Kleijnen, Jack/ABB-6455-2020
ZR 0
Z8 0
ZA 0
TC 2
ZB 0
ZS 0
Z9 2
SN 0025-1909
UT WOS:A1992HL33800002
ER

PT J
AU LI, L
TI THE ROLE OF INVENTORY IN DELIVERY-TIME COMPETITION
SO MANAGEMENT SCIENCE
VL 38
IS 2
BP 182
EP 197
DI 10.1287/mnsc.38.2.182
PD FEB 1992
PY 1992
AB The paper operationalizes the notion of shortage cost by considering the
   behavior of customers and competing firms and examines the role of
   inventory in response time competition.  We start with a single-firm
   production control model in which custoemrs are characterized by their
   preferences of price, quality and delivery time.  The optimal
   production/inventory policy and the optimal choice between make-to-order
   and make-to-stock operations are determined in simple "newsboy"-like
   formulas.  The basic model is then extended to an n-firm market game in
   which firms compete for orders from the aspect of early delivery.  One
   could think of this setting as an oligopoly racing market.  The analysis
   shows that competition can breed a demand for produce-to-stock, just as
   other economic phenomena such as economies of scale, uncertainty, or
   seasonality can induce make-to-stock, and that delivery-time competition
   increases the buyer's welfare while decreasing the producer's welfare.
ZS 2
ZB 0
Z8 11
TC 125
ZA 0
ZR 0
Z9 138
SN 0025-1909
UT WOS:A1992HL33800003
ER

PT J
AU SIMCHILEVI, D
TI HIERARCHICAL PLANNING FOR PROBABILISTIC DISTRIBUTION-SYSTEMS IN
   EUCLIDEAN SPACES
SO MANAGEMENT SCIENCE
VL 38
IS 2
BP 198
EP 211
DI 10.1287/mnsc.38.2.198
PD FEB 1992
PY 1992
AB We develop an analytical model to assist the design and control of
   probabilistic distribution systems.  These distribution systems are
   characterized by the explicit inclusion of probabilistic elements.  The
   probabilistic aspect considered is that only a subset of all potential
   customers needs service on any given working day.  This subset of
   customers and their demand are determined according to some probability
   distribution.  The cost of operating such systems is significantly
   affected by decisions on the number and locations of the distribution
   centers, the allocation of customers to each center, and the routing
   strategy.  We propose a three-stage hierarchical approach in which
   decisions about the number of centers and their locations (first stage),
   customers allocations (second stage) and routing strategies (third
   stage) are combined to reduce total system cost.
ZR 0
ZS 0
ZA 0
ZB 0
Z8 0
TC 9
Z9 9
SN 0025-1909
UT WOS:A1992HL33800004
ER

PT J
AU GLAZER, R
   STECKEL, JH
   WINER, RS
TI LOCALLY RATIONAL DECISION-MAKING - THE DISTRACTING EFFECT OF INFORMATION
   ON MANAGERIAL PERFORMANCE
SO MANAGEMENT SCIENCE
VL 38
IS 2
BP 212
EP 226
DI 10.1287/mnsc.38.2.212
PD FEB 1992
PY 1992
AB This paper describes a phenomenon called "locally rotional"
   decision-making, in which the mere presence of information may have
   dysfunctional consequences even if decision makers do not process the
   information incorrectly.  Using the results from an experiment conducted
   with a strategic market simulation game, we find that the accessibility
   of information results in a disposition to focus on those components of
   decision-making most clearly addressed by the information.  If these are
   not the components most closely tied to success, overall performance may
   in fact suffer.  The decision-making process is thus "locally rational"
   since it may be optimal with respect to specific components of a larger
   plan, but globally suboptimal with regard to ultimate outcomes and for
   the organization as a whole.  We describe the implications of the
   phenomenon for the use of market-related data in managerial
   decision-making.
RI Winer, Russell/ABH-5955-2020
ZR 0
ZA 0
TC 51
ZS 0
Z8 1
ZB 0
Z9 52
SN 0025-1909
UT WOS:A1992HL33800005
ER

PT J
AU YUAN, YF
   MEHREZ, A
   GAFNI, A
TI REDUCING BIAS IN A PERSONNEL ASSIGNMENT PROCESS VIA MULTIPLICATIVE
   UTILITY SOLUTION
SO MANAGEMENT SCIENCE
VL 38
IS 2
BP 227
EP 239
DI 10.1287/mnsc.38.2.227
PD FEB 1992
PY 1992
AB In this paper we consider a type of bias which stems from the
   mathematical algorithm often used to determine an optimal match between
   two groups.  We compare two different solution concepts for the matching
   assignment problem:  the traditionally stable solution vs. a
   multiplicative utility approach that should avoid the bias.  Simulation
   modeling leads us to conclude that:  (1) With respect to all sizes
   compared in our experiment, applicants and employers groups were always
   treated far more equally under the multiplicative utility approach than
   the stable approach.  (2) When using the stable algorithm, the size of
   the bias is affected by the size of the problem (i.e., the larger the
   problem size is, the larger the performance discrepancy between two
   groups of participants).  Further analyses of the sensitivity of the
   finding to different assumptions (e.g., correlation in the preference
   orderings of the two groups, or use of nonlinear conversion from ranks
   to utilities) also resulted in a superior performance of the
   multiplicative utility algorithm in terms of a more equitable outcome.
Z8 0
ZB 0
ZR 0
ZA 0
ZS 0
TC 4
Z9 4
SN 0025-1909
UT WOS:A1992HL33800006
ER

PT J
AU RAJAN, A
   RAKESH
   STEINBERG, R
TI DYNAMIC PRICING AND ORDERING DECISIONS BY A MONOPOLIST
SO MANAGEMENT SCIENCE
VL 38
IS 2
BP 240
EP 262
DI 10.1287/mnsc.38.2.240
PD FEB 1992
PY 1992
AB This paper considers the relationship between pricing and ordering
   decisions for a monopolistic retailer facing a known demand function
   where, over the inventory cycle, the product may exhibit:  (i) physical
   decay or deterioration of inventory called wastage; and (ii) decrease in
   market value called value drop associated with each unit of inventory on
   hand.  The retailer is allowed to continuously vary the selling price of
   the product over the cycle.  We introduce a notion of instantaneous
   margin, and use it to derive profit maximizing conditions for the
   retailer.
   The model explains the markdown of retail goods subject to decay.  It
   also provides guidance in determining when price changes during the
   cycle are worthwile due to product aging, how often such changes should
   be made, and how such changes affect ordering intervals and quantities.
OI Rakesh, Rakesh/0000-0003-1293-5113
ZS 0
TC 127
ZR 0
Z8 9
ZB 1
ZA 0
Z9 136
SN 0025-1909
UT WOS:A1992HL33800007
ER

PT J
AU SALTZMAN, RM
   HILLIER, FS
TI A HEURISTIC CEILING POINT ALGORITHM FOR GENERAL INTEGER
   LINEAR-PROGRAMMING
SO MANAGEMENT SCIENCE
VL 38
IS 2
BP 263
EP 283
DI 10.1287/mnsc.38.2.263
PD FEB 1992
PY 1992
AB This paper first examines the role of ceiling points in solving a pure,
   general integer linear programming problem (P).  Several kinds of
   ceiling points are defined and analyzed and one kind called "feasible
   1-ceiling points" proves to be of special interest.  We demonstrate that
   all optimal solutions for a problem (P) whose feasible region is
   nonempty and bounded are feasible 1-ceiling points.  Consequently, such
   a problem may be solved by enumerating just its feasible 1-ceiling
   points.  The paper then describes an algorithm called the Heuristic
   Ceiling Point Algorithm (HCPA) which approximately solves (P) by
   searching only for feasible 1-ceiling points relatively near the optimal
   solution for the LP-relaxation; such solutions are apt to have a high
   (possibly even optimal) objective function value.  The results of
   applying the HCPA to 48 test problems taken from the literature indicate
   that this approach usually yields a very good solution with a moderate
   amount of computational effort.
ZB 0
TC 10
ZA 0
ZS 0
ZR 0
Z8 0
Z9 10
SN 0025-1909
UT WOS:A1992HL33800008
ER

PT J
AU GOFFIN, JL
   HAURIE, A
   VIAL, JP
TI DECOMPOSITION AND NONDIFFERENTIABLE OPTIMIZATION WITH THE PROJECTIVE
   ALGORITHM
SO MANAGEMENT SCIENCE
VL 38
IS 2
BP 284
EP 302
DI 10.1287/mnsc.38.2.284
PD FEB 1992
PY 1992
AB This paper deals with an application of a variant of Karmarkar's
   projective algorithm for linear programming to the solution of a generic
   nondifferentiable minimization problem.  This problem is closely related
   to the Dantzig-Wolfe decomposition technique used in large-scale convex
   programming.  The proposed method is based on a column generation
   technique defining a sequence of primal linear programming maximization
   problems.  Associated with each problem one defines a weighted potential
   function which is minimized using a variant of the projective algorithm.
   When a point close to the minimum of the potential function is reached,
   a corresponding point in the dual space is constructed, which is close
   to the analytic center of a polytope containing the solution set of the
   nondifferentiable optimization problem.  An admissible cut of the
   polytope, corresponding to a new supporting hyperplane of the epigraph
   of the function of minimize, is then generated at this approximate
   analytic center.  In the primal space this new cut translates into a new
   column for the associated linear programming problem.  The algorithm has
   performed well on a set of convex nondifferentiable programming
   problems.
ZB 1
ZA 0
ZS 1
ZR 0
Z8 2
TC 119
Z9 121
SN 0025-1909
UT WOS:A1992HL33800009
ER

PT J
AU WHANG, SJ
TI CONTRACTING FOR SOFTWARE-DEVELOPMENT
SO MANAGEMENT SCIENCE
VL 38
IS 3
BP 307
EP 324
DI 10.1287/mnsc.38.3.307
PD MAR 1992
PY 1992
AB Software contracting is a multi-faceted issue that involves legal,
   economic, managerial and technological considerations.  To better
   understand the economic aspect of software contracting, this paper
   provides a summary review of software development contracts, followed by
   a game-theoretic model developed to incorporate incentive and
   information issues associated with software contracting.  In the model
   an outside contractor is hired to develop a software system over
   multiple periods.  Due to the uncertainties about costs or technology,
   the developer faces the risk of having to abandon the project at an
   intermediate phase.  The user is better informed of the benefit of the
   system, while the developer privately discovers the development costs as
   the project advances.  Given the limited information, the contracting
   parties make decisions in their own interest, leaving each party
   vulnerable to the other's opportunistic behavior.  In this setting, we
   construct a viable contract that aligns the incentives of the
   contracting parties and produces the same equilibrium outcome as in
   in-house development.  We also relate the implications of the model to
   the actual contract cases.
ZR 0
ZS 1
TC 81
ZB 0
Z8 2
ZA 0
Z9 84
SN 0025-1909
UT WOS:A1992HN03100001
ER

PT J
AU GEOFFRION, AM
TI INDEXING IN MODELING LANGUAGES FOR MATHEMATICAL-PROGRAMMING
SO MANAGEMENT SCIENCE
VL 38
IS 3
BP 325
EP 344
DI 10.1287/mnsc.38.3.325
PD MAR 1992
PY 1992
AB Indexing structures are of fundamental importance to modeling languages
   for mathematical programming as a device for mathematical abstraction,
   and because they facilitate achieving conciseness, stability, and
   error-resistance.  The aim of this article is to stimulate discussion of
   such structures, especially the two most common kinds found in algebriac
   style languages:  sets and relations.  We offer a taxonomy of set-based
   and relation-based indexing structures, a suite of detailed examples
   illustrating this taxonomy, and a number of specific principles (some
   arguable and some not) for incorporating indexing structures into
   modeling languages.  We also examine four modeling languages in detail
   with respect to their indexing capabilities:  AMPL, GAMS, LINGO, and
   SML.  By attempting to work all of the illustrative examples in each
   language, we are able to reach some conclusions concerning relative
   expressive power, economy of notation, obedience to our principles of
   "good" language design, ease of data handling, and other criteria.
TC 17
Z8 1
ZR 0
ZS 0
ZB 0
Z9 17
SN 0025-1909
UT WOS:A1992HN03100002
ER

PT J
AU MOORTHY, KS
   PNG, IPL
TI MARKET-SEGMENTATION, CANNIBALIZATION, AND THE TIMING OF PRODUCT
   INTRODUCTIONS
SO MANAGEMENT SCIENCE
VL 38
IS 3
BP 345
EP 359
DI 10.1287/mnsc.38.3.345
PD MAR 1992
PY 1992
AB Consider a seller who faces two customer segments with differing
   valuations of quality of a durable product.  Demand is stationary and
   known, the technology exists to release two products simultaneously, and
   the seller can commit in advance to subsequent prices and qualities. 
   Should he introduce two differentiated products at once or one at a
   time?  Under the simultaneous strategy, the lower quality would
   cannibalize demand for the higher quality.  To reduce cannibalization,
   the seller could lower the quality of the low-end model and reduce the
   price of the high-end.  Alternatively, he could increase the quality of
   the low-end model, but delay its release.  Sequential introduction,
   however, would mean that the profits from the low-end model arrive
   later.  We show that sequential introduction is better than simultaneous
   introduction when cannibalization is a problem and customers are
   relatively more impatient than the seller.  However, when the seller
   cannot pre-commit, sequential selling is much less attractive because
   then he cannot use his product designs to alleviate cannibalization.
RI Png, Ivan P.L./P-3216-2015; Othman, Nor Hayati/D-7658-2017; Naing, Nyi Nyi/M-3455-2015
OI Png, Ivan P.L./0000-0001-7463-5517; Othman, Nor
   Hayati/0000-0002-8640-5740; Naing, Nyi Nyi/0000-0001-8308-5625
ZA 0
ZR 0
ZB 0
Z8 10
ZS 3
TC 234
Z9 245
SN 0025-1909
UT WOS:A1992HN03100003
ER

PT J
AU GRIFFIN, A
   HAUSER, JR
TI PATTERNS OF COMMUNICATION AMONG MARKETING, ENGINEERING AND MANUFACTURING
   - A COMPARISON BETWEEN 2 NEW PRODUCT TEAMS
SO MANAGEMENT SCIENCE
VL 38
IS 3
BP 360
EP 373
DI 10.1287/mnsc.38.3.360
PD MAR 1992
PY 1992
AB Models and scientific evidence suggest that firms are more successful at
   new-product development if there is greater communication among
   marketing, engineering, and manufacturing.  This paper examines
   communication patterns for two matched product-development teams where
   the key difference between the groups is that one used a phase-review
   development process and the other used Quality Function Deployment
   (QFD), a product-development process adopted recently at over 100 United
   States and Japanese firms.  To our knowledge, this is the first
   head-to-head comparison of traditional U.S. product development
   processes with QFD.
   Our data suggest that QFD enhances communication levels within the core
   team (marketing, engineering, manufacturing).  QFD changes communication
   patterns from "up-over-down" flows through management to more horizontal
   routes where core team members communicate directly with one another. 
   On the other hand, the QFD team communicates less on planning
   information and less with members of the firm external to the team.  If
   this paucity of external communication means that the team has the
   information it needs for product development, and the QFD process has
   provided an effective means for moving the information through the team,
   it is a positive impact of QFD.  If the result means that QFD induces
   team insularity, even when the team needs to reach out to external
   information sources, it is a cause for concern.
RI Hauser, John R/O-3046-2019
ZS 0
ZA 1
ZR 0
ZB 2
Z8 0
TC 310
Z9 311
SN 0025-1909
UT WOS:A1992HN03100004
ER

PT J
AU NAU, RF
TI JOINT COHERENCE IN GAMES OF INCOMPLETE INFORMATION
SO MANAGEMENT SCIENCE
VL 38
IS 3
BP 374
EP 387
DI 10.1287/mnsc.38.3.374
PD MAR 1992
PY 1992
AB Decisions are often made under conditions of uncertainty about the
   actions of supposedly-rational competitors.  The modeling of optimal
   behavior under such conditions is the subject of noncooperative game
   theory, of which a cornerstone is Harsanyi's formulation of games of
   incomplete information.  In an incomplete-information game, uncertainty
   may surround the attributes as well as the strategic intentions of
   opposing players.  Harsanyi develops the concept of a Bayesian
   equilibrium, which is a Nash equilibrium of a game in which the players'
   reciprocal beliefs about each others' attributes are consistent with a
   common prior distribution, as though they had been jointly drawn at
   random from populations with commonly-known proportions of types.  The
   relation of such game-theoretic solution concepts to subjective
   probability theory and nonstrategic decision analysis has been
   controversial, as reflected in critiques by Kadane and Larkey and
   responses from Harsanyi, Shubil, and others, which have appeared in this
   journal.  This paper shows that the Bayesian equilibrium concept and
   common prior assumption can be reconclied with a subjective view of
   probability by (i) supposing that players elicit each other's
   probabilities and utilities through the acceptance of gambles, and (ii)
   invoking a multi-agent extension of de Finetti's axiom of coherence (no
   arbitrage opportunities, a.k.a. "Dutch books").  However, the Nash
   property of statistical independence between players is weakened, and
   the probability distributions characterizing a solution of the game
   admit novel interpretations.
Z8 0
ZR 0
ZS 0
ZA 0
TC 12
ZB 0
Z9 12
SN 0025-1909
UT WOS:A1992HN03100005
ER

PT J
AU AHMED, MA
   GROSS, D
   MILLER, DR
TI CONTROL VARIATE MODELS FOR ESTIMATING TRANSIENT PERFORMANCE-MEASURES IN
   REPAIRABLE ITEM SYSTEMS
SO MANAGEMENT SCIENCE
VL 38
IS 3
BP 388
EP 399
DI 10.1287/mnsc.38.3.388
PD MAR 1992
PY 1992
AB We develop a new modeling idea for comparing infinite-source,
   ample-server models (infinity/infinity) and finite-source, finite-server
   models (f/f).  The comparison provides an efficient estimate of the
   error when approximating an f/f system with an infinity/infinity system
   and allows the analytical solution of the infinity/infinity model to be
   used as a control variate.  We show that using infinity/infinity models
   as control variates for f/f systems can be an effective variance
   reduction technique for system performance estimates.  Using these
   estimates will allow us to determine more efficiently when
   infinity/infinity models are good approximations for f/f systems.
ZS 0
ZR 0
ZB 0
Z8 0
TC 4
Z9 4
SN 0025-1909
UT WOS:A1992HN03100006
ER

PT J
AU GLYNN, PW
   HEIDELBERGER, P
TI EXPERIMENTS WITH INITIAL TRANSIENT DELETION FOR PARALLEL, REPLICATED
   STEADY-STATE SIMULATIONS
SO MANAGEMENT SCIENCE
VL 38
IS 3
BP 400
EP 418
DI 10.1287/mnsc.38.3.400
PD MAR 1992
PY 1992
AB A simple and effective way to exploit parallel processors in discrete
   event simulations is to run multiple independent replications, in
   parallel, on multiple processors and to average the results at the end
   of the runs.  We call this the method of parallel replications.  This
   paper is concerned with using the method of parallel replications for
   estimating steady-state performance measures.  We report on the results
   of queueing network simulation experiments that compare the statistical
   properties of several possible estimators that can be formed using this
   method.  The theoretical asymptotic properties of these estimators were
   determined in Glynn and Heidelberger (1989a, b).  Both the theory and
   the experimental results reported here strongly indicate that a
   nonstandard (in the context of steady-state simulation), yet easy to
   apply, estimation procedure is required on highly parallel machines. 
   This nonstandard estimator is a ratio estimator.  The experiments also
   show that use of the ratio estimator is advantageous even on machines
   with only a moderate degree of parallelism.
Z8 0
ZR 0
TC 6
ZB 1
ZA 0
ZS 0
Z9 6
SN 0025-1909
UT WOS:A1992HN03100007
ER

PT J
AU RABINOWITZ, G
   MEHREZ, A
   RABINA, A
TI A NONLINEAR HEURISTIC SHORT-TERM MODEL FOR HYDROELECTRIC
   ENERGY-PRODUCTION - THE CASE OF THE HAZBANI-DAN WATER-SYSTEM
SO MANAGEMENT SCIENCE
VL 38
IS 3
BP 419
EP 438
DI 10.1287/mnsc.38.3.419
PD MAR 1992
PY 1992
AB A two-stage decision and control model for the operation of the power
   station in the Hazbani-Dan Water System (Israel) was developed and
   implemented.  In this system, river water is stored and then either
   consumed by agricultural farms or released to a hydroelectric power
   station.  Under management policy, agricultural consumption is taken as
   a constraint.  The problem was solved via a two-stage procedure
   consisting of a long-term model (LTM) and a short-term model (STM).  The
   LTM was presented by Rabinowitz et al. (1988).  This paper reports on
   the development and analysis of the STM, in which operational
   flexibilities of the power station are taken into consideration, thereby
   improving the LTM solution.
   Our main contributions are aimed at:  (1) describing the
   (nontraditional) systematic thinking process which transformed the
   mathematically expressed problem into an efficiently solvable model; (2)
   presenting the analysis of the model; and (3) reporting on a practical
   application of the model in a unique system.
RI Rabinowitz, Gad/F-1773-2012
OI Rabinowitz, Gad/0000-0003-1853-1961
Z8 0
ZA 0
ZS 0
ZR 0
TC 1
ZB 0
Z9 1
SN 0025-1909
UT WOS:A1992HN03100008
ER

PT J
AU CHEN, MJ
   SMITH, KG
   GRIMM, CM
   SMITH, KG
   GRIMM, CM
TI ACTION CHARACTERISTICS AS PREDICTORS OF COMPETITIVE RESPONSES
SO MANAGEMENT SCIENCE
VL 38
IS 3
BP 439
EP 455
DI 10.1287/mnsc.38.3.439
PD MAR 1992
PY 1992
AB A central question in competitive dynamics is whether a competitive
   response can be predicted.  This study links various characteristics of
   actions with the total number and the time lag of competitors'
   responses.  The hypothesized relationships were tested with a sample of
   competitive moves among U.S. airlines.  The results suggested that
   responses are influenced by the characteristics of the actions that
   evoked them.  Specifically, the total number of competitors affected by
   an action and the importance to these competitors of the markets under
   attack by the action increase the number of competitive responses. 
   Strategic, as opposed to tactical, actions or actions which require
   substantial implementation efforts reduce the number and delay the
   timing of rivals' counteractions.  Finally, contrary to prediction,
   competitors who have stake in the markets under attack by a competitive
   move react slowly.
ZB 1
ZA 0
ZR 0
Z8 10
TC 219
ZS 1
Z9 230
SN 0025-1909
UT WOS:A1992HN03100009
ER

PT J
AU SHENG, ORL
TI ANALYSIS OF OPTIMAL FILE MIGRATION POLICIES IN DISTRIBUTED
   COMPUTER-SYSTEMS
SO MANAGEMENT SCIENCE
VL 38
IS 4
BP 459
EP 482
DI 10.1287/mnsc.38.4.459
PD APR 1992
PY 1992
AB File migration shows promise as a means of improving data processing
   performance in distributed systems, but practical application of this
   idea will require development of effective policies that will allow a
   system to fully realize the Potentials of file migration. Deriving of
   optimal policies, while computationally complex, nevertheless, is
   essential to provide insights about how effective migration policies for
   large systems should be structured. In this paper, analytic properties
   and performance of optimal file migration policies are investigated
   based on a Markov decision process model of file migration policies.
   Optimal migration policies are compared with optimal static policies and
   the sufficient conditions under which file migration provides absolute
   improvement or no advantage over static policies are presented.
   Numerical experiments and simulations were performed to analyze the
   impact of model assumptions and system parameters on the cost
   improvement generated by file migration. It is shown that optimal file
   migration is able to generate substantial cost improvement under certain
   conditions and that it is robust both with respect to the initial file
   allocation at an initial system design/reorganization point and to
   impreciseness of system environments. This analysis should provide
   system designers and administrators guidance toward achieving effective
   file migration control.
Z8 0
TC 2
ZB 0
ZR 0
ZS 0
Z9 2
SN 0025-1909
UT WOS:A1992HR98900001
ER

PT J
AU MOORE, MC
TI SIGNALS AND CHOICES IN A COMPETITIVE INTERACTION - THE ROLE OF MOVES AND
   MESSAGES
SO MANAGEMENT SCIENCE
VL 38
IS 4
BP 483
EP 500
DI 10.1287/mnsc.38.4.483
PD APR 1992
PY 1992
AB This study examines the effect of signals from a competitor on the
   decisions of managers in a situation of strategic interdependence. The
   context is a multi-period pricing simulation and the payoffs are
   structured in accordance with a Prisoner's Dilemma. The signals consist
   of messages from the competitor and observations of the pricing
   decisions made by the competitor. The managers' responses to particular
   types of signals and particular combinations of moves and messages
   change over the course of the simulation. Suggestions for future
   research on competitive signaling are offered.
ZA 0
ZS 0
ZB 0
Z8 1
TC 35
ZR 0
Z9 36
SN 0025-1909
UT WOS:A1992HR98900002
ER

PT J
AU DANIELS, RL
TI ANALYTICAL EVALUATION OF MULTICRITERIA HEURISTICS
SO MANAGEMENT SCIENCE
VL 38
IS 4
BP 501
EP 513
DI 10.1287/mnsc.38.4.501
PD APR 1992
PY 1992
AB This paper considers the problem of evaluating the solution quality of
   multi-criteria heuristics. By assuming an additive multi-attribute value
   structure, efficient and heuristic solutions can be translated into
   value measures that depend only on the relative importance assigned to
   the criteria of interest. Approximation errors are then defined as the
   value penalty incurred by approximating an efficient solution with its
   heuristic alternative. Results are derived which can be used to
   eliminate solutions that cannot represent the best available alterative
   among the set of efficient and heuristic solutions. For the bicriterion
   case, a polynomial algorithm for determining the mean and maximum
   relative heuristic error for a given problem instance is presented. For
   more general multi-criteria problems, the maximum relative approximation
   error can be determined by solving a series of linear programming
   problems.
ZS 0
ZR 0
ZA 0
ZB 0
Z8 0
TC 6
Z9 6
SN 0025-1909
UT WOS:A1992HR98900003
ER

PT J
AU BROCKHOFF, K
TI RESEARCH-AND-DEVELOPMENT COOPERATION BETWEEN FIRMS - A PERCEIVED
   TRANSACTION COST PERSPECTIVE
SO MANAGEMENT SCIENCE
VL 38
IS 4
BP 514
EP 524
DI 10.1287/mnsc.38.4.514
PD APR 1992
PY 1992
AB Transaction cost is considered as an explanatory variable for the choice
   between markets and various organizational arrangements for performing
   some predefined tasks, such as engaging in private R&D. With respect to
   R&D cooperation between firms, we show that the perception of high
   transaction cost is related to certain characteristics of the firm and
   to the type of R&D task. We also show a relationship between the
   perception of transaction cost and the perceived success of the
   cooperation. The analysis sheds light on various determinants of
   transaction costs.
Z8 1
ZS 2
ZB 3
TC 66
ZA 0
ZR 0
Z9 69
SN 0025-1909
UT WOS:A1992HR98900004
ER

PT J
AU RAJAGOPALAN, S
TI DETERMINISTIC CAPACITY EXPANSION UNDER DETERIORATION
SO MANAGEMENT SCIENCE
VL 38
IS 4
BP 525
EP 539
DI 10.1287/mnsc.38.4.525
PD APR 1992
PY 1992
AB This paper considers the deterministic capacity expansion problem with
   deterioration. First, the paper extends the conventional model by
   incorporating capacity deterioration effects and operating costs that
   are a function of. (i) the age of the facility and (ii) the extent of
   utilization of capacity. The model still has the useful properties of
   the standard model. enabling the use of efficient algorithms. Second,
   the paper extends well-known planning horizon results to this model
   using a novel dual-based approach, which also provides additional
   intuition. Finally, interesting computational results are provided that
   compare optimal and near-optimal forecast horizon values. The impact of
   capacity deterioration and convexity in variable costs on forecast
   horizons is also considered.
ZB 1
ZS 0
ZR 0
TC 20
Z8 0
Z9 20
SN 0025-1909
UT WOS:A1992HR98900005
ER

PT J
AU WHITE, DJ
TI A MIN-MAX-MAX-MIN APPROACH TO SOLVING A STOCHASTIC-PROGRAMMING PROBLEM
   WITH SIMPLE RECOURSE
SO MANAGEMENT SCIENCE
VL 38
IS 4
BP 540
EP 554
DI 10.1287/mnsc.38.4.540
PD APR 1992
PY 1992
AB This paper studies a problem of determining the level of certain
   decisions, taken prior to certain events taking place, and the
   subsequent additional resource procurement decisions needed to implement
   the initial program once these events have materialised.
   The problem is formulated first of all as a max-min problem, and then as
   an equivalent min-max problem.
   The min-max problem is easier to solve than the max-min problem.
   The information provided in solving the min-max problem may be used to
   facilitate the solution of the max-min problem.
ZB 0
Z8 0
TC 3
ZS 0
ZR 0
Z9 3
SN 0025-1909
UT WOS:A1992HR98900006
ER

PT J
AU LEVY, H
TI STOCHASTIC-DOMINANCE AND EXPECTED UTILITY - SURVEY AND ANALYSIS
SO MANAGEMENT SCIENCE
VL 38
IS 4
BP 555
EP 593
DI 10.1287/mnsc.38.4.555
PD APR 1992
PY 1992
AB While Stochastic Dominance has been employed in various forms as early
   as 1932, it has only been since 1969-1970 that the notion has been
   developed and extensively employed in the area Of economics, finance,
   agriculture, statistics, marketing an operations research.
   In this survey, the first-, second- and third-order stochastic dominance
   rules are discussed with an emphasis on the development in the area
   since the 1980s.
ZA 0
Z8 16
ZS 1
ZB 15
ZR 0
TC 384
Z9 400
SN 0025-1909
UT WOS:A1992HR98900007
ER

PT J
AU LEUNG, J
TI A NEW GRAPH-THEORETIC HEURISTIC FOR FACILITY LAYOUT
SO MANAGEMENT SCIENCE
VL 38
IS 4
BP 594
EP 605
DI 10.1287/mnsc.38.4.594
PD APR 1992
PY 1992
AB The facility layout problem is important in the modern manufacturing
   environment because increased machine flexibility and product
   diversification create additional complexities in scheduling and
   material handling. An important first step in facility layout is the
   determination of which machines should be adjacent. This problem can be
   modelled as that of finding a maximum weight planar subgraph of a graph,
   given a measure of the desirability that two machines be adjacent based
   on the anticipated flows and technological constraints. We present a new
   heuristic that is a generalization of previous work of Foulds and
   Robinson. Preliminary computational results are presented which suggest
   that this heuristic performs well.
RI Leung, Janny/F-6838-2011
OI Leung, Janny/0000-0002-9086-6056
Z8 4
ZA 0
ZB 0
ZR 0
ZS 0
TC 32
Z9 36
SN 0025-1909
UT WOS:A1992HR98900008
ER

PT J
AU HARTL, RF
TI OPTIMAL ACQUISITION OF POLLUTION-CONTROL EQUIPMENT UNDER UNCERTAINTY
SO MANAGEMENT SCIENCE
VL 38
IS 5
BP 609
EP 622
DI 10.1287/mnsc.38.5.609
PD MAY 1992
PY 1992
AB This paper considers a firm, which has to acquire a certain amount of
   pollution control equipment in order to comply with government pollution
   standards.  Due to political battles and lobbying efforts, the
   compliance date and the date when it is announced are not known in
   advance.  Furthermore, the target stock of pollution control equipment
   is also unknown.  This amounts to an optimal control problem, in which
   the terminal time and the terminal state are random variables for which
   certain probability distributions can be estimated.  The model
   explicitly considers technological progress in the production of
   abatement equipment, which leads to decreasing installation costs over
   time.  Furthermore it is assumed that having a high stock of abatement
   equipment at early stages improves the firm's public image and thus its
   revenue.  Tax deductions and other benefits for health conscious firms
   are also taken into account.
   Using optimal control theory the optimal investment in pollution control
   equipment is obtained, and the sensitivity with respect to discounting,
   wear out, technological progress and with respect to the parameters of
   the probability distributions is investigated.
RI Hartl, Richard F/C-7043-2017
OI Hartl, Richard F/0000-0002-0461-0979
ZA 0
Z8 1
ZR 0
TC 11
ZB 0
ZS 0
Z9 12
SN 0025-1909
UT WOS:A1992HW66500001
ER

PT J
AU LANT, TK
TI ASPIRATION LEVEL ADAPTATION - AN EMPIRICAL EXPLORATION
SO MANAGEMENT SCIENCE
VL 38
IS 5
BP 623
EP 644
DI 10.1287/mnsc.38.5.623
PD MAY 1992
PY 1992
AB Organizations have been modeled as goal directed systems which use
   simple decision rules to adapt behavior in response to performance
   feedback.  This paper examines the formation of organizational goals, or
   aspiration levels, over time in groups of individuals representing top
   management teams of simulated organizations.  The analysis compares the
   empirical validity of an adaptive attainment discrepancy model with
   models derived from rational and adaptive expectations theories.  The
   results suggest that the attainment discrepancy model, which is based on
   a simple decision rule of adjustment to performance feedback, provides
   the most robust description of aspiration formation.  They are also
   informative with regard to the application of expectation models to
   aspiration formation:  There is a great deal of similarity between these
   results and those of prior studies on expectation formation.  In
   addition, the study finds that there tends to be an optimistic bias in
   aspiration formation, that adaptation is not consistently incremental,
   and that adaptive learning may, over time, lead to behavioral outcomes
   that are consistent with rationality.
ZB 5
ZR 0
ZA 0
ZS 0
TC 248
Z8 2
Z9 251
SN 0025-1909
UT WOS:A1992HW66500002
ER

PT J
AU DYER, JS
   FISHBURN, PC
   STEUER, RE
   WALLENIUS, J
   ZIONTS, S
TI MULTIPLE CRITERIA DECISION-MAKING, MULTIATTRIBUTE UTILITY-THEORY - THE
   NEXT 10 YEARS
SO MANAGEMENT SCIENCE
VL 38
IS 5
BP 645
EP 654
DI 10.1287/mnsc.38.5.645
PD MAY 1992
PY 1992
AB Management science and decision science have grown exponentially since
   midcentury. Two closely-related fields central to this growth are
   multiple criteria decision making (MCDM) and multiattribute utility
   theory (MAUT). This paper comments on the history of MCDM and MAUT and
   discusses topics we believe are important in their continued development
   and usefulness to management science over the next decade. Our aim is to
   identify exciting directions and promising areas for future research.
Z8 15
ZB 22
ZS 1
ZA 0
TC 325
ZR 0
Z9 340
SN 0025-1909
EI 1526-5501
UT WOS:A1992HW66500003
ER

PT J
AU GLEESON, ME
TI RENOVATION OF PUBLIC-HOUSING - SUGGESTIONS FROM A SIMPLE-MODEL
SO MANAGEMENT SCIENCE
VL 38
IS 5
BP 655
EP 666
DI 10.1287/mnsc.38.5.655
PD MAY 1992
PY 1992
AB This paper presents a simple model to contrast the benefit and cost of
   renovating public housing units against the benefit and cost of building
   new ones.  Benefit is measured as the additional expected life created,
   and empirically-estimated survivor functions for housing are used to
   calculate maximum costs at which renovation is cost-effective relative
   to new construction.  Actual renovation costs for an existing program
   are compared with calculated maximums.  Results suggest that past
   renovation practice may not have been cost-effective relative to new
   construction.  Possible changes in program guidelines are presented. 
   The paper concludes with a discussion of policy implications.
TC 2
ZR 1
Z8 0
ZS 0
ZB 0
Z9 3
SN 0025-1909
UT WOS:A1992HW66500004
ER

PT J
AU SARGENT, RG
   SOM, TK
TI CURRENT ISSUES IN FREQUENCY-DOMAIN EXPERIMENTATION
SO MANAGEMENT SCIENCE
VL 38
IS 5
BP 667
EP 687
DI 10.1287/mnsc.38.5.667
PD MAY 1992
PY 1992
AB This paper presents an examination of certain issues in Frequency Domain
   Experimentation (FDE) for discrete event simulation. Experimental
   results are presented to demonstrate that (i) conclusions drawn from FDE
   are dependent on the oscillation frequency and unless frequencies are
   chosen carefully, misleading results can be obtained; (ii)
   interpretation of results from frequency domain experiments are
   fundamentally different from the interpretation of results from
   regression analysis-specifically, a term found significant by FDE is not
   to be interpreted as a term able to explain a significant portion of the
   variation in the response over the experimental region; and (iii) basic
   assumptions required for FDE, in particular the assumption that input
   and output processes constitute a time-invariant linear system, do not
   hold for M/M/ 1 queues. Other issues discussed are indexing, run length
   determination, computational effort, and why FDE is not applicable for
   terminating simulations. It is concluded that further developments are
   needed before FDE can be used by practitioners.
ZS 0
TC 12
ZB 0
Z8 0
ZR 0
Z9 12
SN 0025-1909
EI 1526-5501
UT WOS:A1992HW66500005
ER

PT J
AU LOVEJOY, WS
TI STOPPED MYOPIC POLICIES IN SOME INVENTORY MODELS WITH GENERALIZED DEMAND
   PROCESSES
SO MANAGEMENT SCIENCE
VL 38
IS 5
BP 688
EP 707
DI 10.1287/mnsc.38.5.688
PD MAY 1992
PY 1992
AB This paper considers single-item inventory systems with immediate
   delivery and no economies of scale.  Bounds are provided on the value
   loss relative to optimal cost for restricting attention to the class of
   inventory stocking policies that behave myopically up to a specified
   stopping time.  The stopping time may be random, and may depend on
   demand histories as well as information exogenous to the firm.  The
   bounds are robust to the nature of the demand process faced after the
   stopping time, so are applicable when the statistics of demand after the
   stopping time are unknown.  Stopping times that are large with high
   probability imply that near-term decisions are completely specified with
   high probability.  The general bounding results allow one to consider
   demand processes that may otherwise be analytically intractable.
   It is shown that the class of demand models for which the assumption of
   additive i.i.d. shocks is appropriate is the same class admitting
   effective myopic stocking policies.  The bounds also make rigorous the
   intuitive notion that myopic policies are least effective in systems
   with precipitous drops in demand coupled with an inability to recover
   cash invested in inventory.  The option of selling inventory at discount
   is a reality in many real systems and enhances the attractiveness of the
   myopic stocking policy.
   In numerical examples, the myopic policy is shown to be an effective
   competitor in a range of systems for which optimal policies are not
   known.  The results suggest that for systems with immediate delivery, no
   economies of scale, and no currently known optimal policy, the myopic
   stocking rule is a reasonable default policy to adopt.
ZR 0
Z8 1
ZA 0
TC 34
ZB 0
ZS 0
Z9 35
SN 0025-1909
UT WOS:A1992HW66500006
ER

PT J
AU WHITT, W
TI UNDERSTANDING THE EFFICIENCY OF MULTISERVER SERVICE SYSTEMS
SO MANAGEMENT SCIENCE
VL 38
IS 5
BP 708
EP 723
DI 10.1287/mnsc.38.5.708
PD MAY 1992
PY 1992
AB In the design and operation of service systems, it is important to
   determine an appropriate level of server utilization (the proportion of
   time each server should be working).  In a multiserver queue with
   unlimited waiting space, the appropriate server utilization typically
   increases as the number of servers (and the arrival rate) increases.  We
   explain this economy of scale and give a rough quantitative
   characterization.  We also show how increased variability in the arrival
   and service processes tends to reduce server utilization with a given
   grade of service.  As part of this analysis, we develop simple
   approximations for the mean steady-state waiting time and the full
   steady-state waiting-time distribution.  These approximations exploit an
   infinite-server approximation for the probability of delay and a
   single-server approximation for the conditional waiting-time
   distribution given that waiting occurs.  The emphasis is on simple
   formulas that directly convey understanding.
RI Whitt, Ward/D-5337-2013
OI Whitt, Ward/0000-0003-4298-9964
ZR 0
ZA 0
TC 83
ZB 1
ZS 0
Z8 2
Z9 84
SN 0025-1909
UT WOS:A1992HW66500007
ER

PT J
AU BITRAN, GR
   LEONG, TY
TI DETERMINISTIC APPROXIMATIONS TO COPRODUCTION PROBLEMS WITH SERVICE
   CONSTRAINTS AND RANDOM YIELDS
SO MANAGEMENT SCIENCE
VL 38
IS 5
BP 724
EP 742
DI 10.1287/mnsc.38.5.724
PD MAY 1992
PY 1992
AB We study production planning problems where multiple item categories are
   produced simultaneously.  The items have random yields and are used to
   satisfy the demands of many products.  These products have specification
   requirements that overlap.  An item originally targeted to satisfy the
   demand of one product may be used to satisfy the demand of other
   products when it conforms to their specifications.  Customers' demand
   must be satisfied from inventory 100-alpha% of the time.  We formulate
   the problem with service constraints and provide near-optimal solution
   to the problem with fixed planning horizon.  We also propose simple
   heuristics for the problem solved with a rolling horizon.  Some of the
   heuristics performed very well over a wide range of parameters.
RI LEONG, Thin Yin/E-8560-2012
ZS 0
ZB 0
ZR 0
ZA 0
TC 51
Z8 2
Z9 53
SN 0025-1909
UT WOS:A1992HW66500008
ER

PT J
AU TANG, CS
TI CONTROLLING INVENTORIES IN AN ACYCLIC ASSEMBLY SYSTEM
SO MANAGEMENT SCIENCE
VL 38
IS 5
BP 743
EP 750
DI 10.1287/mnsc.38.5.743
PD MAY 1992
PY 1992
AB This note presents a model of an acyclic assembly system that faces
   yield loss and uncertain demand.  While there is no known production
   rule for managing acyclic systems, we develop a production rule whose
   operating characteristics could be measured analytically.  Thus, the
   operating characteristics can be used as a benchmark for future
   comparison.  To facilitate our analysis, we extend the model for a
   serial production system that produces a single product (Tang 1990). 
   This extension entails a modification of the production rule and the
   analysis of a decomposition scheme.
ZS 0
ZA 0
TC 7
ZR 0
ZB 0
Z8 0
Z9 7
SN 0025-1909
UT WOS:A1992HW66500009
ER

PT J
AU GUPTA, SK
   KYPARISIS, J
   IP, CM
TI PROJECT SELECTION AND SEQUENCING TO MAXIMIZE NET PRESENT VALUE OF THE
   TOTAL RETURN
SO MANAGEMENT SCIENCE
VL 38
IS 5
BP 751
EP 752
DI 10.1287/mnsc.38.5.751
PD MAY 1992
PY 1992
AB This note considers a problem of simultaneous selection of a subset of N
   projects and determination of an optimal sequence to implement these
   projects so as to maximize the net present value of the total return. 
   We first establish an optimal sequence of all projects which does not
   depend on the particular subset of selected projects and then propose an
   efficient polynomial dynamic programming method for solving the problem.
Z8 2
ZR 0
ZA 0
TC 22
ZS 0
ZB 0
Z9 24
SN 0025-1909
UT WOS:A1992HW66500010
ER

PT J
AU HENDERSON, JC
   LEE, S
TI MANAGING I/S DESIGN TEAMS - A CONTROL THEORIES PERSPECTIVE
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 757
EP 777
DI 10.1287/mnsc.38.6.757
PD JUN 1992
PY 1992
AB The control relationship between project managers and team members is a
   central aspect of the working of any Information System (I/S) design
   team. This paper combines research on managerial control and team-member
   control in order to explore a range of control behaviors that can affect
   the performance of an I/S design team. Measures are developed and
   validated for managerial control and team-member control from both an
   outcome and a process perspective. Results from a study of 41 actual I/S
   design teams indicate that high-performing teams exhibit high process
   control by managers and high outcome control by team members. The
   results also support the proposition that both managerial and
   team-member control coexists and that increases in the total level of
   control behavior is positively correlated with performance.
TC 295
ZR 0
ZA 0
ZS 1
Z8 1
ZB 0
Z9 297
SN 0025-1909
EI 1526-5501
UT WOS:A1992JA62100001
ER

PT J
AU AUSTER, ER
TI THE RELATIONSHIP OF INDUSTRY EVOLUTION TO PATTERNS OF TECHNOLOGICAL
   LINKAGES, JOINT VENTURES, AND DIRECT-INVESTMENT BETWEEN UNITED-STATES
   AND JAPAN
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 778
EP 792
DI 10.1287/mnsc.38.6.778
PD JUN 1992
PY 1992
AB Although economic activity between the U.S. and Japan has skyrocketed in
   the last decade, there are few large sample, cross-industry studies
   analyzing multiple forms of investment by the Japanese in the U.S. This
   study analyzes the key characteristics of each stage of industry
   evolution and the costs and benefits of each form of resource investment
   to predict the patterns of technological linkages, joint ventures, and
   direct investment of Japanese companies in the U.S. The results find
   support for a model predicting a predominance of technological linkages
   in emerging industries, joint ventures in growing industries, and direct
   investment in maturing industries. Technological linkages are most
   attractive in emerging industries as firms struggle to acquire
   technology, information and expertise and share cost and risk, yet
   retain flexibility. Joint ventures proliferate in growing industries
   because they offer a means of acquiring and expanding customer bases,
   yet reducing vulnerability. In maturing industries, where firms' key
   competencies are more developed, direct investment allows the company to
   generate demand in new markets without the disadvantage of joint
   governance.
ZR 0
Z8 2
ZS 0
TC 51
ZA 0
ZB 0
Z9 53
SN 0025-1909
UT WOS:A1992JA62100002
ER

PT J
AU SULLIVAN, MW
TI BRAND EXTENSIONS - WHEN TO USE THEM
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 793
EP 806
DI 10.1287/mnsc.38.6.793
PD JUN 1992
PY 1992
AB This empirical study investigates whether brand extensions should be
   introduced early or late in the life cycle of a product category. The
   longitudinal/cross-category sample of frequently purchased consumer
   brands is used to analyze how the performance of brand extensions
   depends on order of entry. The results indicate that early-entering
   brand extensions do not perform as well on average as either
   early-entering new-name products or late-entering brand extensions. This
   conclusion is based on four findings. First, the brand extensions were
   introduced later on average than the new-name products. Second, the
   early brand extensions had a lower probability of surviving than either
   the early-entering new-name products or the late-entering brand
   extensions. Third, the brand extensions earned higher market shares on
   average than new-name products, controlling for order of entry. Fourth,
   the extensions obtained smaller market share premia from entering early
   than did new-name products.
ZR 0
ZB 1
Z8 2
ZA 0
TC 69
ZS 1
Z9 71
SN 0025-1909
UT WOS:A1992JA62100003
ER

PT J
AU MCCARDLE, KF
   WINKLER, RL
TI REPEATED GAMBLES, LEARNING, AND RISK-AVERSION
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 807
EP 818
DI 10.1287/mnsc.38.6.807
PD JUN 1992
PY 1992
AB We analyze a decision problem with repeated gambles and find that under
   some seemingly reasonable risk-averse utility functions, recommended
   behavior for the initial decision can be highly fisk-taking and
   counterintuitive. Further analysis reveals that the derived utility
   function for the return on the first gamble is discontinuous because
   gains or losses carry with them positive or negative signals regarding
   future prospects. A variant of the basic model without a discontinuity
   in derived utility has essentially the same implications. The issues
   raised in this paper present no conceptual difficulties for the standard
   expected utility theory; in principle, we can model the grand world and
   understand fully all implications of grand-world utility functions. In
   practice, however, this ideal may not always be attainable and as a
   result we may be faced with serious modeling and assessment problems.
ZA 0
TC 13
ZB 0
Z8 0
ZR 0
ZS 0
Z9 13
SN 0025-1909
UT WOS:A1992JA62100004
ER

PT J
AU KIRKWOOD, CW
TI ESTIMATING THE IMPACT OF UNCERTAINTY ON A DETERMINISTIC MULTIATTRIBUTE
   EVALUATION
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 819
EP 826
DI 10.1287/mnsc.38.6.819
PD JUN 1992
PY 1992
AB A method is presented to estimate the impact of uncertainty on the
   results of a multiattribute evaluation prior to conducting a complete
   probabilistic multiattribute utility analysis. The method assumes that a
   deterministic analysis has been completed using a weighted-additive
   multiattribute value (evaluation) function and that either an additive
   or multiplicative utility function is appropriate for the multiattribute
   utility analysis. An approximation procedure is developed to estimate
   whether uncertainty about attribute levels could change the
   deterministic evaluation results. An illustrative application
   investigates the accuracy of the procedure and its use to simplify
   analysis of the effects of uncertainty.
ZR 0
Z8 0
ZA 0
TC 21
ZS 0
ZB 0
Z9 21
SN 0025-1909
UT WOS:A1992JA62100005
ER

PT J
AU SHUBIK, M
   SOBEL, MJ
TI ON MATCHING BOOK - A PROBLEM IN BANKING AND CORPORATE-FINANCE
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 827
EP 839
DI 10.1287/mnsc.38.6.827
PD JUN 1992
PY 1992
AB In each of the asset and liability markets in which the banking firm is
   an intermediary, typically there are instruments with differing
   maturities. The bank matching book problem is to manage the term
   structures of assets and liabilities. In our first model, the bank
   borrows and lends only short run. In our second model, the bank borrows
   only short run but can lend short run and long run. The criterion in
   both models is the expected value of the present value of dividends
   issued. Both models yield dynamic programming problems. Broad aspects of
   optimal policies are indicated.
RI Sobel, Matthew J/C-2649-2015
OI Sobel, Matthew J/0000-0002-9729-3756
TC 3
Z8 0
ZS 0
ZB 0
ZA 0
ZR 0
Z9 3
SN 0025-1909
UT WOS:A1992JA62100006
ER

PT J
AU TEW, BV
   REID, DW
   RAFSNIDER, GT
TI RATIONAL MEAN-VARIANCE DECISIONS FOR SUBSISTENCE FARMERS
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 840
EP 845
DI 10.1287/mnsc.38.6.840
PD JUN 1992
PY 1992
AB This paper explores the issue of approximating expected utility in
   applying portfolio theory. It has been demonstrated that expected
   utility is very closely approximated by an appropriate quadratic
   function. Recent studies have again questioned the empirical validity of
   mean-variance analysis. These efforts disregard the importance of the
   differences among various approximations, and historically, have focused
   on domestic financial securities. We re-examine the problem in the
   context of determining risk-efficient portfolios of production
   activities for subsistence farmers. The risks faced by these farmers are
   large and probably actuarially nonneutral. Thus, recommendations based
   on an inappropriate quadratic approximation could result in substantial
   losses in welfare.
ZB 0
TC 4
ZS 0
ZR 0
Z8 0
Z9 4
SN 0025-1909
UT WOS:A1992JA62100007
ER

PT J
AU WASHBURN, A
TI PRESENT VALUES WITH RENEWALS
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 846
EP 850
DI 10.1287/mnsc.38.6.846
PD JUN 1992
PY 1992
AB Expected present values can be calculated in the presence of a sequence
   of events that cause the cash flow process to restart after each one.
   Methods are derived and illustrated by examples.
TC 2
ZR 0
ZB 0
ZS 0
Z8 0
Z9 2
SN 0025-1909
UT WOS:A1992JA62100008
ER

PT J
AU BROCKETT, PL
   KAHANE, Y
TI RISK, RETURN, SKEWNESS AND PREFERENCE
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 851
EP 866
DI 10.1287/mnsc.38.6.851
PD JUN 1992
PY 1992
AB This paper considers choice between individual projects and shows that
   when the choice set includes arbitrary distributions, then any assumed
   relationship between expected utility theory and general moment
   preferences for individual decision makers is theoretically unsound. In
   particular, a risk averse investor with any common utility function may,
   when choosing between two positive return opportunities, prefer the
   project simultaneously having a lower mean, higher variance, and lower
   positive skewness. Moreover, the decision maker can prefer opportunities
   with higher variance even when the opportunities are continuous,
   unimodal, and arbitrarily visually and statistically close to the normal
   distribution in shape. Our conclusions hold for any decision maker with
   a utility function whose derivatives alternate in sign being strictly
   positive or negative (i.e.. we exclude the uninteresting cases of
   quadratic and cubic utilities).
   The method of analysis is based upon the theory of Tchebychev systems of
   functions which deals with the expected value of [utility] functions of
   stochastic variables with known moments. Although we focus on the first
   three moments, the results, as presented here, apply to all higher
   moments as well. It is also shown that there can be extremely large
   deviations between the certainty equivalents of distributions having the
   same moments. so this result is also pertinent to practical decision
   analysts as well. The paper demonstrates that the properties of utility
   functions have implications which are much more subtle than previously
   recognized for evaluating distributions in terms of their moments.
ZB 1
Z8 0
ZA 0
TC 45
ZS 0
ZR 0
Z9 45
SN 0025-1909
UT WOS:A1992JA62100009
ER

PT J
AU COFFMAN, EG
   GILBERT, EN
TI SERVICE BY A QUEUE AND A CART
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 867
EP 883
DI 10.1287/mnsc.38.6.867
PD JUN 1992
PY 1992
AB Items arrive randomly at a production facility that functions asa
   single-server queueing system. The items might represent parts, raw
   material, etc. and the server might be a factory worker or a machine in
   a production line. Following service, items are placed in a buffer where
   they are accumulated before delivery to a customer or some downstream
   activity in a production line. In practice, the buffer might be called a
   hopper; it may take the form of a cart or a pallet moved by a forklift.
   For simplicity the discussion here keeps with the cart terminology.
   The cart is delivered at times to be determined; during its absence the
   queue will in general grow by new arrivals. An item's average time in
   system, from arrival to delivery, is to be made small. The system must
   compromise between infrequent deliveries to avoid long delays in the
   queue and frequent deliveries to avoid long waits in the cart. This
   problem has a simple relation with standard batch-sizing problems in
   production scheduling.
   The cart delivery (batch-sizing) strategy considered here depends on two
   integers M and N. Delivery begins when N are in the cart or when the
   queue is empty and at least M are in the cart (M less-than-or-equal-to
   N). Items are assumed to arrive by a Poisson process, and their service
   times have a general distribution. Generating functions are derived
   which determine probability distributions for the numbers k in the cart,
   q in the queue, and k + q in the system. Numerical results are given for
   special cases M = N, N = infinity, and M = 0.
ZB 0
TC 4
Z8 0
ZR 0
ZS 0
ZA 0
Z9 4
SN 0025-1909
UT WOS:A1992JA62100010
ER

PT J
AU GLASSERMAN, P
   YAO, DD
TI SOME GUIDELINES AND GUARANTEES FOR COMMON RANDOM NUMBERS
SO MANAGEMENT SCIENCE
VL 38
IS 6
BP 884
EP 908
DI 10.1287/mnsc.38.6.884
PD JUN 1992
PY 1992
AB Common random numbers (CRN) is a widely-used technique for reducing
   variance in comparing stochastic systems through simulation. Its
   popularity derives from its intuitive appeal and ease of implementation.
   However, though CRN has been observed to work well with a broad range of
   models, the class of systems for which it is provably advantageous has
   remained rather limited.
   This paper has two purposes: We first discuss the effectiveness and
   optimality of CRN in a general setting, stressing the roles played by
   monotonicity and continuity properties. We then present specific, new
   classes of systems and comparisons for which CRN is beneficial and even
   optimal. Our conclusions for these systems are largely consistent with
   simulation practice and lend further theoretical support to folklore.
   Our results differ from those of previous analyses primarily because we
   put conditions on the timing of events, rather than the sequence of
   states, in a discrete-event simulation.
   We formulate our results in three settings corresponding to three
   applications of CRN: distributional comparisons, structural comparisons,
   and sensitivity analysis. In each case, we make use of conditions that
   simultaneously ensure monotonicity and continuity in the timing of
   events. These properties are established through explicit recursions for
   event epochs in terms of increasing, continuous functions.
Z8 0
ZA 0
ZS 0
ZR 0
TC 67
ZB 0
Z9 67
SN 0025-1909
UT WOS:A1992JA62100011
ER

PT J
AU GABA, A
   WINKLER, RL
TI IMPLICATIONS OF ERRORS IN SURVEY DATA - A BAYESIAN MODEL
SO MANAGEMENT SCIENCE
VL 38
IS 7
BP 913
EP 925
DI 10.1287/mnsc.38.7.913
PD JUL 1992
PY 1992
AB Data from surveys often include errors, and such errors can have a
   serious effect on inferences about behavior or perceptions.  In this
   paper a model is developed for making inferences based on dichotomous
   survey data with possible errors. A likelihood analysis reveals an
   identification problem, which can be avoided when a Bayesian approach is
   taken. The model is illustrated with purchase recall data from two
   previous studies, and the analysis shows that errors can have a
   significant impact on inferences about behavior. Ignoring such errors
   leads to point estimates that are systematically too high in many cases
   and to interval estimates that are unrealistically narrow. The effective
   amount of information in the survey data is reduced dramatically by the
   presence of errors. These results have important implications for the
   use and value of survey data in marketing and in many other areas.
ZA 0
TC 34
ZS 0
Z8 0
ZB 2
ZR 0
Z9 34
SN 0025-1909
UT WOS:A1992JD75600001
ER

PT J
AU TAM, KY
   KIANG, MY
TI MANAGERIAL APPLICATIONS OF NEURAL NETWORKS - THE CASE OF BANK FAILURE
   PREDICTIONS
SO MANAGEMENT SCIENCE
VL 38
IS 7
BP 926
EP 947
DI 10.1287/mnsc.38.7.926
PD JUL 1992
PY 1992
AB This Paper introduces a neural-net approach to perform discriminant
   analysis in business research. A neural net represents a nonlinear
   discriminant function as a pattern of connections between its processing
   units. Using bank default data, the neural-net approach is compared with
   linear classifier, logistic regression, kNN, and ID3. Empirical results
   show that neural nets is a promising method of evaluating bank
   conditions in terms of predictive accuracy, adaptability, and
   robustness. Limitations of using neural nets as a general modeling tool
   are also discussed.
RI Kiang, Melody/Q-6877-2019; Tam, Kar Yan/
OI Tam, Kar Yan/0000-0003-3242-0184
Z8 15
ZA 0
ZR 2
ZS 7
ZB 8
TC 576
Z9 596
SN 0025-1909
UT WOS:A1992JD75600002
ER

PT J
AU MURPHY, FH
   STOHR, EA
   MA, PC
TI COMPOSITION RULES FOR BUILDING LINEAR-PROGRAMMING MODELS FROM COMPONENT
   MODELS
SO MANAGEMENT SCIENCE
VL 38
IS 7
BP 948
EP 963
DI 10.1287/mnsc.38.7.948
PD JUL 1992
PY 1992
AB This Paper describes some rules for combining component models into
   complete linear pr The objective is to lay the foundations for systems
   that give users flexibility in designing new models and reusing old
   ones, while, at the same time, providing better documentation and better
   diagnostics than is provided by current systems. The results presented
   here rely on two different sets of properties of LP models: first, the
   syntactic relationships among indices that define the rows and columns
   of the LP, and second, the meanings attached to these indices. These two
   kinds of information allow us to build a complete algebraic statement of
   a model from a collection of components provided by the model builder.
ZR 0
TC 13
Z8 0
ZB 0
ZS 0
ZA 0
Z9 13
SN 0025-1909
UT WOS:A1992JD75600003
ER

PT J
AU MURPHY, FH
   STOHR, EA
   ASTHANA, A
TI REPRESENTATION SCHEMES FOR LINEAR-PROGRAMMING MODELS
SO MANAGEMENT SCIENCE
VL 38
IS 7
BP 964
EP 991
DI 10.1287/mnsc.38.7.964
PD JUL 1992
PY 1992
AB Because of the difficulties often experienced in formulating and
   understanding large-scale models, much current research is directed
   towards developing systems to support the construction and understanding
   of management science models. This paper discusses eight different
   methods for representing linear programming models during the
   formulation phase. The approaches discussed are matrix generators,
   block-schematic and algebraic languages, three different kinds of
   graphical schemes, a database-oriented approach and Structured Modeling.
   While these eight approaches do not cover the entire spectrum of
   possible representation schemes, they are representative of past and
   current approaches to developing interfaces for large-scale linear
   programming systems. The different model representation schemes are
   compared using a common example and the transformations that allow one
   to change from one representation to another are discussed.
TC 18
ZB 0
Z8 0
ZS 0
ZA 0
ZR 0
Z9 18
SN 0025-1909
UT WOS:A1992JD75600004
ER

PT J
AU WESTLAND, JC
TI CONGESTION AND NETWORK EXTERNALITIES IN THE SHORT RUN PRICING OF
   INFORMATION-SYSTEM SERVICES
SO MANAGEMENT SCIENCE
VL 38
IS 7
BP 992
EP 1009
DI 10.1287/mnsc.38.7.992
PD JUL 1992
PY 1992
AB Transfer pricing provides management with an efficient tool for
   coordinating the use of information system services. In practice these
   services, if they are charged out to end users, are priced via an
   allocation of historical costs based on individual usage, or are
   assigned a price based on the fair market value of outside alteratives.
   Both approaches encourage suboptimal usage of information systems
   resources; they ignore three constituents of optimal transfer prices:
   (1) the reaction of other users to any change in a given user's
   consumption of service; (2) the technical response to additional use of
   an information system service, in the form of congestion and network
   externalities; and (3) end-user preferences for the information system
   service. Together, these influences on demand contribute to an
   externality. Two types of externalities are significant in information
   systems-congestion externalities decrease, and network externalities
   increase the utility of services. This research provides a complete
   model for computing optimal transfer price which corrects several
   existing problems in information system service valuation. When full
   absorption cost allocations contain significant fixed, precommitted or
   sunk cost components, it is not possible to balance the budget. Direct
   costing improves on full absorption costing, but mis-specifies costs
   when demand is nonlinear. To balance the budget with a minimum of
   disutility to end users management must resort to second-best pricing.
   Inefficiency arises from two sources when externalities are ignored in
   transfer pricing. End users cannot plan service usage, and thus
   encounter unanticipated congestion which lowers morale and efficiency,
   and increases costly expediting. Where congestion effects are highly
   nonlinear, congestion may effectively shut down the system. On the other
   hand, incorrect transfer prices can motivate usage too low to take
   advantage of network benefits. End users may confuse externality effects
   and intrinsic value of an information system service. In these cases,
   the price and performance of outside alteratives exert a complex and
   subtle influence on use and pricing of services. Where there exist
   identical outside and inside processing alteratives, and transfer
   pricing does not reflect this, there is a significant tendency to
   overprice and underutilize internal services. In this case there may be
   a tendency to outsource when processing should be kept in-house. Future
   markets for information systems will favor technologies which exhibit
   strong network externalities, and pricing of these technologies will
   become increasingly complex because of the interrelationship of
   hardware, software and data originated externalities. The models
   provided in this research will allow management to take advantage of
   these opportunities.
ZA 0
TC 46
ZR 0
ZS 1
Z8 2
ZB 0
Z9 49
SN 0025-1909
UT WOS:A1992JD75600005
ER

PT J
AU BORDLEY, RF
   HAZEN, G
TI NONLINEAR UTILITY-MODELS ARISING FROM UNMODELLED SMALL WORLD
   INTERCORRELATIONS
SO MANAGEMENT SCIENCE
VL 38
IS 7
BP 1010
EP 1017
DI 10.1287/mnsc.38.7.1010
PD JUL 1992
PY 1992
AB Savage's axioms show the rationality of maximizing expected utility when
   all uncertainties are explicitly modelled. But individuals actually make
   decisions in bounded contexts called small worlds. Savage's axioms do
   not imply the optimality of maximizing expected utility in small worlds
   unless lotteries in different small worlds are probabilistically
   independent. Relaxing this independence assumption causes Savage's
   axioms to imply the optimality of maximizing a nonlinear utility model
   which includes, as special cases, the Chew weighted linear utility
   model, the Bell elation/disappointment model and the Allais
   mean/variance model in utility-independent small worlds.
RI Hazen, Gordon/B-7463-2009
TC 4
ZB 0
ZR 0
Z8 0
ZS 0
Z9 4
SN 0025-1909
UT WOS:A1992JD75600006
ER

PT J
AU WEIN, LM
   CHEVALIER, PB
TI A BROADER VIEW OF THE JOB-SHOP SCHEDULING PROBLEM
SO MANAGEMENT SCIENCE
VL 38
IS 7
BP 1018
EP 1033
DI 10.1287/mnsc.38.7.1018
PD JUL 1992
PY 1992
AB We define a job-shop scheduling problem with three dynamic decisions:
   assigning due-dates to exogenously arriving jobs, releasing jobs from a
   backlog to the shop floor, and sequencing jobs at each of two
   workstations in the shop. The job-shop is modeled as a multiclass
   queueing network and the objective is to minimize both the
   work-in-process (WIP) inventory on the shop floor and the due-date lead
   time (due-date minus arrival date) of jobs, subject to an upper bound
   constraint on the proportion of tardy jobs. A general two-step approach
   to this problem is proposed: (1) release and sequence jobs in order to
   minimize the WIP inventory subject to completing jobs at a specified
   rate, and (2) given the policies in (1), set due-dates that will attempt
   to minimize the due-date lead time, subject to the job tardiness
   constraint. A simulation study shows that this approach easily
   outperforms other combinations of traditional due-date setting, job
   release, and priority sequencing policies for two cases (moderately
   loaded and heavily loaded) of a particular shop. As a result of the
   study, three scheduling principles are proposed that can significantly
   improve the performance of a two-station job-shop; in particular, better
   due-date performance can be achieved by ignoring due-dates on the shop
   floor. Although we have only considered a two-station shop, the approach
   and scheduling principles presented here might also be useful for larger
   shops.
OI Chevalier, Philippe/0000-0001-6443-624X
TC 84
ZB 0
Z8 6
ZS 0
ZR 0
ZA 0
Z9 90
SN 0025-1909
UT WOS:A1992JD75600007
ER

PT J
AU CHAND, S
   SETHI, SP
   SORGER, G
TI FORECAST HORIZONS IN THE DISCOUNTED DYNAMIC LOT SIZE MODEL
SO MANAGEMENT SCIENCE
VL 38
IS 7
BP 1034
EP 1048
DI 10.1287/mnsc.38.7.1034
PD JUL 1992
PY 1992
AB We derive a sharp upper bound on the minimal forecast horizon in the
   discounted dynamic lot size model with constant initial demand. This
   bound is given by m(m + 1), where m is the EOQ's worth, i.e., the number
   of periods for which the total demand equals Economic Order Quantity.
   Our results do not require the solution of the infinite horizon problem
   to be unique. Nor do they require the infinite horizon problem to be
   well defined. We also prove some sensitivity results with respect to the
   discount factor and the setup cost.
RI Sorger, Gerhard/C-7084-2017; Sethi, Suresh P/C-4517-2012
OI Sorger, Gerhard/0000-0003-4070-526X; 
ZS 0
ZR 0
Z8 0
TC 19
ZB 1
ZA 0
Z9 19
SN 0025-1909
UT WOS:A1992JD75600008
ER

PT J
AU SHERALI, HD
   HOBEIKA, AG
   TRANI, AA
   KIM, BJ
TI AN INTEGRATED SIMULATION AND DYNAMIC-PROGRAMMING APPROACH FOR
   DETERMINING OPTIMAL RUNWAY EXIT LOCATIONS
SO MANAGEMENT SCIENCE
VL 38
IS 7
BP 1049
EP 1062
DI 10.1287/mnsc.38.7.1049
PD JUL 1992
PY 1992
AB The Federal Aviation Administration and National Aeronautics and Space
   Administration are researching several problems targeted at improving
   airport capacity. Among the foremost of these problems is the issue of
   improving the operational use of runways. The efficiency of runway usage
   is dictated primarily by the runway occupancy time (ROT) which is the
   time that an aircraft spends on the runway or its vicinity, until a new
   arrival or departure can be processed on this runway. This paper
   considers the problem of determining the geometry and location of high
   speed exits on a runway to minimize the weighted ROT of a population of
   aircraft under various landing scenarios and frequencies of usage. Both
   the problem of designing a new runway and modifying an existing one are
   addressed. It is shown that the continuous location problem of siting
   runway turnoffs admits a natural finite set of candidate optimal
   locations. To characterize problem data and determine optimal exit
   locations, a simulation program integrated with a polynomial-time
   dynamic programming algorithm is developed. The methodology has been
   implemented on a personal computer, and an example is presented to
   illustrate the approach.
ZB 0
ZA 0
Z8 0
TC 8
ZR 0
ZS 0
Z9 8
SN 0025-1909
UT WOS:A1992JD75600009
ER

PT J
AU TAGARAS, G
   COHEN, MA
TI POOLING IN 2-LOCATION INVENTORY SYSTEMS WITH NONNEGLIGIBLE REPLENISHMENT
   LEAD TIMES
SO MANAGEMENT SCIENCE
VL 38
IS 8
BP 1067
EP 1083
DI 10.1287/mnsc.38.8.1067
PD AUG 1992
PY 1992
AB This paper deals with the analysis of two-location periodic review
   inventory systems with non-negligible replenishment lead times.
   Emergency transshipments are used in these systems as a recourse action
   to reduce the occurrence of shortages. A class of partial pooling
   policies is proposed for the control of transshipments. The cost
   performance of this class of policies is shown to be inferior to that of
   complete pooling. An approximate model and a heuristic algorithm are
   introduced to compute near-optimal stocking policy solutions.
   Comparisons with simulation results verify the satisfactory performance
   of the approximate model and algorithm. Numerical sensitivity analysis
   provides additional insight into the nature of optimal transshipment
   behavior.
ZB 0
Z8 1
TC 115
ZR 0
ZS 0
ZA 0
Z9 116
SN 0025-1909
UT WOS:A1992JH94100001
ER

PT J
AU WARDELL, DG
   MOSKOWITZ, H
   PLANTE, RD
TI CONTROL CHARTS IN THE PRESENCE OF DATA CORRELATION
SO MANAGEMENT SCIENCE
VL 38
IS 8
BP 1084
EP 1105
DI 10.1287/mnsc.38.8.1084
PD AUG 1992
PY 1992
AB Traditional statistical process control charts assume that observations
   are independent and normally distributed about some mean. We investigate
   the robustness of traditional charts to data correlation when the
   correlation can be described by an ARMA (1,1) model. We compare the
   performance of the Shewhart chart and the Exponentially Weighted Moving
   Average (EWMA) chart to the performance of the Special-Cause Control
   (SCC) chart and the Common-Cause Control (CCC) chart proposed by Alwan
   and Roberts (1988), which are designed to account for data correlation.
   We also explore the possibility of putting limits on the CCC chart, in
   order to predict quality abnormalities. The measure of performance used
   is the average run length (ARL). The results show that the ability of
   the EWMA chart to detect shifts in the process mean is quite robust to
   data correlation. while the corresponding individuals Shewhart chart
   rarely detects such shifts more quickly than the other charts. The SCC
   and CCC charts are shown to be preferred in most cases when a shift in
   the process mean exceeds 2 standard deviations. The experimental results
   can aid practitioners in deciding which chart would be most effective at
   detecting specified shifts in the process mean given the nature of their
   particular correlated environments. Two methodologies are utilized to
   explain the relative performance of the SPC charts compared: the dynamic
   step response function, and response surface methodology. Such methods
   not only facilitate a discussion of our results. but also make it
   possible to predict the relative performance of the charts when the
   process can be described by a model which is more complex than the ARMA
   (1,1) model.
RI , Don/AAH-8062-2020
Z8 9
ZS 2
TC 120
ZA 0
ZR 0
ZB 4
Z9 131
SN 0025-1909
UT WOS:A1992JH94100002
ER

PT J
AU KIM, SK
   SUH, YS
TI CONDITIONAL MONITORING POLICY UNDER MORAL HAZARD
SO MANAGEMENT SCIENCE
VL 38
IS 8
BP 1106
EP 1120
DI 10.1287/mnsc.38.8.1106
PD AUG 1992
PY 1992
AB This paper extends the previous research on conditional monitoring by
   allowing the principal to choose the level of monitoring investment and
   by finding the properties of an interior optimal monitoring policy which
   is not of a bang-bang nature. We show that, under a concave monitoring
   technology, the optimal monitoring investment is decreasing in the
   observed outcome and lower-tailed in a variety of contexts.
TC 6
ZB 0
ZA 0
ZR 0
Z8 0
ZS 0
Z9 6
SN 0025-1909
UT WOS:A1992JH94100003
ER

PT J
AU STIDHAM, S
TI PRICING AND CAPACITY DECISIONS FOR A SERVICE FACILITY - STABILITY AND
   MULTIPLE LOCAL OPTIMA
SO MANAGEMENT SCIENCE
VL 38
IS 8
BP 1121
EP 1139
DI 10.1287/mnsc.38.8.1121
PD AUG 1992
PY 1992
AB We consider a model for optimal pricing and capacity for a service
   facility. The problem is formulated as one of optimal design of a
   single-server queueing system. in which the design variables are the
   service rate and the arrival rate (equivalently, the price charged for
   admission). The model is a variant of one introduced by Dewan and
   Mendelson, We allow for an upper bound on the arrival rate and consider
   slightly more general user value functions. We show that an optimal
   solution may not lie in the interior of the feasible region and thus may
   not be characterized by the first-order differential conditions.
   Moreover, the first-order conditions typically have several solutions,
   some of which may be relative minima and produce a negative value of the
   objective function (customer value minus the sum of expected delay cost
   and capacity cost per unit time). We also examine the stability of the
   equilibrium arrival rate and the convergence of a dynamic adaptive
   algorithm for finding the optimal service rate, in the context of a
   model in which the distribution of customers' value of service is
   uniform. We show that the equilibrium arrival rate is stable if and only
   if the service rate is above a threshold value, which depends on the
   price charged for admission and the parameters of the uniform
   distribution of value of service. The dynamic, adaptive algorithm always
   converges to a relative maximum of the objective function if the service
   rate can be adjusted every time the arrival rate changes. Otherwise, the
   algorithm will start to diverge if and when the service rate ever falls
   below the threshold value associated with stability of the equilibrium
   arrival rate.
ZA 0
TC 95
ZS 0
ZB 0
Z8 4
ZR 0
Z9 99
SN 0025-1909
UT WOS:A1992JH94100004
ER

PT J
AU DADA, M
TI A 2-ECHELON INVENTORY SYSTEM WITH PRIORITY SHIPMENTS
SO MANAGEMENT SCIENCE
VL 38
IS 8
BP 1140
EP 1153
DI 10.1287/mnsc.38.8.1140
PD AUG 1992
PY 1992
AB A two-echelon system for spare parts is analyzed. The system allows the
   use of priority inventory pooling to expedite service when a stock-out
   occurs. First, a tractable aggregate model is derived. This model is
   then disaggregated to approximate the performance of the exact system.
   Results of computer tests are also presented.
Z8 1
ZA 0
ZS 1
ZB 0
TC 11
ZR 0
Z9 13
SN 0025-1909
EI 1526-5501
UT WOS:A1992JH94100005
ER

PT J
AU KALAI, E
   KAMIEN, MI
   RUBINOVITCH, M
TI OPTIMAL SERVICE SPEEDS IN A COMPETITIVE ENVIRONMENT
SO MANAGEMENT SCIENCE
VL 38
IS 8
BP 1154
EP 1163
DI 10.1287/mnsc.38.8.1154
PD AUG 1992
PY 1992
AB This is a study of the economic behavior of vendors of service in
   competition. A simple model with two competing exponential servers and
   Poisson arrivals is considered. Each server is free to choose his own
   service rate at a cost (per time unit) that is strictly convex and
   increasing. There is a fixed reward to a server for each customer that
   he serves. The model is designed to study one specific aspect of
   competition, namely, competition in speed of service as a means for
   capturing a larger market share in order to maximize long-run expected
   profit per time unit. A two-person strategic game is formulated and its
   solutions are characterized. Depending on the revenue per customer
   served and on the cost of maintaining service rates, the following three
   situations may arise: (i) a unique symmetric strategic (Nash)
   equilibrium in which expected waiting time is infinite; (ii) a unique
   symmetric strategic equilibrium in which expected waiting time is
   finite; and (iii) several, nonsymmetric strategic equilibria with
   infinite expected waiting time. An explicit expression for the market
   share of each server as a function of the service rates of the two
   servers is also given.
ZR 0
ZA 0
TC 70
ZB 1
ZS 0
Z8 3
Z9 73
SN 0025-1909
UT WOS:A1992JH94100006
ER

PT J
AU KLEIJNEN, JPC
TI REGRESSION METAMODELS FOR SIMULATION WITH COMMON RANDOM NUMBERS -
   COMPARISON OF VALIDATION TESTS AND CONFIDENCE-INTERVALS
SO MANAGEMENT SCIENCE
VL 38
IS 8
BP 1164
EP 1185
DI 10.1287/mnsc.38.8.1164
PD AUG 1992
PY 1992
AB Linear regression analysis is important in many fields. In the analysis
   of simulation results, a regression (meta) model can be applied, even
   when common pseudorandom numbers are used. To test the validity of the
   specified regression model, Rao (1959) generalized the F statistic for
   lack of fit, whereas Kleijnen (1983) proposed a cross-validation
   procedure using a Student's t statistic combined with Bonferroni's
   inequality. This paper reports on an extensive Monte Carlo experiment
   designed to compare these two methods. Under the normality assumption,
   cross-validation is conservative, whereas Rao's test realizes its
   nominal type I error and has high power. Robustness is investigated
   through lognormal and uniform distributions. When simulation responses
   are distributed lognormally, then cross-validation using Ordinary Least
   Squares is the only technique that has acceptable type I error. Uniform
   distributions give results similar to the normal case. Once the
   regression model is validated, confidence intervals for the individual
   regression parameters are computed. The Monte Carlo experiment compares
   several confidence interval procedures. Under normality, Rao's procedure
   is preferred since it has good coverage probability and acceptable
   half-length. Under lognormality, Ordinary Least Squares achieves nominal
   coverage probability. Uniform distributions again give results similar
   to the normal case.
RI Kleijnen, Jack/ABB-6455-2020; Kleijnen, Jack/AAL-6469-2020; Kleijnen, jack/
OI Kleijnen, jack/0000-0001-8413-2366
ZA 0
ZR 0
ZB 1
ZS 0
TC 31
Z8 0
Z9 31
SN 0025-1909
UT WOS:A1992JH94100007
ER

PT J
AU VONPUELZ, A
   LEE, SM
TI A MULTIPLE-OBJECTIVE PROGRAMMING TECHNIQUE FOR STRUCTURING TAX-EXEMPT
   SERIAL REVENUE DEBT ISSUES
SO MANAGEMENT SCIENCE
VL 38
IS 8
BP 1186
EP 1200
PD AUG 1992
PY 1992
AB A multiple-objective decision model to structure tax-exempt serial
   revenue bonds is presented in this paper. Based on goals dealing with
   true interest cost, marketability, debt coverage, production, and level
   debt, we define a goal programming model to generate a maturity schedule
   and coupon rate assignment for a municipal bond issue. The model is
   designed to be a flexible interactive decision making tool to aid in the
   development of a minimal-risk, cost-effective issue.
Z8 0
ZR 0
TC 2
ZA 0
ZS 0
ZB 0
Z9 2
SN 0025-1909
UT WOS:A1992JH94100008
ER

PT J
AU LASSERRE, JB
TI AN INTEGRATED MODEL FOR JOB-SHOP PLANNING AND SCHEDULING
SO MANAGEMENT SCIENCE
VL 38
IS 8
BP 1201
EP 1211
DI 10.1287/mnsc.38.8.1201
PD AUG 1992
PY 1992
AB We consider an integrated job-shop planning and scheduling model. To
   solve the problem we use a (multi-pass) decomposition approach which
   alternates between solving a planning problem with a fixed sequence of
   products on the machines, and a job-shop scheduling problem for a fixed
   choice of the production plan. The generated production plans are
   feasible i.e., there exists at least one feasible schedule to realize
   that plan. Quality of the solution is investigated and numerical results
   are presented.
ZA 0
ZB 0
Z8 14
TC 58
ZR 0
ZS 0
Z9 72
SN 0025-1909
UT WOS:A1992JH94100009
ER

PT J
AU HALL, RW
TI A NOTE ON BOUNDS FOR DIRECT SHIPPING COST
SO MANAGEMENT SCIENCE
VL 38
IS 8
BP 1212
EP 1214
DI 10.1287/mnsc.38.8.1212
PD AUG 1992
PY 1992
AB The bounds on direct shipping cost developed by Gallego and Simchi-Levi
   are used in this note to demonstrate that it is difficult to rule out
   multiple stop inventory-routing strategies, even when the optimal
   shipment size for direct shipping is a full vehicle.
Z8 0
ZR 0
ZS 1
ZB 0
ZA 0
TC 22
Z9 23
SN 0025-1909
UT WOS:A1992JH94100010
ER

PT J
AU KAPLAN, EH
   HERSHLAG, A
   DECHERNEY, AH
   LAVY, G
TI TO BE OR NOT TO BE - THAT IS CONCEPTION - MANAGING INVITRO FERTILIZATION
   PROGRAMS
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1217
EP 1229
DI 10.1287/mnsc.38.9.1217
PD SEP 1992
PY 1992
AB The performance of in vitro fertilization-embryo transfer (IVF-ET)
   programs is summarized typically as the average probability of achieving
   pregnancy per cycle. Variation in conception probabilities across women
   reduces the usefulness of such an aggregate measure. More relevant is
   the conditional probability of achieving pregnancy on a given cycle
   following a number of failed IVF-ET attempts. We construct a model that
   accurately describes 1,257 treatment cycles performed at Yale over 571
   different women. The model assumes a split population, where some women
   can never conceive via IVF-ET, while the remaining women have identical
   and constant per cycle probabilities of conception. This model produces
   estimates that are highly consistent with the data, and suggests that
   continuing treatment beyond some threshold number of cycles is not
   efficacious. Recognizing this, we determine cutoffs beyond which
   treatment should not continue for IVF-ET programs with fixed capacities.
   We also consider cutoff policies where program participants may belong
   to one of several different split populations, detailing the case of two
   groups. Finally, we show how one may reduce the average time in
   treatment (including waiting time) considerably with minimal impact on
   the probability of achieving pregnancy.
RI DeCherney, Alan H/AAS-2944-2020
ZB 1
ZS 0
TC 8
ZA 0
Z8 0
ZR 0
Z9 8
SN 0025-1909
EI 1526-5501
UT WOS:A1992JN46000001
ER

PT J
AU CHINTAGUNTA, PK
   VILCASSIM, NJ
TI AN EMPIRICAL-INVESTIGATION OF ADVERTISING STRATEGIES IN A DYNAMIC
   DUOPOLY
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1230
EP 1244
DI 10.1287/mnsc.38.9.1230
PD SEP 1992
PY 1992
AB The equilibrium profit-maximizing advertising policies of firms
   operating in a dynamic duopoly are derived by linking in a single
   framework the econometric estimation of the market response function and
   the technique of differential games that characterizes dynamic
   competitive behavior. We use the Lanchester model of combat to represent
   the system dynamics that capture the competitive shifts due to
   investments in advertising by the two market rivals. We determine the
   equilibrium advertising levels using both closed- and open-loop
   policies. We also compare these equilibrium advertising policies for
   each firm to those obtained using an optimal control theory formulation
   wherein the advertising spending levels of the rival are assumed to be
   known.
   The empirical results obtained by analyzing the advertising rivalry
   between Coke and Pepsi for the period 1968-1981 under the above three
   alterative spending policies provide some interesting insights into the
   nature of competition between these two market rivals. A significant
   contribution of this paper is to extend the existing literature on
   advertising competition by integrating theoretical and empirical
   analyses.
RI Chintagunta, Pradeep K/A-4764-2017; Vilcassim, Naufel/C-6307-2014
ZB 2
TC 98
ZA 0
Z8 13
ZR 0
ZS 0
Z9 111
SN 0025-1909
UT WOS:A1992JN46000002
ER

PT J
AU ELMAGHRABY, SE
   KAMBUROWSKI, J
TI THE ANALYSIS OF ACTIVITY NETWORKS UNDER GENERALIZED PRECEDENCE RELATIONS
   (GPRS)
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1245
EP 1263
DI 10.1287/mnsc.38.9.1245
PD SEP 1992
PY 1992
AB We present a model for activity networks under generalized precedence
   relations (GPRs), discuss its temporal analysis and the issues that may
   arise relative to inconsistency among the specified relations and the
   activity durations. We also give more precise definition to the concept
   of criticality of an activity, and introduce the new concept of
   flexibility of an activity which is akin to the traditional concept of
   activity floats in regular CPM, with the latter taking on different
   meaning from its common interpretation in standard CPM.
   Issues of optimization are raised when one assumes, for each activity, a
   piecewise-linear time-cost function that permits positive and negative
   deviations from its least-cost duration between specified lower and
   upper bounds on that duration. We seek the optimal activity durations
   subject to the specified GPRs and a given due date lambda. We also seek
   the construction of the complete project duration-cost function between
   the project minimum duration and its least-cost duration when the due
   date lambda is interpreted, first, as a "deadline" and, second, as a
   "target date" with rewards for early, and penalties for late completion.
   The relations between the problems posed and the uncapacitated minimum
   cost flow problems are revealed and are utilized in the algorithmic
   solution of the problems.
Z8 13
ZR 0
TC 110
ZB 1
ZS 1
ZA 0
Z9 121
SN 0025-1909
UT WOS:A1992JN46000003
ER

PT J
AU ERICKSON, G
   JACOBSON, R
TI GAINING COMPARATIVE ADVANTAGE THROUGH DISCRETIONARY EXPENDITURES - THE
   RETURNS TO RESEARCH-AND-DEVELOPMENT AND ADVERTISING
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1264
EP 1279
DI 10.1287/mnsc.38.9.1264
PD SEP 1992
PY 1992
AB We explore the extent to which R&D and advertising expenditures generate
   a comparative advantage that allows firms to earn supranormal profits.
   After controlling for unobserved firm-specific factors and the feedback
   between discretionary expenditures and profitability, our results
   suggest substantially lower accounting and stock market returns to R&D
   and advertising than indicated in previous research. Isolating
   mechanisms, which prevent imitation, do not appear sufficient for either
   R&D or advertising expenditures to generate, on the average, a long-run
   comparative advantage.
ZA 0
ZB 0
ZR 0
Z8 1
TC 169
ZS 2
Z9 172
SN 0025-1909
EI 1526-5501
UT WOS:A1992JN46000004
ER

PT J
AU SCHOTTER, A
   WEIGELT, K
TI BEHAVIORAL CONSEQUENCES OF CORPORATE INCENTIVES AND LONG-TERM BONUSES -
   AN EXPERIMENTAL-STUDY
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1280
EP 1298
DI 10.1287/mnsc.38.9.1280
PD SEP 1992
PY 1992
AB This paper examines whether long-term managerial bonus schemes change
   the allocative behavior of subjects in a laboratory setting. Using four
   different compensation schemes, we show that a necessary condition for
   reconciling divergent time preferences between principals and agents is
   a compensation scheme that induces behavior consistent with lower
   discount rates. Within subject results show that subjects recognize
   changes across compensation schemes and change their behavior as
   predicted by formal theory. Results also suggest that subjects become
   more myopic in their investment decisions if compensation contracts are
   incorrectly structured.
ZR 0
ZB 1
ZS 1
ZA 0
Z8 0
TC 14
Z9 15
SN 0025-1909
UT WOS:A1992JN46000005
ER

PT J
AU IYER, AV
   SCHRAGE, LE
TI ANALYSIS OF THE DETERMINISTIC (S, S) INVENTORY PROBLEM
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1299
EP 1313
DI 10.1287/mnsc.38.9.1299
PD SEP 1992
PY 1992
AB The traditional or textbook approach for finding an (s, S) inventory
   policy is to take a demand distribution as given and then find a reorder
   point s and order up to point S that are optimal for this demand
   distribution. In reality, the demand distribution may have been obtained
   by fitting it to some historical demand stream. In contrast, the
   deterministic (s, S) inventory problem is to directly determine the (s,
   S) pair that would have been optimal for the original demand stream,
   bypassing the distribution fitting step. The deterministic (s, S)
   inventory problem thus chooses parameters s and S which minimize setup,
   holding and backorder costs when the corresponding (s, S) policy is
   implemented over n periods with known demands d1, d2,...,d(n). Our
   contributions are two: (a) a polynomial time algorithm for finding an
   optimal (s, S) for the deterministic problem, and (b) an empirical
   comparison of the two approaches. In (b) we compare the long term
   average costs of the two approaches as a function of the amount of data
   available, distributional assumptions, and order lead time.
ZS 0
TC 12
ZB 0
Z8 0
ZR 0
ZA 0
Z9 12
SN 0025-1909
UT WOS:A1992JN46000006
ER

PT J
AU LEE, HL
TI LOT SIZING TO REDUCE CAPACITY UTILIZATION IN A PRODUCTION PROCESS WITH
   DEFECTIVE ITEMS, PROCESS CORRECTIONS, AND REWORK
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1314
EP 1328
DI 10.1287/mnsc.38.9.1314
PD SEP 1992
PY 1992
AB This paper deals with the lot sizing problem in which the key features
   of imperfections in a production process are explicitly modelled. These
   features include: process shifting to out-of-control states, detection
   of the out-of-control shifts, corrective actions following the
   detections, and the fixed setup and variable processing times of
   reworks. The problem is motivated by the wafer probe operation in
   semiconductor manufacturing. The key objective that drives the lot
   sizing decision is to reduce the total processing time on a critical
   resource. Such an objective is aimed at reducing the congestion level at
   this resource.
Z8 0
TC 74
ZS 0
ZB 0
ZR 0
ZA 0
Z9 74
SN 0025-1909
UT WOS:A1992JN46000007
ER

PT J
AU DIABY, M
   BAHL, HC
   KARWAN, MH
   ZIONTS, S
TI A LAGRANGEAN RELAXATION APPROACH FOR VERY-LARGE-SCALE CAPACITATED
   LOT-SIZING
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1329
EP 1340
DI 10.1287/mnsc.38.9.1329
PD SEP 1992
PY 1992
AB In this paper, we develop a Lagrangean relaxation-based heuristic
   procedure to generate near-optimal solutions to very-large-scale
   capacitated lot-sizing problems (CLSP) with setup times and limited
   overtime. Our computational results show that large problems involving
   several thousand products and several thousand 0/1 integer variables can
   be solved in a reasonable amount of computer time to within one percent
   of their optimal solution. The proposed procedure is general enough to
   be applied directly or with slight modification to real-life production
   problems.
RI Karwan, Mark/H-5150-2016
OI Karwan, Mark/0000-0001-9478-6988
ZR 0
ZB 0
Z8 3
TC 71
ZS 1
ZA 0
Z9 75
SN 0025-1909
UT WOS:A1992JN46000008
ER

PT J
AU AHMADI, RH
   DASU, S
   TANG, CS
TI THE DYNAMIC LINE ALLOCATION PROBLEM
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1341
EP 1353
DI 10.1287/mnsc.38.9.1341
PD SEP 1992
PY 1992
AB Consider a plant that has information about the arrival schedule of its
   "inputs" over a planning cycle. The plant has parallel production lines
   for processing multiple types of products. However, changeover cost and
   changeover time are incurred when a line changes from processing one
   type of products to a different type of products. We present a dynamic
   line allocation problem that determines an optimal line allocation so
   that the total relevant cost (changeover and waiting costs) is
   minimized. In this paper we analyze the complexity of the problem and
   develop three different heuristics for generating near-optimal
   allocations.
ZS 0
ZR 0
TC 9
ZA 0
ZB 0
Z8 0
Z9 9
SN 0025-1909
UT WOS:A1992JN46000009
ER

PT J
AU WITTROCK, RJ
TI OPERATOR ASSIGNMENT AND THE PARAMETRIC PREFLOW ALGORITHM
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1354
EP 1359
DI 10.1287/mnsc.38.9.1354
PD SEP 1992
PY 1992
AB This note addresses a problem of assigning human operators to operations
   in a manufacturing system. The problem involves a set of operations, a
   work load for each operation, and a set of human operators, each skilled
   at a subset of the operations. The task is to assign the operators to
   the operations so as to maximize the capacity of the system, robustly.
   The problem is formulated as a network flow problem with a lexicographic
   objective. It is then shown how to solve this problem very efficiently
   as a parametric sequence of network maximum flow problems, by
   application of the "parametric preflow" algorithm of Gallo, Grigoriadis
   and Tarjan.
Z8 0
ZA 0
ZR 0
ZS 0
TC 4
ZB 0
Z9 4
SN 0025-1909
UT WOS:A1992JN46000010
ER

PT J
AU GLYNN, PW
TI PATHWISE CONVEXITY AND ITS RELATION TO CONVERGENCE OF TIME-AVERAGE
   DERIVATIVES
SO MANAGEMENT SCIENCE
VL 38
IS 9
BP 1360
EP 1366
DI 10.1287/mnsc.38.9.1360
PD SEP 1992
PY 1992
AB In this note, we further develop the pathwise convexity approach
   introduced by Hu (1991) to prove consistency of infinitesimal
   perturbation analysis for the derivative of the steady-state waiting
   time of the G/G/1 queue. In addition to generalizing the argument, we
   illustrate the technique with applications to stochastic storage theory
   and networks of queues.
ZS 0
ZB 0
TC 3
Z8 0
ZR 0
ZA 0
Z9 3
SN 0025-1909
UT WOS:A1992JN46000011
ER

PT J
AU MCCARTHY, PS
   KANNAN, PK
   CHANDRASEKHARAN, R
   WRIGHT, GP
TI ESTIMATING LOYALTY AND SWITCHING WITH AN APPLICATION TO THE AUTOMOBILE
   MARKET
SO MANAGEMENT SCIENCE
VL 38
IS 10
BP 1371
EP 1393
DI 10.1287/mnsc.38.10.1371
PD OCT 1992
PY 1992
AB A brand switching model that considers the choices: previous choice,
   current choice, and substitute choice, if the current choice were not
   available, is developed and estimated. An important assumption of the
   model is that the market consists of two types of consumers: "Loyals"
   and "Shoppers." The model provides estimates for: (1) the proportion of
   Loyals in a submarket, and (2) the success of each submarket in
   capturing Shoppers. We illustrate how the model can be used to
   characterize the competitive structure of a market. We also show how the
   estimated parameters of the model can be validated using simulation and
   a theoretically derived covariance matrix.
   Our empirical application to automobile data from J. D. Power and
   Associates provides insights into several interesting marketing
   phenomena including: (1) the competitiveness of domestic versus foreign
   makes of automobiles, (2) competition between submarkets defined by
   form, and (3) the effect of previous dealer experience on loyalty and
   shopping.
RI Kannan, Pallassana K/D-8192-2011
Z8 0
ZS 0
ZA 0
ZR 0
ZB 0
TC 23
Z9 23
SN 0025-1909
UT WOS:A1992JU45300001
ER

PT J
AU COLLOPY, F
   ARMSTRONG, JS
TI RULE-BASED FORECASTING - DEVELOPMENT AND VALIDATION OF AN EXPERT
   SYSTEMS-APPROACH TO COMBINING TIME-SERIES EXTRAPOLATIONS
SO MANAGEMENT SCIENCE
VL 38
IS 10
BP 1394
EP 1414
DI 10.1287/mnsc.38.10.1394
PD OCT 1992
PY 1992
AB This paper examines the feasibility of rule-based forecasting, a
   procedure that applies forecasting expertise and domain knowledge to
   produce forecasts according to features of the data. We developed a rule
   base to make annual extrapolation forecasts for economic and demographic
   time series. The development of the rule base drew upon protocol
   analyses of five experts on forecasting methods, This rule base,
   consisting of 99 rules, combined forecasts from four extrapolation
   methods (the random walk, regression, Brown's linear exponential
   smoothing, and Holt's exponential smoothing) according to rules using 18
   features of time series. For one-year ahead ex ante forecasts of 90
   annual series, the median absolute percentage error (MdAPE) for
   rule-based forecasting was 13% less than that from equally-weighted
   combined forecasts. For six-year ahead ex ante forecasts, rule-based
   forecasting had a MdAPE that was 42% less. The improvement in accuracy
   of the rule-based forecasts over equally-weighted combined forecasts was
   statistically significant. Rule-based forecasting was more accurate than
   equal-weights combining in situations involving significant trends, low
   uncertainty, stability, and good domain expertise.
TC 144
ZA 0
ZB 5
ZR 0
Z8 0
ZS 2
Z9 145
SN 0025-1909
UT WOS:A1992JU45300002
ER

PT J
AU YANG, WN
   NELSON, BL
TI MULTIVARIATE BATCH MEANS AND CONTROL VARIATES
SO MANAGEMENT SCIENCE
VL 38
IS 10
BP 1415
EP 1431
DI 10.1287/mnsc.38.10.1415
PD OCT 1992
PY 1992
AB We consider applying the nonoverlapping batch means output analysis
   method in conjunction with the control-variate variance-reduction
   technique to estimate a steady-state multivariate mean vector. The
   effects of the number of batches and the number of control variates on
   the multivariate point and region estimators and the univariate point
   and interval estimators are considered. The results are experiment
   analysis guidelines in terms of an appropriate range of the number of
   batches to choose as a function of the number of responses and control
   variates. The results have implications for terminating simulations as
   well.
RI Nelson, Barry L/B-7490-2009
ZA 0
TC 5
Z8 0
ZR 0
ZS 0
ZB 0
Z9 5
SN 0025-1909
UT WOS:A1992JU45300003
ER

PT J
AU FISHMAN, GS
   KULKARNI, VG
TI IMPROVING MONTE-CARLO EFFICIENCY BY INCREASING VARIANCE
SO MANAGEMENT SCIENCE
VL 38
IS 10
BP 1432
EP 1444
DI 10.1287/mnsc.38.10.1432
PD OCT 1992
PY 1992
AB This paper compares the performances of two well-known Monte Carlo
   procedures for estimating an unknown quantity as the size of the problem
   grows. One method based on the standard Monte Carlo approach generates K
   i.i.d. data points. The other derives its data from a single K-step
   sample path generated by a Markov chain. The paper gives necessary and
   sufficient conditions for the Markov chain approach to perform more
   efficiently than the standard Monte Carlo approach does. Moreover, it
   identifies circumstances under which this better efficiency grows with
   increasing problem size. This improved efficiency comes from reduced
   sample generating and function evaluating costs in the Markov chain
   approach that more than compensate for the increased variance of the
   estimator that the Markov chain sampling approach induces when compared
   to the standard Monte Carlo approach. Several examples illustrate how
   the benefits arise; one also demonstrates a case in which the standard
   Monte Carlo approach becomes increasingly preferred as the problem size
   grows.
TC 2
ZR 0
ZS 0
Z8 0
ZB 0
Z9 2
SN 0025-1909
UT WOS:A1992JU45300004
ER

PT J
AU HAMBRICK, DC
   DAVENI, RA
TI TOP TEAM DETERIORATION AS PART OF THE DOWNWARD SPIRAL OF LARGE CORPORATE
   BANKRUPTCIES
SO MANAGEMENT SCIENCE
VL 38
IS 10
BP 1445
EP 1466
DI 10.1287/mnsc.38.10.1445
PD OCT 1992
PY 1992
AB This exploratory study of 57 large bankruptcies and 57 matched survivors
   examined the top management team (TMT) characteristics associated with
   major corporate failure. Prior research was used to guide selection of
   specific team characteristics for study. Not only did the failing firms
   show significant annual, or cross-sectional, divergence from survivors
   on several indicators of TMT composition, but also those divergences
   became more pronounced, even accelerating, over the last five years of
   the bankrupts' lives. The results thus suggest that deterioration of the
   top management team is a central element of the downward spiral of large
   corporate failures. Based upon a limited test of causality, the authors
   propose that a two-way process is at work: (1) team deficiencies bring
   about or aggravate corporate deterioration, either through strategic
   errors or stakeholder uneasiness with the flawed team; and (2) corporate
   deterioration brings about team deterioration, through a combination of
   voluntary departures, scapegoating, and limited resources for attracting
   new executive talent.
TC 322
ZR 0
Z8 10
ZB 0
ZS 3
ZA 0
Z9 335
SN 0025-1909
EI 1526-5501
UT WOS:A1992JU45300005
ER

PT J
AU KARIMI, IA
TI OPTIMAL CYCLE TIMES IN MULTISTAGE SERIAL SYSTEMS WITH SET-UP AND
   INVENTORY COSTS
SO MANAGEMENT SCIENCE
VL 38
IS 10
BP 1467
EP 1481
DI 10.1287/mnsc.38.10.1467
PD OCT 1992
PY 1992
AB Scheduling of multistage serial production systems under constant demand
   and infinite horizon is considered. The production stages operate with
   periodic shut-downs and startups. An integer nonlinear programming
   formulation is presented for determining a stationary, cyclic schedule
   with no stock-outs in any inventory and minimum sum of set-up and
   inventory costs, It allows a lot-sizing policy involving arbitrary,
   noninteger splitting/ merging of lots. Three, almost optimal, heuristic
   algorithms and an exact branch and bound algorithm are developed using
   analytical results. Their evaluation using simulated problems shows the
   branch and bound algorithm to be the best, as it is fast even for
   systems with as many as 11 stages.
RI Karimi, Iftekhar/D-4607-2009
OI Karimi, Iftekhar/0000-0001-7122-0578
ZS 0
TC 13
ZR 0
Z8 0
ZA 0
ZB 0
Z9 13
SN 0025-1909
UT WOS:A1992JU45300006
ER

PT J
AU GLASS, CA
TI FEASIBILITY OF SCHEDULING LOT SIZES OF 3 PRODUCTS ON ONE MACHINE
SO MANAGEMENT SCIENCE
VL 38
IS 10
BP 1482
EP 1494
DI 10.1287/mnsc.38.10.1482
PD OCT 1992
PY 1992
AB This paper considers the Economic Lot Scheduling Problem: that is, the
   problem of finding a feasible schedule that allows cyclic production of
   several products on a single facility so as to minimize holding and set
   up costs. We consider the case when three products are required to be
   produced in a given fixed lot size and at regular intervals. We derive a
   very simple test for existence of a feasible schedule and a method of
   constructing feasible schedules if one exists. The approach is simpler
   than the mixed integer programming approach and enumeration schemes
   currently proposed in the literature and is constructive.
OI Glass, Celia A./0000-0002-1880-7721
ZA 0
TC 19
Z8 1
ZS 0
ZB 0
ZR 0
Z9 20
SN 0025-1909
UT WOS:A1992JU45300007
ER

PT J
AU STORER, RH
   WU, SD
   VACCARI, R
TI NEW SEARCH SPACES FOR SEQUENCING PROBLEMS WITH APPLICATION TO JOB SHOP
   SCHEDULING
SO MANAGEMENT SCIENCE
VL 38
IS 10
BP 1495
EP 1509
DI 10.1287/mnsc.38.10.1495
PD OCT 1992
PY 1992
AB In this paper search heuristics are developed for generic sequencing
   problems with emphasis on job shop scheduling. The proposed methods
   integrate problem specific heuristics common to Operations Research and
   local search approaches from Artificial Intelligence in order to obtain
   desirable properties from both. The applicability of local search to a
   wide range of problems, and the incorporation of problem-specific
   information are both properties of the proposed algorithms. Two methods
   are proposed, both of which are based on novel definitions of solution
   spaces and of neighborhoods in these spaces. Applications of the
   proposed methodology are developed for job shop scheduling problems, and
   can be easily applied with any scheduling objective. To demonstrate
   effectiveness, the method is tested on the job shop scheduling problem
   with the minimum makespan objective. Encouraging results are obtained.
Z8 6
ZS 0
TC 274
ZA 0
ZB 4
ZR 0
Z9 280
SN 0025-1909
UT WOS:A1992JU45300008
ER

PT J
AU SARKAR, D
   ZANGWILL, WI
TI FILE AND WORK TRANSFERS IN CYCLIC QUEUE SYSTEMS
SO MANAGEMENT SCIENCE
VL 38
IS 10
BP 1510
EP 1523
DI 10.1287/mnsc.38.10.1510
PD OCT 1992
PY 1992
AB A cyclic queue has one server and n nodes, where each node has its own
   distinct type of customers that arrive from the outside. The server
   visits the nodes cyclically, serving the customers first at node 1, then
   at node 2, and so on through node n, and then repeating from node 1
   again. Setup times are incurred when the server switches nodes.
   Typically, in the past, cyclic queues required that the work at any node
   arrive from the outside only. Our extension permits special nodes termed
   dual nodes. At these nodes the total work can include not only the
   outside customers, but also work transferred from other nodes. The
   transferred work is attended to as a batch at the dual nodes.
   Dual nodes permit a number of applications to be modeled including
   computer file transfer, rework in manufacturing, and internal mail
   delivery. If there are m dual nodes, the expected waiting time
   calculation requires solution of a linear system of size n(1 + m) + 2m
   or less. Often the system size is less, and for a queue with one dual
   node we prove that a system of only size n is required.
Z8 0
ZA 0
ZS 0
ZR 0
ZB 0
TC 3
Z9 3
SN 0025-1909
UT WOS:A1992JU45300009
ER

PT J
AU ZENIOS, SA
   ZIEMBA, WT
TI INTRODUCTION TO THE FOCUSED ISSUE ON FINANCIAL MODELING
SO MANAGEMENT SCIENCE
VL 38
IS 11
BP 1525
EP 1528
DI 10.1287/mnsc.38.11.1525
PD NOV 1992
PY 1992
RI Zenios, Stavros A/F-3346-2013
OI Zenios, Stavros A/0000-0001-7576-4898
ZB 0
TC 1
ZS 0
ZR 0
Z8 1
ZA 0
Z9 2
SN 0025-1909
UT WOS:A1992JZ76200001
ER

PT J
AU LEVY, H
   SAMUELSON, PA
TI THE CAPITAL-ASSET PRICING MODEL WITH DIVERSE HOLDING PERIODS
SO MANAGEMENT SCIENCE
VL 38
IS 11
BP 1529
EP 1542
DI 10.1287/mnsc.38.11.1529
PD NOV 1992
PY 1992
AB Assuming that assets are traded in discrete time and that risk averse
   investors differ in their holding periods, we investigate the conditions
   under which the CAPM holds. It is shown that when portfolio rebalancing
   is allowed the CAPM holds in four cases not rigorously analyzed
   previously. These four cases are: (a) quadratic preferences; (b)
   one-period normal distributions when utility is defined on the
   multiperiod terminal wealth which is not nor-mal; (c) the terminal
   wealth is log-normally distributed; and (d) the terminal wealth W(T) is
   normally distributed, but in this case diverse holding periods are not
   allowed. Case d is similar to the Sharpe-Lintner model with the
   exception that T - 1 revisions are allowed.
ZA 0
TC 16
ZB 0
ZR 0
ZS 0
Z8 0
Z9 16
SN 0025-1909
UT WOS:A1992JZ76200002
ER

PT J
AU CADSBY, CB
TI THE CAPM AND THE CALENDAR - EMPIRICAL ANOMALIES AND THE RISK-RETURN
   RELATIONSHIP
SO MANAGEMENT SCIENCE
VL 38
IS 11
BP 1543
EP 1561
DI 10.1287/mnsc.38.11.1543
PD NOV 1992
PY 1992
AB Tinic and West ( 1984) argue that a tradeoff between risk and return
   exists only in January. This study demonstrates that it is not just the
   January Effect on stock returns which is related to the measured
   risk-turn relationship and how that measure is apparently affected by
   the calendar. Other returns anomalies can also be paired with a
   conclusion about the relationship between risk and return. For example,
   risk appears to be rewarded at the turn of the month but not during the
   rest of the year and late in the week but not early in the week. This
   paper argues that, given the returns anomalies, the corresponding
   calendar effects on the risk-return relationship are consistent with the
   CAPM. Thus, the anomaly to be explained is not the relationship between
   risk and return focused on by Tinic and West (1984) but rather the
   calendar related variations in the returns themselves.
TC 6
Z8 0
ZB 0
ZR 0
ZS 0
ZA 0
Z9 6
SN 0025-1909
UT WOS:A1992JZ76200003
ER

PT J
AU MACLEAN, LC
   ZIEMBA, WT
   BLAZENKO, G
TI GROWTH VERSUS SECURITY IN DYNAMIC INVESTMENT ANALYSIS
SO MANAGEMENT SCIENCE
VL 38
IS 11
BP 1562
EP 1585
DI 10.1287/mnsc.38.11.1562
PD NOV 1992
PY 1992
AB This paper concerns the problem of optimal dynamic choice in discrete
   time for an investor. In each period the investor is faced with one or
   more risky investments. The maximization of the expected logarithm of
   the period by period wealth, referred to as the Kelly criterion, is a
   very desirable investment procedure'  It has many attractive properties,
   such as maximizing the asymptotic rate of growth of the investor's
   fortune. On the other hand, instead of focusing on maximal growth, one
   can develop strategies based on maximum security. For example, one can
   minimize the ruin probability subject to making a positive return or
   compute a confidence level of increasing the investor's initial fortune
   to a given final wealth goal. This paper is concerned with methods to
   combine these two approaches. We derive computational formulas for a
   variety of growth and security measures. Utilizing fractional Kelly
   strategies, we can develop a complete tradeoff of growth versus
   security. The theory is applicable to favorable investment situations
   such as blackjack, horseracing, lotto games, index and commodity futures
   and options trading. The results provide insight into how one should
   properly invest in these situations.
ZB 0
ZA 0
ZS 0
Z8 1
ZR 0
TC 70
Z9 71
SN 0025-1909
UT WOS:A1992JZ76200004
ER

PT J
AU TURNER, AL
   WEIGEL, EJ
TI DAILY STOCK-MARKET VOLATILITY - 1928-1989
SO MANAGEMENT SCIENCE
VL 38
IS 11
BP 1586
EP 1609
DI 10.1287/mnsc.38.11.1586
PD NOV 1992
PY 1992
AB This paper examines the daily return variability of the S&P 500 and the
   Dow Jones indices over the 1928-1989 period. We use the traditional
   close-to-close standard deviation of returns, two alternative estimators
   incorporating the daily high and low of the index, and a robust
   estimator to measure the volatility of stock index returns. The 1980s
   were the third most volatile decade behind the 1920s and 30s. To a large
   extent, this was caused by the anomalous behavior of the fourth quarter
   of 1987. Returns in the 1980s had far more skewness and kurtosis than in
   any other decade studied; these results were not entirely due to 1987,
   as returns in 1988 and 1989 had large measures of both skewness and
   kurtosis. The frequency of extreme-return events increased in the 1980s,
   but was still dramatically less than the 1920s and 30s. When extreme
   negative days occurred in the 1980s the losses tended to be more severe
   than in the previous four decades. Extreme-return days are preceded by
   significant losses and are intertemporally clustered. There is no
   evidence of short-term market reversals after either positive or
   negative jumps in stock index returns.
TC 14
ZB 0
ZA 0
ZS 1
ZR 0
Z8 0
Z9 15
SN 0025-1909
EI 1526-5501
UT WOS:A1992JZ76200005
ER

PT J
AU KUWAHARA, H
   MARSH, TA
TI THE PRICING OF JAPANESE EQUITY WARRANTS
SO MANAGEMENT SCIENCE
VL 38
IS 11
BP 1610
EP 1641
DI 10.1287/mnsc.38.11.1610
PD NOV 1992
PY 1992
AB Discrepancies, between the Black-Scholes value of Japanese equity
   warrants and their observed prices are explained in part by the
   stochastic volatility of changes in prices of the underlying stocks. We
   fit GARCH and EGARCH models to the stochastic volatility and briefly
   compare their performance to the CEV model. A hopscotch algorithm is
   used to value the warrants in the presence of the stochastic stock price
   volatility. The stochastic volatility-hopscotch warrant values still
   differ substantially from corresponding prices; in contrast,
   away-from-the-money short-term Nikkei 225 options valued with the same
   stochastic volatility models are close to observed prices. A regression
   model is used to fit the differences between warrant values and prices
   as a function of proxies for market impediments.
ZS 0
Z8 6
ZB 0
TC 12
ZR 0
Z9 18
SN 0025-1909
UT WOS:A1992JZ76200006
ER

PT J
AU MULVEY, JM
   VLADIMIROU, H
TI STOCHASTIC NETWORK PROGRAMMING FOR FINANCIAL-PLANNING PROBLEMS
SO MANAGEMENT SCIENCE
VL 38
IS 11
BP 1642
EP 1664
DI 10.1287/mnsc.38.11.1642
PD NOV 1992
PY 1992
AB Several financial planning problems are posed as dynamic generalized
   network models with stochastic parameters. Examples include: asset
   allocation for portfolio selection, international cash management, and
   programmed-trading arbitrage. Despite the large size of the resulting
   stochastic programs, the network structure can be exploited within the
   solution strategy giving rise to efficient implementations. Empirical
   results are presented indicating the benefits of the stochastic network
   approach for the asset allocation case.
ZS 1
Z8 14
TC 129
ZR 0
ZB 0
ZA 0
Z9 144
SN 0025-1909
EI 1526-5501
UT WOS:A1992JZ76200007
ER

PT J
AU KANG, P
   ZENIOS, SA
TI COMPLETE PREPAYMENT MODELS FOR MORTGAGE-BACKED SECURITIES
SO MANAGEMENT SCIENCE
VL 38
IS 11
BP 1665
EP 1685
DI 10.1287/mnsc.38.11.1665
PD NOV 1992
PY 1992
AB The estimation of prepayment rates for pools of mortgages is a critical
   component in determining the value of mortgage-backed securities-MBS for
   short-and derivative products. This paper discusses the development of
   prepayment models for pools of fixed-rate mortgages. The models are
   complete: calibrated functional forms are given for all of the factors
   that determine prepayment rates. Hence, the models can be used as
   benchmarks against the simple models of the Public Securities
   Association, the Federal Housing Administration experience, or the
   variety of projected prepayment rates generated by proprietary industry
   models.
   The key factors that determine prepayment rates are: ( 1) refinancing
   incentive, (2) seasonal variations, (3) seasoning of the mortgage pool,
   and (4) burnout effect. Each factor is modeled separately and is
   calibrated using historical data. A multiplicative relationship
   determines the prepayment rate of the mortgage pool. A novel feature of
   our model is the use of basis functions that capture the complex
   interactions between the control variables, i.e., interest rate
   differentials and time, and the response parameter, i.e., prepayment
   rates.
RI Zenios, Stavros A/F-3346-2013
OI Zenios, Stavros A/0000-0001-7576-4898
TC 30
ZA 0
ZB 0
ZR 0
Z8 2
ZS 0
Z9 32
SN 0025-1909
UT WOS:A1992JZ76200008
ER

PT J
AU VENKATESH, A
   VITALARI, NP
TI AN EMERGING DISTRIBUTED WORK ARRANGEMENT - AN INVESTIGATION OF
   COMPUTER-BASED SUPPLEMENTAL WORK AT HOME
SO MANAGEMENT SCIENCE
VL 38
IS 12
BP 1687
EP 1706
DI 10.1287/mnsc.38.12.1687
PD DEC 1992
PY 1992
AB Recent advances in information technology and changes in social and
   economic relationships have led individual workers and organizations to
   explore various types of distributed work arrangements. This paper
   examines a specific type of distributed work arrangement, supplemental
   work at home. This arrangement refers to full-time employees doing
   job-related work at home in the evenings and on weekends. Based on a
   theoretical analysis of supplemental work, data gathered from a 346
   computer-owners and 104 nonowners are empirically examined. The results
   suggest that the amount of time spent on supplemental work is positively
   related to work self-determination variables (flexibility and control),
   portability of work tasks, the availability of a telecommunications link
   between the firm and the home, and household income, and negatively
   related to commuting time and the presence of children at home. The
   paper discusses the implications of supplemental work for organizational
   design and the employer-employee relationship. It concludes that
   compared to other types of work at home, supplemental work is one remote
   work arrangement that is likely to persist, especially for professionals
   and managers.
Z8 0
ZB 0
ZA 0
ZR 0
ZS 1
TC 78
Z9 79
SN 0025-1909
UT WOS:A1992KE26600001
ER

PT J
AU COLLINS, JM
   RUEFLI, TW
TI STRATEGIC RISK - AN ORDINAL APPROACH
SO MANAGEMENT SCIENCE
VL 38
IS 12
BP 1707
EP 1731
DI 10.1287/mnsc.38.12.1707
PD DEC 1992
PY 1992
AB Strategic management researchers have shown increasing awareness of the
   importance of the concept of risk at the strategic level. In recognition
   of this interest, this research adopts a commonly used conceptualization
   of risk and shows how this conceptualization leads to a new measure of
   risk, based upon the chance of loss of relative position within a set of
   firms. This framework is shown to be particularly appropriate for
   strategy research. Information contained in probability distributions
   describing the relative positions of sets of firms over time is shown to
   be partitionable on the basis of gain or loss in position as well as on
   firm identity, leading to the derivation of a new measure of strategic
   risk for an individual firm. This development also provides a
   hierarchical quantification of risk at the levels of the industry, group
   and individual firm. The ordinal risk measure is applied to both
   hypothetical data for illustration and to data on the U.S. airline
   industry.
ZB 0
TC 37
ZS 0
ZR 0
Z8 1
ZA 0
Z9 38
SN 0025-1909
EI 1526-5501
UT WOS:A1992KE26600002
ER

PT J
AU ERICKSON, GM
TI EMPIRICAL-ANALYSIS OF CLOSED-LOOP DUOPOLY ADVERTISING STRATEGIES
SO MANAGEMENT SCIENCE
VL 38
IS 12
BP 1732
EP 1749
DI 10.1287/mnsc.38.12.1732
PD DEC 1992
PY 1992
AB Closed-loop (perfect) equilibria in a Lanchester duopoly differential
   game of advertising competition are used as the basis for empirical
   investigation. Two systems of simultaneous nonlinear equations are
   formed, one from a general Lanchester model and one from a constrained
   model. Two empirical applications are conducted. In one involving
   Coca-Cola and Pepsi-Cola, a formal statistical testing procedure is used
   to detect whether closed-loop equilibrium advertising strategies are
   used by the competitors rather than open-loop strategies. In the second
   application, involving Anheuser-Busch and Miller, the general model is
   estimated. Results indicate that closed-loop equilibria better explain
   dynamic advertising competition than do open-loop equilibria. Also,
   closed-loop equilibrium advertising strategies implied by model
   estimates show that competitive advertising levels may or may not be
   monotonic in market share.
ZR 0
Z8 11
TC 88
ZS 0
ZB 0
ZA 0
Z9 99
SN 0025-1909
UT WOS:A1992KE26600003
ER

PT J
AU HO, CJ
   LAU, HS
TI MINIMIZING TOTAL-COST IN SCHEDULING OUTPATIENT APPOINTMENTS
SO MANAGEMENT SCIENCE
VL 38
IS 12
BP 1750
EP 1764
DI 10.1287/mnsc.38.12.1750
PD DEC 1992
PY 1992
AB This paper considers various rules for scheduling appointments for
   medical clinic outpatients and investigates their ability to minimize a
   weighted sum of medical personnel's and patients' idle-time costs. it is
   shown that the idle times incurred by any given rule are affected by the
   following three ''environmental factors'' (in decreasing order of
   importance): the probability of no-show, the coefficient of variation of
   service times, and the number of patients per clinical session.
   Theoretically, an appropriate scheduling rule can be identified only if
   one knows the values of these parameters and the ratio between the
   medical personnel's and patients' idle-time costs.
   Under environments characterized by 27 different combinations of the
   three environmental factors, the performance of nine scheduling rules
   are evaluated using simulation. Some of the rules evaluated are original
   to this study. The results are presented in the form of ''efficient
   frontiers,'' together with a simple procedure for identifying the best
   scheduling rule for given environmental-parameter values. This
   rule-identification procedure is shown to be easily adaptable for
   circumstances with limited knowledge about the environmental factors; it
   also reveals that the simple Bailey-Welch individual-appointment rules
   are surprisingly robust.
ZB 4
ZA 0
ZS 2
TC 151
Z8 6
ZR 0
Z9 157
SN 0025-1909
UT WOS:A1992KE26600004
ER

PT J
AU DONOHUE, JM
   HOUCK, EC
   MYERS, RH
TI SIMULATION DESIGNS FOR QUADRATIC RESPONSE-SURFACE MODELS IN THE PRESENCE
   OF MODEL MISSPECIFICATION
SO MANAGEMENT SCIENCE
VL 38
IS 12
BP 1765
EP 1791
DI 10.1287/mnsc.38.12.1765
PD DEC 1992
PY 1992
AB This article considers the selection of experimental designs for the
   estimation of second-order response surface metamodels in a simulation
   environment. Rather than construct designs based on the premise that the
   postulated model exactly represents the simulated response, as is the
   case in optimal design theory, we assume that the estimation process may
   be biased by the presence of unfitted third-order terms. We therefore
   seek to specify experimental plans that address the bias due to possible
   model misspecification as well as traditional variance considerations.
   The performance measure used for this ''fit-protect'' scenario is Box
   and Draper's design criterion of average mean squared error of predicted
   response. Four important classes of response surface experimental plans
   are examined: (1) central composite designs, (2) Box-Behnken plans, (3)
   three-level factorial experiments, and (4) small central composite
   designs. Each design class is studied in conjunction with three
   pseudorandom number assignment strategies; (1) the use of a unique set
   of streams at each design point; (2) the assignment of a common stream
   set to all experimental points; and (3) the simultaneous use of common
   and antithetic streams through design blocking. Comparisons of both
   design classes and assignment strategies are presented to assist the
   user in the selection of an appropriate experimental strategy.
ZB 0
ZA 0
Z8 0
ZR 0
ZS 0
TC 14
Z9 14
SN 0025-1909
UT WOS:A1992KE26600005
ER

PT J
AU CALABRESE, JM
TI OPTIMAL WORKLOAD ALLOCATION IN OPEN NETWORKS OF MULTISERVER QUEUES
SO MANAGEMENT SCIENCE
VL 38
IS 12
BP 1792
EP 1802
DI 10.1287/mnsc.38.12.1792
PD DEC 1992
PY 1992
AB In this paper, we examine the general problem of workload allocation in
   an open Jackson network of multiserver queues. We show that use of the
   open network model leads to a separable, convex formulation of the
   problem with relatively simple optimality conditions. Using these
   conditions, we prove in general that server groups with the same number
   of servers should be loaded equally and larger groups should be loaded
   more heavily than smaller groups. It is also shown that server pooling,
   combining servers into larger groups, will always reduce congestion
   and/or increase throughput. We discuss the significance of our results
   for job shop applications and also for the concept of a production
   bottleneck. In systems with an unbalanced configuration of servers,
   traditional, deterministic bottleneck analysis is distinctly nonoptimal;
   our results provide a simple way to locate production bottlenecks in
   shops with significant queueing effects.
TC 35
ZA 0
Z8 0
ZS 1
ZB 0
ZR 0
Z9 36
SN 0025-1909
UT WOS:A1992KE26600006
ER

PT J
AU DEMEULEMEESTER, E
   HERROELEN, W
TI A BRANCH-AND-BOUND PROCEDURE FOR THE MULTIPLE RESOURCE-CONSTRAINED
   PROJECT SCHEDULING PROBLEM
SO MANAGEMENT SCIENCE
VL 38
IS 12
BP 1803
EP 1818
DI 10.1287/mnsc.38.12.1803
PD DEC 1992
PY 1992
AB In this paper a branch-and-bound procedure is described for scheduling
   the activities of a project of the PERT/CPM variety subject to
   precedence and resource constraints where the objective is to minimize
   project duration. The procedure is based on a depth-first solution
   strategy in which nodes in the solution tree represent resource and
   precedence feasible partial schedules. Branches emanating from a parent
   node correspond to exhaustive and minimal combinations of activities,
   the delay of which resolves resource conflicts at each parent node.
   Precedence and resource-based bounds described in the paper are combined
   with new dominance pruning rules to rapidly fathom major portions of the
   solution tree. The procedure is programmed in the C language for use on
   both a mainframe and a personal computer. The procedure has been
   validated using a standard set of test problems with between 7 and 50
   activities requiring up to three resource types each. Computational
   experience on a personal computer indicates that the procedure is 11.6
   times faster than the most rapid solution procedure reported in the
   literature while requiring less computer storage. Moreover, problems
   requiring large amounts of computer time using existing approaches for
   solving this problem type are rapidly solved with our procedure using
   the dominance rules described, resulting in a significant reduction in
   the variability in solution times as well.
ZB 2
ZR 0
ZS 6
ZA 0
Z8 26
TC 332
Z9 362
SN 0025-1909
UT WOS:A1992KE26600007
ER

PT J
AU NIMAN, NB
TI MODELING COORDINATION IN ORGANIZATIONS AND MARKETS
SO MANAGEMENT SCIENCE
VL 38
IS 12
BP 1819
EP 1826
DI 10.1287/mnsc.38.12.1819
PD DEC 1992
PY 1992
AB In an earlier issue of Management Science, Thomas Malone (1987) utilizes
   the concept of vulnerability costs in order to compare the degree of
   flexibility exhibited by markets and hierarchies. The purpose of this
   note is to redefine the concept of vulnerability to include the
   corresponding opportunity costs that are created when a coordinating
   structure restricts the ability to adjust to a change in market
   conditions. The conclusion reached is that those structures experiencing
   the lowest opportunity costs are the least vulnerable, and can therefore
   be classified as the most flexible.
ZB 0
ZA 0
ZR 0
ZS 0
TC 5
Z8 0
Z9 5
SN 0025-1909
UT WOS:A1992KE26600008
ER

PT J
AU NANDAKUMAR, P
   DATAR, SM
   AKELLA, R
TI MODELS FOR MEASURING AND ACCOUNTING FOR COST OF CONFORMANCE QUALITY
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 1
EP 16
DI 10.1287/mnsc.39.1.1
PD JAN 1993
PY 1993
AB We build a model to measure and account for the cost of quality. We
   incorporate the impact of quality on lead time variance and on service
   reliability and demand. Quality costs are a joint and nonlinear function
   of various parameters of the manufacturing process. Our model shows that
   it may not be optimal for quality improvement efforts to target products
   that have the highest defective levels, largest direct costs or consume
   the maximum capital resources. A stochastic dynamic programming model is
   developed to evaluate the optimal trade-offs across prevention and
   appraisal costs and the costs of failure.
ZB 0
Z8 0
ZA 0
TC 33
ZR 0
ZS 0
Z9 33
SN 0025-1909
UT WOS:A1993KM62000001
ER

PT J
AU KAHNEMAN, D
   LOVALLO, D
TI TIMID CHOICES AND BOLD FORECASTS - A COGNITIVE PERSPECTIVE ON
   RISK-TAKING
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 17
EP 31
DI 10.1287/mnsc.39.1.17
PD JAN 1993
PY 1993
AB Decision makers have a strong tendency to consider problems as unique.
   They isolate the current choice from future opportunities and neglect
   the statistics of the past in evaluating current plans. Overly cautious
   attitudes to risk result from a failure to appreciate the effects of
   statistical aggregation in mitigating relative risk. Overly optimistic
   forecasts result from the adoption of an inside view of the problem,
   which anchors predictions on plans and scenarios. The conflicting biases
   are documented in psychological research. Possible implications for
   decision making in organizations are examined.
CT CONF ON FUNDAMENTAL ISSUES IN STRATEGY
CY NOV, 1990
CL SILVERADO, CA
Z8 9
ZA 0
TC 880
ZB 32
ZR 2
ZS 2
Z9 893
SN 0025-1909
UT WOS:A1993KM62000002
ER

PT J
AU UMANATH, NS
   RAY, MR
   CAMPBELL, TL
TI THE IMPACT OF PERCEIVED ENVIRONMENTAL UNCERTAINTY AND PERCEIVED AGENT
   EFFECTIVENESS ON THE COMPOSITION OF COMPENSATION CONTRACTS
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 32
EP 45
DI 10.1287/mnsc.39.1.32
PD JAN 1993
PY 1993
AB Recently, a stream of theoretical development concerning the design of
   optimal compensation plans has emerged in the marketing literature.
   Little empirical work has been done so far to validate the theoretical
   predictions. The findings from the few field studies are equivocal and
   conflicting which we ascribe to failure to account for the major
   assumptions underlying the theoretical predictions. We argue that, in
   order to enhance the rigor of 'theory testing', the field studies must
   be complemented by laboratory experiments where the conditions
   stipulated by the assumptions of the theory can be systematically
   imposed and / or relaxed. This should help in the reconciliation of the
   differences found in the field studies. The experiment reported in this
   paper is a first step towards filling this void in the empirical
   research in this area. Here, we assess the impact of perceived
   environmental uncertainty and perceived agent effectiveness on the
   magnitude (total pay) and composition (salary-incentive mix) of
   employment compensation. The hypotheses stem from propositions
   analytically derived by Basu, Lal, Srinivasan, and Staelin (1985) and
   Lal and Srinivasan (1988). The insurance industry middle management
   compensation problem served as the experimental context.
   The results of the experiment ratified the hypothesis that an increase
   in perceived agent effectiveness leads to award of compensation
   contracts of larger total expected value and a larger proportion of
   performance-contingent pay However, the hypothesis that an increase in
   perceived environmental uncertainty prompts the principal to award
   compensation contracts of smaller total expected value and a smaller
   proportion of performance-contingent pay was rejected. We discuss
   possible alternative explanations for the conflicting results associated
   with the uncertainty variable and identify future research opportunities
   in this area.
Z8 1
ZR 0
ZA 0
ZS 0
ZB 0
TC 13
Z9 14
SN 0025-1909
UT WOS:A1993KM62000003
ER

PT J
AU THOMPSON, P
   HOROWITZ, I
TI EXPERIMENTATION AND OPTIMAL OUTPUT DECISIONS - THE COOPERATIVE VERSUS
   THE ENTREPRENEURIAL FIRM
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 46
EP 53
DI 10.1287/mnsc.39.1.46
PD JAN 1993
PY 1993
AB This paper studies and contrasts the experimental inclinations of
   entrepreneurial and cooperative firms supplying a perishable good under
   uncertain demand, when larger stocks might yield additional information
   about the demand-generating process. While these firms might react
   differently, and in the case of the cooperative not unambiguously, to
   environmental change, neither variant will find the higher
   output-possibly more informative-option especially attractive.
ZB 0
TC 3
ZA 0
ZS 0
Z8 0
ZR 0
Z9 3
SN 0025-1909
UT WOS:A1993KM62000004
ER

PT J
AU ADEROHUNMU, RS
   ARONSON, JE
TI THE SOLUTION OF MULTIPERIOD NETWORK MODELS WITH BUNDLE CONSTRAINTS BY
   AGGREGATION
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 54
EP 71
DI 10.1287/mnsc.39.1.54
PD JAN 1993
PY 1993
AB We present a new network aggregation/disaggregation approach for solving
   a multiperiod, network model with bundle (Generalized Upper Bounding)
   side constraints. The model describes production planning and
   distribution problems. Instead of solving the original multicommodity
   problem, we transform it so that a pair of single-commodity network flow
   problems can be solved. The original network is aggregated and the
   resulting problem is solved. Its solution determines a disaggregated
   problem that yields a feasible, near optimal solution to the original
   problem.
   We describe the determination of theoretical a priori and a posteriori
   bounds. We also introduce a very fight ''computational'' error bound.
   The implementation of the algorithm was tested against MPSX/370, and the
   specialized code for solving networks with side constraints NETSIDE. The
   proposed solution method was found to be much more efficient with
   negligible error.
TC 2
ZS 0
ZR 0
ZB 0
Z8 0
ZA 0
Z9 2
SN 0025-1909
UT WOS:A1993KM62000005
ER

PT J
AU BRANDEAU, ML
   OWENS, DK
   SOX, CH
   WACHTER, RM
TI SCREENING WOMEN OF CHILDBEARING AGE FOR HUMAN-IMMUNODEFICIENCY-VIRUS - A
   MODEL-BASED POLICY ANALYSIS
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 72
EP 92
DI 10.1287/mnsc.39.1.72
PD JAN 1993
PY 1993
AB This paper analyzes the costs and benefits of screening women of
   childbearing age for HIV. The analysis is based on a dynamic
   compartmental model of the HIV epidemic that incorporates disease
   transmission and progression over time, behavioral changes, and effects
   of screening and associated counseling and education. The model allows
   one to consider not only effects on the screened women and their
   newborns, but also effects on the rest of the population. The analysis
   reveals that the primary benefit of screening programs targeted to women
   of childbearing age lies not in the prevention of HIV infection in their
   newborns but in the prevention of infection in their adult contacts. We
   find that screening medium and high risk women is likely to be
   cost-beneficial. Screening women regardless of risk group may also be
   cost-beneficial if screened positive women show relatively modest levels
   of behavioral change, but screening programs that reach primarily low
   risk women are not likely to be cost-beneficial. The results hold over a
   broad range of sensitivity analyses of important variables.
Z8 0
ZB 6
ZS 0
ZR 0
ZA 0
TC 33
Z9 33
SN 0025-1909
UT WOS:A1993KM62000006
ER

PT J
AU WHITE, DJ
TI SOLVING INFINITE-HORIZON DISCOUNTED MARKOV GAMES USING A SUPERHARMONIC
   LEAST-ELEMENT ALGORITHM
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 93
EP 100
DI 10.1287/mnsc.39.1.93
PD JAN 1993
PY 1993
AB In this paper we present an algorithm for solving infinite horizon
   discounted Markov games based upon the fact that the value function is a
   least element of a superharmonic set. The algorithm produces a pair of
   policies whose value function is within a specified error of the
   solution to the fixed point equation. Part of the algorithm involves
   solving a set of fractional programs which are replaced by equivalent
   linear programs.
ZB 0
TC 1
Z8 0
ZS 0
ZR 0
Z9 1
SN 0025-1909
UT WOS:A1993KM62000007
ER

PT J
AU BAKER, KR
   POWELL, SG
   PYKE, DF
TI OPTIMAL ALLOCATION OF WORK IN ASSEMBLY SYSTEMS
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 101
EP 106
DI 10.1287/mnsc.39.1.101
PD JAN 1993
PY 1993
AB We investigate how to allocate work in stochastic assembly systems so as
   to maximize throughput. We use Markov models for systems with
   exponential processing times and simulation-based methods for other
   probability distributions. We find that assembly systems should be
   unbalanced in the direction of assigning less work to assembly and more
   to component stations. We also find that greater parallelism offers
   greater opportunity for improvement.
RI Baker, Kenneth R/B-9784-2015
ZA 0
ZS 0
ZR 0
Z8 0
ZB 0
TC 24
Z9 24
SN 0025-1909
UT WOS:A1993KM62000008
ER

PT J
AU ROLLER, LH
   TOMBAK, MM
TI COMPETITION AND INVESTMENT IN FLEXIBLE TECHNOLOGIES
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 107
EP 114
DI 10.1287/mnsc.39.1.107
PD JAN 1993
PY 1993
AB This paper examines the implications of market structure on investment
   in flexible manufacturing systems (FMS). We analyze a two stage game, in
   which firms choose between a flexible and a less flexible technology in
   the first stage, then choose production quantities in the second stage.
   In equilibrium, a large proportion of FMS firms is associated with more
   concentrated markets. Our model predicts that a larger market and/or a
   more differentiated product results in a higher proportion of FMS firms
   being sustained. These predictions are empirically supported using
   cross-section industry level data from both the US and Japan.
ZS 0
TC 41
ZA 0
Z8 0
ZR 0
ZB 0
Z9 41
SN 0025-1909
UT WOS:A1993KM62000009
ER

PT J
AU DELLAMICO, M
   FISCHETTI, M
   TOTH, P
TI HEURISTIC ALGORITHMS FOR THE MULTIPLE DEPOT VEHICLE SCHEDULING PROBLEM
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 115
EP 125
DI 10.1287/mnsc.39.1.115
PD JAN 1993
PY 1993
AB We consider the NP-hard Multiple Depot Vehicle Scheduling Problem, in
   which a given set of time-tabled trips have to be assigned to vehicles
   stationed at different depots, so as to minimize the number of vehicles
   used and the overall operational cost. The problem arises in the
   management of transportation companies In this paper some structural
   properties of the problem are studied and used to design a new
   polynomial-time heuristic algorithm which always guarantees the use of
   the minimum number of vehicles. Several effective refining procedures
   are also proposed. Extensive computational results on test problems
   involving up to 1,000 trips and 10 depots are reported, showing that the
   new approach always produces very tight approximate solutions in small
   computing times and outperforms other heuristics from the literature.
RI Dell'Amico, Mauro/AAC-9659-2020
OI Dell'Amico, Mauro/0000-0002-3283-6131
TC 54
ZA 0
ZR 0
ZS 0
Z8 0
ZB 0
Z9 54
SN 0025-1909
UT WOS:A1993KM62000010
ER

PT J
AU HILLIER, FS
   SO, KC
   BOLING, RW
TI TOWARD CHARACTERIZING THE OPTIMAL ALLOCATION OF STORAGE SPACE IN
   PRODUCTION LINE SYSTEMS WITH VARIABLE PROCESSING TIMES
SO MANAGEMENT SCIENCE
VL 39
IS 1
BP 126
EP 133
DI 10.1287/mnsc.39.1.126
PD JAN 1993
PY 1993
AB This investigation considers certain issues regarding the optimal design
   of unpaced production lines with variable processing times. Under
   certain assumptions, including an equal allocation of buffer storage
   space between the respective pairs of stations, it is known that the
   optimal allocation of work is characterized by the ''bowl phenomenon''
   whereby the interior stations (especially the center ones) are given
   preferential treatment (less work) over the end stations. The key
   question now being posed is: given an equal allocation of work to the
   respective stations, does the optimal allocation of buffer storage space
   between the respective pairs of stations follow an analogous pattern
   (the ''storage bowl phenomenon'') whereby the interior buffers
   (especially the center ones) are given preferential treatment (more
   space) over the end buffers? Because the decision variables now are
   discrete instead of continuous, the answer found in this study is:
   sometimes, but not in general. Characterizing the optimal allocation of
   storage space is a surprisingly subtle and complex problem. Despite the
   ambiguities, one dominant theme that runs throughout all of the results
   obtained is that, to the extent that preferential treatment in storage
   space allocations should be given, priority should be given to the
   interior buffers (especially the center ones) over the end buffers. The
   other key conclusion is that, when the total amount of storage space
   also is a decision variable, the overall optimal solution commonly
   follows a storage bowl phenomenon whereby the allocation of buffer
   storage space fits an inverted bowl pattern.
ZA 0
Z8 2
ZS 0
TC 79
ZB 1
ZR 0
Z9 81
SN 0025-1909
UT WOS:A1993KM62000011
ER

PT J
AU WADE, M
TI THE EFFECTS OF POPULATION AGING ON THE PHYSICIAN SERVICES MARKET - A
   COMPUTABLE EQUILIBRIUM-ANALYSIS
SO MANAGEMENT SCIENCE
VL 39
IS 2
BP 135
EP 148
DI 10.1287/mnsc.39.2.135
PD FEB 1993
PY 1993
AB This paper formulates a computable equilibrium model (CEM) of the market
   for physician services. The simulation results based upon the CEM are
   consistent with widely held beliefs about the effects of aging on the
   health care sector, for example, that aggregate expenditures will
   increase as the population ages. In addition, however, the simulations
   suggest differential effects on prices and expenditures for various
   types of services and on expenditures by different types of consumers.
   For example, prices and aggregate expenditures for services typically
   used by the elderly are found to increase under ''older'' age
   distributions, whereas prices and aggregate expenditures for other
   services are found to decrease. Elderly women are found to be
   unequivocally worse off under older as opposed to younger age
   structures; they spend more yet consume fewer services.
ZA 0
ZB 0
ZR 0
ZS 0
Z8 0
TC 0
Z9 0
SN 0025-1909
UT WOS:A1993KU58700001
ER

PT J
AU MANSFIELD, E
TI THE DIFFUSION OF FLEXIBLE MANUFACTURING SYSTEMS IN JAPAN, EUROPE AND THE
   UNITED-STATES
SO MANAGEMENT SCIENCE
VL 39
IS 2
BP 149
EP 159
DI 10.1287/mnsc.39.2.149
PD FEB 1993
PY 1993
AB This paper is concerned with the rate of diffusion of flexible
   manufacturing systems, one of the most important industrial applications
   of information technology. Using data from about 175 firms, I analyze
   diffusion rates in Japan, Western Europe and the United States, a major
   purpose being to determine whether, as is often claimed, U.S. firms have
   been relatively slow to introduce this innovation, and if so, why.
CT 1990 ANNUAL MEETING OF THE AMERICAN ECONOMIC ASSOC
CY DEC 28-30, 1990
CL WASHINGTON, DC
SP AMER ECON ASSOC
ZB 0
TC 65
ZR 0
ZS 0
ZA 0
Z8 0
Z9 65
SN 0025-1909
UT WOS:A1993KU58700002
ER

PT J
AU DOBSON, G
   KALISH, S
TI HEURISTICS FOR PRICING AND POSITIONING A PRODUCT-LINE USING CONJOINT AND
   COST DATA
SO MANAGEMENT SCIENCE
VL 39
IS 2
BP 160
EP 175
DI 10.1287/mnsc.39.2.160
PD FEB 1993
PY 1993
AB Designing and pricing a product-line is the very essence of every
   business. In recent years quantitative methods to assist managers in
   this task have been gaining in popularity. Conjoint analysis is already
   widely used to measure preferences for different product profiles, and
   build market simulation models. In the last few years several papers
   have been published that suggest how to optimally choose a product-line
   based on such data.
   We formalize this problem as a mathematical program where the objective
   of the firm is either profit or total welfare. Unlike alternative
   published approaches, we introduce fixed and variable costs for each
   product profile. The number of products to be introduced is endogenously
   determined on the basis of their desirability, fixed and variable costs,
   and in the case of profits, their cannibalization effect on other
   products. While the problem is difficult (NP-complete), we show that the
   maximum welfare problem is equivalent to the uncapacitated plant
   location problem, which can be solved very efficiently using the greedy
   interchange heuristic. Based on past published experience with this
   problem, and on simulations we perform, we show that optimal or near
   optimal solutions are obtained in seconds for large problems. We develop
   a new greedy heuristic for the profit problem, and its application to
   simulated problems shows that it too runs quickly, and with better
   performance than various alternatives and previously published
   heuristics. We also show how the methodology can be applied, taking
   existing products of both the firm and the competition into account.
ZA 0
ZR 0
ZS 0
ZB 0
Z8 3
TC 138
Z9 141
SN 0025-1909
UT WOS:A1993KU58700003
ER

PT J
AU WALLSTEN, TS
   BUDESCU, DV
   ZWICK, R
TI COMPARING THE CALIBRATION AND COHERENCE OF NUMERICAL AND VERBAL
   PROBABILITY JUDGMENTS
SO MANAGEMENT SCIENCE
VL 39
IS 2
BP 176
EP 190
DI 10.1287/mnsc.39.2.176
PD FEB 1993
PY 1993
AB Despite the common reliance on numerical probability estimates in
   decision research and decision analysis, there is considerable interest
   in the use of verbal probability expressions to communicate opinion. A
   method is proposed for obtaining and quantitatively evaluating verbal
   judgments in which each analyst uses a limited vocabulary that he or she
   has individually selected and scaled. An experiment compared this method
   to standard numerical responding under three different payoff
   conditions. Response mode and payoff never interacted. Probability
   scores and their components were virtually identical for the two
   response modes and for all payoff groups. Also, judgments of
   complementary events were essentially additive under all conditions. The
   two response modes differed in that the central response category was
   used more frequently in the numerical than the verbal case, while
   overconfidence was greater verbally than numerically. Response
   distributions and degrees of overconfidence were also affected by
   payoffs. Practical and theoretical implications are discussed.
ZB 19
TC 118
ZS 0
Z8 1
ZA 0
ZR 1
Z9 120
SN 0025-1909
UT WOS:A1993KU58700004
ER

PT J
AU SOGOMONIAN, AG
   TANG, CS
TI A MODELING FRAMEWORK FOR COORDINATING PROMOTION AND PRODUCTION DECISIONS
   WITHIN A FIRM
SO MANAGEMENT SCIENCE
VL 39
IS 2
BP 191
EP 203
DI 10.1287/mnsc.39.2.191
PD FEB 1993
PY 1993
AB This paper presents a modeling framework for evaluating the benefits of
   coordinating promotion and production decisions over a finite planning
   horizon within a firm. These decisions include the timing and level of
   promotion, and the level of production. The modeling framework consists
   of the development of a baseline model and an integrated model. In the
   baseline (integrated) model, the firm would consider those promotion and
   production decisions separately (jointly). For each of the models, we
   formulate the problem that determines the optimal promotion and
   production decisions so that the total net profit is maximized as a
   mixed integer program. By exploiting the structure of the problem, we
   show that each problem can be reformulated as a ''longest path'' problem
   over a network. Hence, each problem can be solved efficiently. This
   solution approach enables us to evaluate the benefits of coordinating
   promotion and production decisions by comparing the total net profit
   generated by the baseline model to that of the integrated model.
Z8 3
ZA 0
ZS 0
ZR 0
TC 61
ZB 1
Z9 64
SN 0025-1909
UT WOS:A1993KU58700005
ER

PT J
AU IYOGUN, P
   ATKINS, D
TI A LOWER BOUND AND AN EFFICIENT HEURISTIC FOR MULTISTAGE MULTIPRODUCT
   DISTRIBUTION-SYSTEMS
SO MANAGEMENT SCIENCE
VL 39
IS 2
BP 204
EP 217
DI 10.1287/mnsc.39.2.204
PD FEB 1993
PY 1993
AB This paper concerns lot-sizing in a multistage and multifacility pure
   distribution network. A facility at the end of the distribution network
   experiences a deterministic and continuous demand. Each facility has an
   echelon holding cost rate for each item it distributes, and a
   facility-dependent set up cost. In this paper an algorithm is presented
   of complexity 0(rd log r) where r is the number of end facilities and d
   is the maximum depth of the distribution system. The algorithm exploits
   a lower bound obtained by decomposing the distribution network into
   facilities-in-series problems. Using a set up cost allocation procedure,
   the maximum of the continuous solution of the decomposed problem is
   obtained. This maximizing solution provides the lower bound which is
   used for solving the distribution problem. This gives a power-of-two
   heuristic with a worst case performance no more than 2% above optimal.
Z8 0
ZS 0
ZB 0
ZR 0
ZA 0
TC 8
Z9 8
SN 0025-1909
UT WOS:A1993KU58700006
ER

PT J
AU KUMAR, A
   OW, PS
   PRIETULA, MJ
TI ORGANIZATIONAL SIMULATION AND INFORMATION-SYSTEMS DESIGN - AN OPERATIONS
   LEVEL EXAMPLE
SO MANAGEMENT SCIENCE
VL 39
IS 2
BP 218
EP 240
DI 10.1287/mnsc.39.2.218
PD FEB 1993
PY 1993
AB The interplay between organizational structure, the decisions made by
   agents within the structure, and the technology supporting those agents
   is an important and complex, but not well understood, phenomenon in
   modern organizational studies. In this paper we describe how simulating
   key aspects of an organization's structure, in this case a hospital, can
   yield insights into the design of information systems and their
   performance, In particular, we report on a project that simulates
   alternative distributed decision-making approaches for patient
   scheduling tasks. The results indicate that there are important and
   complicated interactions between the alternative organizational
   structures simulated, the form of the information systems supporting
   those structures, and the task environment. This suggests that current,
   universal, a priori assumptions about the interplay between technology
   and organizational structure are questionable. Furthermore,
   organization-specific simulation is seen as a potentially useful method
   of explicating the important tradeoffs in alternative design
   possibilities.
ZR 0
Z8 0
ZA 0
TC 19
ZS 0
ZB 0
Z9 19
SN 0025-1909
UT WOS:A1993KU58700007
ER

PT J
AU EICK, SG
   MASSEY, WA
   WHITT, W
TI MT/G/INFINITY QUEUES WITH SINUSOIDAL ARRIVAL RATES
SO MANAGEMENT SCIENCE
VL 39
IS 2
BP 241
EP 252
DI 10.1287/mnsc.39.2.241
PD FEB 1993
PY 1993
AB In this paper we describe the mean number of busy servers as a function
   of time in an M(t)/G/infinity queue (having a nonhomogeneous Poisson
   arrival process) with a sinusoidal arrival rate function. For an
   M(t)/G/infinity model with appropriate initial conditions, it is known
   that the number of busy servers at time t has a Poisson distribution for
   each t, so that the full distribution is characterized by its mean. Our
   formulas show how the peak congestion lags behind the peak arrival rate
   and how much less is the range of congestion than the range of offered
   load. The simple formulas can also be regarded as consequences of linear
   system theory, because the mean function can be regarded as the image of
   a linear operator applied to the arrival rate function. We also
   investigate the quality of various approximations for the mean number of
   busy servers such as the pointwise stationary approximation and several
   polynomial approximations. Finally, we apply the results for sinusoidal
   arrival rate functions to treat general periodic arrival rate functions
   using Fourier series. These results are intended to provide a better
   understanding of the behavior of the M(t)/G/infinty model and related
   M(t)/G/s/r models where some customers are lost or delayed.
RI Whitt, Ward/D-5337-2013
OI Whitt, Ward/0000-0003-4298-9964
Z8 0
ZS 0
ZA 0
TC 98
ZR 0
ZB 1
Z9 98
SN 0025-1909
UT WOS:A1993KU58700008
ER

PT J
AU CRAMTON, PC
TI DYNAMIC BARGAINING WITH TRANSACTION COSTS (VOL 37, PG 1221, 1991)
SO MANAGEMENT SCIENCE
VL 39
IS 2
BP 253
EP 253
DI 10.1287/mnsc.39.2.253
PD FEB 1993
PY 1993
Z8 0
TC 0
ZS 0
ZR 0
ZA 0
ZB 0
Z9 0
SN 0025-1909
UT WOS:A1993KU58700009
ER

PT J
AU ALI, A
   KALWANI, MU
   KOVENOCK, D
TI SELECTING PRODUCT DEVELOPMENT-PROJECTS - PIONEERING VERSUS INCREMENTAL
   INNOVATION STRATEGIES
SO MANAGEMENT SCIENCE
VL 39
IS 3
BP 255
EP 274
DI 10.1287/mnsc.39.3.255
PD MAR 1993
PY 1993
AB In this paper, we investigate project selection choices of duopolists
   facing two alternatives: undertaking a ''pioneering'' type project (Type
   A) aimed to develop a highly innovative product, or an ''incremental
   innovation'' type project (Type B) aimed to develop a less innovative
   product such as the modification of an existing product. A key objective
   of our research is to examine how firm characteristics such as their
   differential efficiencies in completing projects, differences in the
   degree of substitutability between Type A and B products, and first
   mover advantages affect product development strategies. We develop a
   game-theoretic model to obtain insights into the project selection
   problem taking into account competitive reactions to a firm's choice of
   project development strategies and technical uncertainties associated
   with project completion times. We report model findings on recommended
   project selection strategies for efficient and disadvantaged firms.
   Further, we examine how a firm's choice of a Type A project is affected
   by an increase in the variance of the project completion time of a Type
   A project relative to that of a Type B project, while the ratio of their
   mean completion times is held constant.
RI Kovenock, Dan/Q-3767-2019
TC 47
ZA 0
ZS 0
ZB 0
Z8 2
ZR 0
Z9 49
SN 0025-1909
UT WOS:A1993KX02300001
ER

PT J
AU DUNCAN, G
   GORR, W
   SZCZYPULA, J
TI BAYESIAN FORECASTING FOR SEEMINGLY UNRELATED TIME-SERIES - APPLICATION
   TO LOCAL-GOVERNMENT REVENUE FORECASTING
SO MANAGEMENT SCIENCE
VL 39
IS 3
BP 275
EP 293
DI 10.1287/mnsc.39.3.275
PD MAR 1993
PY 1993
AB One important implementation of Bayesian forecasting is the Multi-State
   Kalman Filter (MSKF) method. It is particularly suited for short and
   irregular time series data. In certain applications, time series data
   are available on numerous parallel observational units which, while not
   having cause-and-effect relationships between them, are subject to the
   same external forces (e.g., business cycles). Treating them separately
   may lose useful information for forecasting. For such situations,
   involving seemingly unrelated time series, this article develops a
   Bayesian forecasting method called C-MSKF that combines the MSKF method
   with the Conditionally Independent Hierarchical method, A case study on
   forecasting income tax revenue for each of forty school districts in
   Allegheny County, Pennsylvania, based on fifteen years of data, is used
   to illustrate the application of C-MSKF in comparison with univariate
   MSKF. Results show that C-MSKF is more accurate than MSKF. The relative
   accuracy of C-MSKF increases with decreasing length of historical time
   series data, increasing forecasting horizon, and sensitivity of school
   districts to the economic cycle.
TC 11
ZR 0
Z8 0
ZA 0
ZB 0
ZS 2
Z9 13
SN 0025-1909
EI 1526-5501
UT WOS:A1993KX02300002
ER

PT J
AU AGNETIS, A
   LUCERTINI, M
   NICOLO, F
TI FLOW MANAGEMENT IN FLEXIBLE MANUFACTURING CELLS WITH PIPELINE OPERATIONS
SO MANAGEMENT SCIENCE
VL 39
IS 3
BP 294
EP 306
DI 10.1287/mnsc.39.3.294
PD MAR 1993
PY 1993
AB The problem of flow management for a class of flexible manufacturing
   cells is considered. The cell is designed for cyclic production of one
   product. This product is characterized by a sequence of operations of
   given length and each requiring a set of resources; the problem is
   therefore to allocate such resources and scheduling the operations in
   order to maximize the throughput. A general model is proposed and
   several special cases are discussed, corresponding to either polynomial
   or NP-complete problems. The cases analyzed differ from each other in
   the number of operating machines and in the number of product units
   present at the same time in the cell. The solution to the polynomial
   problems is given in terms of shortest path on particular networks.
OI Agnetis, Alessandro/0000-0001-5803-0438
TC 12
Z8 0
ZA 0
ZR 0
ZB 0
ZS 0
Z9 12
SN 0025-1909
UT WOS:A1993KX02300003
ER

PT J
AU MOSKOWITZ, H
   PLANTE, R
   TSAI, HT
TI A MULTISTAGE SCREENING MODEL FOR EVALUATION AND CONTROL OF
   MISCLASSIFICATION ERROR IN THE DETECTION OF HYPERTENSION
SO MANAGEMENT SCIENCE
VL 39
IS 3
BP 307
EP 321
DI 10.1287/mnsc.39.3.307
PD MAR 1993
PY 1993
AB Hypertension is one of the most important risk factors with respect to
   coronary heart disease and stroke. The benefits of early detection of
   hypertension and the subsequent design of follow-up treatment programs
   are well documented. Consequently, screening programs have been designed
   to identify subjects as normotensive (normal) or hypertensive
   (abnormal). In order for these programs to be effective, full
   participation of the subject population is required. However, such
   classification programs can incur massive risks of incorrectly
   classifying subjects as normotensive who are truly hypertensive and
   incorrectly classifying subjects as hypertensive who are truly
   normotensive. To date, the only means to reduce these risks of
   misclassification is to require subjects to make numerous visits for
   blood pressure measurement before they can be classified. Such
   requirements reduce the level of participation in screening programs and
   also delay the identification of subjects who are truly hypertensive,
   thereby depriving them of the benefits of early detection and immediate
   follow-up treatment.
   We propose a multiple-stage screening model that controls for maximum as
   well as average misclassification error which is used to design and / or
   evaluate screening programs for hypertension. A multiple-stage screening
   model not only permits the early detection of subjects who are truly
   hypertensive, but also requires a much smaller level of participation of
   subjects, while retaining control of misclassification risks that are
   comparable to those of screening programs based on numerous visits. We
   then design multiple-stage screening programs for several different
   subject populations.
ZB 0
TC 15
ZS 0
Z8 0
ZA 0
ZR 0
Z9 15
SN 0025-1909
EI 1526-5501
UT WOS:A1993KX02300004
ER

PT J
AU LIVNY, M
   MELAMED, B
   TSIOLIS, AK
TI THE IMPACT OF AUTOCORRELATION ON QUEUING-SYSTEMS
SO MANAGEMENT SCIENCE
VL 39
IS 3
BP 322
EP 339
DI 10.1287/mnsc.39.3.322
PD MAR 1993
PY 1993
AB The performance of single-server queues with independent interarrival
   intervals and service demands is well understood, and often analytically
   tractable. In particular, the M / M / 1 queue has been thoroughly
   studied, due to its analytical tractability. Little is known, though,
   when autocorrelation is introduced into interarrival times or service
   demands, resulting in loss of analytical tractability. Even the simple
   case of an M / M / 1 queue with autocorrelations does not appear to be
   well understood. Such autocorrelations do, in fact, abound in real-life
   systems, and worse, simplifying independence assumptions can lead to
   very poor estimates of performance measures. This paper reports the
   results of a simulation study of the impact of autocorrelation on
   performance in an FIFO queue. The study used two computer methods for
   generating autocorrelated random sequences, with different
   autocorrelation characteristics. The simulation results show that the
   injection of autocorrelation into interarrival times, and to a lesser
   extent into service demands, can have a dramatic impact on performance
   measures. From a performance viewpoint, these effects are generally
   deleterious, and their magnitude depends on the method used to generate
   the autocorrelated process. The paper discusses these empirical results
   and makes some recommendations to practitioners of performance analysis
   of queuing systems.
OI Melamed, Benjamin/0000-0002-2568-2293
ZR 1
Z8 0
ZB 0
TC 94
ZA 0
ZS 0
Z9 95
SN 0025-1909
UT WOS:A1993KX02300005
ER

PT J
AU SMITH, JE
TI MOMENT METHODS FOR DECISION-ANALYSIS
SO MANAGEMENT SCIENCE
VL 39
IS 3
BP 340
EP 358
DI 10.1287/mnsc.39.3.340
PD MAR 1993
PY 1993
AB Decision models involving continuous probability distributions almost
   always require some form of approximation. The usual approach to
   evaluating these kinds of models is to construct a discrete
   approximation for each continuous distribution and compute value
   lotteries and certain equivalents using these discrete approximations.
   Although decision analysts are quite comfortable with this approach,
   there has been relatively little consideration of how these discrete
   approximations affect the results of the analysis. In the first part of
   this paper, we review three common methods of constructing discrete
   approximations and compare their performance in a simple example.
   The results of the example suggest a different approach that offers
   potential improvements in accuracy and efficiency over the usual
   approach. The basic idea is that given discrete approximations that
   accurately represent the moments of assessed ''input'' distributions, we
   may easily and accurately compute the moments of the ''output''
   distribution or value lotteries. These moments then summarize what we
   know about the value lottery and certain equivalent, and provide the
   basis for computing approximate value lotteries and certain equivalents.
   In this paper, we discuss the methods supporting this moment approach
   and evaluate their performance in the context of the example.
ZS 1
Z8 1
TC 71
ZR 0
ZA 0
ZB 5
Z9 73
SN 0025-1909
UT WOS:A1993KX02300006
ER

PT J
AU FU, MC
   HU, JQ
TI 2ND DERIVATIVE SAMPLE PATH ESTIMATORS FOR THE GI/G/M QUEUE
SO MANAGEMENT SCIENCE
VL 39
IS 3
BP 359
EP 383
DI 10.1287/mnsc.39.3.359
PD MAR 1993
PY 1993
AB Applying the technique of smoothed perturbation analysis (SPA) to the GI
   / G / m queue with first-come, first-served (FCFS) queue discipline, we
   derive sample path estimators for the second derivative of mean
   steady-state system time with respect to a parameter of the service time
   distribution. Such estimators provide a possible means for speeding up
   the convergence of gradient-based stochastic optimization algorithms.
   The derivation of the estimators sheds some new light on the
   complications encountered in applying the technique of SPA. The most
   general cases require the simulation of additional sample subpaths;
   however, an approximation procedure is also introduced which eliminates
   the need for additional simulation. Simulation results indicate that the
   approximation procedure is reasonably accurate. When the service times
   are exponential or deterministic, the estimator simplifies and the
   approximation procedure becomes exact. For the M / M / 2 queue, the
   estimator is proved to be strongly consistent.
RI Fu, Michael C/N-4098-2013
OI Fu, Michael C/0000-0003-2105-4932
ZS 0
TC 8
ZR 0
ZB 0
Z8 0
ZA 0
Z9 8
SN 0025-1909
UT WOS:A1993KX02300007
ER

PT J
AU ROUSSEAU, JJ
   SEMPLE, JH
TI CATEGORICAL OUTPUTS IN DATA ENVELOPMENT ANALYSIS
SO MANAGEMENT SCIENCE
VL 39
IS 3
BP 384
EP 386
DI 10.1287/mnsc.39.3.384
PD MAR 1993
PY 1993
AB A new linear programming formulation for handling categorical outputs in
   DEA is presented which eliminates the difficulties of interpretation and
   computation that accompanied earlier mixed integer models.
RI Semple, John/F-8137-2012
ZA 0
ZB 0
ZR 0
TC 25
ZS 1
Z8 0
Z9 26
SN 0025-1909
UT WOS:A1993KX02300008
ER

PT J
AU CHEN, SX
TI COMMENTS ON THE 2-PRODUCT, SINGLE-MACHINE, STATIC DEMAND, INFINITE
   HORIZON LOT SCHEDULING PROBLEM
SO MANAGEMENT SCIENCE
VL 39
IS 3
BP 387
EP 388
PD MAR 1993
PY 1993
AB One of the necessary and sufficient conditions derived by F. F. Boctor
   (1982) for feasibility of a repetitive two-product schedule is that the
   cycle times (T1 and T2) must be integer multiples of some time interval
   T (Propositions 2, 3 and 4). This result also holds for N-product
   schedules. However, the proof for Propositions 3 and 4 in [1] is not
   exactly valid and therefore a correction has to be made.
ZR 0
ZS 0
Z8 0
ZB 0
TC 0
Z9 0
SN 0025-1909
UT WOS:A1993KX02300009
ER

PT J
AU HARVEY, CM
TI MULTIATTRIBUTE RISK LINEARITY
SO MANAGEMENT SCIENCE
VL 39
IS 3
BP 389
EP 394
DI 10.1287/mnsc.39.3.389
PD MAR 1993
PY 1993
AB In applying multiattribute utility theory, one typically assumes the
   condition of mutual utility independence and uses a multiattribute
   utility function that is additive or multiplicative. This paper proposes
   a model in which this condition is not satisfied, that is, the risk
   attitude for one attribute depends on the amounts of the other
   attributes. We introduce a condition on this dependence called
   ''multiattribute risk linearity'' that implies a logarithmic form for
   the multiattribute utility function, and we show that a logarithmic
   utility function can be determined by assessment procedures that require
   the same number of indifference assessments as those for a
   multiplicative utility function.
ZR 0
ZB 0
ZS 0
Z8 0
TC 3
Z9 3
SN 0025-1909
UT WOS:A1993KX02300010
ER

PT J
AU GERWIN, D
TI MANUFACTURING FLEXIBILITY - A STRATEGIC PERSPECTIVE
SO MANAGEMENT SCIENCE
VL 39
IS 4
BP 395
EP 410
DI 10.1287/mnsc.39.4.395
PD APR 1993
PY 1993
AB To help meet competitive realities operations managers need to know more
   about the strategic aspects of manufacturing flexibility. This paper
   takes steps toward meeting that need by critically reviewing the
   literature and establishing a research agenda for the area. A conceptual
   model, which places flexibility within a broad context, helps to
   identify certain assumptions of theoretical studies which need to be
   challenged. The model also provides a basis for identifying specific
   flexibility dimensions. The manner in which these dimensions may limit
   the effectiveness of a manufacturing process, and the problems in
   operationalizing them are discussed. Focusing next on the neglected area
   of applied work, concepts are presented for analyzing whether desired
   amounts of flexibility are being achieved and whether the potential for
   flexibility built into a manufacturing process is being tapped. Once
   more, a procedure is outlined for altering a plant's types and amounts
   of flexibility over time. The research agenda, which grows out of the
   appraisal of theoretical and applied work, indicates the value in
   studying generic flexibility strategies, the flexibility dimensions,
   methods of delivery, ways of evaluating and changing a process's
   flexibility, and above all measurement problems. The conclusions
   indicate principles for strategic research, some of which have relevance
   for the development of mathematical models.
ZS 8
ZA 2
ZB 2
TC 603
Z8 10
ZR 0
Z9 622
SN 0025-1909
UT WOS:A1993LB25100001
ER

PT J
AU SENGUPTA, K
   ABDELHAMID, TK
TI ALTERNATIVE CONCEPTIONS OF FEEDBACK IN DYNAMIC DECISION ENVIRONMENTS -
   AN EXPERIMENTAL INVESTIGATION
SO MANAGEMENT SCIENCE
VL 39
IS 4
BP 411
EP 428
DI 10.1287/mnsc.39.4.411
PD APR 1993
PY 1993
AB Studies conducted in recent years have shown that outcome feedback in
   dynamic decision-making tasks does not lead to improved performance.
   This has led researchers to examine alternatives to outcome feedback for
   improving decision makers' performance in such tasks. This study
   examines the feasibility of improving performance in dynamic tasks by
   providing cognitive feedback or feedforward. We report a laboratory
   experiment in which subjects managed a set of simulated software
   development projects. Results indicate that subjects provided with
   cognitive feedback performed best, followed by those provided with
   feedforward. Subjects provided with outcome feedback performed poorly.
   We discuss the implications of the results for decision support in
   dynamic tasks.
ZR 0
ZA 0
Z8 0
ZS 1
TC 98
ZB 0
Z9 99
SN 0025-1909
UT WOS:A1993LB25100002
ER

PT J
AU ULRICH, K
   SARTORIUS, D
   PEARSON, S
   JAKIELA, M
TI INCLUDING THE VALUE OF TIME IN DESIGN-FOR-MANUFACTURING DECISION-MAKING
SO MANAGEMENT SCIENCE
VL 39
IS 4
BP 429
EP 447
DI 10.1287/mnsc.39.4.429
PD APR 1993
PY 1993
AB Design for manufacturing (DFM) has been promoted as a way to enhance
   product development and production system performance. Current DFM
   practices encourage the minimization of the number of parts in a design
   through the physical integration of several geometric features in the
   same part. While this part integration often reduces the manufacturing
   cost of the product, it also can extend product development lead time,
   because complex parts typically require tooling with large lead times.
   This paper presents an economic model that makes explicit the trade-off
   between lower unit costs and longer product development time. This model
   is applied to a particular example in a field study of the application
   of DFM to Polaroid cameras.
ZR 0
Z8 0
ZS 0
TC 60
ZA 0
ZB 0
Z9 60
SN 0025-1909
UT WOS:A1993LB25100003
ER

PT J
AU BOGETOFT, P
TI PARALLELISM IN INFORMATION PRODUCTION - MORAL HAZARD AND RELATIVE
   PERFORMANCE EVALUATIONS
SO MANAGEMENT SCIENCE
VL 39
IS 4
BP 448
EP 457
DI 10.1287/mnsc.39.4.448
PD APR 1993
PY 1993
AB We analyse how to design incentive schemes for agents producing
   information. The agents may, for example, be divisional managers, market
   researchers, OR consultants, financial analysts, corporate auditors,
   research scientists or political pollsters. We show that an agent should
   be compensated more for making a correct rather than an incorrect
   prediction, and for agreeing rather than disagreeing with colleagues.
   Depending on the environment, correctness should be compensated more or
   less than agreement. Also, compensation should increase with the
   difficulties of making correct or conforming predictions. One
   consequence of the result is that it may sometimes reduce a principal's
   total incentive costs to engage with more information producers
   performing parallel investigations, because the possibility to make
   relative performance evaluations of the agents may substantially reduce
   the costs of motivating the agents in performing their duties as
   desired.
TC 7
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
Z9 7
SN 0025-1909
UT WOS:A1993LB25100004
ER

PT J
AU CAULKINS, JP
TI ZERO-TOLERANCE POLICIES - DO THEY INHIBIT OR STIMULATE ILLICIT DRUG
   CONSUMPTION
SO MANAGEMENT SCIENCE
VL 39
IS 4
BP 458
EP 476
DI 10.1287/mnsc.39.4.458
PD APR 1993
PY 1993
AB Some have suggested fighting the drug problem with so-called
   ''zero-tolerance'' policies that impose stiff sanctions for possession
   of even trace amounts of illicit drugs. Such policies can swamp the
   criminal justice system and violate the principle that the punishment
   should fit the crime, but these objections have often been suppressed by
   an overriding desire to minimize consumption.
   This paper argues to the contrary that under plausible conditions
   zero-tolerance policies may actually encourage controlled users to
   consume more, not less, than they would if the punishment increased in
   proportion to the quantity possessed at the time of arrest. This result
   holds even if for every quantity the punishment under the proportional
   policy is less than or equal to that under the zero-tolerance policy.
   The argument relies on a mathematical model that describes how a typical
   controlled user's purchasing habits are affected by the punishment
   anticipated as a function of the quantity possessed. A variety of
   possible punishment policies are evaluated. The consumption minimizing
   policy for a given individual user is obtained, as well as the
   consumption minimizing policy that belongs to a restricted class of
   policies that are more likely to be politically feasible.
ZS 0
ZB 1
TC 10
Z8 0
ZA 0
ZR 0
Z9 10
SN 0025-1909
UT WOS:A1993LB25100005
ER

PT J
AU CATTRYSSE, D
   SALOMON, M
   KUIK, R
   VANWASSENHOVE, LN
TI A DUAL ASCENT AND COLUMN GENERATION HEURISTIC FOR THE DISCRETE LOTSIZING
   AND SCHEDULING PROBLEM WITH SETUP TIMES
SO MANAGEMENT SCIENCE
VL 39
IS 4
BP 477
EP 486
DI 10.1287/mnsc.39.4.477
PD APR 1993
PY 1993
AB In this paper the Discrete Lotsizing and Scheduling Problem (DLSP) with
   setup times is considered. DLSP is the problem of determining the
   sequence and size of production batches for multiple items on a single
   machine. The objective is to find a minimal cost production schedule
   such that dynamic demand is fulfilled without backlogging.
   DLSP is formulated as a Set Partitioning Problem (SPP). We present a
   dual ascent and column generation heuristic to solve SPP. The quality of
   the solutions can be measured, since the heuristic generates lower and
   upper bounds. Computational results on a personal computer show that the
   heuristic is rather effective, both in terms of quality of the solutions
   as well as in terms of required memory and computation time.
OI Cattrysse, Dirk/0000-0002-3421-888X
ZA 0
TC 52
ZR 0
ZB 0
Z8 1
ZS 0
Z9 53
SN 0025-1909
UT WOS:A1993LB25100006
ER

PT J
AU MURALIDHAR, K
TI THE BOOTSTRAP APPROACH FOR TESTING SKEWNESS PERSISTENCE
SO MANAGEMENT SCIENCE
VL 39
IS 4
BP 487
EP 491
DI 10.1287/mnsc.39.4.487
PD APR 1993
PY 1993
AB This study presents a new methodology for testing changes in skewness
   between time periods (or samples) using the bootstrap method. A Monte
   Carlo simulation experiment was conducted to compare the effectiveness
   of the bootstrap method with the method suggested by Lau, Wingender and
   Lau (1989) to test skewness persistence. The results show the bootstrap
   method to be more powerful than the other method. The bootstrap method
   was also used to determine the persistence of skewness in stock returns.
   The results show that, in a large percentage of stocks, skewness
   persists over time.
RI Muralidhar, Krishnamurty/A-7618-2009
TC 9
ZR 0
Z8 0
ZS 0
ZB 0
ZA 0
Z9 9
SN 0025-1909
UT WOS:A1993LB25100007
ER

PT J
AU LAGUNA, M
   GLOVER, F
TI BANDWIDTH PACKING - A TABU SEARCH APPROACH
SO MANAGEMENT SCIENCE
VL 39
IS 4
BP 492
EP 500
DI 10.1287/mnsc.39.4.492
PD APR 1993
PY 1993
AB The bandwidth packing (BWP) problem is a combinatorially difficult
   problem arising in the area of telecommunications. The problem consists
   of assigning calls to paths in a capacitated graph, such that capacities
   are not violated and the total profit is maximized. In this paper we
   discuss the development of a tabu search (TS) method for the BWP
   problem. The method makes use of an efficient implementation of the
   k-shortest path algorithm, that allows the identification of a
   controlled set of feasible paths for each call. A tabu search is then
   performed to find the best path assignment for each call. The TS method
   developed here incorporates a number of features that have proved useful
   for obtaining optimal and near optimal solutions to difficult
   combinatorial problems. We establish the effectiveness of our approach
   by comparing its performance in speed and solution quality to other
   specialized heuristics and to a standard optimization package applied to
   a 0-1 integer programming formulation of the problem.
Z8 5
ZA 0
TC 74
ZR 0
ZS 0
ZB 0
Z9 79
SN 0025-1909
UT WOS:A1993LB25100008
ER

PT J
AU CLEMEN, RT
   WINKLER, RL
TI AGGREGATING POINT ESTIMATES - A FLEXIBLE MODELING APPROACH
SO MANAGEMENT SCIENCE
VL 39
IS 4
BP 501
EP 515
DI 10.1287/mnsc.39.4.501
PD APR 1993
PY 1993
AB In many decision situations information is available from a number of
   different sources. Aggregating the diverse bits of information is an
   important aspect of the decision-making process but entails special
   statistical modeling problems in characterizing the information. Prior
   research in this area has relied primarily on the use of historical data
   as a basis for modeling the information sources. We develop a Bayesian
   framework that a decision maker can use to encode subjective knowledge
   about the information sources in order to aggregate point estimates of
   an unknown quantity of interest. This framework features a highly
   flexible environment for modeling the probabilistic nature and
   interrelationships of the information sources and requires
   straightforward and intuitive subjective judgments using proven
   decision-analysis assessment techniques. Analysis of the constructed
   model produces a posterior distribution for the quantity of interest. An
   example based on health risks due to ozone exposure demonstrates the
   technique.
ZS 1
ZB 0
ZR 0
Z8 1
ZA 0
TC 40
Z9 41
SN 0025-1909
UT WOS:A1993LB25100009
ER

PT J
AU ASSUNCAO, JL
   MEYER, RJ
TI THE RATIONAL EFFECT OF PRICE PROMOTIONS ON SALES AND CONSUMPTION
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 517
EP 535
DI 10.1287/mnsc.39.5.517
PD MAY 1993
PY 1993
AB We explore the rational effect of price variation on sales and
   consumption in markets where consumers are uncertain about the future
   price of goods. We first derive an optimal ordering policy which
   expresses the amount a consumer should purchase and consume in a given
   period as a function of the observed price of the good, the distribution
   of future prices, and the nature of his or her inventory. This policy
   extends previous normative models of inventory control, such as those by
   Golabi (1985) and Kalymon (1970) to the case where the amount to consume
   in a given period is an explicit decision variable and prices follow a
   first-order stochastic process. We then use this model to explore how
   changes in the long-run frequency and temporal correlations of price
   promotions should normatively affect the contemporaneous relationship
   between purchase, consumption and price. Among the predictions which
   follow from the model are that consumption should rationally increase
   with the size of existing inventories, the short-term sensitivity of
   sales to prices should be greater than that of consumption to price, and
   this discrepancy increases with decreases in the temporal correlation of
   price deals and the long-term relative frequency of price deals.
Z8 1
ZA 0
ZR 0
ZS 0
TC 72
ZB 0
Z9 73
SN 0025-1909
UT WOS:A1993LE85000001
ER

PT J
AU MOINZADEH, K
   INGENE, C
TI AN INVENTORY MODEL OF IMMEDIATE AND DELAYED DELIVERY
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 536
EP 548
DI 10.1287/mnsc.39.5.536
PD MAY 1993
PY 1993
AB This paper considers the long run, profit maximizing strategy of a
   distributor that holds a good (good 1) in inventory for immediate
   delivery and that offers a second good (good 2) for delayed delivery.
   When the two goods are substitutes, an out-of-stock situation for good 1
   will cause some consumers (''walkers'') to seek the good elsewhere,
   other consumers (''waiters'') to accept a raincheck for later delivery
   of good 1, and others still (''switchers'') to place an order for good
   2. It is shown that a profit maximizing strategy may entail setting a
   price for the delayed delivery item so as to encourage switching
   behavior. The rationale is that the distributor can hold a smaller
   inventory, thereby incurring lower holding costs, because out-of-stock
   situations are less costly than they would be without some consumers
   being willing to switch.
ZR 0
ZB 0
TC 11
Z8 4
ZS 0
ZA 0
Z9 15
SN 0025-1909
UT WOS:A1993LE85000002
ER

PT J
AU GRAY, AE
   SEIDMANN, A
   STECKE, KE
TI A SYNTHESIS OF DECISION-MODELS FOR TOOL MANAGEMENT IN AUTOMATED
   MANUFACTURING
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 549
EP 567
DI 10.1287/mnsc.39.5.549
PD MAY 1993
PY 1993
AB The evidence is clear that a lack of attention to structured tool
   management has resulted in the poor performance of many manufacturing
   systems. Plant tooling systems affect product design options, machine
   loading, job batching, capacity scheduling, and real-time part routing
   decisions. With increasing automation in manufacturing systems, there is
   a growing need to integrate tool management more thoroughly into system
   design, planning and control.
   This paper critically evaluates various tool management approaches,
   identifying the operational tradeoffs and analyzing the models developed
   to address management decisions involving tooling. These decisions range
   from selecting the optimal machining parameters and the most economic
   processing rate for a particular operation, to the loading of tools and
   jobs on machines and the determination of the optimal tool-mix
   inventories needed for a particular production schedule. We present an
   integrated conceptual framework for resource planning to examine how
   tool management issues, depending upon their scope, can be classified
   into tool-level, machine-level, and system-level concerns. This
   framework specifies how decisions made at one level constrain those at
   lower levels, and how information from lower levels feeds back to higher
   level decisions. The framework structures our critical evaluation of the
   modeling approaches found in the academic literature and points to
   promising directions for future research.
Z8 0
ZS 3
ZB 0
ZR 0
ZA 0
TC 129
Z9 131
SN 0025-1909
EI 1526-5501
UT WOS:A1993LE85000003
ER

PT J
AU SIMAAN, Y
TI PORTFOLIO SELECTION AND ASSET PRICING - 3-PARAMETER FRAMEWORK
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 568
EP 577
DI 10.1287/mnsc.39.5.568
PD MAY 1993
PY 1993
AB Idiosyncratic security risks are modelled as following a joint spherical
   distribution characterized by a mean vector and a generalized covariance
   matrix. Skewness is generated by a single factor for the whole economy,
   but upon which different securities have different loadings. This
   results in three-fund separation-two funds to span the spherical risk
   and one more fund to span the additional skewness risk. A
   three-parameter normative portfolio analysis that allows short sales
   restrictions is developed. In addition, a three-parameter capital asset
   pricing model is provided.
ZB 0
ZA 0
TC 35
ZR 0
Z8 2
ZS 0
Z9 37
SN 0025-1909
UT WOS:A1993LE85000004
ER

PT J
AU SIMAAN, Y
TI WHAT IS THE OPPORTUNITY COST OF MEAN-VARIANCE INVESTMENT STRATEGIES
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 578
EP 587
DI 10.1287/mnsc.39.5.578
PD MAY 1993
PY 1993
AB An analytical framework is set up to evaluate the foregone opportunity
   cost of mean-variance investment strategies. A parametric structure of
   the joint distribution of security returns, for which mean-variance
   investment strategy is suboptimal, is specified. For all constant
   absolute risk-aversion investors, the optimal strategy, its
   corresponding mean-variance alternative, and the foregone opportunity
   cost of mean-variance investment strategy are analytically derived and
   operationalized empirically. When the investor's opportunity set
   includes the riskless asset, the premium to replace the mean-variance
   investment strategy by its optimal one does not exceed 0.05 cents on an
   invested dollar regardless of the investor's risk aversion. When the
   riskless asset is denied, the opportunity costs of mean-variance
   investment strategies increase with the degree of risk aversion.
ZR 0
ZS 0
Z8 2
ZA 0
ZB 0
TC 34
Z9 36
SN 0025-1909
UT WOS:A1993LE85000005
ER

PT J
AU WEINGARTNER, HM
   GAVISH, B
TI HOW TO SETTLE AN ESTATE
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 588
EP 601
DI 10.1287/mnsc.39.5.588
PD MAY 1993
PY 1993
AB This paper considers the equitable division of a set of assets, all or
   some of which are indivisible, among two beneficiaries, simultaneously
   using several methods of valuing the assets. The problem arises when a
   fiduciary is required to distribute the assets-of a trust or estate, or
   to divide the property in a divorce or in dissolution of a
   partnership-in which the assets have separate market values and tax
   bases. In other variations of this problem, the beneficiaries are
   presumed also to possess an infinitely divisible asset, such as cash, or
   some of the assets may be liquidated. Models for combining consideration
   of subjective values for the assets in addition to the objective market
   values are considered. Computational methods for these problems are
   discussed and illustrated.
ZB 0
ZR 0
TC 1
ZS 0
Z8 0
Z9 1
SN 0025-1909
UT WOS:A1993LE85000006
ER

PT J
AU SARIN, RK
   WEBER, M
TI EFFECTS OF AMBIGUITY IN MARKET EXPERIMENTS
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 602
EP 615
DI 10.1287/mnsc.39.5.602
PD MAY 1993
PY 1993
AB Prior studies have shown that individuals are averse to ambiguity in
   probability. Many decisions are, however, made in market settings where
   an individual's decision is influenced by decisions of others
   participating in the market. In this paper, we extend the previous
   research to evaluate the effect of ambiguity on individual decisions and
   the resulting market price in market settings. We therefore examine an
   important issue: whether ambiguity effects persist in the face of market
   incentives and feedback.
   Two different market organizations, the sealed bid auction and the
   double oral auction, were employed. The subjects in the experiments were
   graduate business students and bank executives. Our results show that
   the individual bids and market prices for lotteries with ambiguous
   probabilities are consistently lower than the corresponding bids and
   market prices for equivalent lotteries with well-defined probabilities.
   The aversion to ambiguity therefore does not vanish in market settings.
   Our results provide insights into what a manager can expect in bidding
   situations where the object of the sale (oil leases, mineral rights)
   involves ambiguity in probability due to, for example, lack of
   information or prior experience. The results may also be useful in
   understanding some phenomena in insurance and equity markets.
ZS 0
TC 86
ZB 4
ZA 0
Z8 0
ZR 0
Z9 86
SN 0025-1909
UT WOS:A1993LE85000007
ER

PT J
AU LEE, CY
   CHENG, TCE
   LIN, BMT
TI MINIMIZING THE MAKESPAN IN THE 3-MACHINE ASSEMBLY-TYPE FLOWSHOP
   SCHEDULING PROBLEM
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 616
EP 625
DI 10.1287/mnsc.39.5.616
PD MAY 1993
PY 1993
AB This paper considers minimizing the makespan in the 3-machine
   assembly-type flowshop scheduling problem. After problem formulation, we
   present a proof to show that the general version of this problem is
   strongly NP-complete. We then discuss a few polynomially solvable cases
   of the problem and present the solution algorithms. Next, a branch and
   bound solution scheme is suggested. Finally, three heuristics to find
   approximate solutions to the general problem are proposed and their
   error bounds are analyzed.
RI Lin, Bertrand M.T./G-3497-2013; Cheng, Edwin/D-5688-2015
OI Lin, Bertrand M.T./0000-0003-0456-296X; Cheng, Edwin/0000-0001-5127-6419
ZB 0
Z8 9
TC 182
ZR 0
ZS 0
ZA 0
Z9 190
SN 0025-1909
UT WOS:A1993LE85000008
ER

PT J
AU SZWARC, W
   LIU, JJ
TI WEIGHTED TARDINESS SINGLE-MACHINE SCHEDULING WITH PROPORTIONAL WEIGHTS
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 626
EP 632
DI 10.1287/mnsc.39.5.626
PD MAY 1993
PY 1993
AB This paper considers Arkin and Roundy's single machine weighted
   tardiness scheduling model with tardiness penalties proportional to the
   processing times. It presents a two-Stage decomposition mechanism that
   proves to be powerful in solving the problem completely or reducing it
   to a much smaller problem. Three types of orderings of adjacent jobs are
   derived that play a crucial role in problem decomposition. The
   decomposition method solves 155 out of 320 test problems with job sizes
   ranging from 20 to 150. It reduces 163 unsolved problems to smaller
   subproblems with sizes not exceeding 25 jobs. The job sizes of the
   remaining two unsolved subproblems are 30 and 45.
Z8 1
ZB 0
ZS 0
ZR 0
TC 20
Z9 21
SN 0025-1909
UT WOS:A1993LE85000009
ER

PT J
AU GOH, CH
   GREENBERG, BS
   MATSUO, H
TI 2-STAGE PERISHABLE INVENTORY MODELS
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 633
EP 649
DI 10.1287/mnsc.39.5.633
PD MAY 1993
PY 1993
AB In this paper we consider perishable inventory systems with two types of
   demand. Demand may be for either fresh items or for somewhat older
   items. We model the system with two inventory stages. The first stage
   holds fresh items and the second stage holds the older items. We
   approximate the performance of the two-stage inventory system and
   compare two managerial policies.
ZB 2
TC 36
Z8 2
ZS 0
ZA 0
ZR 0
Z9 38
SN 0025-1909
UT WOS:A1993LE85000010
ER

PT J
AU GROSFELDNIR, A
   RONEN, B
TI A SINGLE BOTTLENECK SYSTEM WITH BINOMIAL YIELDS AND RIGID DEMAND
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 650
EP 653
DI 10.1287/mnsc.39.5.650
PD MAY 1993
PY 1993
AB This paper considers a ''single bottleneck system'': a multistage
   production system where all setups except one are zero. The stage with
   nonzero setup is defined to be the bottleneck; it may be thought of as
   the critical resource whose throughput largely determines the throughput
   of the entire system, as a envisioned by the OPT philosophy. Production
   is in lots with uncertain (binomial) yields and demand needs to be
   satisfied in full, thus possibly necessitating multiple production runs.
   We show how the optimal control problem can be reduced to that of
   optimal lotsizing a single stage.
Z8 0
TC 26
ZA 0
ZS 0
ZR 0
ZB 0
Z9 26
SN 0025-1909
UT WOS:A1993LE85000011
ER

PT J
AU BALAKRISHNAN, J
TI THE DYNAMICS OF PLANT LAYOUT
SO MANAGEMENT SCIENCE
VL 39
IS 5
BP 654
EP 655
DI 10.1287/mnsc.39.5.654
PD MAY 1993
PY 1993
AB This note develops a fathoming procedure for the Dynamic Plant Layout
   Problem (DPLP) discussed by Rosenblatt (1986) in this journal. This
   procedure can be used to reduce the number of candidate static layouts
   to be examined. An important feature of our procedure is that a feasible
   dynamic solution is not required in order to apply it. The effectiveness
   of this procedure depends on the relative magnitude of the shifting
   costs.
Z8 2
ZB 0
TC 14
ZA 0
ZR 0
ZS 0
Z9 16
SN 0025-1909
UT WOS:A1993LE85000012
ER

PT J
AU HOFFMAN, KL
   PADBERG, M
TI SOLVING AIRLINE CREW SCHEDULING PROBLEMS BY BRANCH-AND-CUT
SO MANAGEMENT SCIENCE
VL 39
IS 6
BP 657
EP 682
DI 10.1287/mnsc.39.6.657
PD JUN 1993
PY 1993
AB The crew scheduling problem is one that has been studied almost
   continually for the past 40 years but all prior approaches have always
   approximated the problem of finding an optimal schedule for even the
   smallest of an airline's fleets. The problem is especially important
   today since costs for flying personnel of major U.S. carriers have grown
   and now often exceed $1.3 billion a year and are the second largest item
   (next to fuel cost) of the total operating cost of major U.S. carriers.
   Thus even small percentage savings amount to substantial dollar amounts.
   We present a branch-and-cut approach to solving to proven optimality
   large set partitioning problems arising within the airline industry. We
   first provide some background related to this important application and
   then describe the approach for solving representative problems in this
   problem class. The branch-and-cut solver generates cutting planes based
   on the underlying structure of the polytope defined by the convex hull
   of the feasible integer points and incorporates these cuts into a
   tree-search algorithm that uses automatic reformulation procedures,
   heuristics and linear programming technology to assist in the solution.
   Numerical experiments are reported for a sample of 68 large-scale
   real-world crew scheduling problems. These problems include both pure
   set partitioning problems and set partitioning problems with side
   constraints. These ''base constraints'' represent contractual labor
   requirements and have heretofore not been represented explicitly in the
   construction of crew schedules thus making it impossible to provide any
   measure of how far the obtained solution was from optimality. An
   interesting result of obtaining less costly schedules is that the crews
   themselves are happier with the schedules because they spend more of
   their duty time flying than waiting on the ground.
ZS 3
ZR 1
Z8 2
TC 261
ZA 0
ZB 1
Z9 267
SN 0025-1909
UT WOS:A1993LM08400001
ER

PT J
AU ZIPKIN, P
TI MORTGAGES AND MARKOV-CHAINS - A SIMPLIFIED EVALUATION MODEL
SO MANAGEMENT SCIENCE
VL 39
IS 6
BP 683
EP 691
DI 10.1287/mnsc.39.6.683
PD JUN 1993
PY 1993
AB This paper has two purposes. The first is purely expository: to
   introduce stochastic interest-rate models and security-evaluation
   methods in a simple mathematical setting. Specifically, we assume the
   uncertainties in the model are represented by a discrete-time,
   finite-state Markov chain. Second, using this framework, we present a
   relatively simple model for the evaluation of mortgage-backed
   securities.
ZA 0
ZB 0
ZS 0
TC 14
Z8 0
ZR 0
Z9 14
SN 0025-1909
UT WOS:A1993LM08400002
ER

PT J
AU MCCONNELL, JJ
   SINGH, M
TI VALUATION AND ANALYSIS OF COLLATERALIZED MORTGAGE OBLIGATIONS
SO MANAGEMENT SCIENCE
VL 39
IS 6
BP 692
EP 709
DI 10.1287/mnsc.39.6.692
PD JUN 1993
PY 1993
AB This study develops a model for the valuation of Collateralized Mortgage
   Obligations (CMOs). The model is based on a two-factor model of the term
   structure of interest rates and embeds an empirically estimated mortgage
   prepayment function. The model is used to analyze various CMO tranches,
   including standard sequential pay fixed-rate tranches, Planned
   Amortization Class (PAC) tranches, Targeted Amortization Class (TAC)
   tranches, floating-rate tranches, Interest Only (IO) and Principal Only
   (PO) tranches, Z-bonds and Residuals. The results of this analysis
   illustrate the sensitivity of the various tranches to differences in CMO
   structure, changes in interest rates, the characteristics of the
   underlying collateral, and mortgage prepayments.
ZA 0
Z8 2
ZS 0
ZR 0
ZB 0
TC 8
Z9 10
SN 0025-1909
UT WOS:A1993LM08400003
ER

PT J
AU FEDERGRUEN, A
   ZHENG, YS
TI OPTIMAL POWER-OF-2 REPLENISHMENT STRATEGIES IN CAPACITATED GENERAL
   PRODUCTION DISTRIBUTION NETWORKS
SO MANAGEMENT SCIENCE
VL 39
IS 6
BP 710
EP 727
DI 10.1287/mnsc.39.6.710
PD JUN 1993
PY 1993
AB In this paper we develop a model for a capacitated
   production/distribution network of general (but acyclic) topology with a
   general bill of materials, as considered in MRP (Material Requirement
   Planning) or DRP (Distribution Requirement Planning) systems. This model
   assumes stationary, deterministic demand rates and a standard stationary
   cost structure; it is a generalization of the uncapacitated model
   treated in the seminal papers of Maxwell and Muckstadt (1985) and Roundy
   (1986). The capacity constraints consist of bounds on the frequency with
   which individual items can or need to be replenished.
   We derive a pair of simple and efficient algorithms capable of
   determining an optimal power-of-two policy. These algorithms consist of
   a limited number of maximum flow computations in networks closely
   related to the production/distribution network. The complexity of these
   algorithms, even when applied to the uncapacitated model, compares
   favorably with that of the existing alternative solution methods.
ZS 0
Z8 0
ZR 0
TC 24
ZB 0
ZA 0
Z9 24
SN 0025-1909
UT WOS:A1993LM08400004
ER

PT J
AU STEINER, G
   YEOMANS, S
TI LEVEL SCHEDULES FOR MIXED-MODEL, JUST-IN-TIME PROCESSES
SO MANAGEMENT SCIENCE
VL 39
IS 6
BP 728
EP 735
DI 10.1287/mnsc.39.6.728
PD JUN 1993
PY 1993
AB A mixed-model manufacturing facility running under a Just-in-Time (JIT)
   production system is controlled by setting the production sequence of
   the final assembly process. This sequence is set to achieve the primary
   goal of an organization operating under a JIT system, which is to
   maintain a constant rate of part usage. In this paper, a graph-theoretic
   approach is used to determine an optimal solution for this goal for a
   new, nonconvex objective function. Furthermore, it is shown that a
   schedule always exists such that, at all times, the deviation of actual
   production from the desired level of production for every product is
   never more than one unit.
Z8 0
ZR 0
TC 85
ZA 0
ZB 0
ZS 0
Z9 85
SN 0025-1909
UT WOS:A1993LM08400005
ER

PT J
AU GRAVES, GW
   MCBRIDE, RD
   GERSHKOFF, I
   ANDERSON, D
   MAHIDHARA, D
TI FLIGHT CREW SCHEDULING
SO MANAGEMENT SCIENCE
VL 39
IS 6
BP 736
EP 745
DI 10.1287/mnsc.39.6.736
PD JUN 1993
PY 1993
AB A new crew scheduling optimization system has been developed for United
   Airlines. The system was developed to permit quick response to schedule
   changes and to reduce crew scheduling costs. It was designed to work
   efficiently for both the medium sized problems (300 flights daily) and
   the very large problems (1,700 flights daily) that United must solve.
   The system has two main components, a generator and an optimizer. The
   generator creates pairings (candidate crew trips) which are fed as
   variables to the optimizer as an elastic embedded set partitioning
   integer programming problem. The optimizer then seeks to find a set of
   pairings that covers all of the flight segments exactly once with
   minimal cost. Once a disjoint solution has been found, the system cycles
   between the generator and the optimizer to improve it. Savings of
   $16,000,000 annually in crew scheduling costs have been obtained.
ZS 1
ZR 0
Z8 1
ZB 0
TC 66
ZA 0
Z9 68
SN 0025-1909
UT WOS:A1993LM08400006
ER

PT J
AU BISSCHOP, JJ
   KUIP, CAC
TI COMPOUND SETS IN MATHEMATICAL-PROGRAMMING MODELING LANGUAGES
SO MANAGEMENT SCIENCE
VL 39
IS 6
BP 746
EP 756
DI 10.1287/mnsc.39.6.746
PD JUN 1993
PY 1993
AB This paper presents a series of simple but realistic examples in which
   common algebraic indexing conventions are not so convenient. In
   particular, it analyzes the difficulties caused by the conventions that
   each model component must have a fixed number of indices and that the
   order of the indices is significant to their meaning. To deal with these
   difficulties compensating extensions to algebraic notation are proposed.
   The proposed notation is compared to existing notation in terms of the
   human abilities to understand, maintain and verify model descriptions.
ZR 0
TC 1
Z8 0
ZA 0
ZB 0
ZS 0
Z9 1
SN 0025-1909
UT WOS:A1993LM08400007
ER

PT J
AU KALISKI, JA
   YE, YY
TI A SHORT-CUT POTENTIAL REDUCTION ALGORITHM FOR LINEAR-PROGRAMMING
SO MANAGEMENT SCIENCE
VL 39
IS 6
BP 757
EP 776
DI 10.1287/mnsc.39.6.757
PD JUN 1993
PY 1993
AB As most interior point algorithms iterate, they repeatedly perform
   costly matrix operations, such as projections, on the entire constraint
   matrix. For large-scale linear programming problems, such operations
   consume the great majority of the computation time required. However,
   for problems where the number of variables far exceeds the number of
   constraints, operations over the entire constraint matrix are
   unnecessary. We will examine and extend decomposition techniques which
   greatly reduce the amount of work required by such interior point
   methods as the dual affine scaling and the dual potential reduction
   algorithms. In an effort to judge the practical viability of the
   decompositioning, we compare the performance of the dual potential
   reduction algorithm with and without decompositioning over a set of
   randomly generated transportation problems. Accompanying a theoretical
   justification of these techniques, we focus on the implementation
   details and computational results of one such technique.
ZS 0
TC 15
ZB 0
ZR 0
Z8 0
Z9 15
SN 0025-1909
UT WOS:A1993LM08400008
ER

PT J
AU LAL, R
   SRINIVASAN, V
TI COMPENSATION PLANS FOR SINGLE-PRODUCT AND MULTIPRODUCT SALESFORCES - AN
   APPLICATION OF THE HOLMSTROM-MILGROM MODEL
SO MANAGEMENT SCIENCE
VL 39
IS 7
BP 777
EP 793
DI 10.1287/mnsc.39.7.777
PD JUL 1993
PY 1993
AB The agency theory approach to understanding salesforce compensation
   plans is modified to incorporate the intratemporal nature of the
   salesperson's effort-rate decision, i.e., the decision about the
   effort-rate at any given point in time potentially depends upon the
   sales performance up to that point in time in the accounting period.
   Under the assumptions considered in this paper, Holmstrom and Milgrom
   (1987) have shown that the optimal compensation plan is linear in total
   sales over the accounting period. The comparative statics results
   obtained here corroborate most of the corresponding results in the
   salesforce compensation literature; moreover, we derive many additional
   results not available in the literature. It is demonstrated that the
   commission income as a fraction of total compensation goes up with an
   increase in the effectiveness of the sales-effort or an increase in base
   sales. On the other hand, the salary component of the total compensation
   goes up with increases in uncertainty, absolute risk aversion, marginal
   cost of production, perceived cost of effort, and/or alternative job
   opportunities for the salesperson. We provide a discussion of different
   selling situations where our results may be more or less applicable. An
   examination of empirical studies already available in the literature
   reveals support for our findings regarding the relative emphasis of
   salary and incentive pay in the compensation plan. We also extend the
   agency theory approach to compare commission rates across products for a
   multiproduct salesperson. Here it is shown that commission rates are
   higher for products with higher sales-effort effectiveness, lower levels
   of uncertainty, and/or lower marginal costs.
TC 124
ZA 0
ZS 1
Z8 10
ZR 0
ZB 0
Z9 133
SN 0025-1909
UT WOS:A1993LQ99900001
ER

PT J
AU ARYA, A
   FELLINGHAM, JC
   YOUNG, RA
TI THE EFFECTS OF RISK-AVERSION ON PRODUCTION DECISIONS IN DECENTRALIZED
   ORGANIZATIONS
SO MANAGEMENT SCIENCE
VL 39
IS 7
BP 794
EP 805
DI 10.1287/mnsc.39.7.794
PD JUL 1993
PY 1993
AB This paper presents a principal-agent model in which subsequent to
   contracting the risk averse agent becomes informed about the production
   process. Communication of the agent's information is always valuable.
   The optimal contract given this information asymmetry is characterized
   by less production and a larger risk premium than when information is
   symmetric, leading to an efficiency loss. Comparative statics show that
   the loss in expected production increases as the agent becomes more risk
   averse.
Z8 0
ZR 0
ZA 0
ZB 0
TC 6
ZS 0
Z9 6
SN 0025-1909
UT WOS:A1993LQ99900002
ER

PT J
AU SHELLEY, MK
TI OUTCOME SIGNS, QUESTION FRAMES AND DISCOUNT RATES
SO MANAGEMENT SCIENCE
VL 39
IS 7
BP 806
EP 815
DI 10.1287/mnsc.39.7.806
PD JUL 1993
PY 1993
AB This study explains why gain/loss discount rate differences reported in
   previous studies cannot be attributed to outcome sign alone, but rather,
   must be associated with particular outcome-sign/question-frame
   combinations. To do so, it extends Loewenstein's (1988) framing model of
   intertemporal choice to negative outcomes and uses the resulting
   predictions to interpret and integrate the results of three previous
   studies comparing subjective discount rates (Thaler 1981, Loewenstein
   1988, Benzion et al. 1989). The new framework reveals previously
   unidentified linkages among outcome signs, question frames, and discount
   rates. To investigate whether losses and gains are, in fact, discounted
   differently, an experiment is conducted that includes a neutral-frame
   intertemporal choice scenario (no proposed change in outcome timing) for
   each outcome sign. The results show that subjective discount rates vary
   in a predictable way according to the outcome sign and question frame
   combination examined.
Z8 0
ZR 0
ZS 1
TC 68
ZA 0
ZB 10
Z9 69
SN 0025-1909
UT WOS:A1993LQ99900003
ER

PT J
AU BURNS, WJ
   CLEMEN, RT
TI COVARIANCE STRUCTURE MODELS AND INFLUENCE DIAGRAMS
SO MANAGEMENT SCIENCE
VL 39
IS 7
BP 816
EP 834
DI 10.1287/mnsc.39.7.816
PD JUL 1993
PY 1993
AB Statisticians use covariance structure modeling as a versatile tool for
   modeling and testing theory. The models that result provide explicit and
   detailed descriptions of stochastic systems. We show how covariance
   structure models are related-mathematically, conceptually,
   philosophically and practically-to Gaussian influence diagrams as
   described by Shachter and Kenley (1989). This relationship suggests ways
   in which covariance structure modeling can be used to advantage in the
   prescriptive domain of decision analysis. The paper includes an example
   concerning the management of hazardous materials, in which a covariance
   structure model is converted to an influence diagram for use in a
   prescriptive analysis.
ZS 0
Z8 0
TC 21
ZA 0
ZB 6
ZR 0
Z9 21
SN 0025-1909
UT WOS:A1993LQ99900004
ER

PT J
AU TURNER, AL
   HENSEL, CR
TI WERE THE RETURNS FROM STOCKS AND BONDS OF DIFFERENT COUNTRIES REALLY
   DIFFERENT IN THE 1980S
SO MANAGEMENT SCIENCE
VL 39
IS 7
BP 835
EP 844
DI 10.1287/mnsc.39.7.835
PD JUL 1993
PY 1993
AB We analyzed the total equity returns of indexes from Australia, Canada,
   Germany, Japan, the UK, and the US and total fixed income returns of
   indexes from all but Australia (excluded due to lack of data) to see if
   the returns of stocks and bonds were statistically different across
   markets during the 1980s. At the end of 1989, these countries
   represented over 87% of the market capitalization of the Morgan Stanley
   Capital International (MSCI) World Equity Index and over 88% of the
   Salomon Brothers World Bond Index. This study used monthly observations
   from January 1980 through December 1989 and examined returns based in
   local currency and hedged and unhedged US dollars.
   We found that sample mean stock and bond returns during the 1980s were
   statistically indistinguishable across countries. However, because the
   sample variances were so large relative to the sample means, it would
   have been difficult to detect differences in population means by any
   test. We found evidence of variance heterogeneity, which may be
   explainable by other economic factors. We also found that intercountry
   stock and bond correlations were not significantly different. Thus, we
   confirmed the results of other researchers, such as Jobson and Korkie
   (1981), but in a broader global context using more asset types and
   different statistical tests. Our work suggests reducing the number of
   input estimates to a MV global asset allocation problem. For
   practitioners trying to put MV analysis to use, these findings could
   have a significant effect on the practice of asset allocation.
ZA 0
ZB 0
TC 2
Z8 0
ZS 0
ZR 0
Z9 2
SN 0025-1909
UT WOS:A1993LQ99900005
ER

PT J
AU CHOPRA, VK
   HENSEL, CR
   TURNER, AL
TI MASSAGING MEAN-VARIANCE INPUTS - RETURNS FROM ALTERNATIVE GLOBAL
   INVESTMENT STRATEGIES IN THE 1980S
SO MANAGEMENT SCIENCE
VL 39
IS 7
BP 845
EP 855
DI 10.1287/mnsc.39.7.845
PD JUL 1993
PY 1993
AB This paper explores the impact of adjustments to the inputs on total
   returns, terminal wealth, and portfolio turnover in an unconstrained
   monthly mean-variance (MV) asset allocation over time. It is well known
   that MV allocations are very sensitive to small forecast errors in the
   means and covariances. This sensitivity is especially pronounced for
   errors in means. One way to control this sensitivity to forecast errors
   is to use Stein estimation. We examined three naive applications of
   Stein estimation for six individual country stock indexes, five country
   bond indexes and five cash indexes.
   This study has two major conclusions. First, any of the suggested
   adjustments to inputs dominate the results of an unadjusted-input MV
   optimization. Adjusted-input portfolios have higher mean return, less
   variance and greater terminal wealth than unadjusted-input portfolios.
   Second, these improvements become even greater with transaction costs.
ZB 0
ZS 1
ZA 0
ZR 0
Z8 2
TC 27
Z9 30
SN 0025-1909
UT WOS:A1993LQ99900006
ER

PT J
AU GRAUER, RR
   HAKANSSON, NH
TI ON THE USE OF MEAN-VARIANCE AND QUADRATIC APPROXIMATIONS IN IMPLEMENTING
   DYNAMIC INVESTMENT STRATEGIES - A COMPARISON OF RETURNS AND INVESTMENT
   POLICIES
SO MANAGEMENT SCIENCE
VL 39
IS 7
BP 856
EP 871
DI 10.1287/mnsc.39.7.856
PD JUL 1993
PY 1993
AB This paper compares two approximation schemes for calculating the
   optimal portfolios in the discrete-time dynamic investment model,
   specifically, the mean-variance (MV) and the quadratic approximations,
   to the exact power function method. Future returns are estimated via the
   empirical probability assessment approach. The results show that (i)
   with quarterly revision, the MV model approximates the dynamic model
   very well; (ii) with annual revision, there are often sharp differences
   between the power function model and the MV approximation; and (iii)
   these differences become even larger when the quadratic approximation is
   used.
TC 57
ZA 0
ZR 0
ZB 0
Z8 6
ZS 0
Z9 62
SN 0025-1909
UT WOS:A1993LQ99900007
ER

PT J
AU ELNAJDAWI, MK
   KLEINDORFER, PR
TI COMMON CYCLE LOT-SIZE SCHEDULING FOR MULTIPRODUCT, MULTISTAGE PRODUCTION
SO MANAGEMENT SCIENCE
VL 39
IS 7
BP 872
EP 885
DI 10.1287/mnsc.39.7.872
PD JUL 1993
PY 1993
AB In this paper we study the Common Cycle Scheduling Problem (CCSP). This
   classic production problem is concerned with determining optimal
   production lot sizes for a given set of products using a common
   facility. CCSP is based on scheduling all products using a common (base)
   cycle time, so that the lot size for each product is the forecasted
   demand for that product over the base cycle time. This research provides
   an optimizing framework for CCSP for a multi-stage, multi-product,
   flow-shop environment under deterministic and stationary conditions,
   assuming a fixed sequence is maintained across all processing stages.
   The framework presented considers the costs of work-in-process inventory
   and determines a jointly optimal common cycle time and production
   schedule (start and finish times for each product's production lot-size)
   for the multi-stage facility in question. The paper also reports some
   results on the impact of alternative sequencing rules for the CCSP
   context.
ZB 0
Z8 2
ZR 0
ZS 0
TC 30
ZA 0
Z9 32
SN 0025-1909
UT WOS:A1993LQ99900008
ER

PT J
AU BLUMSTEIN, A
   CANELACACHO, JA
   COHEN, J
TI FILTERED SAMPLING FROM POPULATIONS WITH HETEROGENEOUS EVENT FREQUENCIES
SO MANAGEMENT SCIENCE
VL 39
IS 7
BP 886
EP 889
DI 10.1287/mnsc.39.7.886
PD JUL 1993
PY 1993
AB A hierarchical model is developed to account for selection biases that
   result from processes in which events have a fixed probability of being
   sampled, but individuals in the population generate events at varying
   rates. It is shown that inferences about the population parameters from
   such unrepresentative samples are not only possible but can be
   statistically powerful, provided the selection biases are adequately
   controlled for and the specification of the model is appropriate. The
   model assumptions are sufficiently flexible to accommodate a variety of
   stochastic processes with heterogeneous event frequencies. In an
   example, the model is applied to data on robbery rates for prison
   inmates in order to estimate the robbery rates for all offenders. The
   model fits the data well, and the results show that the bias toward high
   rate offenders among prison inmates is substantial.
ZR 0
ZA 0
TC 17
Z8 0
ZB 0
ZS 0
Z9 17
SN 0025-1909
UT WOS:A1993LQ99900009
ER

PT J
AU KIRKWOOD, CW
TI AN ALGEBRAIC APPROACH TO FORMULATING AND SOLVING LARGE MODELS FOR
   SEQUENTIAL DECISIONS UNDER UNCERTAINTY
SO MANAGEMENT SCIENCE
VL 39
IS 7
BP 900
EP 913
DI 10.1287/mnsc.39.7.900
PD JUL 1993
PY 1993
AB This article presents an algebraic approach to formulating and solving
   large models for sequential decisions under uncertainty. With this
   approach, decision analysis optimization methods can be applied to
   complex decision problems which are generally analyzed in management
   science practice using heuristics. Using the approach, a decision
   problem is formulated in terms of decision variables, random variables,
   and functions relating these variables. This leads to a compact
   representation, and a simple algorithm can be used to quickly solve
   algebraic models that would have decision trees with several hundred
   thousand endpoints. An application to research and development planning
   illustrates the usefulness of such large sequential decision models.
ZA 0
ZR 0
Z8 1
ZS 0
TC 21
ZB 0
Z9 21
SN 0025-1909
UT WOS:A1993LQ99900010
ER

PT J
AU LI, YM
TI GROWTH-SECURITY INVESTMENT STRATEGY FOR LONG AND SHORT RUNS
SO MANAGEMENT SCIENCE
VL 39
IS 8
BP 915
EP 924
DI 10.1287/mnsc.39.8.915
PD AUG 1993
PY 1993
AB It is well known that the investment policy maximizing the expected
   logarithm of wealth each period is a long-run optimal capital growth
   criterion. However, the growth-optimal strategy entails a considerable
   risk of losing a substantial portion of wealth for the investment in the
   short run. This paper extends the long-run capital growth criterion to a
   multiperiod investment policy which maximizes the capital growth and at
   the same time achieves a given probability of maintaining an accumulated
   risk-free return over an finite investment horizon.
ZR 0
ZS 0
Z8 1
ZB 0
ZA 0
TC 7
Z9 8
SN 0025-1909
UT WOS:A1993LU26700001
ER

PT J
AU FINKELSHTAIN, I
   CHALFANT, JA
TI PORTFOLIO CHOICES IN THE PRESENCE OF OTHER RISKS
SO MANAGEMENT SCIENCE
VL 39
IS 8
BP 925
EP 936
DI 10.1287/mnsc.39.8.925
PD AUG 1993
PY 1993
AB he effects of multivariate risk are examined in a model of portfolio
   choice. The conditions under which portfolio choices are separable from
   consumption decisions are derived. Unless the appropriate restrictions
   hold on investors' preferences or on the probability distribution of
   risks, the optimal portfolio is affected by other risks. This requires
   generalizing the usual measures of risk aversion. With one risky asset,
   matrix measures of risk aversion are used to generalize the results of
   Arrow (1965) and Pratt (1964) concerning the effects of risk aversion
   and wealth on the optimal portfolio. With two risky assets, the choices
   made by two investors coincide if and only if their generalized
   risk-aversion measures are identical. Ross's notion of stronger risk
   aversion is then used to characterize the effect of risk aversion on the
   level of investment in the riskier asset.
ZR 0
ZS 0
ZA 0
ZB 0
TC 14
Z8 0
Z9 14
SN 0025-1909
UT WOS:A1993LU26700002
ER

PT J
AU VONNITZSCH, R
   WEBER, M
TI THE EFFECT OF ATTRIBUTE RANGES ON WEIGHTS IN MULTIATTRIBUTE UTILITY
   MEASUREMENTS
SO MANAGEMENT SCIENCE
VL 39
IS 8
BP 937
EP 943
DI 10.1287/mnsc.39.8.937
PD AUG 1993
PY 1993
AB Multiattribute utility theory requires a specific relation between the
   range of outcomes of each attribute and the weight for that attribute.
   The greater the range, the greater the weight has to be. Experimental
   results show that subjects do not adjust their judgments properly if the
   range is varied. For the two methods tested the adjustment is smaller
   than required by theory. The bias was smaller for a regression procedure
   than for the direct ratio method. Weights based on an intuitive range
   were not found to be superior to those elicited over different ranges.
ZS 0
ZA 0
TC 91
Z8 0
ZR 0
ZB 7
Z9 92
SN 0025-1909
UT WOS:A1993LU26700003
ER

PT J
AU ANUPINDI, R
   AKELLA, R
TI DIVERSIFICATION UNDER SUPPLY UNCERTAINTY
SO MANAGEMENT SCIENCE
VL 39
IS 8
BP 944
EP 963
DI 10.1287/mnsc.39.8.944
PD AUG 1993
PY 1993
AB Supply chain management is becoming an increasingly important issue,
   especially when in most industries the cost of materials purchased
   comprises 40-60% of the total sales revenue. Despite the benefits cited
   for single sourcing in the popular literature, there is enough evidence
   of industries having two/three sources for most parts. In this paper we
   address the operational issue of quantity allocation between two
   uncertain suppliers and its effects on the inventory policies of the
   buyer. Based on the type of delivery contract a buyer has with the
   suppliers, we suggest three models for the supply process. Model I is a
   one-delivery contract with all of the order quantity delivered either in
   the current period with probability beta, or in the next period with
   probability 1 - beta. Model II is also a one-delivery contract with a
   random fraction of the order quantity delivered in the current period;
   the portion of the order quantity not delivered is cancelled. Model III
   is similar to Model Il with the remaining quantity delivered in the next
   period. We derive the optimal ordering policies that minimize the total
   ordering, holding and penalty costs with backlogging. We show that the
   optimal ordering policy in period n for each of these models is as
   follows: for x greater-than-or-equal-to u(n)BAR order nothing; for
   v(n)BAR less-than-or-equal-to X < u(n)BAR, use only one supplier; and
   for x < v(n)BAR, order from both suppliers. For the limiting case in the
   single period version of Model I, we derive conditions under which one
   would continue ordering from one or the other or both suppliers. For
   Model II, we give, sufficient conditions for not using the second (more
   expensive) supplier when the demand and yield distributions have some
   special form. For the single period version of Models II and III with
   equal marginal ordering costs we show that the optimal order quantities
   follow a ratio rule when demand is exponential and yields are either
   normal or gamma distributed.
ZB 0
Z8 15
ZR 0
ZA 0
TC 269
ZS 0
Z9 282
SN 0025-1909
UT WOS:A1993LU26700004
ER

PT J
AU NGUYEN, QC
   STONE, RE
TI A MULTIPERIOD MINIMAX RESOURCE-ALLOCATION PROBLEM WITH SUBSTITUTABLE
   RESOURCES
SO MANAGEMENT SCIENCE
VL 39
IS 8
BP 964
EP 974
DI 10.1287/mnsc.39.8.964
PD AUG 1993
PY 1993
AB In this paper we consider a multiperiod resource allocation model in
   which the resources are storable and substitutable. A specific
   application of this model relates to the multiperiod production planning
   for electronic circuit board assembly factories. In this case, resources
   are electronic components, which are storable, that is, excess
   components in one period can be used in subsequent periods. Components
   that can be used in the same function on a circuit board are considered
   substitutable. Substitutability between components, however, may be
   dependent upon the specific circuit board on which they reside. Given
   that there are certain production requirements for the circuit boards,
   and that some components are in short supply, our algorithm (a) revises
   the production levels of the affected circuit boards, and (b)
   efficiently allocates the available components according to the revised
   production, so as to minimize the maximum weighted deviation from the
   original production plans. The weights reflect the relative importance
   of the circuit boards. The objective function uses cumulative production
   levels and cumulative demands to allow for back-scheduling.
   We present a primal-dual algorithm that is very efficient. An
   implementation of the algorithm compares favorably with a standard
   linear programming code. We solved a problem with 300 components, 20
   different circuit boards (average of 10 functions/board) for 10 time
   periods (approximately 30,000 variables) in less than one minute on a
   VAX 11/785. We also discuss upper and lower bound extensions, and a
   lexicographic algorithm to ensure that less critical resources are also
   allocated effectively.
ZB 0
Z8 0
ZS 0
ZR 0
ZA 0
TC 5
Z9 5
SN 0025-1909
UT WOS:A1993LU26700005
ER

PT J
AU DUENYAS, I
   HOPP, WJ
   SPEARMAN, ML
TI CHARACTERIZING THE OUTPUT PROCESS OF A CONWIP LINE WITH DETERMINISTIC
   PROCESSING AND RANDOM OUTAGES
SO MANAGEMENT SCIENCE
VL 39
IS 8
BP 975
EP 988
DI 10.1287/mnsc.39.8.975
PD AUG 1993
PY 1993
AB We model a CONWIP (CONstant Work-in-Process) production line with
   deterministic processing times and exponential failure and repair times
   as a closed queueing network. We derive an approximation for the mean
   and variance of the output during a specified interval and give
   computable conditions under which this approximation performs well. We
   show through empirical tests that the approximation is robust and
   illustrate its usefulness as the basis for a procedure for selecting an
   economic production quota and a card count for a CONWIP line.
TC 34
ZR 0
Z8 1
ZA 0
ZB 0
ZS 0
Z9 35
SN 0025-1909
UT WOS:A1993LU26700006
ER

PT J
AU NELSON, BL
   HSU, JC
TI CONTROL-VARIATE MODELS OF COMMON RANDOM NUMBERS FOR MULTIPLE COMPARISONS
   WITH THE BEST
SO MANAGEMENT SCIENCE
VL 39
IS 8
BP 989
EP 1001
DI 10.1287/mnsc.39.8.989
PD AUG 1993
PY 1993
AB Using common random numbers (CRN) in simulation experiment design is
   known to reduce the variance of estimators of differences in system
   performance. However, when more than two systems are compared, exact
   simultaneous statistical inference in conjunction with CRN is typically
   impossible. We introduce control-variate models of CRN that permit exact
   statistical inference, specifically multiple comparison's with the best.
   These models explain the effect of CRN via a linear regression of the
   simulation output on ''control variates'' that are functions of the
   simulation inputs. We establish theoretically, and illustrate
   empirically, that the control-variate models lead to sharper statistical
   inference in the sense that the probability of detecting differences in
   systems' performance is increased.
RI Nelson, Barry L/B-7490-2009
ZR 0
TC 9
ZB 0
ZA 0
Z8 0
ZS 0
Z9 9
SN 0025-1909
UT WOS:A1993LU26700007
ER

PT J
AU BISCHAK, DP
   KELTON, WD
   POLLOCK, SM
TI WEIGHTED BATCH MEANS FOR CONFIDENCE-INTERVALS IN STEADY-STATE
   SIMULATIONS
SO MANAGEMENT SCIENCE
VL 39
IS 8
BP 1002
EP 1019
DI 10.1287/mnsc.39.8.1002
PD AUG 1993
PY 1993
AB We propose a new procedure for providing confidence-interval estimators
   of the mean of a covariance-stationary process. The procedure, a
   modification of the method of batch means, is an improvement over
   existing methods when the process displays strong correlation and a
   comparatively small number of observations is available.
   We assign weights to the observations within a batch. The weights are
   determined by the order of the time-series model fit to the process and
   by its estimated parameters. For a given model and its parameters, the
   weights minimize the variance of the weighted point estimator of the
   mean; the point and variance estimators formed when these optimal
   weights are applied are unbiased. The time-series identification
   procedure and estimation of the parameters and weights bring in bias.
   Formulas for optimal weights are given for AR(p) and MA(1) processes.
   Experiments were conducted on AR(1), AR(2), and MA(2) processes as well
   as on the M/M/1 queue delay process and a periodic inventory system cost
   process. Results show that for processes with strong correlation over
   many lags, as is typical in queue-delay processes and inventory
   processes, the achieved coverage of the constructed interval is closer
   to nominal levels than for the unweighted-batch-means method. The
   coverage and average half-length is not as greatly affected by the
   number of batches, and nonnormality of the weighted batch means is not
   as severe.
ZB 0
TC 10
ZS 0
ZA 0
ZR 0
Z8 0
Z9 10
SN 0025-1909
UT WOS:A1993LU26700008
ER

PT J
AU WHITT, W
TI LARGE FLUCTUATIONS IN A DETERMINISTIC MULTICLASS NETWORK OF QUEUES
SO MANAGEMENT SCIENCE
VL 39
IS 8
BP 1020
EP 1028
DI 10.1287/mnsc.39.8.1020
PD AUG 1993
PY 1993
AB In this paper we investigate a relatively simple deterministic
   four-class two-queue multiclass open network of single-server FIFO
   queues with traffic intensity one at each queue. Our purpose is to
   better understand the effect of feedback with class-dependent service
   times at the queues. The example is sufficiently tractable that we are
   able to describe its transient behavior in great detail. The transient
   behavior depends strongly on the initial conditions and, for some
   initial conditions, the sample paths of the queue-length processes at
   individual stations have sudden large fluctuations (a large jump up
   followed immediately by a large jump down). These large fluctuations
   occur because batches of customers with short service times build up in
   the queues. Consistent with recent work by Dai and Wang (1993) on
   Brownian network models, these fluctuations rule out conventional
   heavy-traffic limit theorems. We show how to obtain proper heavy-traffic
   limits for this example by weakening the topology or enlarging the space
   of prospective limits (and changing the topology). This example also
   dramatically demonstrates a disadvantage of the FIFO discipline compared
   to other disciplines like head-of-the-line processor-sharing (HOL-PS)
   among the classes at each queue (under which, the large fluctuations do
   not occur). Finally, the critical arrival rate for stability in our
   example actually depends on the service discipline, being even lower if
   the classes with longer service times are given high priority at each
   queue. This phenomenon can occur in the network setting because
   individual queues can be empty when there is work in the network.
RI Whitt, Ward/D-5337-2013
OI Whitt, Ward/0000-0003-4298-9964
ZR 0
ZB 0
TC 23
ZA 0
ZS 0
Z8 1
Z9 24
SN 0025-1909
UT WOS:A1993LU26700009
ER

PT J
AU RACHEV, ST
   SENGUPTA, A
TI LAPLACE-WEIBULL MIXTURES FOR MODELING PRICE CHANGES
SO MANAGEMENT SCIENCE
VL 39
IS 8
BP 1029
EP 1038
DI 10.1287/mnsc.39.8.1029
PD AUG 1993
PY 1993
AB B. Mandelbrot and E. Fama in the sixties, and W. Ziemba in the
   seventies, suggested stable laws for modeling stock returns and
   commodity prices. Geometric stable distributions, with Laplace
   distribution playing the role of a ''normal'' law, have been found to
   give better fit to such data. We study the ''stability'' properties of
   Laplace and a mixture of Laplace and Weibull and discuss the statistical
   inference for such mixture models. Application of the mixture
   distribution to modeling price changes in real estate prices in France
   is given.
RI Rachev, Svetlozar/ABD-9457-2020
TC 12
ZA 0
ZS 0
Z8 2
ZB 0
ZR 0
Z9 14
SN 0025-1909
UT WOS:A1993LU26700010
ER

PT J
AU KARMARKAR, U
   PITBLADDO, R
TI INTERNAL PRICING AND COST ALLOCATION IN A MODEL OF MULTIPRODUCT
   COMPETITION WITH FINITE-CAPACITY INCREMENTS
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1039
EP 1053
DI 10.1287/mnsc.39.9.1039
PD SEP 1993
PY 1993
AB Internal prices are used in practice to allocate central resources to a
   firms' profit centers. The fixed costs of capacity acquisitions are
   often included in these prices. We examine the interaction between
   capacity acquisition and competition when capacity is available in fixed
   increments. We find predictably that if the increments are small, unit
   capacity cost is a good approximation for the internal price, and if the
   increments are large, the internal price is zero. However, the
   relationship between the internal price and the capacity increment for
   intermediate cases is quite irregular, to the extent that it is not
   possible to approximate the internal price with accounting data. The
   analysis also suggests that full cost allocation overcharges for the
   opportunity cost of capacity. Furthermore, the right internal price does
   not act either as a way of recovering fixed costs or as a proxy for
   externalities such as congestion costs. The conclusions are not
   materially altered in the case where variable costs increase at the
   margin, and where these costs rather than hard capacity constraints are
   the reason to restrict output.
ZS 0
Z8 2
ZB 0
TC 10
ZR 0
ZA 0
Z9 12
SN 0025-1909
UT WOS:A1993LZ50700001
ER

PT J
AU HENNART, JF
   PARK, YR
TI GREENFIELD VS ACQUISITION - THE STRATEGY OF JAPANESE INVESTORS IN THE
   UNITED-STATES
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1054
EP 1070
DI 10.1287/mnsc.39.9.1054
PD SEP 1993
PY 1993
AB Multinational firms can enter a foreign market by taking over existing
   local firms (acquisitions) or by setting up new ventures (greenfield
   investments). Surprisingly, there has been limited empirical work on
   this topic. This paper examines the determinants of this choice by
   looking at Japanese entries into the United States. By focusing on firms
   of one country entering a single market, we are able to separate the
   impact of a firm's strategy from that of the characteristics of the
   target industry or country.
   This paper tests simultaneously a number of competing hypotheses. The
   results suggest that acquisitions are used by Japanese investors with
   weak competitive advantages, while investors with strong advantages find
   that greenfield investments are a more efficient way to transfer these
   advantages to the U.S. Acquisitions are also chosen to enter industries
   with either very high or very low growth rates, when entry is at a scale
   that is large relative to the parent, and when entry is into a different
   industry. The Japanese investor's previous experience of the U.S.
   market, its financial situation, and its status as a follower in an
   oligopolistic industry have no statistically significant impact on the
   entry mode. Neither do U.S. stock market conditions.
ZS 2
ZR 0
Z8 5
ZB 1
TC 349
ZA 0
Z9 356
SN 0025-1909
UT WOS:A1993LZ50700002
ER

PT J
AU NUTT, PC
TI THE IDENTIFICATION OF SOLUTION IDEAS DURING ORGANIZATIONAL
   DECISION-MAKING
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1071
EP 1085
DI 10.1287/mnsc.39.9.1071
PD SEP 1993
PY 1993
AB This research investigated the idea development stage of a strategic
   decision making process. The tactics that decision makers apply to
   identify ideas were uncovered from a systematic study of 168 decision
   cases. These tactics and contextual factors describing the decision
   situation were analyzed to determine how each influences success
   measured by decision merit, development time, initial adoption, and
   sustained adoption. A ''synthesized template'' which integrated useful
   practices and procedures from several sources had the most success, but
   this tactic was seldom used. A ''cyclical search'' in which repeated
   searches were carried out to learn about opportunities was quite
   successful when used under conditions of low importance, low urgency,
   and good staff support. The success of the design tactic, which calls
   for innovation, improved when urgency was present and multiple
   alternatives were sought. The idea tactic which imposed a fully
   developed solution was widely used and seldom successful.
ZR 0
Z8 0
ZS 3
TC 21
ZA 0
ZB 0
Z9 24
SN 0025-1909
UT WOS:A1993LZ50700003
ER

PT J
AU KEEFER, DL
   VERDINI, WA
TI BETTER ESTIMATION OF PERT ACTIVITY TIME PARAMETERS
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1086
EP 1091
DI 10.1287/mnsc.39.9.1086
PD SEP 1993
PY 1993
AB This paper builds upon earlier work from the decision/risk analysis area
   m presenting simple, easy-to-use approximations for the mean and
   variance of PERT activity times. These approximations offer significant
   advantages over the PERT formulas currently being taught and used, as
   well as over recently proposed modifications. For instance, they are
   several orders of magnitude more accurate than their PERT counterparts
   in estimating means and variances of beta distributions if the data
   required for all methods are obtained accurately. Moreover, they utilize
   probability data that can be assessed more reliably than those required
   by the PERT formulas, while still requiring just three points from each
   activity time probability distribution. Using the proposed
   approximations can significantly improve the accuracy of probability
   statements about project completion time, and their use complements
   ongoing efforts to improve PERT analyses of networks involving multiple
   critical paths.
ZA 0
ZB 0
Z8 7
ZR 0
ZS 0
TC 61
Z9 68
SN 0025-1909
UT WOS:A1993LZ50700004
ER

PT J
AU MCGAVIN, EJ
   SCHWARZ, LB
   WARD, JE
TI 2-INTERVAL INVENTORY-ALLOCATION POLICIES IN A ONE-WAREHOUSE
   N-IDENTICAL-RETAILER DISTRIBUTION-SYSTEM
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1092
EP 1107
DI 10.1287/mnsc.39.9.1092
PD SEP 1993
PY 1993
AB For a system of N-identical-retailers we construct a model for
   determining warehouse inventory-allocation policies which minimize
   system lost sales per retailer between system replenishments. An
   allocation policy is specified by: (a) the number of withdrawals from
   warehouse stock; (b) the intervals between successive withdrawals; (c)
   the quantity of stock to be withdrawn from the warehouse in each
   interval; and (d) the division of withdrawn stock among the retailers.
   We show that in the case of two withdrawals, available stock in each
   interval should be divided to ''balance'' retailer inventories.
   We also develop an infinite-retailer model and use it to determine
   two-interval allocation heuristics for N-retailer systems. Simulation
   tests suggest that the infinite-retailer heuristic policies are
   near-optimal for as few as two retailers. Simulation tests indicate that
   the risk-pooling benefits of allocation policies with two well-chosen
   intervals are comparable to those of base-stock policies with four equal
   intervals.
Z8 6
ZA 0
ZS 0
TC 48
ZB 0
ZR 0
Z9 54
SN 0025-1909
UT WOS:A1993LZ50700005
ER

PT J
AU GLYNN, PW
   IGLEHART, DL
TI NOTES - CONDITIONS FOR THE APPLICABILITY OF THE REGENERATIVE METHOD
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1108
EP 1111
DI 10.1287/mnsc.39.9.1108
PD SEP 1993
PY 1993
AB The regenerative method for estimating steady-state parameters is one of
   the basic methods in simulation output analysis. This method depends on
   central limit theorems for regenerative processes and weakly consistent
   estimates for the variance constants arising in the central limit
   theorems. A weak sufficient condition for both the central limit
   theorems and consistent estimates is given. Previous authors have
   implicitly made stronger moment assumptions which have led to strongly
   consistent variance estimates, more than is needed for the regenerative
   method to hold. The relationship between conditions for the validity of
   the regenerative method and those for the validity of standardized time
   series methods is also discussed.
ZB 0
ZS 0
Z8 0
ZR 1
ZA 0
TC 20
Z9 21
SN 0025-1909
UT WOS:A1993LZ50700006
ER

PT J
AU CHARNES, JM
   KELTON, WD
TI MULTIVARIATE AUTOREGRESSIVE TECHNIQUES FOR CONSTRUCTING
   CONFIDENCE-REGIONS ON THE MEAN VECTOR
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1112
EP 1129
DI 10.1287/mnsc.39.9.1112
PD SEP 1993
PY 1993
AB We develop a method for constructing confidence regions on the mean
   vectors of multivariate processes that is based on a vector
   autoregressive (VAR) representation of the data-generating process. A
   confidence-region-construction algorithm for a general autoregressive
   model is given. We establish the asymptotic validity of the
   confidence-region estimator (that is, the exact achievement of nominal
   coverage probability as the sample size tends to infinity) when the
   output process is a stationary vector autoregressive process of known,
   finite order. With respect to confidence-region volume, coverage
   probability, and execution time, we carry out an experimental
   performance comparison of VAR versus the methods of Bonferroni Batch
   Means (BBM), Multivariate Batch Means (MBM), and Multivariate Spectral
   Analysis (SPA). The experimental results indicate that (i) VAR delivered
   confidence regions with the smallest volume; (ii) BBM delivered
   confidence regions with the largest volume, the highest coverage and the
   smallest execution time; (iii) in small samples, all of the methods
   might yield confidence-region estimators whose coverage differs
   significantly from the nominal level; and (iv) in large samples for
   which the sample autocorrelation function indicates a vector
   autoregressive dependence structure, VAR is a viable technique for
   simulation output analysis.
ZR 0
ZS 0
Z8 1
ZA 0
TC 2
ZB 0
Z9 3
SN 0025-1909
UT WOS:A1993LZ50700007
ER

PT J
AU GREENLEAF, EA
   RAO, AG
   SINHA, AR
TI GUARANTEES IN AUCTIONS - THE AUCTION HOUSE AS NEGOTIATOR AND MANAGERIAL
   DECISION-MAKER
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1130
EP 1145
DI 10.1287/mnsc.39.9.1130
PD SEP 1993
PY 1993
AB The multimillion dollar price guarantees that an auction house can offer
   for paintings have already had a large impact on auction house profits,
   and place new demands on the auctioneer's decision making and
   negotiating skills. Yet auctioneers have not been studied as independent
   entities and decision makers. To create a price guarantee, the auction
   house and the seller must negotiate both the guarantee amount and the
   extra commission the seller pays if the auction price exceeds the
   guarantee. We present a normative model of negotiations and find the
   frontier of guarantee and commission that is the Nash bargaining
   solution. We also determine the optimal reserve that the auctioneer
   should place on guaranteed property. We find that guarantees decrease
   the auction house's expected revenue compared to a conventional auction,
   but do allow it to attract business which might otherwise be lost.
   Guarantees benefit sellers, increasing the expected value and lowering
   the variance of their auction revenue. The auctioneer's optimal strategy
   depends not only on the distribution of the artwork's auction price, but
   also the price it will bring if it fails to sell at auction. In the
   latter case the auction house must pay the seller the guarantee and then
   sell the artwork, which it now owns, in a private secondary market where
   buyers regard the property as ''damaged goods'' and lower their offers.
   Although all points on the frontier produce equal expected revenue,
   several frequently used decision making rules suggest that both parties
   may prefer a guarantee arrangement where the seller pays no additional
   commission and the guarantee has the lowest value on the frontier.
RI Greenleaf, Eric A/A-6552-2008
Z8 1
ZR 0
ZB 0
ZS 0
TC 20
ZA 0
Z9 21
SN 0025-1909
UT WOS:A1993LZ50700008
ER

PT J
AU CHINTAGUNTA, PK
TI INVESTIGATING THE SENSITIVITY OF EQUILIBRIUM PROFITS TO ADVERTISING
   DYNAMICS AND COMPETITIVE EFFECTS
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1146
EP 1162
DI 10.1287/mnsc.39.9.1146
PD SEP 1993
PY 1993
AB The author investigates the validity of the ''flat maximum
   principle''-the insensitivity of a firm's profits to changes in its
   optimal advertising level-in a duopolistic market in which advertising
   by the two firms has carryover effects. Two alternative competitive
   scenarios are examined (i) in which total industry sales are allowed to
   vary over time, and (ii) where firms are engaged in market share
   rivalry. For (i), the open-loop Nash equilibrium advertising strategies
   for the firms are derived assuming a specific sales response function
   and an infinite time horizon. A numerical analysis of the sensitivity of
   firms' profit functions to advertising expenditures is performed at
   different levels of the (a) discount rate, (b) advertising elasticity,
   and (c) advertising decay rate. An empirical illustration from the
   pharmaceutical industry is provided. Special cases of the model
   formulation are examined analytically in order to highlight the
   intuition behind the flatness of the maximum and to study the
   sensitivity of results obtained to choice of equilibrium strategy
   (closed-loop vs. open-loop). For the market share game, closed-loop
   policies are considered and the flat maximum principle is illustrated in
   the context of Coke-Pepsi rivalry in the soft drinks market.
RI Chintagunta, Pradeep K/A-4764-2017
ZS 0
ZB 0
ZA 0
ZR 0
Z8 6
TC 32
Z9 38
SN 0025-1909
UT WOS:A1993LZ50700009
ER

PT J
AU AUCAMP, DC
TI ON THE EXTENSIVE NUMBER OF PLAYS TO ACHIEVE SUPERIOR PERFORMANCE WITH
   THE GEOMETRIC MEAN STRATEGY
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1163
EP 1172
DI 10.1287/mnsc.39.9.1163
PD SEP 1993
PY 1993
AB The advantages of the Geometric Mean or Log Strategy have been well
   documented and recommended by many because a follower of this strategy
   will ultimately outperform in the long-run any other significantly
   different strategy, almost surely. This paper provides both theory and
   evidence to indicate that the ''long-run'' can be quite long in risky
   situations. These cases are typified by many business ventures and
   undiversified speculative investments in OTC securities. On the other
   hand, it is shown that the Log Strategy can ''virtually dominate'' in a
   moderate number of plays in cases when risk is low.
TC 10
ZR 0
ZS 0
ZB 0
Z8 1
Z9 11
SN 0025-1909
UT WOS:A1993LZ50700010
ER

PT J
AU WAN, Y
   WOLFF, RW
TI BOUNDS FOR DIFFERENT ARRANGEMENTS OF TANDEM QUEUES WITH NONOVERLAPPING
   SERVICE TIMES
SO MANAGEMENT SCIENCE
VL 39
IS 9
BP 1173
EP 1178
DI 10.1287/mnsc.39.9.1173
PD SEP 1993
PY 1993
AB We bound the difference in performance measures among different orders
   of tandem queues when service times are nonoverlapping. Two types of
   nonoverlapping service times, with respect to (w.r.t.) tasks and w.r.t.
   customers, are defined; it is not required that service times be
   independent. For nonoverlapping service times w.r.t. tasks, we bound the
   sample-path difference in number of customers in system by one, and
   bound the corresponding time-average difference by the traffic intensity
   of the longest station. For nonoverlapping service times w.r.t.
   customers, we bound the difference in mean sojourn time when the service
   times are bounded random variables. While we are motivated by
   probabilistic results, our methods and results are entirely
   deterministic.
TC 14
Z8 0
ZB 0
ZS 0
ZA 0
ZR 0
Z9 14
SN 0025-1909
UT WOS:A1993LZ50700011
ER

PT J
AU TVERSKY, A
   SIMONSON, I
TI CONTEXT-DEPENDENT PREFERENCES
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1179
EP 1189
DI 10.1287/mnsc.39.10.1179
PD OCT 1993
PY 1993
AB The standard theory of choice-based on value maximization-associates
   with each option a real value such that, given an offered set, the
   decision maker chooses the option with the highest value. Despite its
   simplicity and intuitive appeal, there is a growing body of data that is
   inconsistent with this theory. In particular, the relative
   attractiveness of x compared to y often depends on the presence or
   absence of a third option z, and the ''market share'' of an option can
   actually be increased by enlarging the offered set. We review recent
   empirical findings that are inconsistent with value maximization, and
   present a context-dependent model that expresses the value of each
   option as an additive combination of two components: a contingent
   weighting process that captures the effect of the background context,
   and a binary comparison process that describes the effect of the local
   context. The model accounts for observed violations of the standard
   theory and provides a framework for analyzing context-dependent
   preferences.
ZR 0
ZS 1
ZB 115
Z8 7
ZA 0
TC 619
Z9 626
SN 0025-1909
UT WOS:A1993MD61500001
ER

PT J
AU JOHNSON, RV
TI MICROCOMPUTER PERFORMANCE OF FABLE ON HOFFMANN DATA SETS
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1190
EP 1192
DI 10.1287/mnsc.39.10.1190
PD OCT 1993
PY 1993
AB Some of the legitimacy of Hoffmann's (1992) Eureka is gained from his
   statement that ''Eureka  . . .would seem to be approximately six times
   as fast (as Johnson's (1988) FABLE on the literature set). However,
   Eureka had one problem for which its solution was one station over the
   optimal, whereas FABLE's solutions were all optimal.''
TC 5
ZB 0
ZS 0
Z8 0
ZR 0
Z9 5
SN 0025-1909
UT WOS:A1993MD61500002
ER

PT J
AU HOFFMANN, TR
TI MICROCOMPUTER PERFORMANCE OF FABLE ON HOFFMANN DATA SETS - RESPONSE
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1192
EP 1193
DI 10.1287/mnsc.39.10.1192
PD OCT 1993
PY 1993
TC 5
ZS 0
ZB 0
ZR 0
Z8 0
Z9 5
SN 0025-1909
UT WOS:A1993MD61500003
ER

PT J
AU JOHNSON, RV
TI MICROCOMPUTER PERFORMANCE OF FABLE ON HOFFMANN DATA SETS - REPLY
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1193
EP 1193
DI 10.1287/mnsc.39.10.1193
PD OCT 1993
PY 1993
Z8 0
ZR 0
TC 1
ZS 0
ZB 0
Z9 1
SN 0025-1909
UT WOS:A1993MD61500004
ER

PT J
AU HENDRICKS, KB
   MCCLAIN, JO
TI THE OUTPUT PROCESSES OF SERIAL PRODUCTION LINES OF GENERAL MACHINES WITH
   FINITE BUFFERS
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1194
EP 1201
DI 10.1287/mnsc.39.10.1194
PD OCT 1993
PY 1993
AB Little is known about the interaction among manufacturing subsystems in
   a factory. The output of one manufacturing subsystem is usually the
   input to one or more others in the plant. For example, a production line
   may provide input to another manufacturing stage, a shipping system, or
   an automated parts conveyor. In all of these examples, the
   characteristics of the output from the production line can affect the
   subsequent process. This paper examines the output process of a serial
   production line of N machines with general processing time distributions
   and finite buffer capacities.
   Simulation is used to examine the effects of line length, buffer
   capacity, and buffer placement on the inter-departure distribution and
   correlation structure (autocorrelation function) of the output process
   of the production line. Results from this analysis are useful in setting
   production line design parameters and in determining the extent to which
   buffer placement can be used to control the variability of the output
   process, and thereby the amount of work-in-process present in downstream
   subsystems. Additional insights are provided to help explain why small
   buffers in production lines are normally adequate and to help us better
   understand the effects of buffers on tightly coupled production systems.
   By using a variety of processing time distributions, previously unknown
   effects attributed to skew of processing time are revealed. Since skew
   can often be reduced or eliminated by operator training, these effects
   are of particular interest since they can help to quantify some of the
   benefits of training.
Z8 0
ZR 0
ZA 0
ZS 0
TC 38
ZB 0
Z9 38
SN 0025-1909
UT WOS:A1993MD61500005
ER

PT J
AU RITCHKEN, P
   SANKARASUBRAMANIAN, L
   VIJH, AM
TI THE VALUATION OF PATH DEPENDENT CONTRACTS ON THE AVERAGE
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1202
EP 1213
DI 10.1287/mnsc.39.10.1202
PD OCT 1993
PY 1993
AB This article values option contracts based on the average price realized
   over a finite time horizon. Such contracts are of importance to traders
   who periodically transact in spot markets and who require protection
   from adverse moves in their total accrued costs realized over their
   trading horizons. Explicit valuation models for pricing a variety of
   path dependent contracts based on geometric and arithmetic averages are
   developed. The early exercise features of American contracts are
   investigated, and it is shown that this feature has significant value.
TC 46
ZB 0
ZR 0
ZS 0
Z8 1
ZA 0
Z9 47
SN 0025-1909
UT WOS:A1993MD61500006
ER

PT J
AU FARQUHAR, PH
   PRATKANIS, AR
TI DECISION STRUCTURING WITH PHANTOM ALTERNATIVES
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1214
EP 1226
DI 10.1287/mnsc.39.10.1214
PD OCT 1993
PY 1993
AB A phantom alternative is an illusory choice option-it looks real but for
   some reason is unavailable at the time a decision is made. Phantoms can
   both help and hinder successful decision making. On the one hand,
   phantoms can provide useful information on the boundaries of a decision
   problem and thus help generate new options through a restructuring of
   the problem. But phantoms can also produce biases, deception, and
   suboptimal decisions.
   We argue that phantoms should be considered explicitly in decision
   structuring rather than being allowed to work their effects
   surreptitiously. We offer guidelines on recognizing unavailable
   alternatives, utilizing the information provided by phantoms,
   counteracting phantom biases, avoiding deception in decision
   structuring, and guarding against suboptimal decisions.
ZA 0
TC 53
ZR 0
ZS 0
ZB 1
Z8 0
Z9 53
SN 0025-1909
UT WOS:A1993MD61500007
ER

PT J
AU GABA, A
TI INFERENCES WITH AN UNKNOWN NOISE-LEVEL IN A BERNOULLI PROCESS
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1227
EP 1237
DI 10.1287/mnsc.39.10.1227
PD OCT 1993
PY 1993
AB Inferences about a proportion p are often based on data generated from
   dichotomous processes, which are generally modeled as processes that are
   Bernoulli in p. In reality, the assumption that a data-generating
   process is Bernoulli in p is often violated due to the presence of
   noise. The level of noise is usually unknown and, furthermore, dependent
   on the unknown proportion in which one is interested. A specific model
   which takes into account the existence of noise is developed. Any
   arguments about p based exclusively on a likelihood analysis can lead to
   difficulties. A Bayesian approach is used, which also helps us to
   formalize a priori dependence between the proportion and the noise
   level. Empirical data are used to illustrate the model and provide some
   flavor of the implications of our uncertainty about the noise for
   inferences about a proportion.
ZS 1
Z8 0
ZB 0
TC 5
ZR 0
ZA 0
Z9 6
SN 0025-1909
UT WOS:A1993MD61500008
ER

PT J
AU SAKASEGAWA, H
   MIYAZAWA, M
   YAMAZAKI, G
TI EVALUATING THE OVERFLOW PROBABILITY USING THE INFINITE QUEUE
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1238
EP 1245
DI 10.1287/mnsc.39.10.1238
PD OCT 1993
PY 1993
AB This paper presents an approximation formula for the overflow
   probability for GI/GI/c(N) queues in terms of a queue-length
   distribution for the corresponding GI/GI/c (infinity) queues, where N is
   the total capacity of the system. The approximation is based on the
   conservation law, and on assumptions which might be acceptable if N much
   greater than c. The authors' approximation formula is numerically
   examined for various phase-type GI/GI/c(N) queues and the results show
   that the approximation is very good for practical parameter settings.
   The authors' approximation stands merely on a stationarity assumption.
   Therefore, it is also expected to be good for G/G/c(N) queues with a
   large N.
Z8 0
ZA 0
ZR 0
TC 16
ZB 0
ZS 0
Z9 16
SN 0025-1909
UT WOS:A1993MD61500009
ER

PT J
AU KAO, EPC
   SMITH, MS
TI DISCOUNTED AND PER UNIT NET REVENUES AND COSTS OF PRODUCT WARRANTY - THE
   CASE OF PHASE-TYPE LIFETIMES
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1246
EP 1254
DI 10.1287/mnsc.39.10.1246
PD OCT 1993
PY 1993
AB In a paper published in this journal, Mamer (1987) studies the expected
   costs to producers and benefits to consumers of three types of product
   warranty: the ordinary free replacement warranty, the unlimited free
   replacement warranty, and the pro-rata warranty. In addition to assuming
   a random product lifetime, Mamer's models allow for randomness in
   consumer repurchase behavior and for the possibility of an independent
   damage process acting on products sold under warranty. The criteria for
   evaluating warranty policies are discounted costs and net revenues over
   an infinite horizon, and per unit costs and net revenues. In this paper,
   we consider the case of phase-type product lifetimes. Under this
   assumption, we simplify the computation of the expected cost and revenue
   functions. Since most distributions can often be represented by
   phase-type distributions, our simplifications enhance the applicability
   of Mamer's useful yet computationally unwieldy results. For the
   per-unit-net-revenue criterion, our results supplement those of Mamer's.
   There, we also establish an interesting relation pertaining to expected
   net revenues as a function of consumer loyalty. We find that under the
   per-unit-net-revenue criterion, from the producer's perspective,
   repeated purchases by the same customer are not as profitable as one
   would intuitively conjecture. Such a counter-intuitive relation makes
   the need for being able to compute various cost and revenue functions
   more compelling-particularly when lifetimes are not exponential.
ZS 0
ZA 0
ZR 0
TC 8
Z8 0
ZB 0
Z9 8
SN 0025-1909
UT WOS:A1993MD61500010
ER

PT J
AU STEUER, RE
   SILVERMAN, J
   WHISMAN, AW
TI A COMBINED CHEBYSHEV ASPIRATION CRITERION VECTOR INTERACTIVE
   MULTIOBJECTIVE PROGRAMMING PROCEDURE
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1255
EP 1260
DI 10.1287/mnsc.39.10.1255
PD OCT 1993
PY 1993
AB In this paper we combine the Tchebycheff method of Steuer and Choo with
   Wierzbicki's Aspiration Criterion Vector method in order to form an
   improved procedure for interactive multiple objective programming. The
   Combined procedure is sensible because the Tchebycheff and Aspiration
   Criterion Vector methods possess complementary distinguishing
   characteristics, solve similar optimization problems to probe the
   nondominated set, and share a similar computer / user interface. In the
   early iterations, Tchebycheff probes of the nondominated set might be
   conducted to locate promising neighborhoods of search. In later
   iterations, Aspiration Criterion Vector probes might be used to pinpoint
   a final solution. Computational experience is reported showing the
   improved effectiveness of the Combined Procedure when employed in this
   fashion when compared against the Tchebycheff and Aspiration Criterion
   Vector methods run separately.
ZS 0
ZR 0
Z8 0
ZA 0
TC 33
ZB 0
Z9 33
SN 0025-1909
UT WOS:A1993MD61500011
ER

PT J
AU ANDERSEN, P
   PETERSEN, NC
TI A PROCEDURE FOR RANKING EFFICIENT UNITS IN DATA ENVELOPMENT ANALYSIS
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1261
EP 1265
DI 10.1287/mnsc.39.10.1261
PD OCT 1993
PY 1993
AB Data Envelopment Analysis (DEA) evaluates the relative efficiency of
   decision-making units (DMUs) but does not allow for a ranking of the
   efficient unit's themselves. A modified version of DEA based upon
   comparison of efficient DMUs relative to a reference technology spanned
   by all other units is developed. The procedure provides a framework for
   ranking efficient units and facilitates comparison with rankings based
   on parametric methods.
RI Figueiredo, Otavio H S/K-4777-2015
TC 1695
ZB 61
ZS 30
ZR 1
ZA 0
Z8 172
Z9 1882
SN 0025-1909
UT WOS:A1993MD61500012
ER

PT J
AU BANKER, RD
TI MAXIMUM-LIKELIHOOD, CONSISTENCY AND DATA ENVELOPMENT ANALYSIS - A
   STATISTICAL FOUNDATION
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1265
EP 1273
DI 10.1287/mnsc.39.10.1265
PD OCT 1993
PY 1993
AB This paper provides a formal statistical basis for the efficiency
   evaluation techniques of data envelopment analysis (DEA). DEA estimators
   of the best practice monotone increasing and concave production function
   are shown to be also maximum likelihood estimators if the deviation of
   actual output from the efficient output is regarded as a stochastic
   variable with a monotone decreasing probability density function.
   While the best practice frontier estimator is biased below the
   theoretical frontier for a finite sample size, the bias approaches zero
   for large samples. The DEA estimators exhibit the desirable asymptotic
   property of consistency, and the asymptotic distribution of the DEA
   estimators of inefficiency deviations is identical to the true
   distribution of these deviations. This result is then employed to
   suggest possible statistical tests of hypotheses based on asymptotic
   distributions.
TC 427
ZR 0
Z8 6
ZB 7
ZA 0
ZS 10
Z9 442
SN 0025-1909
UT WOS:A1993MD61500013
ER

PT J
AU AXSATER, S
   ROSLING, K
TI INSTALLATION VS ECHELON STOCK POLICIES FOR MULTILEVEL INVENTORY CONTROL
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1274
EP 1280
DI 10.1287/mnsc.39.10.1274
PD OCT 1993
PY 1993
AB This paper compares installation and echelon stock policies for
   multilevel inventory control. The major results are for serial and
   assembly systems. For (Q, r)-rules, echelon stock policies are, in
   general, superior to installation stock policies. A Kanban-policy is
   identified as a restricted type of installation stock (Q, r)-policy.
ZB 0
TC 121
ZA 0
ZR 0
ZS 0
Z8 0
Z9 121
SN 0025-1909
UT WOS:A1993MD61500014
ER

PT J
AU PINTO, MB
   PINTO, JK
   PRESCOTT, JE
TI ANTECEDENTS AND CONSEQUENCES OF PROJECT TEAM CROSS-FUNCTIONAL
   COOPERATION
SO MANAGEMENT SCIENCE
VL 39
IS 10
BP 1281
EP 1297
DI 10.1287/mnsc.39.10.1281
PD OCT 1993
PY 1993
AB Cross-functional teams can greatly facilitate the successful
   implementation of projects. This study examined the influence of a set
   four antecedent constructs (superordinate goals, accessibility, physical
   proximity and formalized rules and procedures) on the attainment of both
   cross-functional cooperation and perceived project outcomes. Through the
   use of path analysis, the results indicated that superordinate goals,
   physical proximity and project team rules and procedures have
   significant direct and/or indirect effects on project outcomes through
   influencing cross-functional cooperation. Further, cross-functional
   cooperation was a significant predictor of both perceived task and
   psychosocial project outcomes. Directions for management practice and
   future research are discussed.
TC 372
ZR 1
ZS 6
Z8 1
ZB 3
ZA 0
Z9 381
SN 0025-1909
UT WOS:A1993MD61500015
ER

PT J
AU ROTEMBERG, JJ
   SALONER, G
TI LEADERSHIP-STYLE AND INCENTIVES
SO MANAGEMENT SCIENCE
VL 39
IS 11
BP 1299
EP 1318
DI 10.1287/mnsc.39.11.1299
PD NOV 1993
PY 1993
AB We study the relationship between a firm's environment and its optimal
   leadership style. We use a model in which contracts between the firm and
   managers are incomplete so that providing incentives to subordinates is
   not straightforward. Leadership style, whether based on organizational
   culture or on the personality of the leader, then affects the incentive
   contracts that can be offered to subordinates. We show that leaders who
   empathize with their employees adopt a participatory style and that
   shareholders gain from appointing such leaders when the firm has the
   potential for exploiting numerous innovative ideas. By contrast, when
   the environment is poor in new ideas, shareholders benefit from hiring a
   more selfish (i.e., more profit maximizing) leader whose style is more
   autocratic.
RI van Lent, Laurence/G-5298-2010
ZA 0
TC 73
ZB 1
Z8 0
ZS 0
ZR 0
Z9 73
SN 0025-1909
UT WOS:A1993MJ61400001
ER

PT J
AU BAYUS, BL
TI HIGH-DEFINITION TELEVISION - ASSESSING DEMAND FORECASTS FOR A
   NEXT-GENERATION CONSUMER DURABLE
SO MANAGEMENT SCIENCE
VL 39
IS 11
BP 1319
EP 1333
DI 10.1287/mnsc.39.11.1319
PD NOV 1993
PY 1993
AB High-Definition Television promises to be the next generation of
   television. This technology has broad implications for consumer markets,
   as well as the underlying manufacturing, technology development, and R&D
   activities of firms. Under increasing pressure from various groups, the
   U.S. government must make major policy and funding decisions based on
   its assessment of the likely demand for HDTV. Three published reports
   which forecast sales of HDTV after its scheduled introduction in the
   mid-1990s are available. Unfortunately, these forecasts offer widely
   differing perspectives on HDTV's potential. This paper presents an
   approach that links product segmentation (based on historical demand
   parameters, and marketing and manufacturing related variables) and
   demand forecasting for new products. The published HDTV forecasts are
   then assessed using this segmentation scheme. Differing from the
   Congressional Budget Office's earlier evaluation, this analysis
   indicates that one report is consistent with historical data from the
   home appliance industry.
ZA 0
ZS 0
ZB 1
Z8 0
TC 62
ZR 0
Z9 62
SN 0025-1909
EI 1526-5501
UT WOS:A1993MJ61400002
ER

PT J
AU DAVIS, R
   THOMAS, LG
TI DIRECT ESTIMATION OF SYNERGY - A NEW APPROACH TO THE
   DIVERSITY-PERFORMANCE DEBATE
SO MANAGEMENT SCIENCE
VL 39
IS 11
BP 1334
EP 1346
DI 10.1287/mnsc.39.11.1334
PD NOV 1993
PY 1993
AB This study examines the linkages between relatedness and synergy in the
   context of diversification among U.S. pharmaceutical firms for the
   period 1960-1980. Rather than assume (as in the entropy, Herfindahl and
   concentric indices of diversification) that the levels of synergy
   generated by different related combinations of business units are
   identical, we estimate synergy directly using a modified version of the
   concentric index. In addition to estimating synergy using capital market
   performance of the firm as a whole, we examine the effects of nondrug
   diversification on the innovative productivity of firms' pharmaceutical
   divisions alone.
   Our two main findings are that production relatedness, such as that
   between drugs and chemicals, in fact did not imply synergy over the
   period of our study; and that the patterns of synergy for different
   types of relatedness shifted over time with the industry life cycle.
ZR 0
Z8 0
ZA 0
TC 55
ZS 1
ZB 1
Z9 56
SN 0025-1909
EI 1526-5501
UT WOS:A1993MJ61400003
ER

PT J
AU TAYUR, SR
TI STRUCTURAL-PROPERTIES AND A HEURISTIC FOR KANBAN-CONTROLLED SERIAL LINES
SO MANAGEMENT SCIENCE
VL 39
IS 11
BP 1347
EP 1368
DI 10.1287/mnsc.39.11.1347
PD NOV 1993
PY 1993
AB Kanban-controlled serial manufacturing systems have been popular in
   Japan for many years. The analytical intractibility of such systems
   makes simulation and heuristics essential in studying them. In this
   paper we develop some theoretical results-reversibility and
   dominance-that characterize the dynamics of these systems, provide
   insight into their behavior and help greatly reduce the simulation
   effort needed to study them. These structural results also provide the
   basis for developing heuristics to deal effectively with particular
   cases. Reversibility deals with certain permutations of the machines;
   dominance deals with the allocation of kanbans to cells. In addition, we
   show that if our goal is to maximize the throughput with a given total
   fixed number of cards, all of the machines should be placed in a single
   cell. These structural results hold in general because no assumptions
   are made on the processing time distribution of the machines, the number
   of cells, the total number of kanbans, or whether or not the machines
   are identical. Based on the structural results, we also develop a
   heuristic for the allocation of kanbans to a balanced line. We briefly
   describe an implementation of this model at a laminate manufacturing
   plant.
ZS 1
ZA 0
TC 59
ZB 0
ZR 0
Z8 0
Z9 60
SN 0025-1909
EI 1526-5501
UT WOS:A1993MJ61400004
ER

PT J
AU STEWART, TJ
TI USE OF PIECEWISE-LINEAR VALUE-FUNCTIONS IN INTERACTIVE MULTICRITERIA
   DECISION-SUPPORT - A MONTE-CARLO STUDY
SO MANAGEMENT SCIENCE
VL 39
IS 11
BP 1369
EP 1381
DI 10.1287/mnsc.39.11.1369
PD NOV 1993
PY 1993
AB This paper describes a Monte Carlo study conducted to evaluate the
   effects of modelling assumptions and design parameters on the behaviour
   of interactive methods for the discrete choice MCDM problem, based on
   explicit value function models. The purpose of the study is to identify
   those assumptions and parameters which lead to the most efficient use of
   preference judgements made by the decision maker, and to the greatest
   robustness to judgmental errors. It is concluded that nonlinearities in
   the value function need to be modelled, achieved here by use of a
   piecewise linear form. It was also found that search for indifference
   points, rather than using simple preference judgements alone, is of
   great advantage, best realized by expressing judgements in terms of
   pairwise trade-offs. Methods incorporating these features are highly
   robust to judgmental errors. Interactive methods of this class are
   compared with a priori fitting of similar value functions, and found to
   give a very similar quality of solution.
RI Stewart, Theodor J/E-8192-2013
OI Stewart, Theodor J/0000-0002-2107-5955
ZS 1
ZR 0
ZB 1
ZA 0
TC 30
Z8 0
Z9 31
SN 0025-1909
UT WOS:A1993MJ61400005
ER

PT J
AU DELQUIE, P
TI INCONSISTENT TRADE-OFFS BETWEEN ATTRIBUTES - NEW EVIDENCE IN PREFERENCE
   ASSESSMENT BIASES
SO MANAGEMENT SCIENCE
VL 39
IS 11
BP 1382
EP 1395
DI 10.1287/mnsc.39.11.1382
PD NOV 1993
PY 1993
AB One of the fundamental postulates of rational choice is that preferences
   manifested by an individual towards alternatives should only depend on
   the merits of these alternatives and not on extraneous, irrelevant
   factors. Violations of this basic principle, so-called preference
   reversals, have puzzled researchers for over twenty years and raised
   concerns about the use of preference modeling in decision analysis. The
   present work seeks to further determine the nature of these phenomena,
   in particular the role played by response mode in certain types of
   preference reversals. Hershey and Schoemaker (1985) found Probability
   and Certainty Equivalents to differ systematically and attributed this
   difference to a framing effect. Here, we generalize their experimental
   design to control for framing effects and study biases on a larger
   scope. Our results show that biases do not disappear in the absence of
   framing, instead they reveal a clear and pervasive bias occurring under
   more controlled experimental conditions than previously known: direct
   trade-offs between two attributes X and Y are biased depending on
   whether X is traded off against Y, or Y traded off against X. From among
   several hypotheses, the data lend support to the general principle of
   compatibility (Tversky et al. 1988; Slovic et al. 1990), which implies
   that an attribute receives more relative weight when it is used as
   ''currency'' in trading off.
ZB 0
TC 62
ZA 0
ZS 2
Z8 0
ZR 0
Z9 63
SN 0025-1909
UT WOS:A1993MJ61400006
ER

PT J
AU GOLEC, JH
TI THE EFFECTS OF INCENTIVE COMPENSATION CONTRACTS ON THE RISK AND RETURN
   PERFORMANCE OF COMMODITY TRADING ADVISERS
SO MANAGEMENT SCIENCE
VL 39
IS 11
BP 1396
EP 1406
DI 10.1287/mnsc.39.11.1396
PD NOV 1993
PY 1993
AB This paper shows that commodity trading advisors' (CTAs) investment
   performance may be partially explained by their incentive compensation
   contracts. Contracts include base, incentive and asset parameters. The
   relationships between contract parameters and performance are
   theoretically indeterminate but are examined here empirically. Results
   indicate that incentive parameters are positively related to return
   means and standard deviations. The dollar amounts of assets CTAs manage
   are negatively related to return means and standard deviations,
   supporting Elton et al.'s (1987, 1989) finding that CTA performance
   falls after public offerings of commodity funds. Intuitively, since
   dollar fees are a function of assets, at the higher asset and fee levels
   achieved through commodity fund offerings, CTAs may safeguard assets and
   fees by pursuing less risky investment strategies.
TC 3
ZA 0
Z8 0
ZS 0
ZB 0
ZR 0
Z9 3
SN 0025-1909
UT WOS:A1993MJ61400007
ER

PT J
AU HUDDART, S
TI THE EFFECT OF A LARGE SHAREHOLDER ON CORPORATE VALUE
SO MANAGEMENT SCIENCE
VL 39
IS 11
BP 1407
EP 1421
DI 10.1287/mnsc.39.11.1407
PD NOV 1993
PY 1993
AB This article analyzes the value of a corporation as a function of its
   ownership structure. Shareholders can acquire costly information about
   the manager's effort to produce output. Concentrating share ownership
   leads the largest shareholder to (i) acquire more precise signals of
   effort and (ii) modify the compensation contract. Better monitoring
   increases output, and hence firm value. However, the (risk averse) large
   shareholder bears more idiosyncratic firm risk as his stake in the firm
   increases. These forces equilibrate at a unique welfare maximizing
   ownership structure. Under a strong condition on the purchase or sale of
   shares by large stockholders, investors have incentives to trade toward
   the ownership structure that maximizes the social surplus. When all
   investors are price takers only a diffuse ownership structure can arise
   in a competitive equilibrium.
RI Huddart, Steven J/I-1469-2013
OI Huddart, Steven J/0000-0002-3301-4375
ZR 0
ZS 0
ZA 1
TC 115
Z8 5
ZB 0
Z9 121
SN 0025-1909
UT WOS:A1993MJ61400008
ER

PT J
AU HILLER, RS
   ECKSTEIN, J
TI STOCHASTIC DEDICATION - DESIGNING FIXED INCOME PORTFOLIOS USING
   MASSIVELY-PARALLEL BENDERS DECOMPOSITION
SO MANAGEMENT SCIENCE
VL 39
IS 11
BP 1422
EP 1438
DI 10.1287/mnsc.39.11.1422
PD NOV 1993
PY 1993
AB Drawing on recent developments in discrete time fixed income options
   theory, we propose a stochastic programming procedure, which we call
   stochastic dedication, for managing asset/liability portfolios with
   interest rate contingent claims. The model uses scenario generation to
   combine deterministic dedication techniques with stochastic duration
   matching methods, and provides the portfolio manager with a risk/return
   Pareto optimal frontier from which a portfolio may be selected based on
   individual risk attitudes. We employ a fixed income risk metric that can
   be interpreted as the fair market value of a collection of interest rate
   options that eliminates bankruptcy risk from the asset/liability
   portfolio. We incorporate this metric into a risk/return stochastic
   optimization model, using a binomial lattice sampling procedure to
   construct interest rate paths and cash flow streams from an
   arbitrage-free term structure model. The resulting parametric linear
   program has a particularly simple subproblem structure, and we have been
   able to solve it using resource-directed decomposition on a massively
   parallel computer system, the Connection Machine CM-2. We take a novel
   approach that uses a standard serial simplex method to solve the master
   problem, but generates scenarios and Benders cuts in a massively
   parallel manner. We discuss the performance of this implementation and
   present the results for a simple pension fund immunization problem.
ZB 0
ZR 1
TC 37
ZS 0
Z8 0
ZA 0
Z9 38
SN 0025-1909
EI 1526-5501
UT WOS:A1993MJ61400009
ER

PT J
AU MORRISON, DG
TI LARRIVEE,JUDITH,E. 1947-1993
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1438
EP 1439
PD DEC 1993
PY 1993
ZB 0
ZS 0
ZR 0
TC 0
Z8 0
ZA 0
Z9 0
SN 0025-1909
UT WOS:A1993MQ37900001
ER

PT J
AU PAICH, M
   STERMAN, JD
TI BOOM, BUST, AND FAILURES TO LEARN IN EXPERIMENTAL MARKETS
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1439
EP 1458
DI 10.1287/mnsc.39.12.1439
PD DEC 1993
PY 1993
AB Boom and bust is a pervasive dynamic for new products- Word of mouth,
   marketing, and learning curve effects can fuel rapid growth, often
   leading to overcapacity, price war, and bankruptcy. Previous experiments
   suggest such dysfunctional behavior can be caused by systematic
   ''misperceptions of feedback,'' where decision makers do not adequately
   account for critical feedbacks, time delays, and nonlinearities which
   condition system dynamics. However, prior studies often failed to vary
   the strength of these feedbacks as treatments, omitted market processes,
   and failed to allow for learning. A decision making task portraying new
   product dynamics is used to test the theory by varying the strength of
   kev feedback processes in a simulated market. Subjects performed the
   task repeatedly, encouraging learning. Nevertheless, performance
   relative to potential is poor and is severely degraded when the feedback
   complexity of the environment is high, supporting the misperception of
   feedback hypothesis. The negative effects of feedback complexity on
   performance were not moderated by experience, even though average
   performance improved. Models of the subjects' decision making heuristics
   are estimated; changes over trials in estimated cue weights explain why
   subjects improve on average but fail to gain insight into the dynamics
   of the system. Though conditions for learning are excellent, experience
   does not appear to mitigate the misperceptions of feedback or systematic
   dysfunction they cause in dynamic decision making tasks. We discuss
   implications for educational use of simulations and games.
ZR 0
TC 176
ZA 0
ZS 0
ZB 7
Z8 1
Z9 177
SN 0025-1909
UT WOS:A1993MQ37900002
ER

PT J
AU MORRICE, DJ
   SCHRUBEN, LW
TI SIMULATION FACTOR SCREENING USING HARMONIC-ANALYSIS
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1459
EP 1476
DI 10.1287/mnsc.39.12.1459
PD DEC 1993
PY 1993
AB In this paper, we provide a quantitative approach to Frequency Domain
   Methodology (FDM) using harmonic analysis. For a certain class of
   metamodels, we give the frequency domain hypothesis and develop the
   corresponding hypothesis test. Minimum simulation model run length
   information for FDM is provided for a subclass of these metamodels. We
   discuss factor screening designs to increase the power of the test and
   illustrate these designs by an example.
ZB 1
ZS 0
TC 17
ZR 0
Z8 0
Z9 17
SN 0025-1909
UT WOS:A1993MQ37900003
ER

PT J
AU JOHNSON, ME
   BRANDEAU, ML
TI AN ANALYTIC MODEL FOR DESIGN OF A MULTIVEHICLE AUTOMATED GUIDED VEHICLE
   SYSTEM
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1477
EP 1489
DI 10.1287/mnsc.39.12.1477
PD DEC 1993
PY 1993
AB We consider the problem of designing a multivehicle automated guided
   vehicle system (AGVS) to supplement an existing nonautomated material
   handling system. The AGVS consists of a pool of vehicles that deliver
   raw components from a central storage area to workcenters throughout the
   factor floor. The objective is to determine which workcenters warrant
   automated component delivery and the number of vehicles required to
   service those workcenters, to maximize the benefit of the AGVS, subject
   to a constraint that the average waiting time for material transport in
   the system not exceed a predefined limit, The pool of vehicles is
   modeled as an M/G/c queuing system and the design model is formulated as
   a binary integer program with nonlinear waiting time constraints, which
   are expressed by approximate queueing formula. We develop two different
   implicit enumeration algorithms to exactly solve the analytical model.
   We illustrate our model with an example of an actual AGVS design problem
   at Hewlett-Packard, and we present computational experience for other
   example design problems. We show how sensitivity analysis can be used to
   ensure that the analytical model yields an optimal solution to the
   design problem.
Z8 1
ZS 0
ZA 0
ZB 0
ZR 0
TC 35
Z9 36
SN 0025-1909
UT WOS:A1993MQ37900004
ER

PT J
AU NANDAKUMAR, P
   MORTON, TE
TI NEAR MYOPIC HEURISTICS FOR THE FIXED-LIFE PERISHABILITY PROBLEM
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1490
EP 1498
DI 10.1287/mnsc.39.12.1490
PD DEC 1993
PY 1993
AB This paper details the application of a class of heuristics to the
   Fixed-life Perishability Problem formulated by Nahmias (1975a) and Fries
   (1975). Various assumptions for this model include i.i.d. demand, linear
   ordering, holding and penalty costs. Goods have a known fixed lifetime
   and perished goods cause a linear outdating cost to be incurred. The
   approach we use, that of developing heuristics from 'near myopic'
   bounds, involves viewing periodic inventory problems in the framework of
   the classic ''newsboy'' model. We exploit various properties of the
   problem under consideration to derive tight bounds on the newsboy
   parameters, thus leading to efficient bounds on the order quantities.
   Computational studies reveal that the heuristic policies are near
   optimal, and are easy to compute.
ZR 0
TC 73
ZA 0
Z8 3
ZB 0
ZS 0
Z9 76
SN 0025-1909
UT WOS:A1993MQ37900005
ER

PT J
AU GALLEGO, G
   YAO, DD
   MOON, I
TI OPTIMAL-CONTROL OF A MANUFACTURING PROCESS THAT INVOLVES TRIAL RUNS
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1499
EP 1505
DI 10.1287/mnsc.39.12.1499
PD DEC 1993
PY 1993
AB We study a manufacturing process that is quite common in semiconductor
   wafer fabrication. In generic terms, the job to be processed consists of
   J units. To process the job, a ''setup'' is required, followed by
   routine processing and testing. In principle, the entirety of the job
   can be set up and processed in a single batch. However, the setup is
   prone to failure, leading to loss of units. Hence, in practice trial
   runs are often conducted, with each trial involving a small batch of
   units. Here we identify an optimal control of such processes. The policy
   prescribes a maximum of k* (less-than-or-equal-to J) single-unit trial
   runs. To establish optimality, we use the recently developed notion of
   stochastic convexity/concavity and related machinery.
RI Gallego, Guillermo/AAK-1549-2020; MOON, ILKYEONG/C-2406-2013
OI Gallego, Guillermo/0000-0002-9664-3750; MOON,
   ILKYEONG/0000-0002-7072-1351
ZB 0
Z8 0
ZA 0
TC 4
ZR 0
ZS 0
Z9 4
SN 0025-1909
UT WOS:A1993MQ37900006
ER

PT J
AU GRABOWSKI, M
   WALLACE, WA
TI AN EXPERT-SYSTEM FOR MARITIME PILOTS - ITS DESIGN AND ASSESSMENT USING
   GAMING
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1506
EP 1520
DI 10.1287/mnsc.39.12.1506
PD DEC 1993
PY 1993
AB Increased maritime traffic, new types of vessels, and construction of
   oil and gas producing structures have made navigating in close waters
   more hazardous.  In addition, attempts to increase shipboard
   productivity have resulted in fewer personnel on board the vessel. This
   paper reports on the development and evaluation of a prototype expert
   system to support the cognitive processes involved in piloting:
   maneuvering and collision avoidance, and the practice of good
   seamanship. A model was constructed and implemented in a frame- and
   rule-based representation. The system was assessed using gaming with
   novice pilots in a merchant marine training facility. The results showed
   significant improvement in the bridge watch team performance, but no
   significant improvement in vessel performance in terms of trackkeeping.
   The paper concludes with a discussion of the motor, perceptual, and
   cognitive skills needed for piloting and how they could be supported by
   expert system technology as part of an integrated bridge system, an
   operational center for navigational and supervisory tasks aboard a ship.
ZS 0
ZR 0
Z8 2
ZA 0
ZB 0
TC 21
Z9 23
SN 0025-1909
UT WOS:A1993MQ37900007
ER

PT J
AU CLOTFELTER, CT
   COOK, PJ
TI THE GAMBLERS FALLACY IN LOTTERY PLAY
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1521
EP 1525
DI 10.1287/mnsc.39.12.1521
PD DEC 1993
PY 1993
AB The ''gambler's fallacy'' is the belief that the probability of an event
   is lowered when that event has recently occurred, even though the
   probability of the event is objectively known to be independent from one
   trial to the next. This paper provides evidence on the time pattern of
   lottery participation to see whether actual behavior is consistent with
   this fallacy. Using data from the Maryland daily numbers game, we find a
   clear and consistent tendency for the amount of money bet on a
   particular number to fall sharply immediately after it is drawn, and
   then gradually to recover to its former level over the course of several
   months. This pattern is consistent with the hypothesis that lottery
   players are in fact subject to the gambler's fallacy.
OI Cook, Philip/0000-0001-5094-9052
TC 116
ZB 14
ZS 1
Z8 2
ZA 0
ZR 0
Z9 118
SN 0025-1909
UT WOS:A1993MQ37900008
ER

PT J
AU WINKLER, RL
   POSES, RM
TI EVALUATING AND COMBINING PHYSICIANS PROBABILITIES OF SURVIVAL IN AN
   INTENSIVE-CARE UNIT
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1526
EP 1543
DI 10.1287/mnsc.39.12.1526
PD DEC 1993
PY 1993
AB In this paper, probabilities of survival assessed by phvsicians for
   patients admitted to an intensive care unit are studied. The
   probabilities from each of four types of physicians are evaluated on an
   overall basis and in terms of specific attributes, and the groups are
   compared. The physicians with the most experience and expertise perform
   better overall. All four groups appear to be reasonably well calibrated,
   and the key factor in relative overall performance is the level of
   discrimination provided by the probabilities. Averages of two, three,
   and four probabilities for each individual patient are also analyzed. As
   the number of the probabilities in the average increases, performance
   improves on average on all dimensions, although the best overall
   performance is exhibited by a combination of probabilities from the two
   physician types performing best individually. Some comparisons are made
   with previous work, and implications for probability assessment and
   combination in medicine and more generally in other areas of application
   are discussed. Important characteristics of the study are the fact that
   it was conducted on-line in a real setting, the involvement of
   individuals with different levels of expertise, the use of a true
   predictive situation with a clearly-defined event, the consideration of
   multiple dimensions of the quality of judgments, and the collection of
   multiple probabilities for each case to permit the investigation of a
   variety of possible combinations of probabilities.
ZB 4
Z8 2
ZS 0
ZA 0
TC 52
ZR 0
Z9 54
SN 0025-1909
UT WOS:A1993MQ37900009
ER

PT J
AU GUTMAN, E
   YAGIL, J
TI A PRACTICAL DERIVED LEASE RATE ALGORITHM
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1544
EP 1551
DI 10.1287/mnsc.39.12.1544
PD DEC 1993
PY 1993
AB Underlying the widely used multiple-investment-sinking fund (MISF)
   method for lease evaluation is the determination of a derived lease rate
   which is a specific rate that provides the lessor with the required
   yield on equity. To compute this derived lease rate, trial-and-error
   techniques are traditionally used. In addition to being based on
   trial-and-error, the employment of these techniques requires a
   specification of the precise time structure of the various types of cash
   flows involved, and this can be somewhat technically cumbersome. To
   overcome these shortcomings, this study presents a mathematical
   derivation of a formal expression for the derived lease rate. Due to the
   widespread use of the MISF method, it seems that the formal expression
   developed here can be very useful for decision makers (at both the
   corporate as well as the individual-investor levels) in determining the
   derived lease rate in practice. Another desirable property of the model
   is that it can be easily employed for the purpose of studying the
   effects of changes in the various parameters involved on the derived
   lease rate.
ZR 0
ZA 0
Z8 0
ZS 0
TC 1
ZB 0
Z9 1
SN 0025-1909
UT WOS:A1993MQ37900010
ER

PT J
AU FEINSTEIN, CD
   THAPA, MN
TI A REFORMULATION OF A MEAN-ABSOLUTE DEVIATION PORTFOLIO OPTIMIZATION
   MODEL
SO MANAGEMENT SCIENCE
VL 39
IS 12
BP 1552
EP 1553
DI 10.1287/mnsc.39.12.1552
PD DEC 1993
PY 1993
AB The purpose of this note is to present a reformulation of the model
   presented by Konno and Yamazaki (1991). In their paper, it was claimed
   that (under the assumption that there is no upper limit on the
   investment in an asset) the number of nonzero assets in the optimal
   portfolio is at most 2T + 2, where T is the number of time periods in
   the data base used to approximate the parameters of the return
   distributions of the assets. The formulation we present, which is shown
   to be equivalent to that of Konno and Yamazaki, has a bound of T + 2 on
   the number of nonzero assets in the optimal portfolio.
TC 55
ZR 0
ZS 0
ZA 0
Z8 9
ZB 1
Z9 64
SN 0025-1909
UT WOS:A1993MQ37900011
ER

PT J
AU AHARONI, Y
   BURTON, RM
TI IS MANAGEMENT SCIENCE INTERNATIONAL - IN SEARCH OF UNIVERSAL RULES
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 1
EP 3
PD JAN 1994
PY 1994
Z8 0
ZB 0
ZA 0
ZR 0
TC 24
ZS 1
Z9 24
SN 0025-1909
UT WOS:A1994NW22100001
ER

PT J
AU HOFSTEDE, G
TI MANAGEMENT SCIENTISTS ARE HUMAN
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 4
EP 13
DI 10.1287/mnsc.40.1.4
PD JAN 1994
PY 1994
AB The culture of the national environment in which an organization
   operates affects the management process through the collective mental
   programming of its members, its managers, and the management scientists
   who offer their theories. Four dimensions of national culture
   differences have been found. Among other things, they affect the
   implicit models in people's minds of what the act of organizing means.
   Among the pioneers in management science around 1900, differences along
   these dimensions are already noticeable. A fifth dimension was added
   when the research instrument used was designed exclusively by Chinese
   scholars, and it provides a cultural explanation for the economic
   success of East Asian countries in the past quarter century. At the same
   time, it highlights the influence of the culture of the management
   scientist on the research questions and the resulting theories.
ZB 1
Z8 3
TC 277
ZR 0
ZS 5
ZA 0
Z9 285
SN 0025-1909
UT WOS:A1994NW22100002
ER

PT J
AU BALIGH, HH
TI COMPONENTS OF CULTURE - NATURE, INTERCONNECTIONS, AND RELEVANCE TO THE
   DECISIONS ON THE ORGANIZATION STRUCTURE
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 14
EP 27
DI 10.1287/mnsc.40.1.14
PD JAN 1994
PY 1994
AB Culture is defined in terms of components and parts. The logical nature
   of the components and of the connections between them are identified and
   analyzed. These connections are used as a basis for the argument that
   there is a meaningful concept of the fit between the components of the
   organization structure and those of its cultural setting. This concept
   of fit is defined and the values it may logically take are identified. A
   theory on the goodness and badness of fit between structure components
   and culture components is discussed and two of its many pieces are
   developed in detail.
ZS 1
ZB 0
TC 31
ZR 0
ZA 0
Z8 0
Z9 32
SN 0025-1909
UT WOS:A1994NW22100003
ER

PT J
AU ROSENZWEIG, PM
TI WHEN CAN MANAGEMENT SCIENCE RESEARCH BE GENERALIZED INTERNATIONALLY
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 28
EP 39
DI 10.1287/mnsc.40.1.28
PD JAN 1994
PY 1994
AB Discussion about international generalizability has rarely addressed the
   full scope of management science research. This paper identifies a
   number of obstacles to international generalizability, and shows how
   they affect technical systems research and social systems research in
   different ways. Examples of management science research are examined
   critically for their validity elsewhere in the world. Implications are
   discussed for the interpretation of existing research and for the design
   of research.
ZS 2
ZA 0
Z8 1
ZR 0
TC 80
ZB 0
Z9 82
SN 0025-1909
UT WOS:A1994NW22100004
ER

PT J
AU LACHMAN, R
   NEDD, A
   HININGS, B
TI ANALYZING CROSS-NATIONAL MANAGEMENT AND ORGANIZATIONS - A THEORETICAL
   FRAMEWORK
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 40
EP 55
DI 10.1287/mnsc.40.1.40
PD JAN 1994
PY 1994
AB The differential social control embedded in core and periphery values
   indigenous to a cultural setting, and the availability of resources in
   that setting, are discussed as critical factors for the effective
   adaptation of organizations and management practices transferred across
   cultural boundaries. The relationships between these factors and
   organizational structure, processes, and behavior, are analyzed and
   specified in a theoretical framework. The framework postulates the
   importance of congruent or, at least, accommodative relationships
   between the core values dominating the local setting, and those
   underlying transferred practices for the effectiveness of ''imported''
   organizational practices. Four main contingencies of local-imported
   values' incongruence are described, and their implications for ''entry''
   and ''coping'' strategies of cross-national organizations are discussed.
   The framework also offers a scheme for generating hypotheses regarding
   the effects of values on structures and behavior in cross-national
   organizations. The theoretical and managerial implications of the scheme
   are discussed and illustrated.
Z8 0
ZR 0
ZS 2
TC 94
ZB 0
ZA 0
Z9 96
SN 0025-1909
UT WOS:A1994NW22100005
ER

PT J
AU SHENKAR, O
   VONGLINOW, MA
TI PARADOXES OF ORGANIZATIONAL THEORY AND RESEARCH - USING THE CASE OF
   CHINA TO ILLUSTRATE NATIONAL CONTINGENCY
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 56
EP 71
DI 10.1287/mnsc.40.1.56
PD JAN 1994
PY 1994
AB Chinese organizations are used in this paper to assess the universality
   of the macro and micro theories of organization that have been largely
   developed in North America. The analysis suggests that the theories vary
   in their degree of applicability to the Chinese context. While some
   theories, such as population ecology, seem to be clearly inapplicable,
   others, such as the equity theory of motivation, are more suitable,
   though they all require significant adjustment before they can be used
   to study and interpret the structure and processes of Chinese
   enterprises, and the attitudes and behavior of those employed in them.
   Making the adjustment, however, is likely to lead to positive
   developments in organizational theory.
ZS 2
TC 204
ZR 0
ZA 0
Z8 2
ZB 1
Z9 207
SN 0025-1909
UT WOS:A1994NW22100006
ER

PT J
AU GRAHAM, JL
   MINTU, AT
   RODGERS, W
TI EXPLORATIONS OF NEGOTIATION BEHAVIORS IN 10 FOREIGN CULTURES USING A
   MODEL DEVELOPED IN THE UNITED-STATES
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 72
EP 95
DI 10.1287/mnsc.40.1.72
PD JAN 1994
PY 1994
AB The universality of a problem-solving model of business negotiations is
   explored using 700 business people from 11 cultures as participants in a
   bargaining simulation. Both theoretical and measurement issues are
   considered using structural equations and partial least squares as the
   primary data analysis approaches. The results regarding the universality
   question are equivocal-findings varied across cultural groups in most
   cases. However, the theoretical model still appears to be a useful tool
   for understanding how business negotiations vary across cultural groups.
Z8 1
ZA 0
TC 134
ZB 0
ZR 0
ZS 2
Z9 136
SN 0025-1909
UT WOS:A1994NW22100007
ER

PT J
AU GHOSHAL, S
   KORINE, H
   SZULANSKI, G
TI INTERUNIT COMMUNICATION IN MULTINATIONAL-CORPORATIONS
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 96
EP 110
DI 10.1287/mnsc.40.1.96
PD JAN 1994
PY 1994
AB In this paper we investigate some of the organizational factors that
   influence subsidiary-headquarters and intersubsidiary communication in
   multinational companies. Our study is based on data collected from 164
   senior managers working in 14 different national subsidiaries within the
   consumer electronics division of Matsushita, a Japanese company, and 84
   senior managers working in nine different national subsidiaries within
   the same business of N.V. Philips, the Holland-based competitor of
   Matsushita. We show that while subsidiary autonomy has no discernable
   influence on interunit communication, interpersonal relationships
   developed through lateral networking mechanisms such as joint work in
   teams, taskforces, and meetings have significant positive effects on the
   frequency of both subsidiary-headquarters and intersubsidiary
   communication. The findings are consistent in the two companies, one
   Japanese and the other European, and the underlying theoretical
   propositions appear applicable across borders.
RI Szulanski, Gabriel/B-3626-2010
ZS 1
ZA 0
ZR 0
TC 288
Z8 4
ZB 2
Z9 293
SN 0025-1909
UT WOS:A1994NW22100008
ER

PT J
AU FARLEY, JU
   LEHMANN, DR
TI CROSS-NATIONAL LAWS AND DIFFERENCES IN MARKET RESPONSE
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 111
EP 122
DI 10.1287/mnsc.40.1.111
PD JAN 1994
PY 1994
AB International differences in general, and cultural differences in
   particular, exert profound influence on what people buy. In modeling
   market response, highly visible international differences in purchase
   behavior seem to lead to an assumption by management scientists that
   there are large parallel international differences in market response to
   such things as price and advertising. In an interpretive review of
   market response models, we do find international differences in response
   parameters, but we also find that parameter differences due to
   cross-national factors tend to be smaller than differences related to
   technical characteristics of the model or to product/market specifics.
   We suggest two new intermediate categories of generalizability between
   the extremes of ''everything is the same'' and ''everything is
   different.'' We also argue that one promising approach to international
   generalization is through appropriate statistical adjustment of
   parameters from existing models.
ZS 1
TC 73
Z8 1
ZB 0
ZR 0
ZA 0
Z9 75
SN 0025-1909
EI 1526-5501
UT WOS:A1994NW22100009
ER

PT J
AU KOGUT, B
   KULATILAKA, N
TI OPERATING FLEXIBILITY, GLOBAL MANUFACTURING, AND THE OPTION VALUE OF A
   MULTINATIONAL NETWORK
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 123
EP 139
DI 10.1287/mnsc.40.1.123
PD JAN 1994
PY 1994
AB The multinational corporation is a network of activities located in
   different countries. The value of this network derives from the
   opportunity to benefit from uncertainty through the coordination of
   subsidiaries which are geographically dispersed. We model this
   coordination as the operating flexibility to shift production between
   two manufacturing plants located in different countries. A stochastic
   dynamic programming model treats explicitly this flexibility as
   equivalent to owning an option, the value of which is dependent upon the
   real exchange rate. The model is extended to analyze hysteresis effects
   and within-country growth options. We show that the management of
   across-border coordination has led to changes in the heuristic rules
   used for performance evaluation and transfer pricing.
Z8 13
ZB 1
ZA 0
ZS 2
TC 551
ZR 0
Z9 564
SN 0025-1909
UT WOS:A1994NW22100010
ER

PT J
AU EUN, CS
   RESNICK, BG
TI INTERNATIONAL DIVERSIFICATION OF INVESTMENT PORTFOLIOS UNITED-STATES AND
   JAPANESE PERSPECTIVES
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 140
EP 161
DI 10.1287/mnsc.40.1.140
PD JAN 1994
PY 1994
AB In this paper, we analyze the gains from international diversification
   of investment portfolios from the Japanese as well as the U.S.
   perspectives. The major findings of this paper include: First, the
   'potential' gains from international, as opposed to purely domestic,
   diversification are much greater for U.S. investors than for Japanese
   investors. For U.S. investors, the gains accrue not so much in terms of
   lower risk as in terms of higher return, and the opposite holds for
   Japanese investors. Second, using various 'ex ante' international
   investment strategies designed to control parameter uncertainty, U.S.
   investors can realize substantial gains from international
   diversification in out-of-sample periods. Japanese investors, however,
   can gain relatively little. Third, hedging exchange risk generally
   allows the U.S., but not Japanese, investors to benefit more from
   international diversification. For U.S. investors, the international
   bond diversification with exchange risk hedging offers a superior
   risk-return trade-off than the international stock diversification, with
   or without hedging.
Z8 0
TC 38
ZA 0
ZS 1
ZB 0
ZR 0
Z9 39
SN 0025-1909
UT WOS:A1994NW22100011
ER

PT J
AU CHENG, JLC
TI ON THE CONCEPT OF UNIVERSAL KNOWLEDGE IN ORGANIZATIONAL SCIENCE -
   IMPLICATIONS FOR CROSS-NATIONAL RESEARCH
SO MANAGEMENT SCIENCE
VL 40
IS 1
BP 162
EP 168
DI 10.1287/mnsc.40.1.162
PD JAN 1994
PY 1994
AB This paper argues that the present conception of universal knowledge as
   generalized findings is incomplete and has limited the role of
   cross-national research to one of validating results obtained from
   single-nation studies. An alternative view is proposed which recognizes
   that there are two types of research findings that can be applied
   cross-nationally: (1) findings that are invariant across different
   national settings, and (2) findings that incorporate the societal
   context into the analysis of the phenomenon under study. This conception
   of universal knowledge is more inclusive in scope and suggests an
   expanded role for cross-national research in organizational inquiry. The
   new role will offer exciting opportunities for the field of
   organizational science, including its enhanced ability to discover
   knowledge that has both universal applicability and global relevance.
Z8 3
ZA 0
ZR 0
ZS 0
TC 39
ZB 0
Z9 42
SN 0025-1909
UT WOS:A1994NW22100012
ER

PT J
AU LYNCH, JG
   BUZAS, TE
   BERG, SV
TI REGULATORY MEASUREMENT AND EVALUATION OF TELEPHONE SERVICE QUALITY
SO MANAGEMENT SCIENCE
VL 40
IS 2
BP 169
EP 194
DI 10.1287/mnsc.40.2.169
PD FEB 1994
PY 1994
AB Regulators of utilities that operate as local monopolies would like to
   set prices or allow rates of return based upon the quality of a
   utility's service. However, quality is highly multidimensional.
   Traditionally, regulators have collected measures of quality on many
   separate dimensions, and compared performance on these dimensions to
   explicit pass-fail standards. They have lacked a method of combining
   complex patterns of substandard and superstandard performance on these
   many dimensions to arrive at an overall evaluation of the quality of
   service. To redress this problem, we first describe the information
   processing problems regulators encounter when they attempt to integrate
   this complex array of information intuitively, and the problems that
   arise when the link between service quality (as reflected in patterns of
   passed and failed standards) and regulatory incentives is not made
   explicit to utility management. We develop a bootstrapped method for
   formalizing each expert regulator's evaluation policy using hierarchical
   conjoint analysis, and apply this method to the evaluation of local
   telephone companies by the Florida Public Service Commission (FPSC). We
   show that experts within the FPSC, the regulated utilities, and a large
   telephone customer exhibit very high agreement about how the various
   dimensions of quality should be differentially weighted. We derive a
   consensus measure of overall quality, Q, and identify a score associated
   with meeting all standards exactly, Q*. Utilities can then be rewarded
   based upon whether or not they exceed Q*, rather than on the basis of
   how many standards are met. Compared with a pattern in which each
   standard is met exactly, there exist patterns of mixed substandard and
   superstandard performance on the individual dimensions of quality that
   are less costly to produce and higher in overall quality. We compare
   utility incentives when rewards are based upon Q to those under the
   current pass
RI Lynch, John G./AAV-5203-2020; Lynch, John/A-8595-2009
OI Lynch, John G./0000-0002-4094-3738; Lynch, John/0000-0002-4094-3738
TC 28
ZB 0
ZS 0
ZA 0
ZR 0
Z8 0
Z9 28
SN 0025-1909
UT WOS:A1994NW22200001
ER

PT J
AU FEICHTINGER, G
   HARTL, RF
   SETHI, SP
TI DYNAMIC OPTIMAL-CONTROL MODELS IN ADVERTISING - RECENT DEVELOPMENTS
SO MANAGEMENT SCIENCE
VL 40
IS 2
BP 195
EP 226
DI 10.1287/mnsc.40.2.195
PD FEB 1994
PY 1994
AB This paper presents a review of recent developments that have taken
   place in the area of dynamic optimal control models in advertising
   subsequent to the comprehensive survey of the literature by Sethi in
   1977. The basic problem underlying these models is that of determining
   optimal advertising expenditures and possibly other variables of
   interest over time for a firm or a group of competing firms under
   consideration. This optimization is done subject to some dynamics that
   define how these variables translate into sales and in tum, into
   profits. The purpose of this update is twofold. On the one hand, new
   contributions in the areas already treated in the earlier survey are
   reviewed. On the other hand, new trends in the advertising literature
   since 1977, such as quality as an additional marketing instrument,
   cumulative sales models, pulsing advertising, and advertising as a part
   of corporate models of the firm, are discussed. The models covered in
   this update are organized under six headings: models with capital stocks
   generated by advertising, price, and quality, sales-advertising response
   models, cumulative sales models for durable goods, models with more than
   one state variables in the advertising process, models incorporating
   interaction with other functional areas, and competitive models. The
   discussion involves specifications, methods used, results, empirical
   validation, if any, and their economic significance. The survey
   concludes with suggestions for extensions and future directions of
   research.
RI Sethi, Suresh P/C-4517-2012; Hartl, Richard F/C-7043-2017
OI Hartl, Richard F/0000-0002-0461-0979
Z8 8
ZS 1
ZR 0
TC 210
ZA 0
ZB 2
Z9 218
SN 0025-1909
UT WOS:A1994NW22200002
ER

PT J
AU COHEN, WM
   LEVINTHAL, DA
TI FORTUNE FAVORS THE PREPARED FIRM
SO MANAGEMENT SCIENCE
VL 40
IS 2
BP 227
EP 251
DI 10.1287/mnsc.40.2.227
PD FEB 1994
PY 1994
AB A critical factor in industrial competitiveness is the ability of firms
   to exploit new technological developments. We term this ability a firm's
   absorptive capacity and argue that such a capability not only enables a
   firm to exploit new extramural knowledge, but to predict more accurately
   the nature of future technological advances. We develop a stylized model
   in which we focus exclusively on firms' decisions to invest in their
   absorptive capacities. We first examine a monopolist's investment
   decision, analyzing the path dependence of its investment and the effect
   of uncertainty. We then consider the effect of competition by modeling
   the impact of entry on an incumbent's investment behavior. Implications
   for management and public policy are then discussed.
RI Levinthal, Daniel/D-1073-2010
OI Levinthal, Daniel/0000-0002-8740-6091
ZS 6
ZB 2
ZR 1
ZA 0
TC 312
Z8 6
Z9 324
SN 0025-1909
UT WOS:A1994NW22200003
ER

PT J
AU BEARD, TR
   BEIL, RO
TI DO PEOPLE RELY ON THE SELF-INTERESTED MAXIMIZATION OF OTHERS - AN
   EXPERIMENTAL TEST
SO MANAGEMENT SCIENCE
VL 40
IS 2
BP 252
EP 262
DI 10.1287/mnsc.40.2.252
PD FEB 1994
PY 1994
AB The assumption that agents engage in maximizing behavior, while
   ubiquitous in economic theory, differs from the assumption that agents
   are willing to rely on the maximizing behavior of others. This paper
   offers an empirical examination of this distinction using experimental
   methods. Utilizing a series of experimental treatments based on a
   simple, two player extensive form game of perfect information, we find
   strong evidence that apparently rational people are often unwilling to
   rely on the self-interested behavior of others, despite the observed
   near universality of maximizing play.
ZR 0
ZB 0
ZS 0
Z8 0
TC 41
ZA 0
Z9 41
SN 0025-1909
UT WOS:A1994NW22200004
ER

PT J
AU LUCE, RD
   VONWINTERFELDT, D
TI WHAT COMMON GROUND EXISTS FOR DESCRIPTIVE, PRESCRIPTIVE, AND NORMATIVE
   UTILITY THEORIES
SO MANAGEMENT SCIENCE
VL 40
IS 2
BP 263
EP 279
DI 10.1287/mnsc.40.2.263
PD FEB 1994
PY 1994
AB Descriptive and normative modeling of decision making under risk and
   uncertainty have grown apart over the past decade. Psychological models
   attempt to accommodate the numerous violations of rationality axioms,
   including independence and transitivity. Meanwhile, normatively oriented
   decision analysts continue to insist on the applied usefulness of the
   subjective expected utility (SEU) model. As this gap has widened, two
   facts have remained largely unobserved. First, most people in real
   situations attempt to behave in accord with the most basic rationality
   principles, even though they are likely to fail in more complex
   situations. Second, the SEU model is likely to provide consistent and
   rational answers to decision problems within a given problem structure,
   but may not be invariant across structures. Thus, people may be more
   rational than the psychological literature gives them credit for, and
   applications of the SEU model may be susceptible to some violations of
   invariance principles.
   This paper attempts to search out the common ground between the
   normative, descriptive, and prescriptive modeling by exploring three
   types of axioms concerning structural rationality, preference
   rationality, and quasi-rationality. Normatively the first two are
   mandatory and the last, suspect. Descriptively, all have been
   questioned, but often the inferences involved have confounded preference
   and structural rationality. We propose a prescriptive view thal entails
   full compliance with preference rationality, modifications of structural
   rationality, and acceptance of quasi-rationality to the extent of
   granting a primary role to the status quo and the decomposition of
   decision problems into gains and losses.
ZA 0
Z8 0
ZS 0
ZB 0
TC 38
ZR 0
Z9 38
SN 0025-1909
UT WOS:A1994NW22200005
ER

PT J
AU HUNG, R
TI MULTIPLE-SHIFT WORKFORCE SCHEDULING UNDER THE 3-4-WORKWEEK WITH
   DIFFERENT WEEKDAY AND WEEKEND LABOR REQUIREMENTS
SO MANAGEMENT SCIENCE
VL 40
IS 2
BP 280
EP 284
DI 10.1287/mnsc.40.2.280
PD FEB 1994
PY 1994
AB Novel workweek arrangements have gained acceptance in many
   seven-days-a-week operations, such as hospitals and data processing
   centers. This note considers a multiple-shift workforce scheduling
   scenario for seven-days-a-week operations under a workweek arrangement
   called the 3-4 workweek. Our model seeks to minimize the workforce size
   subject to satisfying staffing requirements and workrules relating to
   off-days, off-weekends, and work-stretches. We provide an efficient
   optimal algorithm which is intuitive and simple enough to be implemented
   by hand.
TC 33
ZA 0
Z8 0
ZR 0
ZB 0
ZS 0
Z9 33
SN 0025-1909
UT WOS:A1994NW22200006
ER

PT J
AU MILLER, JG
   ROTH, AV
TI A TAXONOMY OF MANUFACTURING STRATEGIES
SO MANAGEMENT SCIENCE
VL 40
IS 3
BP 285
EP 304
DI 10.1287/mnsc.40.3.285
PD MAR 1994
PY 1994
AB This paper describes the development and analysis of a numerical
   taxonomy of manufacturing strategies. The taxonomy was developed with
   standard methods of cluster analysis, and is based on the relative
   importance attached to eleven competitive capabilities defining the
   manufacturing task of 164 large American manufacturing business units.
   Three distinct clusters of manufacturing strategy groups were observed.
   Though there is an industry effect, all three manufacturing strategy
   types are observed in various industries. The two main dimensions along
   which the manufacturing strategy groups differ are the ability of the
   firms in them to differentiate themselves from competition with their
   products and services, and the scope of their product lines and markets.
   A general method for mapping manufacturing strategies on these
   dimensions is described. For each manufacturing group, the relationships
   between the competitive capabilities (which describe the manufacturing
   task), the business context (the business unit strategy), manufacturing
   activities (manufacturing strategy choices), and manufacturing
   performance measures are explored and compared.
ZA 0
TC 575
ZS 6
ZR 0
ZB 1
Z8 5
Z9 585
SN 0025-1909
UT WOS:A1994NW49400001
ER

PT J
AU KARABAKAL, N
   LOHMANN, JR
   BEAN, JC
TI PARALLEL REPLACEMENT UNDER CAPITAL RATIONING CONSTRAINTS
SO MANAGEMENT SCIENCE
VL 40
IS 3
BP 305
EP 319
DI 10.1287/mnsc.40.3.305
PD MAR 1994
PY 1994
AB Contrary to serial replacement, parallel replacement problems require a
   decision maker to evaluate a portfolio of replacement decisions in each
   time period because of economic interdependencies among assets. In this
   paper, we describe a parallel replacement problem in which the economic
   interdependence among assets is caused by capital rationing. The
   research was motivated by the experience gained from a vehicle fleet
   replacement study where solutions to serial replacement problems could
   not be implemented since they violated management's budget plan. When
   firms use budgets to control their expenditures, competition for the
   limited funds creates interdependent problems. In this paper, we
   formulate the problem as a zero-one integer program and develop a
   branch-and-bound algorithm based on Lagrangian relaxation methodology. A
   multiplier adjustment method is developed to solve one Lagrangian dual.
ZS 0
TC 52
ZR 0
ZA 0
ZB 0
Z8 0
Z9 52
SN 0025-1909
UT WOS:A1994NW49400002
ER

PT J
AU CIARALLO, FW
   AKELLA, R
   MORTON, TE
TI A PERIODIC REVIEW, PRODUCTION PLANNING-MODEL WITH UNCERTAIN CAPACITY AND
   UNCERTAIN DEMAND - OPTIMALITY OF EXTENDED MYOPIC POLICIES
SO MANAGEMENT SCIENCE
VL 40
IS 3
BP 320
EP 332
DI 10.1287/mnsc.40.3.320
PD MAR 1994
PY 1994
AB Increasing product complexity, manufacturing environment complexity and
   an increased emphasis on product quality are all factors leading to
   uncertainties in production processes. These uncertainties are in the
   form of unplanned machine maintenance, varying production yields and
   rework, among others. In planning for production, an adequate model must
   incorporate these uncertainties into the representation of the
   production process.
   This paper treats the aggregate planning problem for a single product
   with random demand and random capacity. In the single-period problem,
   random capacity does not affect the optimal policy but results in a
   unimodal, nonconvex cost function. In the multiple-period and
   infinite-horizon settings order-up-to policies that are dependent on the
   distribution of capacity are shown to be optimal in spite of a nonconvex
   cost. In the infinite-horizon setting an intuitive description of the
   situation leads to the notion of a class of extended myopic policies,
   requiring the consideration of review periods of uncertain length.
ZR 0
Z8 12
TC 205
ZA 0
ZS 0
ZB 0
Z9 216
SN 0025-1909
UT WOS:A1994NW49400003
ER

PT J
AU SHAHABUDDIN, P
TI IMPORTANCE SAMPLING FOR THE SIMULATION OF HIGHLY RELIABLE MARKOVIAN
   SYSTEMS
SO MANAGEMENT SCIENCE
VL 40
IS 3
BP 333
EP 352
DI 10.1287/mnsc.40.3.333
PD MAR 1994
PY 1994
AB In this paper we investigate importance sampling techniques for the
   simulation of Markovian systems with highly reliable components. The
   need for simulation arises because the state space of such systems is
   typically huge, making numerical computation inefficient. Naive
   simulation is inefficient due to the rarity of the system failure
   events. Failure biasing is a useful importance sampling technique for
   the simulation of such systems. However, until now, this technique  has
   been largely heuristic. We present a mathematical framework for the
   study of failure biasing. Using this framework we derive variance
   reduction results which explain the orders of magnitude of variance
   reduction obtained in practice. We show that in many cases the magnitude
   of the variance reduction is such that the relative errors of the
   estimates remain bounded as the failure rates of components tend to
   zero. We also prove that the failure biasing heuristic in its original
   form may not give bounded relative error for a large class of systems
   and that a modification of the heuristic works for the general case. The
   theoretical results in this paper agree with experiments on the subject
   which have been reported in a previous paper.
ZR 0
ZA 0
ZS 0
Z8 4
TC 97
ZB 0
Z9 100
SN 0025-1909
UT WOS:A1994NW49400004
ER

PT J
AU BRIMBERG, J
   MEHREZ, A
   ORON, G
TI ECONOMIC-DEVELOPMENT OF GROUNDWATER IN ARID ZONES WITH APPLICATIONS TO
   THE NEGEV DESERT, ISRAEL
SO MANAGEMENT SCIENCE
VL 40
IS 3
BP 353
EP 363
DI 10.1287/mnsc.40.3.353
PD MAR 1994
PY 1994
AB A mixed binary integer linear program is formulated to determine the
   economic development of marginal groundwater sources at local demand
   sites in an arid region. These marginal sources are required to augment
   the supply from an overloaded regional source. The model accounts for
   variable costs of supply, fixed investment costs, capacity constraints
   at the regional and local levels, and water quality requirements at the
   local sites. A Lagrangian relaxation reduces the model to a series of
   simple local problems, the solution of which provides an optimal
   sequence for developing the marginal groundwater sources while reducing
   the demands on the regional source. A heuristic and an exact procedure
   are also proposed to solve the problem for arbitrary levels of supply
   from the regional source. The exact procedure uses characteristics of
   the optimal solution to reduce the model to a series of knapsack-type
   problems. The theory is applied to a small case study taken from the
   Negev Desert in southern Israel.
ZR 0
ZA 0
TC 7
Z8 0
ZB 0
ZS 0
Z9 7
SN 0025-1909
UT WOS:A1994NW49400005
ER

PT J
AU ROTHKOPF, MH
   HARSTAD, RM
TI MODELING COMPETITIVE BIDDING - A CRITICAL-ESSAY
SO MANAGEMENT SCIENCE
VL 40
IS 3
BP 364
EP 384
DI 10.1287/mnsc.40.3.364
PD MAR 1994
PY 1994
AB In analyzing bidding, modeling matters. This paper is a critical
   analysis of the models available to aid competitive bidding decision
   making-bidding strategy and auction design-in real transactions. After
   an introductory overview, this paper describes the contexts in which
   auctions arise, reviews the ''mainstream'' theory of single, isolated
   auctions and discusses the important work involved in enrichment of this
   theory. In doing so, it indicates results that have been obtained and
   the sort of changes in analytical approach that are needed to tackle
   other critical enrichments. The paper summarizes briefly what is known
   about the direct use of models by bidders and auction designers. A
   general theme of this paper is that enriched models are needed to bring
   bidding theory closer to direct applicability in decision making.
Z8 5
ZB 1
ZA 0
ZR 0
TC 164
ZS 0
Z9 169
SN 0025-1909
UT WOS:A1994NW49400006
ER

PT J
AU GENNOTTE, G
   JUNG, A
TI INVESTMENT STRATEGIES UNDER TRANSACTION COSTS - THE FINITE-HORIZON CASE
SO MANAGEMENT SCIENCE
VL 40
IS 3
BP 385
EP 404
DI 10.1287/mnsc.40.3.385
PD MAR 1994
PY 1994
AB We examine the effect of proportional transaction costs on dynamic
   portfolio strategies for an agent who maximizes his expected utility of
   terminal wealth. For portfolios composed of a single risky asset and a
   single riskless asset, Constantinides ( 1979) shows that the optimal
   investment policy is described in terms of a no transaction region,
   where the optimal policy is to refrain from trading if initial portfolio
   holdings lie within the region, and to transact to the nearest boundary
   of the region if portfolio holdings lie outside the region. Because the
   boundaries could not be derived analytically, we developed an efficient
   and tractable algorithm to obtain the boundaries, which are expressed as
   the ratio of the dollar holdings in stocks and bonds. We considered two
   cases: the same transaction costs for the two assets, and costs incurred
   on only the risky asset. We derived the optimal trading strategies and
   utility levels for a large set of realistic parameters. In particular,
   we show that the no transaction region narrows and converges rapidly to
   the infinite horizon limit as the time horizon increases.
Z8 6
ZA 0
TC 38
ZR 0
ZB 0
ZS 0
Z9 44
SN 0025-1909
UT WOS:A1994NW49400007
ER

PT J
AU RAMASWAMY, V
   ANDERSON, EW
   DESARBO, WS
TI A DISAGGREGATE NEGATIVE BINOMIAL REGRESSION PROCEDURE FOR COUNT
   DATA-ANALYSIS
SO MANAGEMENT SCIENCE
VL 40
IS 3
BP 405
EP 417
DI 10.1287/mnsc.40.3.405
PD MAR 1994
PY 1994
AB Various research areas face the methodological problems presented by
   nonnegative integer count data drawn from heterogeneous populations. We
   present a disaggregate negative binomial regression procedure for
   analysis of count data observed for a heterogeneous sample of
   cross-sections, possibly over some fixed time periods. This procedure
   simultaneously pools or groups cross-sections while estimating a
   separate negative binomial regression model for each group. An E-M
   algorithm is described within a maximum likelihood framework to estimate
   the group proportions, the group-specific regression coefficients, and
   the degree of overdispersion in event rates within each derived group.
   The proposed procedure is illustrated with count data entailing
   nonnegative integer counts of purchases (events) for a frequently bought
   consumer good.
Z8 0
ZB 1
TC 15
ZR 0
ZA 0
ZS 0
Z9 15
SN 0025-1909
UT WOS:A1994NW49400008
ER

PT J
AU SCHOUTEN, FAV
   WARTENHORST, P
TI TRANSIENT ANALYSIS OF A 2-UNIT STANDBY SYSTEM WITH MARKOVIAN DEGRADING
   UNITS
SO MANAGEMENT SCIENCE
VL 40
IS 3
BP 418
EP 428
PD MAR 1994
PY 1994
AB A two-unit cold standby system with Markovian degrading units and one
   repair facility is considered. Two types of repair are possible:
   preventive and corrective, where the latter is supposed to be more time
   consuming than the first. The system is controlled by a repair policy of
   control limit type: a preventive repair on the working unit is carried
   out as soon as the state of this unit exceeds a certain threshold unless
   the repair facility is occupied by the other unit, In this paper we
   derive explicit expressions for the Laplace transforms of the up- and
   down-periods of this system, which provide insight in the availability
   of the system and which can be used to obtain approximations for the
   interval availability distribution. An iterative numerical procedure is
   presented for the special case of generalized Erlangian distributed
   repair times.
ZS 0
ZB 0
Z8 0
ZA 0
TC 7
ZR 0
Z9 7
SN 0025-1909
UT WOS:A1994NW49400009
ER

PT J
AU VONHIPPEL, E
TI STICKY INFORMATION AND THE LOCUS OF PROBLEM-SOLVING - IMPLICATIONS FOR
   INNOVATION
SO MANAGEMENT SCIENCE
VL 40
IS 4
BP 429
EP 439
DI 10.1287/mnsc.40.4.429
PD APR 1994
PY 1994
AB To solve a problem, needed information and problem-solving capabilities
   must be brought together. Often the information used in technical
   problem solving is costly to acquire, transfer, and use in a new
   location-is, in our terms, ''sticky.'' In this paper we explore the
   impact of information stickiness on the locus of innovation-related
   problem solving. We find, first, that when sticky information needed by
   problem solvers is held at one site only, problem solving will be
   carried out at that locus, other things being equal. Second, when more
   than one locus of sticky information is called upon by problem solvers,
   the locus of problem solving may iterate among these sites as problem
   solving proceeds. When the costs of such iteration are high, then,
   third, problems that draw upon multiple sites of sticky information will
   sometimes be ''task partitioned'' into subproblems that each draw on
   only one such locus, and / or, fourth, investments will be made to
   reduce the stickiness of information at some locations.
   Information stickiness appears to affect a number of issues of
   importance to researchers and practitioners. Among these are patterns in
   the diffusion of information, the specialization of firms, the locus of
   innovation, and the nature of problems selected by problem solvers.
ZB 17
ZS 11
ZA 0
TC 1626
ZR 0
Z8 4
Z9 1638
SN 0025-1909
UT WOS:A1994NW81800001
ER

PT J
AU HARTWICK, J
   BARKI, H
TI EXPLAINING THE ROLE OF USER PARTICIPATION IN INFORMATION-SYSTEM USE
SO MANAGEMENT SCIENCE
VL 40
IS 4
BP 440
EP 465
DI 10.1287/mnsc.40.4.440
PD APR 1994
PY 1994
AB Even though user participation in information system development has
   long been considered to be a critical factor in achieving system
   success, research has failed to clearly demonstrate its benefits. This
   paper proposes user involvement as an intervening variable between user
   participation and system use. Embedding the constructs of participation
   and involvement into the theoretical framework of Fishbein and Ajzen, a
   model is developed and tested in a field study of information system
   projects. Several key findings emerge from the study. User participation
   and user involvement represent two distinct constructs, with
   participation leading to involvement, and involvement mediating the
   relationship between participation and system use. The critical
   dimension of user participation is overall responsibility. The role of
   user participation and involvement is different, depending upon whether
   system use is mandatory or voluntary.
TC 669
ZS 9
ZA 0
Z8 5
ZR 0
ZB 3
Z9 683
SN 0025-1909
EI 1526-5501
UT WOS:A1994NW81800002
ER

PT J
AU SURESH, NC
   MEREDITH, JR
TI COPING WITH THE LOSS OF POOLING SYNERGY IN CELLULAR MANUFACTURING
   SYSTEMS
SO MANAGEMENT SCIENCE
VL 40
IS 4
BP 466
EP 483
DI 10.1287/mnsc.40.4.466
PD APR 1994
PY 1994
AB The conversion of a functional layout into a cellular manufacturing
   system involves the partitioning of several multiserver work centers.
   The loss of pooling synergy in this process can be significant, and this
   paper investigates the impact of several measures to overcome the
   adverse effects on flow time, work-in-process inventory and machine
   utilization. These can be alleviated to a certain extent through
   reductions in setup times and lot sizes that has been traditionally
   emphasized in group technology, but a more concerted effort is required.
   Analytical models are first utilized to investigate the extent to which
   these adverse effects can be overcome through (1) reduction in setup
   time, (2) lot sizing, (3) reduction in the variability of process-times
   and job arrivals, and, (4) reduction in processing times through
   productivity improvements, all arising from part family-oriented
   processing. These insights are verified through a simulation comparison
   of five cellular manufacturing systems with a functional layout system
   in which optimal lot sizes, low move times and a part family-oriented
   scheduling rule are used.
TC 98
ZS 0
ZA 0
ZB 0
ZR 0
Z8 0
Z9 98
SN 0025-1909
UT WOS:A1994NW81800003
ER

PT J
AU ARYA, A
   FELLINGHAM, JC
   YOUNG, RA
TI CONTRACT-BASED MOTIVATION FOR KEEPING RECORDS OF A MANAGERS REPORTING
   AND BUDGETING HISTORY
SO MANAGEMENT SCIENCE
VL 40
IS 4
BP 484
EP 495
DI 10.1287/mnsc.40.4.484
PD APR 1994
PY 1994
AB This paper analyzes the role of the agent's bankruptcy constraints in
   multiperiod principal-agent models with asymmetric information.
   Conditions are provided under which commitment to a long-term contract
   involving N rounds of investment improves upon repetition of N identical
   single-period contracts. Further, when the agent's reservation wage is
   sufficiently low the optimal contract is always long term. Keeping
   records of a manager's history of reporting activity facilitates
   contracting, since optimal contracts may require a link between past
   reports and future investments over a duration of two or more periods.
ZR 0
TC 3
ZA 0
Z8 0
ZS 0
ZB 0
Z9 3
SN 0025-1909
UT WOS:A1994NW81800004
ER

PT J
AU VENKATRAMAN, N
   LOH, L
   KOH, J
TI THE ADOPTION OF CORPORATE GOVERNANCE MECHANISMS - A TEST OF COMPETING
   DIFFUSION-MODELS
SO MANAGEMENT SCIENCE
VL 40
IS 4
BP 496
EP 507
DI 10.1287/mnsc.40.4.496
PD APR 1994
PY 1994
AB We develop alternative diffusion models of two corporate governance
   mechanisms-joint venture and M- form organizational structure-using
   relevant concepts from the resource-based theory. Using data on joint
   venture adoption from one homogeneous industry (information technology)
   sector and employing both linear and nonlinear estimations, we test the
   explanatory power of the internal-influence model in comparison with a
   competing model of external-influence. Our empirical results support the
   internal-influence model in this sector with additional evidence for
   generalizability provided through a multisector sample of joint venture
   formation. In contrast, empirical results on the diffusion of M-form
   structure are more consistent with the external-influence model.
RI Venkatraman, N. Venkat/AAB-2555-2019; Loh, Lawrence/B-8413-2016
Z8 0
TC 49
ZS 1
ZA 0
ZR 0
ZB 0
Z9 49
SN 0025-1909
UT WOS:A1994NW81800005
ER

PT J
AU ABOUDI, R
   THON, D
TI EFFICIENT ALGORITHMS FOR STOCHASTIC-DOMINANCE TESTS BASED ON FINANCIAL
   MARKET DATA
SO MANAGEMENT SCIENCE
VL 40
IS 4
BP 508
EP 515
DI 10.1287/mnsc.40.4.508
PD APR 1994
PY 1994
AB It is known that when the random variables being compared have a uniform
   probability measure, as is the case when using financial market data,
   the computation of efficient sets for first- and second-degree dominance
   can be greatly simplified if majorization conditions are used instead of
   the dominance definitions. This paper presents an equally efficient
   technique for third-degree dominance.
ZB 0
ZA 0
ZR 0
TC 16
Z8 0
ZS 0
Z9 16
SN 0025-1909
UT WOS:A1994NW81800006
ER

PT J
AU BOARD, JLG
   SUTCLIFFE, CMS
TI ESTIMATION METHODS IN PORTFOLIO SELECTION AND THE EFFECTIVENESS OF SHORT
   SALES RESTRICTIONS - UK EVIDENCE
SO MANAGEMENT SCIENCE
VL 40
IS 4
BP 516
EP 534
DI 10.1287/mnsc.40.4.516
PD APR 1994
PY 1994
AB Forecasting the mean returns vector and the covariance matrix is a key
   feature in implementing portfolio theory. The performance of the
   Bayes-Stein method for forecasting these parameters for use in the
   Markowitz model (with and without short sales) was compared with that of
   seven other estimation methods, and three alternative portfolio
   selection techniques. This paper represents the first large scale
   empirical investigation of the usefulness of the Bayes-Stein approach
   using historical data. This data was drawn from the London Stock
   Exchange. In contrast to earlier studies, the relative performance of
   Bayes-Stein was mixed. While it produced reasonable estimates of the
   mean returns vector, there were superior methods, e.g., overall mean,
   for estimating the covariance matrix when short sales were permitted.
   When short sales were prohibited, actual portfolio performance was
   clearly improved, although there was little to choose between the
   various estimation methods.
OI Sutcliffe, Charles/0000-0003-0187-487X
Z8 0
ZB 0
ZA 0
ZR 0
ZS 0
TC 19
Z9 19
SN 0025-1909
UT WOS:A1994NW81800007
ER

PT J
AU TEISBERG, EO
TI AN OPTION VALUATION ANALYSIS OF INVESTMENT CHOICES BY A REGULATED FIRM
SO MANAGEMENT SCIENCE
VL 40
IS 4
BP 535
EP 548
DI 10.1287/mnsc.40.4.535
PD APR 1994
PY 1994
AB This paper analyzes a utility power plant construction project using an
   option pricing model of the value of the capital investment. It includes
   descriptive factors frequently ignored in the valuation of capital
   investments by regulated firms, including lead time, lumpy and
   sequential cost outlays, irreversibility of expenditures, and
   uncertainty about regulatory outcomes for completed projects. The
   analysis shows the value of shorter lead time technologies, the value of
   flexibility to delay or abandon construction, the incentive to delay
   construction under uncertain regulation, and how cost recovery policies,
   such as possible disallowance of Allow for Funds Used During
   Construction (AFUDC), create incentives to invest less, but to complete
   construction quickly. The analysis may also apply in unregulated
   contexts, where the value of a completed project is affected by
   taxation, the possibility of nationalization, or possible competitors'
   actions that create uncertain restrictions on potential profits.
Z8 3
ZS 0
ZA 0
ZR 0
TC 25
ZB 0
Z9 28
SN 0025-1909
UT WOS:A1994NW81800008
ER

PT J
AU ZAHEER, A
   VENKATRAMAN, N
TI DETERMINANTS OF ELECTRONIC INTEGRATION IN THE INSURANCE INDUSTRY - AN
   EMPIRICAL-TEST
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 549
EP 566
DI 10.1287/mnsc.40.5.549
PD MAY 1994
PY 1994
AB Electronic integration-a form of vertical quasi-integration achieved
   through the deployment of dedicated computers and communication systems
   between relevant actors in the adjacent stages of the value-chain-is an
   important concept to researchers in the information systems field since
   it focuses on the role of information technology in restructuring
   vertical relationships. Drawing on theoretical and empirical research on
   transaction costs, we develop and test a model of the determinants of
   the degree of electronic integration in the commercial segment of the
   property and casualty (P&C) industry. Based on a sample of 120
   independent agencies operating under dedicated information
   technology-mediated conditions, we provide empirical support for three
   hypotheses on the determinants of electronic integration. Implications
   and research extensions are identified to guide further research in this
   important area.
RI Venkatraman, N. Venkat/AAB-2555-2019
ZR 0
ZS 0
ZA 0
TC 168
Z8 1
ZB 0
Z9 169
SN 0025-1909
EI 1526-5501
UT WOS:A1994NW81900001
ER

PT J
AU BALAKRISHNAN, A
   MAGNANTI, TL
   MIRCHANDANI, P
TI A DUAL-BASED ALGORITHM FOR MULTILEVEL NETWORK DESIGN
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 567
EP 581
DI 10.1287/mnsc.40.5.567
PD MAY 1994
PY 1994
AB Given an undirected network with L possible facility types for each
   edge, and a partition of the nodes into L levels or grades, the
   Multi-level Network Design (MLND) problem seeks a fixed cost minimizing
   design that spans all the nodes and connects the nodes at each level by
   facilities of the corresponding or higher grade. This problem
   generalizes the well-known Steiner network problem and the hierarchical
   network design problem, and has applications in telecommunication,
   transportation, and electric power distribution network design. In a
   companion paper we studied alternative model formulations for a
   two-level version of this problem, and analyzed the worst-case
   performance of several heuristics based on Steiner network and spanning
   tree solutions. This paper develops a dual-based algorithm for the MLND
   problem. The method first performs problem preprocessing to fix certain
   design variables, and then applies a dual ascent procedure to generate
   upper and lower bounds on the optimal value. We report extensive
   computational results on large, random two-level test problems
   (containing up to 500 nodes, and 5,000 edges) with varying cost
   structures. The integer programming formulation of the largest of these
   problems has 20,000 integer variables and over 5 million constraints.
   Our tests indicate that the dual-based algorithm is very effective,
   producing solutions that are within 0.9% of optimality.
TC 38
ZB 1
ZA 0
Z8 0
ZS 0
ZR 0
Z9 38
SN 0025-1909
UT WOS:A1994NW81900002
ER

PT J
AU NAHMIAS, S
   SMITH, SA
TI OPTIMIZING INVENTORY LEVELS IN A 2-ECHELON RETAILER SYSTEM WITH PARTIAL
   LOST SALES
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 582
EP 596
DI 10.1287/mnsc.40.5.582
PD MAY 1994
PY 1994
AB This paper considers a retailer inventory system with N first-echelon
   stores and a single second-echelon distribution center (DC). Customer
   demands at the stores are assumed to be random. When a stockout occurs,
   customers are willing to wait for their order to be filled with a known
   probability. Customers who are unwilling to wait result in lost sales.
   The first and second echelons are both restocked at fixed, equally
   spaced time points, where the store restocking frequency is an integer
   multiple of the DC restocking frequency. We also assume that
   replenishment quantities at both echelons can be adjusted up to the time
   of delivery, resulting in replenishment lead times equal to zero. This
   simplification allows us to determine optimal solutions for the partial
   lost sales case, which has proven intractable for two-echelon
   formulations with lead times. Computational results are given for
   illustrative examples.
RI Weller, Matt J/E-8421-2010
ZS 0
ZR 0
ZB 0
TC 80
ZA 0
Z8 2
Z9 82
SN 0025-1909
UT WOS:A1994NW81900003
ER

PT J
AU HAUSMAN, WH
   ERKIP, NK
TI MULTIECHELON VS SINGLE-ECHELON INVENTORY CONTROL POLICIES FOR LOW-DEMAND
   ITEMS
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 597
EP 602
DI 10.1287/mnsc.40.5.597
PD MAY 1994
PY 1994
AB Multi-echelon inventory systems are often controlled as a network of
   single-echelon inventory systems for simplicity of managerial authority,
   organizational control, and performance monitoring. This paper explores
   the amount of suboptimization in such a situation, using an actual
   demand data set provided by other researchers. We consider low-demand,
   high-cost items controlled on an (S - 1, S) basis, with all warehouse
   stockouts met on an emergency-ordering basis. We demonstrate that the
   suboptimality penalty for this data set is 3% to 5% when single-echelon
   systems are appropriately parameterized.
RI Erkip, Nesim/AAJ-3973-2020
OI Erkip, Nesim/0000-0003-4122-6375
ZB 0
ZS 0
ZR 0
ZA 0
TC 39
Z8 0
Z9 39
SN 0025-1909
UT WOS:A1994NW81900004
ER

PT J
AU SONG, JS
TI THE EFFECT OF LEADTIME UNCERTAINTY IN A SIMPLE STOCHASTIC INVENTORY
   MODEL
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 603
EP 613
DI 10.1287/mnsc.40.5.603
PD MAY 1994
PY 1994
AB We study a basic continuous-time single-item inventory model where
   demands form a compound Poisson process and leadtimes are stochastic.
   The performance measure of interest is the long-run average cost. Order
   costs are linear, so a base-stock policy is optimal. We focus on the
   behavior of the optimal base-stock level in response to stochastically
   larger or more variable leadtimes. We also investigate the behavior of
   the corresponding long-run average costs. We show that a stochastically
   larger leadtime requires a higher optimal base-stock level. However, a
   stochastically larger leadtime may not necessarily result in a higher
   optimal average cost, because sometimes the variability effects may
   dominate. On the other hand, a more variable leadtime always leads to a
   higher optimal average cost. The effect of leadtime variability on
   optimal policies depends on the inventory cost structure: A more
   variable leadtime requires a higher optimal base-stock level if and only
   if the unit penalty (holding) cost rate is high (low).
   Similar results regarding the effect of leadtime demand are also
   discussed. In this latter case, the compound Poisson assumption is not
   necessary.
TC 118
ZA 0
ZB 0
ZS 3
Z8 15
ZR 0
Z9 134
SN 0025-1909
UT WOS:A1994NW81900005
ER

PT J
AU ROBERTS, KH
   STOUT, SK
   HALPERN, JJ
TI DECISION DYNAMICS IN 2 HIGH-RELIABILITY MILITARY ORGANIZATIONS
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 614
EP 624
DI 10.1287/mnsc.40.5.614
PD MAY 1994
PY 1994
AB In this research we extend theoretical development about decision making
   in organizations in which many kinds of errors cannot be tolerated.
   Catastrophic consequences can be associated with faulty decision making
   in reliability-seeking organizations, a situation which does not occur
   in most organizations studied in the past. Observations are drawn from
   two nuclear-powered aircraft carriers. We find decision processes which
   appear to change often in these organizations. Important decisions can
   be made by a number of men even at the lowest levels of the
   organization. Task-related factors such as technical complexity, high
   interdependence, and catastrophic consequences associated with rare
   events and more cognitive factors such as accountability and salience
   affect decision processes. A model is presented that accounts for
   dynamic change in decision processes in these organizations.
ZS 2
ZA 0
Z8 2
ZR 2
ZB 4
TC 106
Z9 111
SN 0025-1909
UT WOS:A1994NW81900006
ER

PT J
AU SARIN, R
   WAKKER, P
TI FOLDING BACK IN DECISION TREE ANALYSIS
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 625
EP 628
DI 10.1287/mnsc.40.5.625
PD MAY 1994
PY 1994
AB This note demonstrates that two minimal requirements of decision tree
   analysis, the folding back procedure and the interchangeability of
   consecutive event nodes, imply independence.
ZA 0
ZB 0
TC 10
Z8 0
ZR 0
ZS 0
Z9 10
SN 0025-1909
UT WOS:A1994NW81900007
ER

PT J
AU GONG, LG
   DEKOK, T
   DING, J
TI OPTIMAL LEADTIMES PLANNING IN A SERIAL PRODUCTION SYSTEM
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 629
EP 632
DI 10.1287/mnsc.40.5.629
PD MAY 1994
PY 1994
AB Consider an N stage serial production line where the processing times of
   orders may be random. Since the carrying costs increase from stage to
   stage, the standard production procedure, that is, to determine a total
   leadtime for the entire order by taking an appropriate percentile of the
   distribution of total processing time and then release the order
   immediately from stage to stage during the process, may not be optimal
   since it ignores inventory carrying costs. This article studies a per
   stage planned leadtime dispatching policy for such systems. The order
   will not be released immediately to the next workstation prior to a
   predetermined delivery time, or planned leadtime. The vector of planned
   leadtimes at workstations is to be determined by trading off expected
   holding costs at all stages and expected penalty costs for exceeding the
   total planned leadtime. We show that the optimal vector of planned
   leadtimes may be obtained efficiently by solving an equivalent serial
   inventory model of the type considered in Clark and Scarf (1960).
RI de Kok, Theo M/G-6213-2014
ZR 0
ZS 0
ZA 0
TC 26
ZB 0
Z8 0
Z9 26
SN 0025-1909
UT WOS:A1994NW81900008
ER

PT J
AU LI, LD
   LEE, YS
TI PRICING AND DELIVERY-TIME PERFORMANCE IN A COMPETITIVE ENVIRONMENT
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 633
EP 646
DI 10.1287/mnsc.40.5.633
PD MAY 1994
PY 1994
AB We present a model of market competition in which customer preferences
   are over not only price and quality but also delivery speed. This allows
   a study of market demand and firms' decisions on price, quality,
   technology and responsiveness in a competitive environment. When demand
   arises, a customer chooses the firm that maximizes its expected utility
   of price, quality and response time. The demand function for each firm
   is derived by analyzing a queueing system with competing servers. We
   then study price competition among firms with differentiated processing
   rates. In the equilibrium, the firm with a higher processing rate always
   enjoys a price premium, and, further, enjoys a larger market share when
   its opponent also has adequate processing rate to serve all the
   customers alone.
TC 111
Z8 13
ZR 0
ZS 0
ZB 1
ZA 0
Z9 123
SN 0025-1909
UT WOS:A1994NW81900009
ER

PT J
AU KRASS, IA
   PINAR, MC
   THOMPSON, TJ
   ZENIOS, SA
TI A NETWORK MODEL TO MAXIMIZE NAVY PERSONNEL READINESS AND ITS SOLUTION
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 647
EP 661
DI 10.1287/mnsc.40.5.647
PD MAY 1994
PY 1994
AB The problem of optimally (re)allocating Navy personnel to combat units
   is compounded by several considerations: availability of trained
   personnel, staffing of positions by occupation groups or ranks, and
   maintaining an acceptable level of readiness. In this paper we model
   this problem as a nonlinear nondifferentiable optimization problem. A
   reformulation of the nonlinear optimization problem as a network flow
   problem is then developed. The formulation results in a network flow
   problem with side constraints. An additional, nonnetwork, variable
   measures the readiness level. This new formulation permits the use of
   network optimization tools in order to solve effectively very large
   problems.
   We then develop two numerical methods for solving this problem. One
   method is based on a heuristic that solves (approximately) the
   nondifferentiable problem. The second method is based on a
   Linear-Quadratic Penalty (LQP) algorithm, and it exploits the embedded
   network structure by placing the side constraints into the objective
   function. The resulting nonlinear network program is solved using a
   simplicial decomposition of the network constraint set. Numerical
   results indicate the viability of this approach on problems with up to
   36,000 arcs and 17,000 nodes with 3,700 side constraints.
RI Zenios, Stavros/F-3346-2013
OI Zenios, Stavros/0000-0001-7576-4898
ZR 0
ZS 0
ZB 0
TC 5
Z8 0
Z9 5
SN 0025-1909
UT WOS:A1994NW81900010
ER

PT J
AU LANDSBERGER, M
   MEILIJSON, I
TI THE GENERATING PROCESS AND AN EXTENSION OF JEWITT LOCATION INDEPENDENT
   RISK CONCEPT
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 662
EP 669
DI 10.1287/mnsc.40.5.662
PD MAY 1994
PY 1994
AB A generating process of Jewitt's location independent risk concept is
   derived in terms of left stretches based on single crossings between
   distributions. For concave nondecreasing utility functions this
   stochastic order preserves monotonicity between risk premium and the
   Arrow-Pratt measure of risk aversion. We show that a stronger order, the
   Bickel-Lehmann notion of dispersion, preserves this monotonicity for the
   larger class of nondecreasing utilities.
ZS 0
ZR 0
ZA 0
ZB 0
TC 29
Z8 0
Z9 29
SN 0025-1909
UT WOS:A1994NW81900011
ER

PT J
AU SHALIT, H
   YITZHAKI, S
TI MARGINAL CONDITIONAL STOCHASTIC-DOMINANCE
SO MANAGEMENT SCIENCE
VL 40
IS 5
BP 670
EP 684
DI 10.1287/mnsc.40.5.670
PD MAY 1994
PY 1994
AB This paper introduces the concept of Marginal Conditional Stochastic
   Dominance (MCSD), which states the conditions under which all
   risk-averse individuals, when presented with a given portfolio, prefer
   to increase the share of one risky asset over that of another. MCSD
   rules also answer the question of whether all risk-averse individuals
   include a new asset in their portfolio when assets' returns are
   correlated. MCSD criteria are expressed in terms of the probability
   distributions of the assets and of the underlying portfolio. An
   empirical application of MCSD is provided using stocks traded on the New
   York Stock Exchange. MCSD rules are used to show that, in the long run,
   one cannot assert that the market portfolio is inefficient.
ZR 0
ZS 0
ZA 0
TC 69
ZB 2
Z8 1
Z9 70
SN 0025-1909
UT WOS:A1994NW81900012
ER

PT J
AU SEGEV, A
   ZHAO, JL
TI RULE MANAGEMENT IN EXPERT DATABASE-SYSTEMS
SO MANAGEMENT SCIENCE
VL 40
IS 6
BP 685
EP 707
DI 10.1287/mnsc.40.6.685
PD JUN 1994
PY 1994
AB Expert database systems combine database and expert systems technologies
   to support the effective management of both rules and data. This paper
   studies rule processing strategies in expert database systems involving
   rules that are conditional on joins of relational data. Auxiliary
   constructs for processing join rules are proposed, and a framework of
   join rule processing strategies is developed. Cost functions of several
   strategies are derived based on a stochastic model that characterizes
   the arrival processes of transactions and queries to the database.
   Performance evaluation shows that the proposed data constructs and
   strategies provide an effective method for processing rules.
RI Zhao, J. Leon/A-3921-2008
Z8 1
ZR 0
TC 7
ZA 0
ZS 0
ZB 0
Z9 8
SN 0025-1909
UT WOS:A1994NX28000001
ER

PT J
AU ZENGER, TR
TI EXPLAINING ORGANIZATIONAL DISECONOMIES OF SCALE IN
   RESEARCH-AND-DEVELOPMENT - AGENCY PROBLEMS AND THE ALLOCATION OF
   ENGINEERING TALENT, IDEAS, AND EFFORT BY FIRM SIZE
SO MANAGEMENT SCIENCE
VL 40
IS 6
BP 708
EP 729
DI 10.1287/mnsc.40.6.708
PD JUN 1994
PY 1994
AB The comparative efficiency and success of small firms in R&D remains
   largely unexplained. This paper empirically examines scale diseconomies
   in offering employment contracts as an explanation for diseconomies of
   scale in R&D. The paper argues that small firms more efficiently resolve
   the severe agency problems of hidden information and hidden behavior in
   R&D. Small firms more efficiently offer contracts that reward
   performance than large firms, and consequently, small firms attract and
   retain engineers with higher ability and skill. Further, small firms
   through these more performance-contingent contracts induce higher levels
   of effort than large firms. The study tests and generally confirms these
   hypotheses using data collected from 912 current and former engineering
   employees of two large high-technology companies.
RI Zenger, Todd/L-4654-2019
ZB 0
ZS 3
ZA 0
Z8 1
TC 147
ZR 0
Z9 150
SN 0025-1909
UT WOS:A1994NX28000002
ER

PT J
AU CASEY, JT
TI BUYERS PRICING BEHAVIOR FOR RISKY ALTERNATIVES - ENCODING PROCESSES AND
   PREFERENCE REVERSALS
SO MANAGEMENT SCIENCE
VL 40
IS 6
BP 730
EP 749
DI 10.1287/mnsc.40.6.730
PD JUN 1994
PY 1994
AB Numerous studies have examined individuals' minimum selling prices or
   certainty equivalents for lotteries as measures of preference, but few
   have examined maximum buying prices. Because every transaction involves
   a buyer as well as a seller, buyers' pricing behavior is of interest in
   its own right. Two prospect theory based descriptive models of maximum
   buying prices-the integration and segregation models-are developed from
   different assumptions about cognitive encoding processes. The models
   were tested experimentally using an incentive-compatible cash payoff
   scheme in which maximum buying prices for bets and choices between bets
   were elicited from subjects. Surprisingly, observed maximum buying
   prices were far below expected values even for bets with probabilities
   of winning near 1.0. This suggests buyers are strongly influenced by
   loss aversion and that the conventional assumption that the buying price
   for a risky alternative is a reduction in the alternative's payoffs
   fails to describe behavior. Instead, it appears subjects predominately
   employed a segregation encoding process in which the buying price was
   encoded separately from the bet's payoffs and treated as a sure loss.
   However, an additional result was not explained adequately by either
   encoding model: Buying prices were less risk averse than choices for $3
   expected value bets-creating preference reversals of the standard kind
   (Lichtenstein and Slovic 1971)-but more risk averse for $100 expected
   value bets-creating reverse preference reversals (Casey 1991).
   Implications for the scale compatibility principle (Tversky et al. 1988)
   are discussed. Two theoretical approaches are outlined which offer
   promise in the development of a unified model of price judgments and
   choice preferences under risk.
ZS 0
ZA 0
ZB 0
ZR 0
Z8 1
TC 14
Z9 15
SN 0025-1909
UT WOS:A1994NX28000003
ER

PT J
AU RUEFLI, TW
   WIGGINS, RR
TI WHEN MEAN-SQUARE ERROR BECOMES VARIANCE - A COMMENT ON BUSINESS RISK AND
   RETURN - A TEST OF SIMULTANEOUS RELATIONSHIPS
SO MANAGEMENT SCIENCE
VL 40
IS 6
BP 750
EP 759
DI 10.1287/mnsc.40.6.750
PD JUN 1994
PY 1994
AB In a recent article, Oviatt and Bauerschmidt (1991) investigated
   risk-return relationship by employing the square root of the mean square
   error of returns as a measure of risk and found no significant
   relationship existed in those terms. Ruefli (1991) has suggested that
   under the assumption of stable distributions there is the possibility of
   spurious correlation in estimating the risk-return relationship in
   mean-variance terms. This comment identifies the commonalities between
   mean square error and variance measures, shows that the former measure
   is subject to many of the problems of the latter, and presents further
   evidence regarding the likelihood of spurious correlation in industry
   studies of risk and return. The results suggest an alternative and more
   parsimonious explanation for Oviatt and Bauerschmidt's findings as well
   as for the findings reported in the wider strategic management research
   literature.
TC 16
ZB 0
Z8 1
ZS 0
ZR 0
Z9 17
SN 0025-1909
EI 1526-5501
UT WOS:A1994NX28000004
ER

PT J
AU KEEFER, DL
TI CERTAINTY EQUIVALENTS FOR 3-POINT DISCRETE-DISTRIBUTION APPROXIMATIONS
SO MANAGEMENT SCIENCE
VL 40
IS 6
BP 760
EP 773
DI 10.1287/mnsc.40.6.760
PD JUN 1994
PY 1994
AB Three-point discrete-distribution approximations are often used in
   decision and risk analyses to represent probability distributions for
   continuous random variables-e.g., as probability nodes in decision or
   probability trees. Performance evaluations of such approximations have
   generally been based on their accuracies in estimating moments for the
   underlying distributions. However, moment-based comparisons for recently
   proposed approximations have been limited. Moreover, very little
   research has addressed the accuracies of any such approximations in
   representing expected utilities or certainty equivalents of the
   underlying distributions. This is of potential concern since recent
   research shows three-point discrete-distribution approximations exist
   that match the first several moments of an underlying distribution
   exactly while, counter-intuitively, approximating its certainty
   equivalents poorly. This paper compares the best two approximations for
   estimating means and variances identified in an earlier study with
   promising approximations proposed more recently. Specifically, it
   examines how accurately six simple general-purpose three-point
   approximations represent certainty equivalents for continuous random
   variables as the level of risk aversion is varied, as well as how
   accurately they estimate means and variances. The results show that
   several of these are quite accurate over a variety of test distributions
   when the level of risk aversion and the characteristics of the
   distributions are within reasonable bounds. Their robust performance is
   significant for decision analysis practice.
TC 52
ZR 0
ZA 0
Z8 0
ZS 0
ZB 1
Z9 52
SN 0025-1909
UT WOS:A1994NX28000005
ER

PT J
AU SHWARTZ, M
   LENARD, ML
TI IMPROVING ECONOMIC INCENTIVES IN-HOSPITAL PROSPECTIVE PAYMENT SYSTEMS
   THROUGH EQUILIBRIUM PRICING
SO MANAGEMENT SCIENCE
VL 40
IS 6
BP 774
EP 787
DI 10.1287/mnsc.40.6.774
PD JUN 1994
PY 1994
AB Under the Prospective Payment System (PPS) implemented by Medicare in
   1983, hospitals are paid a set price for each Medicare patient treated,
   rather than being reimbursed for the patient's costs as had been done
   previously. An increasing number of other insurers have adopted a
   similar method of hospital payment. In these systems, the price, which
   depends on the patient's Diagnosis Related Group (DRG), is derived from
   the average cost over all hospitals of all patients in that DRG. We
   propose an alternative method for setting prices in hospital prospective
   payment systems, called equilibrium pricing, in which prices are derived
   from a linear programming model of competitive equilibrium. To evaluate
   the improvement in incentives associated with equilibrium pricing, we
   define a measure, called the disincentive index, of the extent to which
   a set of prices creates economic disincentives to efficient behavior. In
   the situation in which all hospitals compete in a single market area, we
   show that equilibrium pricing creates the best possible economic
   incentives, i.e., by reducing the disincentive index to zero. The
   analysis is then extended to the more realistic situation where
   hospitals compete in limited geographical market areas, whereas prices
   must be uniformly set for a number of such market areas. We prove that,
   with an appropriate generalization of the disincentive index,
   equilibrium prices for a single market area are also optimal for
   multiple market areas. Finally, actual cost and utilization data from
   hospitals that compete in eastern Massachusetts are used to determine
   prices and to evaluate the associated disincentive index for a simulated
   prospective payment system. This empirical study shows a dramatic
   improvement in the incentives created by equilibrium pricing compared to
   average-cost pricing.
ZB 0
ZR 0
TC 3
Z8 0
ZS 0
ZA 0
Z9 3
SN 0025-1909
UT WOS:A1994NX28000006
ER

PT J
AU KALLIO, M
   SALO, S
TI TATONNEMENT PROCEDURES FOR LINEARLY CONSTRAINED CONVEX-OPTIMIZATION
SO MANAGEMENT SCIENCE
VL 40
IS 6
BP 788
EP 797
DI 10.1287/mnsc.40.6.788
PD JUN 1994
PY 1994
AB The emphasis in this article is to exploit the fact that precision
   requirements for solutions of most economic models in practice are
   moderate only. A simple approach is introduced for solving linearly
   constrained partial equilibrium models based on an iterative scheme
   similar to the simplex method. It allows large-scale models to be
   solved, within a practical tolerance, efficiently even in a micro
   computer environment. Extensions to linearly constrained convex
   optimization problems are presented. Finally, a set of computational
   tests on 68 linear programs from the NETLIB library is reported.
   Comparison of our approach with the simplex method (using MINOS 5.1) and
   with Karmarkar's algorithm is reported. For moderate precision
   requirements these preliminary results are highly encouraging.
RI Kallio, Markku J/G-2276-2013
ZA 0
ZR 0
TC 3
ZB 0
Z8 0
ZS 1
Z9 3
SN 0025-1909
UT WOS:A1994NX28000007
ER

PT J
AU ROBINS, RP
   SCHACHTER, B
TI AN ANALYSIS OF THE RISK IN DISCRETELY REBALANCED OPTION HEDGES AND
   DELTA-BASED TECHNIQUES
SO MANAGEMENT SCIENCE
VL 40
IS 6
BP 798
EP 808
DI 10.1287/mnsc.40.6.798
PD JUN 1994
PY 1994
AB The stochastic properties of discretely rebalanced option hedges have
   been studied extensively beginning with Black and Scholes (1973). In
   each analysis hedges were ''delta-neutral'' after rebalancing. We argue
   that the distributional properties of discretely rebalanced hedges are
   such that delta-based hedging is not the variance minimizing strategy.
   This paper obtains analytical expressions for the variance minimizing
   option hedge ratios. We also evaluate the hedge variance to assess the
   magnitude of the variance reduction over delta-based hedges. For
   representative parameter values, we show that systematic departures from
   delta-based hedges can yield significant reductions in hedge variance
   even for one day rebalancing intervals.
RI Schachter, Barry/D-3509-2013
OI Schachter, Barry/0000-0002-9704-0484
ZR 0
ZS 0
TC 5
ZB 0
Z8 1
Z9 6
SN 0025-1909
EI 1526-5501
UT WOS:A1994NX28000008
ER

PT J
AU ROY, A
   HANSSENS, DM
   RAJU, JS
TI COMPETITIVE PRICING BY A PRICE LEADER
SO MANAGEMENT SCIENCE
VL 40
IS 7
BP 809
EP 823
DI 10.1287/mnsc.40.7.809
PD JUL 1994
PY 1994
AB We examine the problem of pricing in a market where one brand acts as a
   price leader. We develop a procedure to estimate a leader's price rule,
   which is optimal given a sales target objective, and allows for the
   inclusion of demand forecasts. We illustrate our estimation procedure by
   calibrating this optimal price rule for both the leader and the follower
   using data on past sales and prices from the mid-size sedan segment of
   the U.S. automobile market. Our results suggest that a leader-follower
   system (Stackelberg) seems more consistent with the pricing behavior in
   this market, than a mutually independent pricing rule (Nash). We also
   find that our optimal price rule explains this market data better than
   other pricing schemes that do not account for optimizing behavior on the
   part of the leader and the follower.
RI Hanssens, Dominique M/D-4922-2011
TC 41
ZS 0
Z8 1
ZB 0
ZR 0
ZA 0
Z9 42
SN 0025-1909
EI 1526-5501
UT WOS:A1994PA56100001
ER

PT J
AU BALACHANDER, S
   SRINIVASAN, K
TI SELECTION OF PRODUCT LINE QUALITIES AND PRICES TO SIGNAL COMPETITIVE
   ADVANTAGE
SO MANAGEMENT SCIENCE
VL 40
IS 7
BP 824
EP 841
DI 10.1287/mnsc.40.7.824
PD JUL 1994
PY 1994
AB We investigate a firm's choice of prices and qualities of a product line
   to signal competitive advantage to potential entrants and to discourage
   entry. The market consists of customer segments with different
   valuations for product quality. We demonstrate that a higher quality and
   a higher price of each product in the line convey the firm's advantage
   to potential competition and prevents entry. We discuss implications for
   optimal product line selection when customers 'self-select' a product
   from the line.
   When product quality change is costly, the superior incumbent continues
   to select a higher quality and price for each product in the line to
   credibly substantiate its competitive advantage, though the distortions
   necessary from the optimal values are lower than before. After
   informative signalling and deterring entry, the firm retains the higher
   quality product line.
ZR 0
ZS 0
Z8 1
ZB 0
ZA 0
TC 38
Z9 39
SN 0025-1909
UT WOS:A1994PA56100002
ER

PT J
AU LAU, HS
   KLETKE, MG
TI A DECISION-SUPPORT SOFTWARE ON BIDDING FOR JOB INTERVIEWS IN COLLEGE
   PLACEMENT OFFICES
SO MANAGEMENT SCIENCE
VL 40
IS 7
BP 842
EP 845
DI 10.1287/mnsc.40.7.842
PD JUL 1994
PY 1994
AB Many university placement offices employ a bidding system to allocate
   on-campus recruiter interview slots to students. Typically, a student is
   given (say) 700 points each week to bid on the firms visiting that week.
   Interview slots for each firm are assigned beginning with the highest
   bidder until all slots are filled. This paper describes the mathematical
   modeling behind a decision support system for helping students to bid in
   such a system. It has three components. The first component elicits a
   student's utilities of getting an interview with the various firms. The
   second component estimates the probability of getting an interview with
   a particular firm for a given bid amount. The final component considers
   our bidding problem as the maximization of a student's expected utility,
   which can be formulated as a nonlinear integer programming (IP) problem.
   It is shown that this IP problem can be transformed into a number of
   nonlinear programming problems without integer requirements, which can
   then be solved very rapidly to give on-line bidding recommendations to a
   large number of students.
ZB 0
Z8 0
TC 1
ZS 0
ZR 0
Z9 1
SN 0025-1909
UT WOS:A1994PA56100003
ER

PT J
AU BALAKRISHNAN, A
   MAGNANTI, TL
   MIRCHANDANI, P
TI MODELING AND HEURISTIC WORST-CASE PERFORMANCE ANALYSIS OF THE 2-LEVEL
   NETWORK DESIGN PROBLEM
SO MANAGEMENT SCIENCE
VL 40
IS 7
BP 846
EP 867
DI 10.1287/mnsc.40.7.846
PD JUL 1994
PY 1994
AB This paper studies a multi-facility network synthesis problem, called
   the Two-level Network Design (TLND) problem, that arises in the
   topological design of hierarchical communication, 'transportation, and
   electric power distribution networks. We are given an undirected network
   containing two types of nodes-primary and secondary-and fixed costs for
   installing either a primary or a secondary facility on each edge.
   Primary nodes require higher grade interconnections than secondary
   nodes, using the more expensive primary facilities. The TLND problem
   seeks a minimum cost connected design that spans all the nodes, and
   connects primary nodes via edges containing primary facilities; the
   design.can use either primary or secondary edges to connect the
   secondary nodes. The TLND problem generalizes the well-known Steiner
   network problem and the hierarchical network design problem. In this
   paper, we study the relationship between alternative model formulations
   for this problem (e.g., directed and undirected models), and analyze the
   worst-case performance for a composite TLND heuristic based upon solving
   embedded subproblems (e.g., minimum spanning tree and either Steiner
   tree or shortest path subproblems). When the ratio of primary to
   secondary costs is the same for all edges and when we solve the embedded
   subproblems optimally, the worst-case performance ratio of the composite
   TLND heuristic is 4/3. This result applies to the hierarchical network
   design problem with constant primary-to-secondary cost ratio since its
   subproblems are shortest path and minimum spanning tree problems. For
   more general situations, we express the TLND heuristic worst-case ratio
   in terms of the performance of any heuristic used to solve the embedded
   Steiner tree subproblem. A companion paper develops and tests a dual
   ascent procedure that generates tight upper and lower bounds on the
   optimal value of a multi-level extension of this problem.
TC 48
ZS 0
Z8 1
ZA 0
ZB 0
ZR 0
Z9 49
SN 0025-1909
UT WOS:A1994PA56100004
ER

PT J
AU AMINI, MM
   RACER, M
TI A RIGOROUS COMPUTATIONAL COMPARISON OF ALTERNATIVE SOLUTION METHODS FOR
   THE GENERALIZED ASSIGNMENT PROBLEM
SO MANAGEMENT SCIENCE
VL 40
IS 7
BP 868
EP 890
DI 10.1287/mnsc.40.7.868
PD JUL 1994
PY 1994
AB Statistical experimental design and analysis is a cornerstone for
   scientific inquiry that is rarely applied in reporting computational
   testing. This approach is employed to study the relative performance
   characteristics of the four leading algorithmic and heuristic
   alternatives to solve the Linear Cost Generalized Assignment Problem
   (LCGAP) against a newly developed heuristic, Variable-Depth Search
   Heuristic (VDSH). In assessing the relative effectiveness of the
   prominent solution methodologies and VDSH under the effects of various
   problem characteristics, we devise a carefully designed experimentation
   of state-of-the-art implementations; through a rigorous statistical
   analysis we identify the most efficient method(s) for commonly studied
   LCGAPs, and determine the effect on solution time and quality of problem
   class and size.
ZA 0
ZB 0
TC 41
ZR 0
ZS 1
Z8 1
Z9 43
SN 0025-1909
UT WOS:A1994PA56100005
ER

PT J
AU HENIG, MI
TI EFFICIENT INTERACTIVE METHODS FOR A CLASS OF MULTIATTRIBUTE
   SHORTEST-PATH PROBLEMS
SO MANAGEMENT SCIENCE
VL 40
IS 7
BP 891
EP 897
DI 10.1287/mnsc.40.7.891
PD JUL 1994
PY 1994
AB Given an acyclic network and a preference-order relation on paths, when
   and how can Bellman's principle of optimality be combined with
   interactive programming to efficiently locate an optimal path? We show
   that if preferences are defined via a collection of attributes, then,
   under common conditions, the principle of optimality is valid if and
   only if the preferences can be represented by a linear (value) function
   over the attributes. Consequently, an interactive programming method is
   suggested which assesses the value function while using the principle of
   optimality to efficiently search for an optimal path.
TC 17
Z8 0
ZR 0
ZS 0
ZB 0
ZA 0
Z9 17
SN 0025-1909
UT WOS:A1994PA56100006
ER

PT J
AU BONETT, DG
   WOODWARD, JA
TI SEQUENTIAL DEFECT REMOVAL SAMPLING
SO MANAGEMENT SCIENCE
VL 40
IS 7
BP 898
EP 902
DI 10.1287/mnsc.40.7.898
PD JUL 1994
PY 1994
AB Standard inspection methods underestimate the true number of defects or
   nonconformities in a complex product (e.g., automobile, mobile home,
   airplane, circuit board, computer program) when an inspector is unable
   to identify every defect with certainty. A nonlinear statistical model
   with a nonlinear constraint is developed for estimating the unknown
   number of defects in a product when inspection is imperfect. A
   sequential defect removal sampling plan is defined in which two or more
   inspectors examine in sequence a product or sample of products and then
   mark or correct any observed defects prior to the next inspection. The
   number of defects identified by each inspector provides the information
   needed to estimate the number of defects in the product in addition to
   the number of defects that have eluded all inspectors. A goodness-of-fit
   test of model assumptions is presented. A test of hypothesis regarding
   the unknown number of defects in quality improvement experiments also is
   described.
TC 11
ZA 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 11
SN 0025-1909
UT WOS:A1994PA56100007
ER

PT J
AU RAJAGOPALAN, S
   SOTERIOU, AC
TI CAPACITY ACQUISITION AND DISPOSAL WITH DISCRETE FACILITY SIZES
SO MANAGEMENT SCIENCE
VL 40
IS 7
BP 903
EP 917
DI 10.1287/mnsc.40.7.903
PD JUL 1994
PY 1994
AB We consider some key features of capacity acquisition, disposal, and
   replacement decisions in this paper that 'are seldom captured in
   capacity expansion models in the literature. First, capacity is often
   purchased in the form of equipment which comes only in a few discrete
   sizes. Second, some or all of the capacity may be replaced periodically
   due to the availability of better and cheaper equipment, or due to
   deterioration and increased operating costs of older equipment. Finally,
   some capacity may be disposed due to declining demand. We present
   integer programming formulations that model all of these aspects. We
   identify special structures in these formulations that are then
   exploited to develop efficient procedures for solving the linear
   relaxation optimally. The solution to the linear relaxation together
   with a heuristic interchange procedure are used in a branch-and-bound
   procedure to obtain optimal solutions. Computational results are
   presented that establish the effectiveness of the procedures in solving
   realistic problems to optimality.
OI Soteriou, Andreas/0000-0001-8527-3742
ZS 0
ZA 0
TC 26
ZR 0
Z8 1
ZB 0
Z9 27
SN 0025-1909
UT WOS:A1994PA56100008
ER

PT J
AU BOZER, YA
   MELLER, RD
   ERLEBACHER, SJ
TI AN IMPROVEMENT-TYPE LAYOUT ALGORITHM FOR SINGLE AND MULTIPLE-FLOOR
   FACILITIES
SO MANAGEMENT SCIENCE
VL 40
IS 7
BP 918
EP 932
DI 10.1287/mnsc.40.7.918
PD JUL 1994
PY 1994
AB In this paper we introduce the use of spacefilling curves in facility
   layout, and we extend a well-known facility layout algorithm (CRAFT) to
   facilities with multiple floors. Spacefilling curves make it possible to
   exchange any two departments and to use more powerful exchange routines
   than two-way or three-way exchanges. We also further enhance CRAFT by
   controlling department shapes, and (with multiple floors) by allowing
   ''flexible'' departmental area requirements. Although the algorithm we
   present can be used for any single-floor or multi-floor facility layout
   problem, its primary target is production facilities. A tailored version
   of the algorithm was successfully tested and used in a large,
   multi-floor production facility. The algorithm differs significantly
   from two previous extensions of CRAFT to multi-floor facilities.
ZS 2
ZR 0
Z8 2
ZB 0
ZA 0
TC 122
Z9 124
SN 0025-1909
UT WOS:A1994PA56100009
ER

PT J
AU DEGROOTE, X
TI THE FLEXIBILITY OF PRODUCTION PROCESSES - A GENERAL FRAMEWORK
SO MANAGEMENT SCIENCE
VL 40
IS 7
BP 933
EP 945
DI 10.1287/mnsc.40.7.933
PD JUL 1994
PY 1994
AB Various models have been developed over the years to analyze the many
   facets of the flexibility of production and operations systems. This
   paper proposes a general framework for the modeling and analysis of
   flexibility. The argument hinges upon the distinction between
   flexibility-a property of the technology-and diversity-a property of the
   environment in which the technology is operated. Flexibility is
   characterized as a hedge against diversity. Intuitive strategic
   properties that are conventionally attributed to flexibility are shown
   to follow directly from this framework. As illustrated by the different
   examples that are discussed, many existing models can be naturally
   interpreted in this context. As an application, the effect of load
   imbalance on a set of parallel machines is analyzed. The problem sheds
   light on the role of flexibility in queuing network and lot-sizing
   models of production.
TC 89
ZB 0
ZS 2
Z8 2
ZA 0
ZR 0
Z9 93
SN 0025-1909
UT WOS:A1994PA56100010
ER

PT J
AU DORROH, JR
   GULLEDGE, TR
   WOMER, NK
TI INVESTMENT IN KNOWLEDGE - A GENERALIZATION OF LEARNING BY EXPERIENCE
SO MANAGEMENT SCIENCE
VL 40
IS 8
BP 947
EP 958
DI 10.1287/mnsc.40.8.947
PD AUG 1994
PY 1994
AB Learning is often perceived as a cost-reducing endogenous by-product of
   production processes. In many applications this by-product is modeled as
   a learning curve; that is, a simple function of time or of cumulative
   production experience. In an earlier paper we presented an alternative
   explanation where managers decide what resources to devote to knowledge
   acquisition. In this paper we expand those results to a situation using
   a more flexible production technology and emphasizing discounted cost.
   Our model explains resource and output behavior for a firm that is
   producing specialized units to contractual order. However, the results
   are quite general and have implications for investment in research,
   engineering, science and technology, software development, and worker
   training. We provide examples where the cost-minimizing producer will
   choose to invest in knowledge creation early in the production program
   and then have the rate of investment decline over time. Other
   interesting results are noted by examining the optimal time paths of the
   control and state variables in a comparative dynamics analysis.
RI Womer, Norman/R-7278-2019
ZB 1
ZR 0
Z8 1
ZA 0
ZS 0
TC 50
Z9 51
SN 0025-1909
UT WOS:A1994PF27200001
ER

PT J
AU BOGETOFT, P
TI INCENTIVE EFFICIENT PRODUCTION FRONTIERS - AN AGENCY PERSPECTIVE ON DEA
SO MANAGEMENT SCIENCE
VL 40
IS 8
BP 959
EP 968
DI 10.1287/mnsc.40.8.959
PD AUG 1994
PY 1994
AB In this paper, we examine how empirical production frontiers may
   contribute to the incentives of production units. We consider a series
   of Data Envelopment Analysis (DEA) frontiers, and we show when these may
   be incentive efficient in the sense that they contain all the
   information that are relevant for optimal incentive provision. The
   frontiers considered include the so-called constant, decreasing and
   varying return to scale models, the free disposability and the free
   replicability models, as well as the increasing and decreasing return to
   scale models based on a relaxed set of assumptions. Also, we illustrate
   how to design optimal incentive schemes based on such frontiers.
TC 75
ZS 1
ZB 2
Z8 0
ZR 0
ZA 0
Z9 76
SN 0025-1909
UT WOS:A1994PF27200002
ER

PT J
AU RAM, S
   NARASIMHAN, S
TI DATABASE ALLOCATION IN A DISTRIBUTED ENVIRONMENT - INCORPORATING A
   CONCURRENCY-CONTROL MECHANISM AND QUEUING COSTS
SO MANAGEMENT SCIENCE
VL 40
IS 8
BP 969
EP 983
DI 10.1287/mnsc.40.8.969
PD AUG 1994
PY 1994
AB This research investigates the problem of allocating database fragments
   across a set of computers connected by a communication network. A
   mathematical model is presented to aid designers in the development of
   distributed database systems. The model takes into account the pattern
   of usage of the databases, communication costs in the network, delays
   due to queuing of data requests, costs for maintaining consistency among
   the various copies of a database, and storage costs. A solution
   procedure based on Lagrangian relaxation is proposed to solve the model.
   Computational results are reported along with several useful
   observations. The model is applicable to organizations that are
   considering migration from a centralized to a distributed computing
   environment.
Z8 1
ZB 0
ZR 1
ZA 0
TC 18
ZS 0
Z9 19
SN 0025-1909
UT WOS:A1994PF27200003
ER

PT J
AU RIGGINS, FJ
   KRIEBEL, CH
   MUKHOPADHYAY, T
TI THE GROWTH OF INTERORGANIZATIONAL SYSTEMS IN THE PRESENCE OF NETWORK
   EXTERNALITIES
SO MANAGEMENT SCIENCE
VL 40
IS 8
BP 984
EP 998
DI 10.1287/mnsc.40.8.984
PD AUG 1994
PY 1994
AB We develop a model of network growth in the presence of network
   externalities for the case where a buyer initiates an
   interorganizational system with its suppliers. In our two-stage model,
   suppliers joining the network in the first stage can gain economic
   benefit from increased market share or higher price for the primary
   product. Suppliers encounter negative externalities since the economic
   benefit accruing to participating suppliers is less for increasingly
   larger networks. In the first stage, the buyer may experience initial
   supplier adoption of the network followed by a ''stalling'' problem due
   to negative externalities. In order to overcome this stalling problem,
   the buyer may find it optimal to subsidize some suppliers' costs to join
   the network in the second stage. We characterize the buyer's optimal
   second stage subsidy policy and show the conditions under which the
   buyer will find it optimal to offer a subsidy. If the suppliers have
   some positive ex ante expectation of a second stage subsidy, the growth
   of the network will be retarded in the first stage resulting in
   suboptimal profits for the buyer.
OI Mukhopadhyay, Tridas/0000-0001-6691-9595
ZR 0
ZA 0
ZB 0
Z8 3
TC 106
ZS 0
Z9 109
SN 0025-1909
UT WOS:A1994PF27200004
ER

PT J
AU GALLEGO, G
   VANRYZIN, G
TI OPTIMAL DYNAMIC PRICING OF INVENTORIES WITH STOCHASTIC DEMAND OVER
   FINITE HORIZONS
SO MANAGEMENT SCIENCE
VL 40
IS 8
BP 999
EP 1020
DI 10.1287/mnsc.40.8.999
PD AUG 1994
PY 1994
AB In many industries, managers face the problem of selling a given stock
   of items by a deadline. We investigate the problem of dynamically
   pricing such inventories when demand is price sensitive and stochastic
   and the firm's objective is to maximize expected revenues. Examples that
   fit this framework include retailers selling fashion and seasonal goods
   and the travel and leisure industry, which markets space such as seats
   on airline flights, cabins on vacation cruises, and rooms in hotels that
   become worthless if not sold by a specific time.
   We formulate this problem using intensity control and obtain structural
   monotonicity results for the optimal intensity (resp., price) as a
   function of the stock level and the length of the horizon. For a
   particular exponential family of demand functions, we find the optimal
   pricing policy in closed form. For general demand functions, we find an
   upper bound on the expected revenue based on analyzing the deterministic
   version of the problem and use this bound to prove that simple, fixed
   price policies are asymptotically optimal as the volume of expected
   sales tends to infinity. Finally, we extend our results to the case
   where demand is compound Poisson; only a finite number of prices is
   allowed; the demand rate is time varying; holding costs are incurred and
   cash flows are discounted; the initial stock is a decision variable; and
   reordering, overbooking, and random cancellations are allowed.
RI Gallego, Guillermo/AAK-1549-2020; Escarabajal, Juan Antonio/C-5644-2012
OI Gallego, Guillermo/0000-0002-9664-3750; 
ZR 0
TC 728
ZA 0
Z8 73
ZB 1
ZS 1
Z9 798
SN 0025-1909
EI 1526-5501
UT WOS:A1994PF27200005
ER

PT J
AU KWON, C
   TEW, JD
TI STRATEGIES FOR COMBINING ANTITHETIC VARIATES AND CONTROL VARIATES IN
   DESIGNED SIMULATION EXPERIMENTS
SO MANAGEMENT SCIENCE
VL 40
IS 8
BP 1021
EP 1034
DI 10.1287/mnsc.40.8.1021
PD AUG 1994
PY 1994
AB In this paper we examine three methods for combining the variance
   reduction techniques of antithetic variates and control variates to
   estimate the mean response in a designed simulation experiment. In
   Combined Method I, we perform h independent pairs of simulation runs as
   follows-on the second run of each such pair, we use random number
   streams that are antithetic (complementary) to the streams used on the
   first run of the pair to drive the non-control-variate components of the
   simulation model; and we use independent random number streams to drive
   the control-variate components of the simulation model. In Combined
   Method II, we also perform h independent pairs of runs; but on each pair
   of runs we use independent random number streams to drive the
   non-control-variate model components, and we use antithetic random
   number streams to drive the control-variate components. In Combined
   Method III, all of the random number streams driving the second run of
   each pair of runs are antithetic to the streams driving the first run of
   the pair. For each of these three methods we derive the variance of the
   resulting estimator of the mean response to make a theoretical
   comparison of the efficiency of each method. We implemented these three
   methods, along with the classical method of control variates, in a
   simulation model of a resource-constrained activity network to show how
   each combined method is implemented in practice and to evaluate the
   performance of each combined method experimentally. The results indicate
   that: (a) Combined Method III outperformed all other methods, and (b)
   the effectiveness of Combined Method III as well as the choice of
   whether to use Combined Method I or Combined Method II depends on the
   degree of correlation between the control variates and the response.
TC 5
Z8 0
ZR 0
ZB 0
ZS 0
Z9 5
SN 0025-1909
UT WOS:A1994PF27200006
ER

PT J
AU GREGORY, R
   KEENEY, RL
TI CREATING POLICY ALTERNATIVES USING STAKEHOLDER VALUES
SO MANAGEMENT SCIENCE
VL 40
IS 8
BP 1035
EP 1048
DI 10.1287/mnsc.40.8.1035
PD AUG 1994
PY 1994
AB Choices that require multiple stakeholders to balance conflicting
   objectives are among today's most controversial decisions. Although many
   techniques exist for helping decision makers to select among projects,
   little attention has been given to processes for identifying improved
   alternatives based on clearly articulated stakeholder values. In this
   paper we describe a general process to inform controversial social
   decisions by first structuring stakeholder objectives and then using
   this information to create policy alternatives. We also report the
   results of a workshop in Sabah, Malaysia which used the proposed
   approach as the basis for multiple stakeholder negotiations.
Z8 1
ZA 0
ZR 0
ZB 34
ZS 1
TC 175
Z9 177
SN 0025-1909
UT WOS:A1994PF27200007
ER

PT J
AU JARRAH, AIZ
   BARD, JF
   DESILVA, AH
TI EQUIPMENT SELECTION AND MACHINE SCHEDULING IN GENERAL MAIL FACILITIES
SO MANAGEMENT SCIENCE
VL 40
IS 8
BP 1049
EP 1068
DI 10.1287/mnsc.40.8.1049
PD AUG 1994
PY 1994
AB With the goal of fiscal self-sufficiency, the United States Postal
   Service (USPS) has embarked upon a 10-year program to modernize, and in
   some cases radically alter, the way it manages and processes the mail.
   At the heart of this effort is the goal of automating virtually all of
   the letter mail by 1995. This means reading, sorting, and then
   sequencing each mail piece to the order in which it will be delivered by
   the carrier with only a minimum of manual labor. In support of this
   goal, a series of long-term planning models has been developed to help
   select equipment and plan for its use at the more than 250 general mail
   facilities (GMF) throughout the nation. This paper reports on one of the
   central studies underlying this effort.
   Because of the size and complexity of the facility design problem, a
   hierarchical approach was followed. Three interrelated models were
   developed starting with a mixed integer linear program to derive
   equipment needs and initial machine schedules. The latter are
   post-processed in two stages to produce implementable schedules that
   reflect current practice. An auxiliary linear program and a heuristic
   were constructed for this purpose. The models and analysis conducted are
   demonstrated with data obtained from the Providence GMF. The results
   indicate that near optimal solutions can be found quite efficiently and
   are expected to lead to substantial savings over the 10-year planning
   horizon.
TC 15
ZB 0
ZR 0
Z8 0
ZS 0
Z9 15
SN 0025-1909
UT WOS:A1994PF27200008
ER

PT J
AU SWANSON, EB
TI INFORMATION-SYSTEMS INNOVATION AMONG ORGANIZATIONS
SO MANAGEMENT SCIENCE
VL 40
IS 9
BP 1069
EP 1092
DI 10.1287/mnsc.40.9.1069
PD SEP 1994
PY 1994
AB In an era of revolutionary new developments in basic information
   technology, innovation in its employment among organizations is
   increasingly crucial to competitive survival and success.  The
   Information Systems (IS) unit within the business is largely responsible
   for meeting this challenge.  Yet, current theory explains little about
   IS innovation and its role in organizational innovation in general.  We
   suggest some needed foundations.  IS innovations are posited to be of
   three types:  Type I innovations confined to the IS task; Type II
   innovations supporting administration of the business; and Type III
   innovations imbedded in the core technology of the business.  Diffusion
   among organizations is conjectured to occur by means of a communication
   circuit in which each IS unit is linked to its professional and business
   environments.  Systematic differences in adoption and evolution patterns
   among IS innovation types are expected.  Three specific IS
   innovations-data administration, the information center, and material
   requirements planning (MRP)-illustrate.
Z8 2
ZS 4
ZB 4
TC 467
ZR 0
ZA 0
Z9 472
SN 0025-1909
UT WOS:A1994PL87700001
ER

PT J
AU MUHANNA, WA
   PICK, RA
TI METAMODELING CONCEPTS AND TOOLS FOR MODEL MANAGEMENT - A
   SYSTEMS-APPROACH
SO MANAGEMENT SCIENCE
VL 40
IS 9
BP 1093
EP 1123
DI 10.1287/mnsc.40.9.1093
PD SEP 1994
PY 1994
AB We present a new framework for model management based on system concepts
   and theory.  Underlying the framework is a set of meta-modeling concepts
   that are useful in capturing the semantics of the modeling process in a
   modeling environment.  These concepts include the notions of a
   general-model type, type specialization, atomic and composite model
   verions, model instances, and parameterized versions.  We describe these
   concepts both conceptually and formally and then briefly present a Model
   Description Language (MDL) that embodies them.  While other researchers
   have suggested some of these concepts primarily in different contexts,
   this paper makes at least four valuable contributions:  (1) the
   identification of fundamental issues and principles related to model
   management; (2) the development and enhanced treatment of meta-modeling
   concepts specifically for model management; (3) the synthesis of those
   concepts into a coherent, unifying framework for model management; and
   (4) a demonstration of the practicality of those concepts through a
   prototype system implementation.  Our framework proposes a
   graph-oriented, nonprocedural, and hierarchical approach for model
   composition.  The framework also supports both model-solver independence
   and model-data independence.  Moreover, it offers general solutions to
   two critical issues in model management:  model-model linkage and
   model-data linkage.  We argue that the system framework can serve as a
   guide for an effective design of a flexible and extensible model
   management system.  An architecture of such a system and its prototype
   implementation-called SYMMS-are briefly described.  Examples are
   presented to illustrate the features and advantages of our approach.
RI Pick, Roger A/H-2737-2012
ZS 0
ZR 0
ZA 0
ZB 2
TC 42
Z8 0
Z9 42
SN 0025-1909
UT WOS:A1994PL87700002
ER

PT J
AU JARRAH, AIZ
   BARD, JF
   DESILVA, AH
TI SOLVING LARGE-SCALE TOUR SCHEDULING PROBLEMS
SO MANAGEMENT SCIENCE
VL 40
IS 9
BP 1124
EP 1144
DI 10.1287/mnsc.40.9.1124
PD SEP 1994
PY 1994
AB For a given planning horizon, workforce composition and set of labor
   requirements, personnel scheduling often reduces to solving three
   problems.  The first is concerned with the assignment of days off; the
   second involves assigning workers to shifts during the day; and the
   third involves the construction of weekly tours.  In many manufacturing
   facilities, tour scheduling is easy because the start and end times of
   shifts are invariant, and no work takes place on the weekend.  But when
   daily patterns vary, such as in the airlines, processing, and public
   service industries, and when part-timers make up a portion of the
   workforce, the complexity of the overall problem increases dramatically.
   This paper presents a new methodology for solving the combined shift and
   days-off scheduling problem when the labor requirements span less than
   24 hours per day.  We begin with an integer programming formulation and
   then introduce a set of aggregate variables and related cuts.  When the
   aggregate variables are fixed the original problem decomposes into seven
   subproblems (one for each day of the week) that are much easier to
   solve.  A partial enumeration scheme and a heuristic for ensuring
   feasibility are employed to find upper and lower bounds which converge
   rapidly to near-optima.
   The methodology is applied to tour scheduling at general mail facilities
   (GMFs).  These facilities are located in most urban areas and process
   millions of mail pieces daily for local and regional distribution.  The
   model accounts for the principal constraints in the U.S. Postal Service
   labor contract, including half-hour breaks, minimum full-time to
   part-time ratios, and variable start times.  Also considered are four
   and five day work weeks, and the possibility of assigning workers across
   labor categories.  A full analysis of the Providence, Rhode Island
   facility is presented.
Z8 1
ZR 0
ZA 0
ZB 0
ZS 0
TC 68
Z9 69
SN 0025-1909
UT WOS:A1994PL87700003
ER

PT J
AU KOHLI, R
   PARK, H
TI COORDINATING BUYER-SELLER TRANSACTIONS ACROSS MULTIPLE PRODUCTS
SO MANAGEMENT SCIENCE
VL 40
IS 9
BP 1145
EP 1150
DI 10.1287/mnsc.40.9.1145
PD SEP 1994
PY 1994
AB Joint ordering policies are examined as a method for reducing the
   transactions cost for multiple products sold by a seller to a
   homogeneous group of buyers.  The problem of determining efficient joint
   ordering policies has the same structure as the previously-examined
   problem of determining the efficient ordering policy for a single
   product.  Efficient joint lot-sizes are independent of prices, and are
   supported by a range of average-unit prices that permit every possible
   allocation of the transactions-cost saving between the buyer and the
   seller.  Product bundling supports efficient joint orders across
   products, just as a quantity discount supports efficient transactions
   for a single product.
ZS 1
ZA 0
Z8 4
ZB 0
ZR 0
TC 32
Z9 36
SN 0025-1909
UT WOS:A1994PL87700004
ER

PT J
AU ELIASHBERG, J
   SAWHNEY, MS
TI MODELING GOES TO HOLLYWOOD - PREDICTING INDIVIDUAL-DIFFERENCES IN MOVE
   ENJOYMENT
SO MANAGEMENT SCIENCE
VL 40
IS 9
BP 1151
EP 1173
DI 10.1287/mnsc.40.9.1151
PD SEP 1994
PY 1994
AB Consumer behavior researchers are getting more interested in the
   experiential aspect of consumption, which focuses on the fun and
   enjoyment that consumers derive from hedonic experiences. We build upon
   the experimental view of consumer behavior, and present an innovative
   modeling approach to studying the dynamics of hedonic consumption
   experiences. We develop a conceptual framework for the enjoyment of a
   hedonic experience, in which we propose that the enjoyment of the
   experience is an outcome of the dynamic interaction between stable
   individual difference factors, temporary moods, and the emotional
   content of the experience. We present an application of the conceptual
   framework in the context of a movie viewing experience. We model the
   interaction between the temporary moods of an individual and the
   emotional content of the movie as a stochastic process. This interaction
   determines the individual's instantaneous emotional states. We develop
   analytical expressions for the dynamic evolution of the probability
   distribution of the levels of achieved emotional stimulation, and,
   through individual difference factors, the expected enjoyment. All
   measurements are taken prior to watching the movie. We use these
   measurements to predict individual differences in the ex-post enjoyment
   of the movie. We present an empirical test of the movie enjoyment model
   (ENJMOD), and find encouraging results at the individual and segment
   level. We discuss the implications of our modeling approach for the
   segmentation and testing of movies, and for the prediction of consumer
   response to similar experiential products.
ZB 0
Z8 2
ZS 1
ZR 0
ZA 0
TC 100
Z9 102
SN 0025-1909
EI 1526-5501
UT WOS:A1994PL87700005
ER

PT J
AU FISHBURN, PC
   SARIN, RK
TI FAIRNESS AND SOCIAL RISK .1. UNAGGREGATED ANALYSES
SO MANAGEMENT SCIENCE
VL 40
IS 9
BP 1174
EP 1188
DI 10.1287/mnsc.40.9.1174
PD SEP 1994
PY 1994
AB This paper is the first of a two-paper study of fairness issues for
   decisions that affect the benefits received and the risks encountered by
   a population.  The study examines fairness for individuals and for
   homogeneous groups within the population.  It considers fairness both
   for population benefit-risk profiles and for probability distributions
   over profiles that reflect uncertainty about outcomes of decisions.
   The present paper focuses on fairness for profiles in which benefits and
   risks are not aggregated within groups or across the population.  It
   ties fairness to notions of envy among individuals and groups that are
   based on individuals' preferences.  The sequel will discuss aggregation
   of benefits and risks along with fairness from an aggregated
   perspective.
ZR 0
TC 12
ZS 0
ZB 0
Z8 0
ZA 0
Z9 12
SN 0025-1909
UT WOS:A1994PL87700006
ER

PT J
AU NAKAYAMA, MK
TI 2-STAGE STOPPING PROCEDURES BASED ON STANDARDIZED TIME-SERIES
SO MANAGEMENT SCIENCE
VL 40
IS 9
BP 1189
EP 1206
DI 10.1287/mnsc.40.9.1189
PD SEP 1994
PY 1994
AB We propose some new two-stage stopping procedures to construct
   absolute-width and relative-width confidence intervals for a simulation
   estimator of the steady-state mean of a stochastic process.  The
   procedures are based on the method of standardized time series proposed
   by Schruben and on Stein's two-stage sampling scheme.  We prove that our
   two-stage procedures give rise to asymptotically valid confidence
   intervals (as the prescribed length of the confidence interval
   approaches zero and the size of the first stage grows to infinity).  The
   sole assumption required is that the stochastic process satisfy a
   functional central limit theorem.
ZA 0
ZR 0
ZS 0
ZB 0
Z8 0
TC 17
Z9 17
SN 0025-1909
UT WOS:A1994PL87700007
ER

PT J
AU ERNST, LR
TI APPORTIONMENT METHODS FOR THE HOUSE-OF-REPRESENTATIVES AND THE COURT
   CHALLENGES
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1207
EP 1227
DI 10.1287/mnsc.40.10.1207
PD OCT 1994
PY 1994
AB Four different methods have been used to apportion the seats in the
   United States House of Representatives among the states following the
   decennial census. The current method, the method of equal proportions,
   has been used for each census since 1940. In 1991, for the first time in
   U.S. history, the constitutionality of an apportionment method was
   challenged in court, by Montana and Massachusetts in separate cases.
   Montana proposed two methods as alternatives to equal proportions, the
   methods of harmonic means and smallest divisors, while Massachusetts
   proposed the method of major fractions. On March 31, 1992, in a
   unanimous decision, the U.S. Supreme Court upheld the constitutionality
   of equal proportions. This author wrote the declarations on the
   mathematical and statistical issues used by the defense in these cases.
   The declarations in the Massachusetts case contain several new
   theoretical and empirical results. This paper discusses the technical
   issues in these eases together with a brief history of the apportionment
   problem.
TC 10
Z8 0
ZR 0
ZB 0
ZS 0
Z9 10
SN 0025-1909
UT WOS:A1994PR83400001
ER

PT J
AU SIVARAMAKRISHNAN, K
TI INFORMATION ASYMMETRY, PARTICIPATION, AND LONG-TERM-CONTRACTS
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1228
EP 1244
DI 10.1287/mnsc.40.10.1228
PD OCT 1994
PY 1994
AB This paper examines the economic value of participative processes in the
   setting of long-term incentives. When informational asymmetries arise
   between employers (supervisors) and employees (subordinates) about
   future states, questions arise as to whether and when resolving these
   informational asymmetries produces economic gains. To address these
   questions, I use a two-period principal agent contracting framework in
   which the agent (employee) receives imperfect private information about
   the second period state in the first period, and make a welfare
   comparison between two alternative communication regimes.
   In the ''delayed communication regime,'' a report from the agent is
   considered only for second period contract. In the ''early communication
   regime,'' the report is considered for first period contracting as well.
   This regime can therefore be viewed as encouraging participation in
   long-term contracts. I identify conditions under which the early
   communication regime is strictly preferable to the delayed communication
   regime. Further, given some additional structure on the agent's
   preferences, this result obtains even if the agent can access capital
   markets to smooth inter-temporal consumption.
   Finally, I examine the setting in which the principal, at the time of
   contracting, has the option of whether or not to install an information
   system that provides the agent with private information about the future
   period state. I identify conditions under which installing the
   information system, and resolving the consequent information asymmetry
   through participation, is strictly preferable to not installing the
   information system.
ZR 0
ZS 0
ZA 0
ZB 0
TC 8
Z8 0
Z9 8
SN 0025-1909
UT WOS:A1994PR83400002
ER

PT J
AU LECUYER, P
   GIROUX, N
   GLYNN, PW
TI STOCHASTIC OPTIMIZATION BY SIMULATION - NUMERICAL EXPERIMENTS WITH THE
   M/M/1 QUEUE IN STEADY-STATE
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1245
EP 1261
DI 10.1287/mnsc.40.10.1245
PD OCT 1994
PY 1994
AB This paper gives numerical illustrations of the behavior of stochastic
   approximation, combined with different derivative estimation techniques,
   to optimize a steady-state system. It is a companion paper to L'Ecuyer
   and Glynn (1993), which gives convergence proofs for most of the
   variants experimented here. The numerical experiments are made with a
   simple M/M/1 queue, which while simple, serves to illustrate the basic
   convergence properties and possible pitfalls of the various techniques.
RI L'Ecuyer, Pierre/O-6577-2019
OI L'Ecuyer, Pierre/0000-0002-3184-0796
Z8 0
ZA 0
ZB 0
TC 46
ZS 0
ZR 0
Z9 46
SN 0025-1909
EI 1526-5501
UT WOS:A1994PR83400003
ER

PT J
AU CHEN, FR
   ZHENG, YS
TI EVALUATING ECHELON STOCK (R,NQ) POLICIES IN SERIAL PRODUCTION INVENTORY
   SYSTEMS WITH STOCHASTIC DEMAND
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1262
EP 1275
DI 10.1287/mnsc.40.10.1262
PD OCT 1994
PY 1994
AB This paper studies echelon stock (R, nQ) policies in serial
   production/inventory systems with stochastic demand. We provide a
   recursive procedure to compute the steady state echelon inventory levels
   of the systems, which can be used to evaluate the long-run average
   holding and backorder costs as well as other performance measures. The
   procedure is based upon an observation of a relationship between the
   inventory status of adjacent stages in a serial system. We also derive
   exact formulas for replenishment frequencies and setup costs. Our
   results apply to both continuous-review systems with compound Poisson
   demand and periodic-review systems with independent, identically
   distributed demands. A preliminary numerical study was conducted to
   explore the cost effectiveness of echelon stock (R, nQ) policies. For
   two-stage systems with simple Poisson demand, we compared among the
   minimum costs of echelon stock (R, nQ) policies, a lower bound on the
   minimum achievable costs, and the minimum costs of installation stock
   (R, nQ) policies. Finally, we present a modification of an existing
   approximate evaluation procedure.
ZB 0
TC 60
ZR 0
ZS 0
Z8 4
ZA 0
Z9 64
SN 0025-1909
UT WOS:A1994PR83400004
ER

PT J
AU GENDREAU, M
   HERTZ, A
   LAPORTE, G
TI A TABU SEARCH HEURISTIC FOR THE VEHICLE-ROUTING PROBLEM
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1276
EP 1290
DI 10.1287/mnsc.40.10.1276
PD OCT 1994
PY 1994
AB The purpose of this paper is to describe TABUROUTE, a new tabu search
   heuristic for the vehicle routing problem with capacity and route length
   restrictions. The algorithm considers a sequence of adjacent solutions
   obtained by repeatedly removing a vertex from its current route and
   reinserting it into another route. This is done by means of a
   generalized insertion procedure previously developed by the authors.
   During the course of the algorithm, infeasible solutions are allowed.
   Numerical tests on a set of benchmark problems indicate that tabu search
   outperforms the best existing heuristics, and TABUROUTE often produces
   the best known solutions.
RI Gendreau, Michel/N-7950-2019; Gendreau, Michel/M-6235-2018
OI Gendreau, Michel/0000-0002-9262-3648; Gendreau,
   Michel/0000-0002-9262-3648
ZB 9
ZA 0
ZS 3
TC 617
ZR 1
Z8 37
Z9 657
SN 0025-1909
UT WOS:A1994PR83400005
ER

PT J
AU SRINIVASAN, K
   KEKRE, S
   MUKHOPADHYAY, T
TI IMPACT OF ELECTRONIC DATA INTERCHANGE TECHNOLOGY ON JIT SHIPMENTS
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1291
EP 1304
DI 10.1287/mnsc.40.10.1291
PD OCT 1994
PY 1994
AB We investigate the degree to which increasing vertical information
   integration using Electronic Data Interchange technology enhances
   shipment performance of suppliers in a Just-in-Time environment. Our
   analysis of shipment data in the automobile industry suggests that
   shipment performance degrades substantially due to increases in part
   variety and trading partners from diverse industries. However,
   investments in information technology to support both the sharing of JIT
   schedules and the establishment of integrated information links are
   related to significant reduction in the level of shipment discrepancies.
OI Mukhopadhyay, Tridas/0000-0001-6691-9595
ZS 0
TC 174
ZA 0
Z8 4
ZB 0
ZR 0
Z9 178
SN 0025-1909
UT WOS:A1994PR83400006
ER

PT J
AU LU, L
   POSNER, ME
TI APPROXIMATION PROCEDURES FOR THE ONE-WAREHOUSE MULTIRETAILER SYSTEM
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1305
EP 1316
DI 10.1287/mnsc.40.10.1305
PD OCT 1994
PY 1994
AB Two heuristic procedures for a one-warehouse multi-retailer system are
   developed. Based on the accuracy desired, the first heuristic evaluates
   a specified number of points. The relative error is within a bound that
   approaches 1/(root 2 In 2) - 1 approximate to 2.014%. The complexity of
   the heuristic is O(n) for a fixed number of evaluations. Although our
   bound only approaches the one of Roundy (1985), when only a small number
   of points are evaluated, our method is faster. We show that the bound
   for our procedure and two bounds proposed by Roundy (1985) are tight.
   The second heuristic pertains to a class of policies called stationary
   interval policies. For this class of policies, we develop a fully
   polynomial-time approximation scheme where the relative error is within
   epsilon > 0, and the computational effort increases as a linear function
   of 1/root epsilon.
   Computational experiments show that these heuristics perform well in
   practice.
ZS 1
Z8 1
ZR 0
TC 26
ZB 0
ZA 0
Z9 28
SN 0025-1909
UT WOS:A1994PR83400007
ER

PT J
AU DANA, JD
   KNETTER, MM
TI LEARNING AND EFFICIENCY IN A GAMBLING MARKET
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1317
EP 1328
DI 10.1287/mnsc.40.10.1317
PD OCT 1994
PY 1994
AB We present a statistical model which uses data on National Football
   League games and betting lines to study how agents learn from past
   outcomes and to test market efficiency. Using Kalman Filter estimation,
   we show that teams' abilities exhibit substantial week-to-week variation
   during the season. This provides an ideal environment in which to study
   how agents learn from past information. While we do not find strong
   evidence of market inefficiency, we are able to make several
   observations on market learning. In particular, agents have more
   difficulty learning from ''noisy'' observations and appear to weight
   recent observations less than our statistical model suggests is optimal.
Z8 0
ZB 0
TC 18
ZS 0
ZR 0
ZA 0
Z9 18
SN 0025-1909
UT WOS:A1994PR83400008
ER

PT J
AU MULVEY, JM
   ZENIOS, SA
TI CAPTURING THE CORRELATIONS OF FIXED-INCOME INSTRUMENTS
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1329
EP 1342
DI 10.1287/mnsc.40.10.1329
PD OCT 1994
PY 1994
AB This paper develops a framework for managing portfolios of fixed income
   instruments based on traditional principles from the equities market,
   i.e., based on diversification. It shows, through an analysis of the
   high-yield bond market over the period 1987 to 1991, that fixed-income
   prices could be highly correlated. These correlations can be quantified
   and integrated, in a systematic way, in an asset/liability management
   framework. For vanishing fixed income securities, however, we cannot
   resort to statistical analysis of historical data in order to quantify
   correlations. The paper develops a forward-looking simulation procedure
   for capturing correlations. Applications are illustrated for examples
   from high-yield bonds and mortgage-backed securities. The superiority of
   the proposed approach over the traditional portfolio immunization
   techniques is demonstrated in the context of funding an insurance
   liability stream with mortgage instruments.
RI Zenios, Stavros A/F-3346-2013
OI Zenios, Stavros A/0000-0001-7576-4898
ZS 0
Z8 0
ZB 0
ZR 1
TC 24
ZA 0
Z9 25
SN 0025-1909
UT WOS:A1994PR83400009
ER

PT J
AU MILNE, F
   NEAVE, EH
TI DOMINANCE RELATIONS AMONG STANDARDIZED VARIABLES
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1343
EP 1352
DI 10.1287/mnsc.40.10.1343
PD OCT 1994
PY 1994
AB This paper examines stochastic dominance relations among discrete random
   variables defined on a common integer domain. While these restrictions
   are minimal, they lead both to new theoretical results and to simpler
   proofs of existing ones. The new results, obtained for dominance
   criteria of any degree, generalize an SSD result of Rothschild-Stiglitz
   to describe how for any dominance criterion a dominated variable is
   equal in distribution to a dominated variable plus perturbation terms.
   If the variables are comparable under FSD the perturbations are downward
   shift terms, while under SSD (TSD) all but two (three) of the
   perturbations are zero mean disturbance terms (noise). Under SSD the
   remaining perturbations are shift terms and under TSD noise and shift
   terms. However, under either SSD or TSD these remaining terms are
   identically zero if the variables to be compared have equal means. The
   paper also finds new proofs of well known results relating dominance
   criteria to preferences.
TC 11
ZB 0
ZR 0
ZS 0
Z8 0
Z9 11
SN 0025-1909
UT WOS:A1994PR83400010
ER

PT J
AU BALACHANDRAN, KR
   RADHAKRISHNAN, S
TI EXTENSIONS TO CLASS DOMINANCE CHARACTERISTICS
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1353
EP 1360
DI 10.1287/mnsc.40.10.1353
PD OCT 1994
PY 1994
AB Balachandran and Schaefer (1979) show that if in the individual optimum
   class A dominates with a first come first serve queue, there could exist
   cases where in the public optimum class B dominates. We derive
   conditions under which providing a nonpreemptive priority allows both
   classes of users to use the facility and get a higher expected public
   net benefit than the first come first serve queue. The class that is
   provided the higher priority may or may not be the class that dominates
   in the public optimum under the first come first serve queue. That means
   that introducing a priority scheme may switch the class that is given
   preference in the public optimum.
   It is shown that there exist situations where the class that is granted
   the higher priority for service could be levied a lower price than the
   class that is granted the lower priority. In the case where the users
   alone have perfect information on the value from using the facility, we
   derive conditions under which a non preemptive priority is superior to
   the first come first serve queue.
   The preemptive priority resume queue is not necessarily always superior
   to the first come first serve queue. We derive conditions under which
   the superiority of the preemptive priority resume queue over the first
   come first serve queue holds.
Z8 0
TC 8
ZS 0
ZR 0
ZA 0
ZB 0
Z9 8
SN 0025-1909
UT WOS:A1994PR83400011
ER

PT J
AU BROWN, CL
   LATTIN, JM
TI INVESTIGATING THE RELATIONSHIP BETWEEN TIME IN MARKET AND PIONEERING
   ADVANTAGE
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1361
EP 1369
DI 10.1287/mnsc.40.10.1361
PD OCT 1994
PY 1994
AB In field studies based on pre-test market and scanner data, researchers
   have found evidence of pioneering advantage in the form of an
   order-of-entry effect: a permanent share advantage that is greatest for
   the first brand to enter a market and smaller for each subsequently
   entering brand. Conceptually, an order-of-entry effect implies that the
   share advantage of a market pioneer over the second entrant is constant,
   regardless of the length of time the pioneer is alone in the market or
   the length of time since the entry of the second brand. We argue that
   pioneering advantage is also related to a brand's length of time in the
   market: the longer the brand's time in market (during which time it can
   impact consumer learning and influence consumer perceptions and
   preferences), the greater its relative share advantage. We present a
   parsimonious model of this time-in-market effect and test our model
   using two data sources: cross-category data collected and analyzed by
   Urban et al. (1986) and regional roll-out data for a single product
   category.
ZB 0
Z8 0
ZR 0
TC 82
ZS 0
ZA 0
Z9 82
SN 0025-1909
UT WOS:A1994PR83400012
ER

PT J
AU HUFF, LC
   ROBINSON, WT
TI THE IMPACT OF LEADTIME AND YEARS OF COMPETITIVE RIVALRY ON PIONEER
   MARKET SHARE ADVANTAGES
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1370
EP 1377
DI 10.1287/mnsc.40.10.1370
PD OCT 1994
PY 1994
AB Research has established that for surviving brands, market pioneers have
   a higher average market share than later entrants. By moving first,
   market pioneers often develop sustainable market share advantages.
   Longer leadtime, which is the time between entries, should increase
   these pioneer advantages. Using two leadtime measures, this prediction
   is supported across 34 categories of frequently purchased consumer
   goods. Increasing the years of competitive rivalry should help a later
   entrant slowly reduce the pioneer's market share advantage. After more
   than two decades in the market, second entrants have eliminated the
   pioneer's market share advantage, but third and later entrants continue
   to trail the pioneer.
ZA 0
ZB 1
Z8 0
ZR 0
TC 72
ZS 0
Z9 72
SN 0025-1909
UT WOS:A1994PR83400013
ER

PT J
AU MILTENBURG, GJ
   WIJNGAARD, J
TI THE U-LINE LINE BALANCING PROBLEM
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1378
EP 1388
DI 10.1287/mnsc.40.10.1378
PD OCT 1994
PY 1994
AB The traditional line balancing (LB) problem considers a production line
   in which stations are arranged consecutively in a line. A balance is
   determined by grouping tasks into stations while moving forward (or
   backward) through a precedence network. Recently many production lines
   are being arranged in a ''U-line,'' as a consequence of the use of
   just-in-time production principles in many factories. In this paper the
   U-line LB problem is introduced and modelled, and solution procedures
   are developed. It is more complex than the traditional LB problem
   because tasks can be grouped by moving forward, backward, or
   simultaneously in both directions, through the precedence network. We
   also show how solution techniques developed for the traditional LB
   problem can be adapted for use with the new problem. Some computational
   results for well-known problems from the literature are given.
ZB 0
ZA 0
ZR 0
ZS 1
Z8 9
TC 162
Z9 171
SN 0025-1909
UT WOS:A1994PR83400014
ER

PT J
AU BAGCHI, U
   JULIEN, FM
   MAGAZINE, MJ
TI DUE-DATE ASSIGNMENT TO MULTI-JOB CUSTOMER ORDERS
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1389
EP 1392
DI 10.1287/mnsc.40.10.1389
PD OCT 1994
PY 1994
AB The paper addresses deterministic, nonpreemptive scheduling of jobs that
   are immediately available for processing on a single machine. The
   jobs-are partitioned into several multijob customer orders. The problem
   is to determine a due-date for each customer order and to schedule all
   the jobs such that a total penalty function is minimized. The total
   penalty function is the sum of penalties for job earliness, penalties
   for job tardiness, and penalties associated with the lead times of
   customer orders. The main result is that there is an optimal solution in
   which the jobs within each customer order are processed contiguously.
   This is an appealing feature in terms of implementation. Efficient
   algorithms are presented for solving special cases of this problem.
ZB 0
ZR 0
Z8 0
ZA 0
TC 11
ZS 0
Z9 11
SN 0025-1909
UT WOS:A1994PR83400015
ER

PT J
AU GALLEGO, G
   SIMCHILEVI, D
TI REJOINDER TO A NOTE ON BOUNDS FOR DIRECT SHIPPING COSTS
SO MANAGEMENT SCIENCE
VL 40
IS 10
BP 1393
EP 1393
DI 10.1287/mnsc.40.10.1393
PD OCT 1994
PY 1994
RI Gallego, Guillermo/AAK-1549-2020
OI Gallego, Guillermo/0000-0002-9664-3750
ZB 0
ZR 0
ZA 0
ZS 0
Z8 0
TC 8
Z9 8
SN 0025-1909
UT WOS:A1994PR83400016
ER

PT J
AU WINKLER, RL
TI EVALUATING PROBABILITIES - ASYMMETRIC SCORING RULES
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1395
EP 1405
DI 10.1287/mnsc.40.11.1395
PD NOV 1994
PY 1994
AB Proper scoring rules are overall evaluation measures that reward
   accurate probabilities.  Specific rules encountered in the literature
   and used in practice are invariably symmetric in the sense that the
   expected score for a perfectly-calibrated probability assessor (or model
   generating probabilities) is minimized at a probability of one-half.  A
   family of asymmetric scoring rule that provide better measures of the
   degree of skill inherent in the probabilities and render scores that are
   more comparable in different situations is developed here.  One member
   of this family, a quadratic asymmetric rule, is applied to evaluate an
   extensive set of precipitation probability forecasts from the U.S.
   National Weather Service.  Connections to previous characterizations of
   proper scoring rules are investigated, and some relevant issues
   pertaining to the design of specific asymmetric rules for particular
   inferential and decision-making problems are discussed briefly.
ZR 0
ZA 0
Z8 0
TC 33
ZS 0
ZB 2
Z9 33
SN 0025-1909
UT WOS:A1994QA17200001
ER

PT J
AU CHEN, FR
   ZHENG, YS
TI LOWER BOUNDS FOR MULTIECHELON STOCHASTIC INVENTORY SYSTEMS
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1426
EP 1443
DI 10.1287/mnsc.40.11.1426
PD NOV 1994
PY 1994
AB We establish lower bounds on the minimum costs of managing certain
   production-distribution networks with setup costs at all stages and
   stochastic demands.  These networks include serial, assembly, and
   one-warehouse multi-retailer systems.  We obtain the bounds through
   novel cost-allocation schemes.  We evaluate the bounds' performance for
   one-warehouse multi-retailer systems by comparing them with simple,
   heuristic policies.  The bounds are quite tight for systems with a small
   number of retailers.  We also present simplified proofs of known
   optimality results for serial and assembly systems.
ZA 0
TC 114
ZB 0
ZS 0
Z8 6
ZR 0
Z9 120
SN 0025-1909
UT WOS:A1994QA17200003
ER

PT J
AU ETTLIE, JE
   PENNERHAHN, JD
TI FLEXIBILITY RATIOS AND MANUFACTURING STRATEGY
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1444
EP 1454
DI 10.1287/mnsc.40.11.1444
PD NOV 1994
PY 1994
AB In this exploratory, empirical study of modernizing durable goods
   plants, it was found that typical measures of flexibility (e.g., number
   of unique parts and part families) are independent.  More importantly,
   plants and firms with greater strategic manufacturing focus, regardless
   of specific emphasis (e.g., cost of quality), scheduled fewer part
   numbers on new flexible automation systems.  This suggests that product
   focus and strategic focus are related in plants producing discrete
   parts.  When flexibility is emphasized as a strategic manufacturing
   focus, new automation systems are significantly more likely to have
   shorter change-over times per part family.  In general, part
   family-changeover time ratios appear to have the greatest potential of
   measures evaluated for building a useful theory of flexibility in
   discrete parts manufacturing.  An evaluation of changes made in part
   types and part families during the implementation period showed that
   product flexibility is pursued as a way to reduce high labor costs in
   manufacturing.  These plants accomplished this end by increasing the
   number of parts scheduled on new systems.  Implications for strategic
   management of flexibility and scope are presented.
CT Industry-University Conference on Manufacturing Strategy
CY JAN 08-09, 1990
CL ANN ARBOR, MI
SP NATL SCI FDN; UNIV MICHIGAN
ZB 0
ZS 1
ZR 0
TC 45
ZA 0
Z8 2
Z9 48
SN 0025-1909
UT WOS:A1994QA17200004
ER

PT J
AU GONCALVES, JF
   LEACHMAN, RC
   GASCON, A
   XIONG, ZK
TI A HEURISTIC SCHEDULING POLICY FOR MULTIITEM, MULTIMACHINE PRODUCTION
   SYSTEMS WITH TIME-VARYING, STOCHASTIC DEMANDS
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1455
EP 1468
DI 10.1287/mnsc.40.11.1455
PD NOV 1994
PY 1994
AB An effective scheduling policy known as the Dynamic Cycle Lengths
   Heuristic was introduced by Leachman and Gascon in 1988 for the
   multi-item, single-machine production system facing stochastic,
   time-varying demands.  In this article we develop a heuristic scheduling
   policy for the multi-machine extension of the same problem.  We
   integrate the concepts of the Dynamic Cycle Lengths Heuristic with a
   nonlinear integer optimization model to obtain an overall scheduling
   policy that allocates items to machines and schedules production
   quantities during the next time period.  We report promising performance
   in limited simulation tests of the policy.
RI Goncalves, Jose Fernando/G-1951-2011
OI Goncalves, Jose Fernando/0000-0002-7565-4530
ZR 0
Z8 1
ZS 0
ZA 0
TC 8
ZB 0
Z9 9
SN 0025-1909
UT WOS:A1994QA17200005
ER

PT J
AU AHMADI, RH
   WURGAFT, H
TI DESIGN FOR SYNCHRONIZED FLOW MANUFACTURING
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1469
EP 1483
DI 10.1287/mnsc.40.11.1469
PD NOV 1994
PY 1994
AB Firms that build flexibility into their manufacturing system gain a
   competitive edge from their ability to efficiently produce a mid-variety
   of products at mid-volumes.  In order to realize the competitive edge of
   flexible systems, manufacturing management has to deal effectively with
   the greater complexity that flexibility brings about.  One of the key
   factors for the success of a flexible system is the management of the
   product set flow.  If the product flow is poorly managed, products may
   have long manufacturing lead times, and materials may spend a large
   amount of time in queues as work in process.  In such a situation, most
   of the competitive potential of the flexible system may be lost.  But if
   the flow of materials through the production/assembly stations is
   carefully synchronized, with materials moving smoothly and continuously
   from one operation to the next, then it is possible to attain short
   manufacturing lead times and little waiting.  We refer to this operating
   condition as synchronized flow.  In this paper, we study how to attain a
   synchronized flow for product sets with different characteristics
   regarding process flexibility and consistency.
ZB 0
ZS 0
TC 20
ZR 0
ZA 0
Z8 0
Z9 20
SN 0025-1909
UT WOS:A1994QA17200006
ER

PT J
AU KANNAN, PK
   SANCHEZ, SM
TI COMPETITIVE MARKET STRUCTURES - A SUBSET-SELECTION ANALYSIS
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1484
EP 1499
DI 10.1287/mnsc.40.11.1484
PD NOV 1994
PY 1994
AB Market structure models are used to identify submarkets or to test for
   the presence of submarkets where within-group competition is much
   stronger than across group competition.  The implicit assumption in such
   models is that the brands in a submarket compete on the basis of their
   shared product features.  However, if significant variety-seeking
   effects exist in the market, such an assumption may not be valid.  We
   present a model based on a subset selection procedure for analyzing
   competitive market structures and develop tests of significance for
   variety-seeking effects present in the market.  For each brand in the
   market, the subset selection procedure identifies sets (submarkets) of
   brands that are in ''close'' competition.  The competitive market
   structure is defined by the possibly overlapping submarkets that are
   identified for each brand and the model provides insights on whether the
   brands in a submarket are of a reinforcing or a variety-seeking kind. 
   The application of our model to two different consumer packaged goods
   markets highlights its contribution relative to extent methods.
RI Kannan, Pallassana K/D-8192-2011
ZB 0
ZS 0
Z8 0
ZA 0
TC 14
ZR 0
Z9 14
SN 0025-1909
UT WOS:A1994QA17200007
ER

PT J
AU GAUTIER, A
   GRANOT, F
TI A PARAMETRIC ANALYSIS OF A CONSTRAINED NONLINEAR INVENTORY-PRODUCTION
   MODEL
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1500
EP 1513
DI 10.1287/mnsc.40.11.1500
PD NOV 1994
PY 1994
AB We discuss in this paper some inventory-production models which can be
   formulated as nonlinear parametric network flow problems with one
   additional linear constraint.  Several sensitivity analysis questions
   are addressed.  The qualitative sensitivity results obtained provide the
   manager with insight to understanding qualitatively how to respond to
   changes in the environment such as production costs, inventory capacity,
   external demand, machine breakdown, strike, or variations in inventory
   carrying cost without additional computation.
ZS 0
ZB 0
ZA 0
ZR 0
Z8 0
TC 2
Z9 2
SN 0025-1909
UT WOS:A1994QA17200008
ER

PT J
AU MACCRIMMON, KR
   WAGNER, C
TI STIMULATING IDEAS THROUGH CREATIVITY SOFTWARE
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1514
EP 1532
DI 10.1287/mnsc.40.11.1514
PD NOV 1994
PY 1994
AB A central task of management is decision making and a crucial aspect of
   decision making is having good alternatives from which to choose.  This
   paper investigates whether computer-based procedures for idea generation
   can help individuals to develop solution alternatives more creatively. 
   Our conceptual framework considers creative processes, environments,
   outputs, and individuals.  In particular, generating alternatives is
   viewed as a process of ''making connections'' - internal connections
   among problem elements and external connections between a problem and
   its environment.  We have developed a computer program (GENI) which
   incorporates a variety of techniques to assist in making these different
   types of connections.  The program is described and an experimental test
   with several managerial problems is presented.  The results show that
   use of the program leads to the development of significantly more
   creative alternatives than does a control treatment.  There is an
   amplification effect in that the performance of the more creative
   individuals is improved the most.  Thus the findings suggest that
   computerized idea generation leads to more creative alternatives
   resulting in potentially better managerial decisions.
ZA 0
Z8 1
ZS 2
ZB 0
TC 114
ZR 0
Z9 117
SN 0025-1909
UT WOS:A1994QA17200009
ER

PT J
AU LAGUNA, M
TI CLUSTERING FOR THE DESIGN OF SONET RINGS IN INTEROFFICE
   TELECOMMUNICATIONS
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1533
EP 1541
DI 10.1287/mnsc.40.11.1533
PD NOV 1994
PY 1994
AB Optical fiber systems play an essential role in today's
   telecommunications networks.  The recently standardized SONET
   (Synchronous Optical Network) technology has made rings the preferred
   architecture for designing survivable networks.  The network design
   problem is very complex in nature, because it involves not only the
   configuration of rings at the logical level, but also the mapping of
   this configuration into physical fiber paths.  This paper deals with the
   problem of finding optimal clusters of offices, which can be used as the
   basis for designing logical rings.  A mathematical model of the problem
   is presented, and a heuristic solution based on the tabu search
   framework is developed to find optimal or near-optimal solutions.
Z8 0
ZS 0
ZB 0
TC 35
ZR 0
ZA 0
Z9 35
SN 0025-1909
UT WOS:A1994QA17200010
ER

PT J
AU MALAKOOTI, B
   ZHOU, YQ
TI FEEDFORWARD ARTIFICIAL NEURAL NETWORKS FOR SOLVING DISCRETE MULTIPLE
   CRITERIA DECISION-MAKING PROBLEMS
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1542
EP 1561
DI 10.1287/mnsc.40.11.1542
PD NOV 1994
PY 1994
AB Decision making involves choosing some course of action among various
   alternatives.  In almost all decision making problems, there are several
   criteria for judging possible alternatives.  The main concern of the
   Decision Maker (DM) is to fulfill his conflicting goals while satisfying
   the constraints of the system.  In this paper, we present an Adaptive
   Feedforward Artificial Neural Network (AF-ANN) approach to solve
   discrete Multiple Criteria Decision Making (MCDM) problems.  The AF-ANN
   is used to capture and represent the DM's preferences and then to select
   the most desirable alternative.  The AF-ANN can adjust and improve its
   representation as more information from the DM becomes available.
   We begin with the assumption that an AF-ANN topology is given, i.e.,
   specific numbers of nodes and links are predetermined.  To adjust the
   parameters of the AF-ANN, we present an iterative learning algorithm
   consisting of two steps:  (a) generating a direction, and (b) a
   one-dimensional search along that direction.  We then present a
   methodology to obtain the most appropriate AF-ANN topology and set its
   parameters.  The procedure starts with a small number of nodes and links
   and then adaptively increases the number of nodes and links until the
   proper topology is obtained.  Furthermore, when the set of training
   patterns (alternatives with their associated evaluations by the DM)
   changes, the AF-ANN model can adapt itself by re-training or expanding
   the existing model.  Some illustrative examples are presented.
   To solve discrete MCDM problems by an AF-ANN, we show how to incorporate
   basic properties of efficiency, concavity, and convexity into the
   AF-ANN.  We formulate the MCDM problems and use the AF-ANN to rank the
   set of discrete alternatives where each alternative is associated with a
   set of conflicting and noncommensurate criteria.  We present a method
   for solving discrete MCDM problems through AF-ANNs which consists of: 
   (a) formulating and assessing the utility function by eliciting
   information from the DM and then training the AF-ANN, and (b) ranking
   and rating alternatives by using the trained AF-ANN model.  Some
   computational experiments are presented to show the effectiveness of the
   method.
Z8 6
TC 73
ZA 0
ZS 0
ZB 2
ZR 0
Z9 77
SN 0025-1909
UT WOS:A1994QA17200011
ER

PT J
AU LECUYER, P
   GLYNN, PW
TI STOCHASTIC OPTIMIZATION BY SIMULATION - CONVERGENCE PROOFS FOR THE
   GI/G/1 QUEUE IN STEADY-STATE
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1562
EP 1578
DI 10.1287/mnsc.40.11.1562
PD NOV 1994
PY 1994
AB Approaches like finite differences with common random numbers,
   infinitesinal perturbation analysis, and the likelihood ratio method
   have drawn a great deal of attention recently as ways of estimating the
   gradient of a performance measure with respect to continuous parameters
   in a dynamic stochastic system.  In this paper, we study the use of such
   estimators in stochastic approximation algorithms, to perform so-called
   ''single-run optimizations'' of steady-state systems.  Under mild
   conditions, for an objective function that involves the mean system time
   in a GI/G/1 queue, we prove that many variants of these algorithms
   converge to the minimizer.  In most cases, however, the simulation
   length must be increased from iteration to iteration; otherwise the
   algorithm may converge to the wrong value.  One exception is a
   particular implementation of infinitesimal perturbation analysis, for
   which the single-run optimization converges to the optimum even with a
   fixed (and small) number of ends of service per iteration.  As a
   by-product of our convergence proofs, we obtain some properties of the
   derivative estimators that could be of independent interest.  Our
   analysis exploits the regenerative structure of the system, but our
   derivative estimation and optimization algorithms do not always take
   advantage of that regenerative structure.  In a companion paper, we
   report numerical experiments with an M/M/1 queue, which illustrate the
   basic convergence properties and possible pitfalls of the various
   techniques.
RI L'Ecuyer, Pierre/O-6577-2019
OI L'Ecuyer, Pierre/0000-0002-3184-0796
Z8 0
ZB 0
ZA 0
ZS 0
ZR 0
TC 46
Z9 46
SN 0025-1909
UT WOS:A1994QA17200012
ER

PT J
AU KELLEY, MR
TI PRODUCTIVITY AND INFORMATION TECHNOLOGY - THE ELUSIVE CONNECTION
SO MANAGEMENT SCIENCE
VL 40
IS 11
BP 1406
EP 1425
DI 10.1287/mnsc.40.11.1406
PD NOV 1994
PY 1994
AB This study analyzes the effect of information technology on the
   efficiency of production operations in a specific manufacturing process.
   Survey data from 584 establishments engaged in the machining process in
   21 different industries are used to construct and test an empirical
   model that takes into account product characteristics, the type of
   technology (computer-programmable automation or conventionally
   controlled) machines, the extent of technological change at the plant,
   process-specific characteristics such as the scale of operations and
   degree of customization, labor policies, and structural features of the
   organization of work.  The results indicate that there is a significant
   efficiency advantage from using programmable automation technology and
   that technological advantages accumulate with experience and with the
   repeated opportunities for learning associated with large volume and
   frequent product changes.  The most efficient use of this technology
   occurs in plants with work practices that involve a higher ratio of
   machines to workers (as in a cellular approach to manufacturing) and
   allow production workers to perform programming tasks to a greater
   degree.  Unionized plants are also significantly more efficient than
   non-union plants.
ZS 1
TC 99
Z8 0
ZB 0
ZA 0
ZR 1
Z9 101
SN 0025-1909
UT WOS:A1994QA17200002
ER

PT J
AU BASU, A
   BLANNING, RW
TI METAGRAPHS - A TOOL FOR MODELING DECISION-SUPPORT SYSTEMS
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1579
EP 1600
DI 10.1287/mnsc.40.12.1579
PD DEC 1994
PY 1994
AB Most decision support systems (DSS) contain stored data, data analysis
   procedures, and decision models.  However, many DSS have grown to the
   point that the average end user is presented with a bewildering array of
   information resources that are difficult to manage in an effective
   manner.  As a result users often gravitate to a few familiar models and
   are unaware of the data resources available to them and how these
   resources relate to the various models.  For example, they may think
   that a model requires data that is unavailable, when in fact that data
   has recently been added to the data base or could be calculated from
   another model.  Or they may believe that all of the data needed to
   execute a set of models is available and find out well into the analysis
   that it is not.  Existing tools for DSS design do not provide an
   effective and comprehensive foundation for modeling all the components
   of a DSS, or for addressing all the important DSS analysis and design
   issues.  In this paper we show how a new graph-theoretic structure,
   called a metagraph, can be used as a unifying basis for addressing many
   important questions in DSS development and use.
ZR 0
ZA 0
ZS 0
Z8 3
ZB 0
TC 38
Z9 40
SN 0025-1909
UT WOS:A1994QG14200001
ER

PT J
AU SETHI, V
   KING, WR
TI DEVELOPMENT OF MEASURES TO ASSESS THE EXTENT TO WHICH AN INFORMATION
   TECHNOLOGY APPLICATION PROVIDES COMPETITIVE ADVANTAGE
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1601
EP 1627
DI 10.1287/mnsc.40.12.1601
PD DEC 1994
PY 1994
AB In order to measure the extent to which information technology provides
   competitive advantage, the construct ''Competitive Advantage Provided by
   an Information Technology Application'' (CAPITA) was operationalized.  A
   field survey gathered data from 185 top information systems executives
   regarding information technology applications which had been developed
   to gain competitive advantage.  A confirmatory analysis revealed that
   CAPITA may be conceptualized in terms of nine dimensions which satisfy
   key measurement criteria including unidimensionality and convergent
   validity, discriminant validity, predictive validity, and reliability.
   The nine dimensions form the basis of a preliminary multidimensional
   measure or index of competitive advantage which has practical uses for
   competitive assessment.  These include justifying and evaluating
   applications and acting as dependent variables in empirical competitive
   advantage research.
   Extensions entail formulating alternative measures of CAPITA to clarify
   the theoretical foundations of the construct, validating the
   latent-structure model on another data set, use of multiple informants
   for data collection, and exploring complex factor structures for the
   construct.
ZB 1
ZR 0
Z8 1
ZA 0
ZS 2
TC 280
Z9 283
SN 0025-1909
UT WOS:A1994QG14200002
ER

PT J
AU BRYNJOLFSSON, E
   MALONE, TW
   GURBAXANI, V
   KAMBIL, A
TI DOES INFORMATION TECHNOLOGY LEAD TO SMALLER FIRMS
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1628
EP 1644
DI 10.1287/mnsc.40.12.1628
PD DEC 1994
PY 1994
AB Many changes in the organization of work in the United States since 1975
   have been attributed to the increased capabilities and use of
   information technology (IT) in business.  However, few studies have
   attempted to empirically examine these relationships.  The primary goal
   of this paper is to assess the hypothesis that investments in
   information technology are at least partially responsible for one
   important organizational change, the shift of economic activity to
   smaller firms.  We examine this hypothesis using industry-level data on
   IT capital and four measures of firm size, including employees and sales
   per firm.  We find broad evidence that investment in IT is significantly
   associated with subsequent decreases in the average size of firms.  We
   also find that these decreases in firm size are most pronounced two to
   three years after the IT investment is made.
RI Brynjolfsson, Erik/H-2412-2012
ZS 3
Z8 2
ZR 0
ZA 0
TC 238
ZB 0
Z9 242
SN 0025-1909
UT WOS:A1994QG14200003
ER

PT J
AU BRYNJOLFSSON, E
TI INFORMATION ASSETS, TECHNOLOGY, AND ORGANIZATION
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1645
EP 1662
DI 10.1287/mnsc.40.12.1645
PD DEC 1994
PY 1994
AB Although there is good reason to expect that the growth of information
   work and information technology will significantly affect the trade-offs
   inherent in different structures for organizing work, the theoretical
   basis for these changes remains poorly understood.  This paper seeks to
   address this gap by analyzing the incentive effects of different
   ownership arrangement in the spirit of the Grossman-Hart-Moore (GHM)
   incomplete contracts theory of the firm.  A key departure from earlier
   approaches is the inclusion of a role for an ''information asset,''
   analogous to the GHM treatment of property.  This approach highlights
   the organizational significance of information ownership and information
   technology.  For instance, using this framework, one can determine when
   1) informed workers are more likely to be owners than employees of
   firms, 2) increased flexibility of assets will facilitate
   decentralization, and 3) the need for centralized coordination will lead
   to centralized ownership.  The framework developed sheds light on some
   of the empirical findings regarding the relationship between information
   technology and firm size and clarifies the relationship between
   coordination mechanisms and the optimal distribution of asset ownership.
   While many implications are still unexplored and untested, building on
   the incomplete contracts approach appears to be a promising avenue for
   the careful, methodical analysis of human organizations and the impact
   of new technologies.
RI Brynjolfsson, Erik/H-2412-2012
ZA 0
ZS 0
TC 115
Z8 3
ZB 1
ZR 0
Z9 118
SN 0025-1909
UT WOS:A1994QG14200004
ER

PT J
AU DOWLING, MJ
   MCGEE, JE
TI BUSINESS AND TECHNOLOGY STRATEGIES AND NEW VENTURE PERFORMANCE - A STUDY
   OF THE TELECOMMUNICATIONS EQUIPMENT INDUSTRY
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1663
EP 1677
DI 10.1287/mnsc.40.12.1663
PD DEC 1994
PY 1994
AB In this paper, a set of hypotheses relating competitive and cooperative
   business strategies and technology strategies to new venture performance
   are developed.  These hypotheses are tested using data collected from
   the Initial Public Offering (IPO) documents of a sample of 52 new
   ventures in the telecommunications equipment industry.  This industry
   has experienced a great deal of technological change as computer and
   telephone technologies have merged allowing a variety of new ventures to
   successfully enter the industry.  The results suggest that new ventures
   pursuing broad cost leadership strategies were more successful. 
   Investments in innovation in terms of relative R&D expenditures were
   also related to higher performance.  Finally, significant interaction
   effects between investments in innovation and competitive strategies and
   performance were found.
ZA 0
Z8 0
ZR 1
ZB 0
ZS 0
TC 57
Z9 58
SN 0025-1909
UT WOS:A1994QG14200005
ER

PT J
AU BUZACOTT, JA
   SHANTHIKUMAR, JG
TI SAFETY STOCK VERSUS SAFETY TIME IN MRP CONTROLLED PRODUCTION SYSTEMS
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1678
EP 1689
DI 10.1287/mnsc.40.12.1678
PD DEC 1994
PY 1994
AB The two management set parameters which determine the performance of a
   material requirements planning (MRP) system are the lead time and the
   safety stock.  The appropriate values of these parameters are influenced
   by the accuracy of forecasts over the lead time, the variability of
   processing time and the degree of congestion, together with the costs of
   inventory and shortages.  These influences are explored using stochastic
   models of a single stage manufacturing system for which work release is
   controlled using MRP.  The major conclusion is that safety time is
   usually only preferable to safety stock when it is possible to make
   accurate forecasts of future required shipments over the lead time,
   otherwise safety stock is more robust in coping with changes in customer
   requirements in the lead time or with fluctuations in forecasts of lead
   time demand.
RI Shanthikumar, George/L-4837-2019; Buzacott, John A/A-5274-2008
ZR 0
ZS 4
Z8 0
ZA 0
TC 74
ZB 0
Z9 77
SN 0025-1909
UT WOS:A1994QG14200006
ER

PT J
AU BOURLAND, KE
   YANO, CA
TI THE STRATEGIC USE OF CAPACITY SLACK IN THE ECONOMIC LOT SCHEDULING
   PROBLEM WITH RANDOM DEMAND
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1690
EP 1704
DI 10.1287/mnsc.40.12.1690
PD DEC 1994
PY 1994
AB Growing interest in designing systems with capacity slack as one form of
   flexibility raises many questions about its use and its usefulness.  In
   the framework of the economic lot scheduling problem with stochastic
   demand, we develop an optimization-based model that considers capacity
   slack, safety stock, and overtime explicitly, and has the objective of
   minimizing the expected cost per unit time of inventory, overtime, and,
   where applicable, setup costs.  The solution is a continuous-time
   production plan that consists of a time-dependent inventory trajectory
   for each of the parts, including the placement of planned idle time in
   the schedule.  We consider schedule stability to be desirable because of
   potential effects on upstream and downstream operations in multistage
   production settings.  Thus, the plan also has certain characteristics
   that contribute to achieving stability.
   Our results on the relative merits of capacity slack and safety stock
   indicate that capacity slack in the form of planned idle time is not a
   cost-effective hedge against demand uncertainty in this context.  Thus,
   it is essential that management carefully identify and evaluate other
   reasons for including idle time in a plan, and use the idle time
   effectively.  For managers who face situations not fully represented by
   our model, this paper provides analytic results that will guide them in
   the placement of planned idle time and the choice of safety stock
   levels.
ZS 1
ZA 0
ZB 0
ZR 0
Z8 0
TC 44
Z9 44
SN 0025-1909
UT WOS:A1994QG14200007
ER

PT J
AU CURRAN, M
TI VALUING ASIAN AND PORTFOLIO OPTIONS BY CONDITIONING ON THE GEOMETRIC
   MEAN PRICE
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1705
EP 1711
DI 10.1287/mnsc.40.12.1705
PD DEC 1994
PY 1994
AB The valuation of Asian, or average price, options and of European
   options on portfolios in a ''Black-Scholes'' environment has given
   researchers trouble.  The difficulty with these problems is that the
   probability distribution of the variable which determines the option
   payoff at expiration, a sum of correlated lognormal random variables,
   has no closed-form representation.  For the Asian case the approach
   generally taken has been to approximate the distribution of the
   arithmetic average price, while for the portfolio option case, attempts
   have focused on discretizing the joint distribution of the terminal
   prices of the assets comprising the portfolio and approximating the
   expected risk-neutral option payoff with a discrete sum.  These
   approaches are not entirely satisfactory.  The
   distribution-approximating procedures for Asian options are not very
   accurate for some cases, while the computational requirements for
   obtaining a reasonably accurate estimate using the discretizing or
   multinomial approaches for portfolio options become excessive as the
   number of assets rises above four or five, because the computation time
   is exponential in the number of assets.  This paper presents a method
   based on conditioning on the geometric mean price which results in a far
   more efficient technique for valuing these options.
ZA 0
Z8 3
ZS 0
ZB 2
ZR 2
TC 92
Z9 96
SN 0025-1909
UT WOS:A1994QG14200008
ER

PT J
AU HARIRI, AMA
   POTTS, CN
TI SINGLE-MACHINE SCHEDULING WITH DEADLINES TO MINIMIZE THE WEIGHTED NUMBER
   OF TARDY JOBS
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1712
EP 1719
DI 10.1287/mnsc.40.12.1712
PD DEC 1994
PY 1994
AB This paper considers a single machine scheduling problem in which jobs
   have due dates and deadlines.  A job may be completed after its due
   date, but not after its deadline, in which case it is tardy.  A branch
   and bound algorithm is proposed to find a schedule which minimizes the
   weighted number of tardy jobs.  It uses lower bounds which are derived
   using the dynamic programming state-space relaxation method. 
   Computational experience with test problems having up to 300 jobs
   indicates that the lower bounds are extremely effective in restricting
   the size of the branch and bound search tree.
ZB 0
Z8 0
TC 13
ZS 0
ZA 0
ZR 0
Z9 13
SN 0025-1909
UT WOS:A1994QG14200009
ER

PT J
AU HELFAT, CE
TI EVOLUTIONARY TRAJECTORIES IN PETROLEUM FIRM RESEARCH-AND-DEVELOPMENT
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1720
EP 1747
DI 10.1287/mnsc.40.12.1720
PD DEC 1994
PY 1994
AB Tacit knowledge and cumulative learning underlie an evolutionary theory
   of business firm development and strategy.  As one test case of the
   theory, this study examines firms' applied research and development
   activities.  Evolutionary theory suggests that firms within an industry
   will tend both to persist and to differ in the amount of effort they
   devote to various R&D applications.  A test of the hypothesis of
   persisent differences in R&D, using uniquely detailed data from the
   petroleum industry, provides support for evolutionary theory.
Z8 3
ZS 0
ZB 1
ZA 0
TC 239
ZR 0
Z9 242
SN 0025-1909
UT WOS:A1994QG14200010
ER

PT J
AU ALEXOPOULOS, C
TI DISTRIBUTION-FREE CONFIDENCE-INTERVALS FOR CONDITIONAL PROBABILITIES AND
   RATIOS OF EXPECTATIONS
SO MANAGEMENT SCIENCE
VL 40
IS 12
BP 1748
EP 1763
DI 10.1287/mnsc.40.12.1748
PD DEC 1994
PY 1994
AB Many simulation experiments are concerned with the estimation of a ratio
   of two unknown means, the estimation of a conditional probability being
   an example.  We propose confidence intervals for the case in which the
   ratio is estimated by using independent, identically distributed random
   pairs with bounded and ordered components.  Emphasis is given to the
   case in which each component can be expressed as the product of a
   Bernoulli and a bounded random variable.  The proposed intervals result
   from distribution-free bounds on error probabilities, are valid for
   every sample size, and their asymptotic width decreases at the same rate
   as that of confidence intervals based on the central limit theorem.  We
   evaluate their performance by means of two experiments.  The first
   considers the estimation of the probability that a path in a directed
   network is shortest while the second considers the estimation of the
   distribution of the inventory level in a stationary inventory system
   with periodic review.  The experiments show that the intervals are
   conservative with superior coverage for small sample sizes
   (less-than-or-equal-to 50).
Z8 0
ZA 0
ZS 0
ZR 0
ZB 0
TC 4
Z9 4
SN 0025-1909
UT WOS:A1994QG14200011
ER

PT J
AU MATZKEVICH, I
   ABRAMSON, B
TI DECISION-ANALYTIC NETWORKS IN ARTIFICIAL-INTELLIGENCE
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 1
EP 22
DI 10.1287/mnsc.41.1.1
PD JAN 1995
PY 1995
AB Researchers in artificial intelligence and decision analysis share a
   concern with the construction of format models of human knowledge and
   expertise. Historically, however, their approaches to these problems
   have diverged. Members of these two communities have recently discovered
   common ground: a family of graphical models of decision theory known as
   influence diagrams or as belief networks. These models are equally
   attractive to theoreticians, decision modelers, and designers of
   knowledge-based systems. From a theoretical perspective, they combine
   graph theory, probability theory and decision theory. From an
   implementation perspective, they lead to powerful automated systems.
   Although many practicing decision analysts have already adopted
   influence diagrams as modeling and structuring tools, they may remain
   unaware of the theoretical work that has emerged from the artificial
   intelligence community. This paper surveys the first decade or so of
   this work.
TC 14
ZR 0
ZS 0
ZA 0
Z8 0
ZB 2
Z9 14
SN 0025-1909
UT WOS:A1995RN11300001
ER

PT J
AU BELL, DE
TI RISK, RETURN, AND UTILITY
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 23
EP 30
DI 10.1287/mnsc.41.1.23
PD JAN 1995
PY 1995
AB Expected utility theory is widely acknowledged to be a rational approach
   to making decisions involving risk. Yet the methodology gives no
   explicit role to measures of risk and return. In this paper we identify
   those families of utility functions that are compatible with a
   risk-return interpretation. From these families we deduce
   utility-compatible measures of risk.
TC 101
ZA 0
ZS 1
ZR 0
ZB 15
Z8 2
Z9 104
SN 0025-1909
UT WOS:A1995RN11300002
ER

PT J
AU BOHN, RE
TI NOISE AND LEARNING IN SEMICONDUCTOR MANUFACTURING
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 31
EP 42
DI 10.1287/mnsc.41.1.31
PD JAN 1995
PY 1995
AB Rapid technological learning is critical to commercial success in VLSI
   semiconductor manufacturing. This learning is done through deliberate
   activities, especially various types of experimentation. Such
   experiments are vulnerable to confounding by process noise, caused by
   process variability. Therefore plants with low noise levels can
   potentially learn more effectively than high noise plants.
   Detailed die yield data from five semiconductor plants were examined to
   estimate process noise levels. A bootstrap simulation was used to
   estimate the error rates of identical controlled experiments conducted
   in each plant. Absolute noise levels were high for all but the best
   plants, leading to lost learning. For example, the probability of
   overlooking a three percent yield improvement was above twenty percent
   in all but one plant. Brute-force statistical methods are either
   expensive or ineffective for dealing with these high noise levels.
   Depending on the criterion used, there was a four- to ten-fold
   difference among the plants.
RI Bohn, Roger/C-6478-2012
OI Bohn, Roger/0000-0002-3628-0388
ZA 0
Z8 0
ZS 0
TC 57
ZB 1
ZR 0
Z9 57
SN 0025-1909
UT WOS:A1995RN11300003
ER

PT J
AU DUENYAS, I
   HOPP, WJ
TI QUOTING CUSTOMER LEAD TIMES
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 43
EP 57
DI 10.1287/mnsc.41.1.43
PD JAN 1995
PY 1995
AB We consider the problem of quoting customer lead times in a
   manufacturing environment under a variety of modeling assumptions.
   First, we examine the case where capacity is infinite. For this case, we
   derive a closed-form expression for the optimal lead time quote. Second,
   we consider the case where capacity is finite and the firm processes
   jobs in first-come-first-served (FCFS) order. We prove the optimality of
   different forms of control limit policies for the situations where the
   lead time is dictated by the market and where firms are able to compete
   on the basis of lead time. Finally, we consider the case where the firm
   may choose to schedule jobs in other than FCFS order and give conditions
   under which the optimal due-date-quoting/order-scheduling policy will
   process jobs in earliest due date (EDD) order.
ZA 0
ZB 0
ZR 0
ZS 1
TC 122
Z8 6
Z9 128
SN 0025-1909
UT WOS:A1995RN11300004
ER

PT J
AU BOWMAN, RA
TI EFFICIENT ESTIMATION OF ARC CRITICALITIES IN STOCHASTIC ACTIVITY
   NETWORKS
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 58
EP 67
DI 10.1287/mnsc.41.1.58
PD JAN 1995
PY 1995
AB An algorithm is described for estimating are and path criticalities in
   stochastic activity networks by combining Monte Carlo simulation with
   exact-analysis conditioned on node release times. These estimators are
   proved to be unbiased and to have lower variance than the corresponding
   standard Monte Carlo estimators. The algorithm is applied to a variety
   of standard and randomly generated test networks to establish that the
   estimators are significantly and robustly more efficient than the
   standard estimators when run time and statistical efficiency are
   properly combined.
TC 29
ZR 0
ZS 0
ZA 0
Z8 3
ZB 2
Z9 32
SN 0025-1909
UT WOS:A1995RN11300005
ER

PT J
AU BATCHELOR, R
   DUA, P
TI FORECASTER DIVERSITY AND THE BENEFITS OF COMBINING FORECASTS
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 68
EP 75
DI 10.1287/mnsc.41.1.68
PD JAN 1995
PY 1995
AB The expected error variance of a combined forecast is necessarily lower
   than that of an individual forecast, but in practice there may be
   considerable variation around these expected values. This paper
   introduces a measure of the benefit from combining, the probability of a
   reduction in error variance, which recognizes this problem. The measure
   is applied to data on the forecasts and forecasting methods of a panel
   of U.S. economists to determine how the benefits of combining vary with
   the number of forecasts combined, and with the diversity in theories and
   techniques among the component forecasts.
RI Dua, Pami/Q-3760-2019
TC 58
Z8 2
ZA 0
ZB 0
ZS 0
ZR 0
Z9 60
SN 0025-1909
UT WOS:A1995RN11300006
ER

PT J
AU TROUTT, MD
TI A MAXIMUM DECISIONAL EFFICIENCY ESTIMATION PRINCIPLE
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 76
EP 82
DI 10.1287/mnsc.41.1.76
PD JAN 1995
PY 1995
AB This paper proposes a systematic approach to certain parameter
   estimation problems relevant to applied optimization models. A
   context-specific measure of decision maker performance called decisional
   efficiency is defined as a function of the unknown parameter vector. The
   values of this measure are considered to be distributed according to a
   performance density. Then a principle of Maximum Decisional Efficiency
   (MDE) is proposed and its relationship to the Maximum Likelihood
   principle of statistics is discussed. The principle is first-illustrated
   on a problem of group ideal point estimation. Next, estimation of the
   ratio of ordering and holding costs in inventories managed by the EOQ
   model is considered. The results in both these examples are intuitively
   appealing, suggesting face validity of the principle. A more detailed
   illustration is developed for the problem of deriving a consensus
   scoring model for credit applicants which combines the data of more than
   one loan officer.
TC 35
ZA 0
ZB 1
Z8 1
ZR 0
ZS 0
Z9 36
SN 0025-1909
UT WOS:A1995RN11300007
ER

PT J
AU GROSSMANN, W
   GUARISO, G
   HITZ, M
   WERTHNER, H
TI A MIN COST FLOW SOLUTION FOR DYNAMIC ASSIGNMENT PROBLEMS IN NETWORKS
   WITH STORAGE DEVICES
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 83
EP 93
DI 10.1287/mnsc.41.1.83
PD JAN 1995
PY 1995
AB The paper presents a minimum-cost now approach for dynamic assignment
   procedures for networks with storage devices over time. Decision
   variables are diversion of flow at specific nodes and the storage of
   material in buffers which have to meet upper and lower capacity
   constraints. Evaluation of a decision is based on utility functions
   which are assumed to be piecewise linear and concave. The solution is
   based on a transformation into a network flow problem as suggested by
   Kuczera (1989). The temporal dimension of the problem is handled by
   constructing a supergraph with a layer for each time period. These
   layers are connected by temporal arcs. Thus the problem can be solved
   entirely by well-known algorithms for the minimum-cost flow problem
   which yield the optimal solution and determine automatically whether a
   feasible solution exists or not. The complexity of the proposed
   algorithm is pseudopolynomial, i.e., linear in the size of the network
   (measured by nodes, arcs, and buffers), linear in the amount of inflow,
   and quadratic in the number of time periods under consideration.
RI Guariso, Giorgio/H-9274-2019
OI Guariso, Giorgio/0000-0002-1991-6372
ZA 0
ZR 0
TC 6
ZB 0
ZS 0
Z8 0
Z9 6
SN 0025-1909
UT WOS:A1995RN11300008
ER

PT J
AU BALAS, E
   LENSTRA, JK
   VAZACOPOULOS, A
TI THE ONE-MACHINE PROBLEM WITH DELAYED PRECEDENCE CONSTRAINTS AND ITS USE
   IN JOB-SHOP SCHEDULING
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 94
EP 109
DI 10.1287/mnsc.41.1.94
PD JAN 1995
PY 1995
AB We study the one machine scheduling problem with release and delivery
   times and the minimum makespan objective, in the presence of constraints
   that for certain pairs of jobs require a delay between the completion of
   the first job and the start of the second (delayed precedence
   constraints). This problem arises naturally in the context of the
   Shifting Bottleneck Procedure for the general job shop scheduling
   problem, as a relaxation of the latter, tighter than the standard
   one-machine relaxation. The paper first highlights the difference
   between the two relaxations through some relevant complexity results.
   Then it introduces a modified Longest Tail Heuristic whose analysis
   identifies those situations that permit efficient branching. As a
   result, an optimization algorithm is developed whose performance is
   comparable to that of the best algorithms for the standard one-machine
   problem. Embedding this algorithm into a modified version of the
   Shifting Bottleneck Procedure that uses the tighter one-machine
   relaxation discussed here results in a considerable overall improvement
   in performance on all classes of job shop scheduling problems.
TC 84
ZR 0
Z8 4
ZS 0
ZA 0
ZB 0
Z9 87
SN 0025-1909
UT WOS:A1995RN11300009
ER

PT J
AU SONG, WMT
   SCHMEISER, BW
TI OPTIMAL MEAN-SQUARED-ERROR BATCH SIZES
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 110
EP 123
DI 10.1287/mnsc.41.1.110
PD JAN 1995
PY 1995
AB When an estimator of the variance of the sample mean is parameterized by
   batch size, one approach for selecting batch size is to pursue the
   minimal mean squared error (mse). We show that the convergence rate of
   the variance of the sample mean, and the bias of estimators of the
   variance of the sample mean, asymptotically depend on the data process
   only through its marginal variance and the sum of the autocorrelations
   weighted by their absolute lags. Combining these results with variance
   results of Goldsman and Meketon, we obtain explicit asymptotic
   approximations for mse, optimal batch size, optimal mse, and robustness
   for four quadratic-form estimators of the variance of the sample mean.
   Our empirical results indicate that the asymptotic approximations are
   reasonably accurate for sample sizes seen in practice. Although we do
   not discuss batch-size estimation procedures, the empirical results
   suggest that the explicit asymptotic batch-size approximation, which
   depends only on a summary measure (which we refer to as the balance
   point) of the nonnegative-lag autocorrelations, is a reasonable
   foundation for such procedures.
TC 92
ZR 0
ZS 0
ZB 0
ZA 0
Z8 1
Z9 93
SN 0025-1909
UT WOS:A1995RN11300010
ER

PT J
AU SIEGEL, AF
TI MEASURING SYSTEMATIC-RISK USING IMPLICIT BETA
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 124
EP 128
DI 10.1287/mnsc.41.1.124
PD JAN 1995
PY 1995
AB A new technology is proposed for estimating the systematic (beta) risk
   of a firm's stock. Just as the implicit volatility of an asset is
   revealed by an ordinary call option, the ''implicit beta'' of a stock
   would be revealed by the price of an option to exchange shares of stock
   for shares of a market index. Considerable benefits would accrue to
   those involved with the theory and practice of finance, if and when
   these exchange options begin trading, due to the availability of
   instantaneous, up-to-the-minute, precise indicators of firms' systematic
   risk levels.
TC 16
ZB 0
ZA 0
ZR 0
ZS 0
Z8 0
Z9 16
SN 0025-1909
UT WOS:A1995RN11300011
ER

PT J
AU THALHEIMER, R
   ALI, MM
TI THE DEMAND FOR PARIMUTUEL HORSE RACE WAGERING AND ATTENDANCE
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 129
EP 143
DI 10.1287/mnsc.41.1.129
PD JAN 1995
PY 1995
AB There has been a long history of patron participation in parimutuel
   horse race wagering and attendance, which are major recreational
   products in consumer budgets. In this paper, the demand for parimutuel
   horse race wagering and attendance has been specified and estimated for
   both Thoroughbred and Standardbred racetracks in a multistate market
   area. The data are annual over the period 1960-1987. It is found that
   demand is price elastic in every case. Racing quality, personal income,
   the number of racing days, competition from a state lottery, and from
   professional sports (baseball, basketball, football) are all significant
   determinants of these demands. Both attendance and wagering are found to
   increase with an increase in racing quality. However, it seems that the
   new patrons, attracted by quality racing, tend to wager less than those
   who attend regularly. The presence of a state lottery is found to have
   resulted in a substantial loss in attendance as well as in wagering at
   each of the racetracks. This, in turn, has resulted in a loss in both
   attendance and wagering-related revenue to racetracks, horsemen at those
   racetracks, and state governments. Professional sports are estimated to
   have a negative impact on attendance and wagering demands. For example,
   an additional 10 days of competition from professional sports in 1987
   would have resulted in a 4% decrease in both attendance and wagering.
   Both attendance and wagering can be increased by lowering the takeout
   rate from present levels or by offering more quality races.
ZA 0
Z8 0
ZB 0
ZR 0
TC 25
ZS 0
Z9 25
SN 0025-1909
UT WOS:A1995RN11300012
ER

PT J
AU RAMAN, K
   CHATTERJEE, R
TI OPTIMAL MONOPOLIST PRICING UNDER DEMAND UNCERTAINTY IN DYNAMIC MARKETS
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 144
EP 162
DI 10.1287/mnsc.41.1.144
PD JAN 1995
PY 1995
AB We examine pricing policy for a monopolist facing uncertain demand in a
   market characterized by dynamics on the demand side (such as diffusion
   or saturation effects) and/or on the cost side (experience curve
   effects). Our model explicitly incorporates the impact of demand
   uncertainty, and thus allows us to analyze the implications of
   uncertainty on the optimal price path, by contrasting the stochastic
   policy with the corresponding deterministic policy. We begin with an
   analysis of the general model and then focus on several special cases
   based on well known demand specifications to gain more specific insights
   and to suggest directional guidelines for dynamic pricing decisions in
   an uncertain environment. In general, the degree of impact of demand
   uncertainty on the optimal pricing policy is determined by the
   interaction among uncertainty, demand and/or cost dynamics, and the
   firm's discount rate. Thus, farsighted firms operating under dynamic
   market conditions with high demand uncertainty, such as high tech
   companies with innovative products for consumer or industrial markets,
   should attach particular importance to the formal consideration of
   uncertainty in their long term pricing decisions.
ZR 1
Z8 0
ZS 0
ZB 0
ZA 0
TC 58
Z9 59
SN 0025-1909
UT WOS:A1995RN11300013
ER

PT J
AU HASSIN, R
TI DECENTRALIZED REGULATION OF A QUEUE
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 163
EP 173
DI 10.1287/mnsc.41.1.163
PD JAN 1995
PY 1995
AB A bidding mechanism for determining priorities in a service system is
   analyzed. It is shown that when all customers have the same exponential
   service demand, this mechanism induces both the socially optimal arrival
   process and the service order. It is also shown that the
   profit-maximizing service rate in this model is smaller than or equal to
   the socially optimal one.
ZB 0
ZS 0
TC 34
ZA 0
Z8 1
ZR 0
Z9 35
SN 0025-1909
UT WOS:A1995RN11300014
ER

PT J
AU CIPRA, T
   TRUJILLO, J
   RUBIO, A
TI HOLT-WINTERS METHOD WITH MISSING OBSERVATIONS
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 174
EP 178
DI 10.1287/mnsc.41.1.174
PD JAN 1995
PY 1995
AB The paper presents a simple procedure for interpolating, smoothing, and
   predicting in seasonal time series with missing observations. The
   approach suggested by Wright (1986) for the Holt's method with
   nonseasonal data published at irregular time intervals is extended to
   the Holt-Winters method in the seasonal case. Numerical examples
   demonstrate the procedure.
RI Trujillo, Juan/L-7079-2014; Cipra, Tomas/N-8668-2019; Cipra, Tomas/P-4882-2017
OI Trujillo, Juan/0000-0003-0139-6724; Cipra, Tomas/0000-0003-0604-324X;
   Cipra, Tomas/0000-0003-0604-324X
ZR 0
TC 14
ZS 0
ZB 1
ZA 0
Z8 0
Z9 14
SN 0025-1909
UT WOS:A1995RN11300015
ER

PT J
AU GREEN, LV
   GUHA, D
TI ON THE EFFICIENCY OF IMBALANCE IN MULTI-FACILITY MULTISERVER SERVICE
   SYSTEMS - NOTE
SO MANAGEMENT SCIENCE
VL 41
IS 1
BP 179
EP 187
DI 10.1287/mnsc.41.1.179
PD JAN 1995
PY 1995
AB We consider the problem of simultaneously allocating servers and demands
   in a service system with independent multiple facilities. We assume a
   fixed number of facilities and total servers which must service a given
   Poisson arrival stream. We also assume that service times are
   identically distributed and independent of the server or facility. The
   allocation decision is one of simultaneously determining the number of
   servers and the fraction of the total arrival stream for each facility
   in order to optimize a given performance measure. Several performance
   measures are considered including minimizing expected system delay and
   equalizing delays across facilities. Our findings demonstrate that the
   overall system performance improves as the individual facilities become
   more unbalanced in the number of allocated servers. More formally, we
   show that if there is a server allocation that is maximal under the
   partial order of majorization, then it is optimal.
ZB 0
Z8 0
ZA 0
ZR 0
TC 12
ZS 0
Z9 12
SN 0025-1909
UT WOS:A1995RN11300016
ER

PT J
AU ANSON, R
   BOSTROM, R
   WYNNE, B
TI AN EXPERIMENT ASSESSING GROUP SUPPORT SYSTEM AND FACILITATOR EFFECTS ON
   MEETING OUTCOMES
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 189
EP 208
DI 10.1287/mnsc.41.2.189
PD FEB 1995
PY 1995
AB This article reports on an experiment investigating the effects of a
   human facilitator and a computerized Group Support System (GSS) on group
   meeting outcomes. These treatments were applied in the same way as they
   are in real organizational situations, with experimental conditions used
   to control confounding influences of other outside factors. Forty-eight
   groups were supported by one, both, or neither of the GSS and
   facilitator treatments. Groups designed a coordinated production
   strategy during the meeting and then implemented their strategy. Group
   performance, perceptions of group cohesion, and group interaction
   processes were assessed as the primary dependent variables.
   Facilitated groups experienced improved group processes and greater
   cohesion, whereas the GSS-supported groups did not. Facilitator and GSS
   support together tended to enhance one another's effective influence on
   cohesion and processes. No significant treatment effects on Performance
   were found. Supplemental analyses revealed that the quality of
   facilitators and the restrictiveness of different GSS tools moderated
   their impacts on appropriation processes and group outcomes.
ZR 0
TC 108
Z8 2
ZA 0
ZB 2
ZS 0
Z9 110
SN 0025-1909
UT WOS:A1995RN11400001
ER

PT J
AU CONNER, KR
TI OBTAINING STRATEGIC ADVANTAGE FROM BEING IMITATED - WHEN CAN ENCOURAGING
   CLONES PAY
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 209
EP 225
DI 10.1287/mnsc.41.2.209
PD FEB 1995
PY 1995
AB An important business strategy research theme concerns finding ways to
   minimize competition faced by the firm. This paper, however, focuses on
   a different set of situations: the model developed suggests that an
   innovator's best strategy may be to encourage ''clones'' of its product
   when a network externality is present. Key factors to consider in
   assessing whether encouraging cloning is the innovator's best strategy
   are: (1) the benefit to be derived in terms of added user base
   ''contributed'' by the clone sales, traded-off against (2) the unit
   sales that will be lost to the clone(s). These factors in turn depend
   upon the strength of the network effect and the degree to which the
   innovator's product quality is perceived by consumers to be superior to
   the clone's. The model further suggests that both the innovator and
   clone earn their highest payoffs when the clone takes the lead in
   price-setting, i.e., when the clone establishes its own price by
   considering, for each price it might set, how the innovator will react
   to that price, and the innovator, as price-follower, responds to the
   price the clone chooses. The paper demonstrates that the
   clone-leader/innovator-follower situation represents the unique Nash
   equilibrium in price-setting strategies. A central implication is that
   when operating in a network externality environment, instead of a
   problem to be avoided, clones may be valuable assets to an innovating
   firm, building up the user base for the innovator's technology by
   bringing lower-valuing consumers into the market, which in turn makes
   the innovator's product more attractive to high- and medium-valuing
   purchasers. Thus when the above-described conditions hold, being cloned
   can be more profitable for an innovating firm than dominating the market
   alone.
Z8 7
ZB 0
TC 95
ZR 1
ZA 0
ZS 0
Z9 103
SN 0025-1909
UT WOS:A1995RN11400002
ER

PT J
AU BALAKRISHNAN, PV
   ELIASHBERG, J
TI AN ANALYTICAL PROCESS MODEL OF 2-PARTY NEGOTIATIONS
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 226
EP 243
DI 10.1287/mnsc.41.2.226
PD FEB 1995
PY 1995
AB There has been a call to investigate the negotiation process (Gale 1986,
   Shubik 1982), as it is felt that this would yield important insights
   beyond those obtained by outcome-oriented theories (Roth 1979). This
   paper proposes a new analytical process model that captures both
   behavioral and economic aspects related to two-party negotiations. The
   proposed model, inspired by Pruitt's (1981) work, explicitly
   incorporates concepts which are both relevant and crucial, such as the
   negotiators' power, concession points, aspiration level, limit, and time
   pressure. Based on this process model, it is possible to predict (1)
   conditions under which agreements will not be reached despite the
   existence of a zone of agreement, (2) conditions under which agreements
   will be reached, and (3) the patterns of the negotiators' offers and
   counteroffers.
ZA 0
TC 36
ZS 0
Z8 0
ZB 0
ZR 0
Z9 36
SN 0025-1909
UT WOS:A1995RN11400003
ER

PT J
AU DONOHUE, JM
   HOUCK, EC
   MYERS, RH
TI SIMULATION DESIGNS FOR THE ESTIMATION OF QUADRATIC RESPONSE-SURFACE
   GRADIENTS IN THE PRESENCE OF MODEL MISSPECIFICATION
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 244
EP 262
DI 10.1287/mnsc.41.2.244
PD FEB 1995
PY 1995
AB This article considers the construction of simulation designs for the
   ordinary least squares estimation of second-order-metamodels. Two
   premises underlie the development of these experimental strategies.
   First it is assumed that the postulated metamodel may be misspecified
   due to the true model structure being of third-order. It is therefore
   important that the locations of the simulation experiments be specified
   to provide protection against bias, as well as variance, in the
   estimation of metamodel parameters. The second premise is based on the
   observation that, in many applications of metamodels, functions of the
   fitted model coefficients (such as the slope gradients) are of greater
   interest than the response function. The integrated mean squared error
   of slopes design criterion that is implemented here addresses both
   premises. This criterion finds application in various optimum seeking
   methods and sensitivity analysis procedures. Combinations of four
   important-classes of response surface designs and three pseudorandom
   number assignments strategies constitute the basic structure of the
   simulation designs studied. The performance of these simulation designs
   is evaluated and, subsequently, compared to a similar set of
   experimental plans that have as their focus the estimation of the
   response function.
Z8 0
ZR 0
TC 12
ZB 0
ZA 0
ZS 0
Z9 12
SN 0025-1909
UT WOS:A1995RN11400004
ER

PT J
AU GLASSERMAN, P
   TAYUR, S
TI SENSITIVITY ANALYSIS FOR BASE-STOCK LEVELS IN MULTIECHELON
   PRODUCTION-INVENTORY SYSTEMS
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 263
EP 281
DI 10.1287/mnsc.41.2.263
PD FEB 1995
PY 1995
AB Effective management of inventories in large-scale production and
   distribution systems requires methods for bringing model solutions
   closer to the complexities of real systems. Motivated by this need, we
   develop simulation-based methods for estimating sensitivities of
   inventory costs with respect to policy parameters. These sensitivity
   estimates are useful in adjusting optimal parameters predicted by a
   simplified model to complexities that can be incorporated in a
   simulation.
   We consider capacitated, multiechelon systems operating under base-stock
   policies and develop estimators of derivatives with respect to
   base-stock levels. We show that these estimates converge to the correct
   value for finite-horizon and infinite-horizon discounted and average
   cost criteria. Our methods are easy to implement and experiments suggest
   that they converge quickly. We illustrate their use by optimizing
   base-stock levels for a subsystem of the PC assembly and distribution
   system of a major computer manufacturer.
Z8 2
ZS 1
ZB 0
ZR 0
ZA 0
TC 141
Z9 143
SN 0025-1909
UT WOS:A1995RN11400005
ER

PT J
AU NAIR, SK
TI MODELING STRATEGIC INVESTMENT DECISIONS UNDER SEQUENTIAL
   TECHNOLOGICAL-CHANGE
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 282
EP 297
DI 10.1287/mnsc.41.2.282
PD FEB 1995
PY 1995
AB Strategic decisions to invest in new equipment are critical not only
   because of the large initial capital costs incurred but even more
   importantly because they affect future unit production costs, revenues,
   and the ability of the firm to perform operations that were not possible
   earlier. Thus these decisions determine the very competitiveness of the
   firm. Further, decisions regarding the choice of technology are very
   expensive to correct if incorrect decisions are identified. These
   decisions have become increasingly urgent and complex because the state
   of the art in technology is changing rapidly. However, many models
   available for evaluating these decisions are either too complex and
   inefficient or too restrictive in the number, types, and the way
   appearance of future technologies is modeled.
   This research attempts to relax some of these restrictions using
   forecast horizon procedures to model capital investment decisions where
   any number of technologies may appear in the future with purchase costs
   and revenues that may vary over time. The appearance of these future
   technologies are considered uncertain with probabilities that may also
   vary with time. However, we assume that the order in which they appear
   is sequential, much like the different generations of microchips for
   microcomputers. We develop a new approach using nonunique terminal
   rewards to solve a dynamic programming model of the problem by
   introducing ''converse'' difference functions and present an algorithm
   that is both simple and efficient. Despite the increase in state space
   from the use of ''converse'' functions, we show that the computational
   burden of the algorithm does not increase. Numerical examples are given
   to illustrate our algorithm. Sensitivity of the optimal decision to
   changes in probabilities, costs, and revenues are also discussed.
ZA 0
ZS 0
ZB 0
ZR 0
Z8 1
TC 40
Z9 41
SN 0025-1909
UT WOS:A1995RN11400006
ER

PT J
AU BEST, M
   BRACKEN, J
TI FIRST-STRIKE STABILITY IN A MULTIPOLAR WORLD
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 298
EP 321
DI 10.1287/mnsc.41.2.298
PD FEB 1995
PY 1995
AB First-strike stability in a multipolar world measures the incentives of
   all major nuclear weapon countries, in all possible coalitions, to
   refrain from preemptive attack. The analysis integrates the interactions
   of offensive weapon arsenals, vulnerable offensive weapons within these
   arsenals, defensive weapons, and value targets reflecting the national
   assets at stake. In the previously-dominant bipolar paradigm, when the
   United States and the Soviet Union possessed almost all of the strategic
   nuclear weapons in the world, first-strike stability was an important
   criterion for assessing defensive deployments of the two sides, without
   consideration of any other countries. In the emerging multipolar world,
   however, the United States and Russia are dramatically reducing their
   offensive forces, and the offensive arsenals of Britain, France, and
   China are becoming relatively more important. Also, proliferation of
   medium-range ballistic missiles to other countries capable of attacking
   Russia, Britain, France, and China, but not necessarily the United
   States (due to range limitations), greatly complicates the overall
   situation. The main thrust-of this paper is to investigate the
   first-strike stability implications of the deployment of strategic
   defenses by the United States and Russia. The principal finding is that
   in a multipolar world first-strike stability increases with the
   deployment of small to medium sized strategic defenses whereas in a
   bipolar world it usually decreases. Although the incentives for the
   United States and Russia to preempt increase, the incentives of the
   other countries decrease, with the combined effect over all coalitions
   of decreasing the incentive to preempt.
ZR 0
ZB 0
TC 1
ZA 0
Z8 0
ZS 0
Z9 1
SN 0025-1909
UT WOS:A1995RN11400007
ER

PT J
AU RUST, RT
   SIMESTER, D
   BRODIE, RJ
   NILIKANT, V
TI MODEL SELECTION CRITERIA - AN INVESTIGATION OF RELATIVE ACCURACY,
   POSTERIOR PROBABILITIES, AND COMBINATIONS OF CRITERIA
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 322
EP 333
DI 10.1287/mnsc.41.2.322
PD FEB 1995
PY 1995
AB We investigate the performance of empirical criteria for comparing and
   selecting quantitative models from among a candidate set. A simulation
   based on empirically observed parameter values is used to determine
   which criterion is the most accurate at identifying the correct model
   specification. The simulation is composed of both nested and nonnested
   linear regression models. We then derive posterior probability estimates
   of the superiority of the alternative models from each of the criteria
   and evaluate the relative accuracy, bias, and information content of
   these probabilities. To investigate whether additional accuracy can be
   derived from combining criteria, a method for obtaining a joint
   prediction from combinations of the criteria is proposed and the
   incremental improvement in selection accuracy considered.
   Based on the simulation, we conclude that most leading criteria perform
   well in selecting the best model, and several criteria also produce
   accurate probabilities of model superiority. Computationally intensive
   criteria failed to perform better than criteria which were
   computationally simpler. Also, the use of several criteria in
   combination failed to appreciably outperform the use of one model. The
   Schwarz criterion performed best overall in terms of selection accuracy,
   accuracy of posterior probabilities, and ease of use. Thus, we suggest
   that general model comparison, model selection, and model probability
   estimation be performed using the Schwarz criterion, which can he
   implemented (given the model log likelihoods) using only a hand
   calculator.
RI Brodie, Roderick/P-7335-2019; Brodie, Roderick J/D-6158-2017
OI Brodie, Roderick/0000-0003-3064-4475; 
Z8 0
ZB 4
TC 42
ZA 0
ZR 0
ZS 1
Z9 43
SN 0025-1909
UT WOS:A1995RN11400008
ER

PT J
AU MORTON, TE
   PENTICO, DW
TI THE FINITE-HORIZON NONSTATIONARY STOCHASTIC INVENTORY PROBLEM -
   NEAR-MYOPIC BOUNDS, HEURISTICS, TESTING
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 334
EP 343
DI 10.1287/mnsc.41.2.334
PD FEB 1995
PY 1995
AB Nonstationary stochastic periodic review inventory problems with
   proportional costs occur in a number of industrial settings with
   seasonal patterns, trends, business cycles, and limited life items.
   Myopic policies for such problems order as if the salvage value in the
   current period for ending inventory were the full purchase price, so
   that information about the future would not be needed. They have been
   shown in the Literature to be optimal when demand ''is increasing over
   time,'' and to provide upper bounds for the stationary finite horizon
   problem (and in some other situations). Some results are also known,
   given special salvaging assumptions, about lower bounds on the optimal
   policy which are near-myopic. Here analogous but stronger bounds are
   derived for the general finite horizon problem, without such special
   assumptions. The best upper bound is an extension of the heuristic used
   by industry for some years for end of season (EOS) problems; the lower
   bound is an extension of earlier analytic methods. Four heuristics were
   tested against the optimal obtained by stochastic dynamic programming
   for 969 problems. The simplest heuristic is the myopic heuristic itself:
   it is good especially for moderately varying problems without heavy end
   of season salvage costs and averages only 2.75% in cost over the
   optimal. However, the best of the heuristics exceeds the optimal in cost
   by an average of only 0.02%, at about 0.5% of the computational cost of
   dynamic programming.
ZB 0
TC 40
Z8 1
ZR 0
ZA 0
ZS 0
Z9 41
SN 0025-1909
UT WOS:A1995RN11400009
ER

PT J
AU KUMAR, A
   SCHWARZ, LB
   WARD, JE
TI RISK-POOLING ALONG A FIXED DELIVERY ROUTE USING A DYNAMIC
   INVENTORY-ALLOCATION POLICY
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 344
EP 362
DI 10.1287/mnsc.41.2.344
PD FEB 1995
PY 1995
AB This paper examines static and dynamic policies for replenishing and
   allocating inventories amongst N retailers located along a fixed
   delivery route. Each retailer faces independent, normally-distributed
   period demand and incurs a proportional holding or backorder cost on
   end-of-period net-inventory. A warehouse places a system-replenishment
   order every m periods which is received after a fixed leadtime of T
   periods. Immediately upon receipt, a delivery vehicle leaves the
   warehouse with the system-replenishment quantity and travels to the
   retailers along a fixed route with fixed leadtimes between successive
   retailers. The warehouse holds no inventory. Under the ''static''
   policy, allocations are determined for all retailers simultaneously at
   the moment the delivery vehicle leaves the warehouse. Under the
   ''dynamic'' policy, allocations are determined sequentially upon arrival
   of the delivery vehicle at each retailer. Our major analytical results,
   under appropriate dynamic (static) allocation assumptions, are: (1)
   optimal allocations under each policy involve bringing each retailer's
   ''normalized-inventory'' to a corresponding ''normalized'' system
   inventory; (2) optimal system replenishments are base-stock policies;
   (3) the minimum expected cost per cycle of dynamic (static) policy can
   be derived from an equivalent-dynamic (static) composite retailer. Given
   this, we prove that the ''risk-pooling incentive''-a simple measure of
   the benefit from adopting dynamic allocation policies-is always
   positive. Our simulation tests confirm that dynamic allocation policies
   yield lower costs than static policies, regardless of whether or not
   their respective allocation assumptions are valid. However, the
   magnitude of the cost savings is very sensitive to some system
   parameters.
TC 28
ZS 0
ZA 0
ZR 0
Z8 2
ZB 0
Z9 30
SN 0025-1909
UT WOS:A1995RN11400010
ER

PT J
AU DANIELS, RL
   KOUVELIS, P
TI ROBUST SCHEDULING TO HEDGE AGAINST PROCESSING TIME UNCERTAINTY IN
   SINGLE-STAGE PRODUCTION
SO MANAGEMENT SCIENCE
VL 41
IS 2
BP 363
EP 376
DI 10.1287/mnsc.41.2.363
PD FEB 1995
PY 1995
AB Schedulers confronted with significant processing time uncertainty often
   discover that a schedule which is optimal with respect to a
   deterministic or stochastic scheduling model yields quite poor
   performance when evaluated relative to the actual processing times. In
   these environments, the notion of schedule robustness, i.e., determining
   the schedule with the best worst-case performance compared to the
   corresponding optimal solution over all potential realizations of job
   processing times, is a more appropriate guide to schedule selection. In
   this paper, we formalize the robust scheduling concept for scheduling
   situations with uncertain or variable processing times. To illustrate
   the development of solution approaches for a robust scheduling problem,
   we consider a single-machine environment where the performance criterion
   of interest is the total flow time over all jobs. We define two measures
   of schedule robustness, formulate the robust scheduling problem,
   establish its complexity, describe properties of the optimal schedule,
   and present exact and heuristic solution procedures. Extensive
   computational results are reported to demonstrate the efficiency and
   effectiveness of the proposed solution procedures.
RI Kouvelis, Panos/ABG-2350-2020
ZS 0
ZR 2
Z8 12
ZA 0
TC 190
ZB 0
Z9 202
SN 0025-1909
UT WOS:A1995RN11400011
ER

PT J
AU RAPOPORT, A
   EREV, I
   ZWICK, R
TI AN EXPERIMENTAL-STUDY OF BUYER-SELLER NEGOTIATION WITH ONE-SIDED
   INCOMPLETE INFORMATION AND TIME DISCOUNTING
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 377
EP 394
DI 10.1287/mnsc.41.3.377
PD MAR 1995
PY 1995
AB We study a multiperiod bargaining mechanism in which a seller negotiates
   with a buyer over the price of an indivisible good. It is common
   knowledge that the good has zero value to the seller. Its value to the
   buyer is privately known, distributed independently of the seller's
   value according to a distribution that is common knowledge. Bargaining
   proceeds as follows. The seller sets a price and offers the buyer an
   opportunity to purchase the good. The buyer either waits for at least
   one more period or agrees to purchase the good at the given price. If
   the buyer refuses the offer, then the process is repeated with the
   seller making a new offer on the next period. Our findings reveal
   several behavioral regularities, which do not support the sequential
   equilibrium for this bargaining mechanism. In line with recent
   developments in behavioral decision theory and game theory, which assume
   bounded rationality, we find that subjects follow simple rules of thumb
   in choosing strategies, reflected in the behavioral consistencies
   observed in this study.
ZB 2
Z8 1
ZS 0
TC 31
ZA 0
ZR 0
Z9 31
SN 0025-1909
UT WOS:A1995RN11500001
ER

PT J
AU PATANKAR, JG
   MITRA, A
TI EFFECTS OF WARRANTY EXECUTION ON WARRANTY RESERVE COSTS
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 395
EP 400
DI 10.1287/mnsc.41.3.395
PD MAR 1995
PY 1995
AB Previous research has usually assumed full execution of warranty if a
   product fails within the warranty time. This paper investigates the
   effect of warranty execution on the expected warranty reserves of a
   linear pro rata rebate plan. The failure distribution investigated
   includes the Weibull distribution with different parameter values. A
   weight function is used that depicts the effect of warranty execution.
   Several forms of this warranty execution function modeling consumer
   behavior, which is influenced by factors such as the rebate plan,
   warranty time, product class, and warranty attrition, are studied.
   Expected present value of warranty reserves, by using a factor that
   includes the firm's discount rate and the general inflation rate, are
   found for the different warranty execution functions. The impact of the
   warranty execution function on the warranty reserves per unit is
   explored. The paper also investigates the effects of the model
   parameters, such as the failure distribution parameters and differences
   in consumer behavior in claiming warranties on warranty costs per unit.
TC 22
ZS 2
ZR 0
ZA 0
ZB 0
Z8 0
Z9 23
SN 0025-1909
UT WOS:A1995RN11500002
ER

PT J
AU WANG, ETG
   SEIDMANN, A
TI ELECTRONIC DATA INTERCHANGE - COMPETITIVE EXTERNALITIES AND STRATEGIC
   IMPLEMENTATION POLICIES
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 401
EP 418
DI 10.1287/mnsc.41.3.401
PD MAR 1995
PY 1995
AB Electronic Data Interchange (EDI) is an emerging type of standardized
   inter-organizational information system. We analyze the impact of EDI on
   the upstream suppliers' competitive position in a simple two-level
   hierarchical market structure where the buyer faces a linear demand
   curve and the competing heterogeneous suppliers have an upward-sloping
   marginal cost function. We show that a supplier's adoption of EDI can
   generate positive externalities for the buyer and negative (or
   competitive) externalities for other suppliers. As a result, the buyer
   provides a price premium to those suppliers who adopt EDI and increases
   their sales volume and market share. Moreover, when the benefits that
   the buyer can derive from implementing EDI are substantial, and the
   suppliers' EDI adoption costs are high, it may be in the buyer's best
   interest to subsidize the suppliers so as to encourage them to adopt
   EDI, instead of mandating them to do so. Regardless of whether the buyer
   employs a mandatory or a subsidizing policy, the buyer and the end
   consumers may be the only ones who gain from this new technology.
   Consequently, a partial adoption by the supplier base may be optimal for
   the buyer when the suppliers' adoption costs are sufficiently high. We
   also show that, while EDI reduces the transaction costs of the buyer,
   the upstream market tends to become more concentrated as a result of
   increased cost differentials. These results provide one economic
   explanation of the fact that many companies have actually reduced their
   supplier base after implementing EDI, despite a significant reduction in
   their market transaction costs.
ZR 0
ZS 0
ZB 0
TC 108
Z8 4
ZA 0
Z9 111
SN 0025-1909
UT WOS:A1995RN11500003
ER

PT J
AU SRINIVASAN, A
   TEENI, D
TI MODELING AS CONSTRAINED PROBLEM-SOLVING - AN EMPIRICAL-STUDY OF THE DATA
   MODELING PROCESS
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 419
EP 434
DI 10.1287/mnsc.41.3.419
PD MAR 1995
PY 1995
AB Modeling is a powerful tool for managing complexity in problem solving.
   Problem solvers usually build a simplified model of the real world and
   then use it to generate a solution to their problem. To date, however,
   little is known about how people actually behave when building a model.
   This study concentrates on data modeling, which involves the
   representation of different types of data and their interrelationships.
   It reports on two laboratory studies, in which subjects engage in data
   modeling to solve a complex problem. Using a think-aloud process-tracing
   methodology, we examine the data modeling behavior as a set of
   activities that are managed by several heuristics. We found that some
   heuristics were effective in reducing the complexity of the problem. An
   important aspect we observed was how subjects moved across levels of
   abstraction in the problem representation. Overall, these observations
   help to explain how people deal with complexity in data modeling. They
   also suggest that it may be advantageous to design systems that support
   work at various levels of abstraction and support transitions among
   those levels.
CT 11th International Conference of Information Systems
CY DEC, 1990
CL COPENHAGEN, DENMARK
Z8 0
ZS 0
ZA 0
ZB 1
ZR 0
TC 28
Z9 28
SN 0025-1909
UT WOS:A1995RN11500004
ER

PT J
AU ROUSSEAU, JJ
   SEMPLE, JH
TI 2-PERSON RATIO EFFICIENCY GAMES
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 435
EP 441
DI 10.1287/mnsc.41.3.435
PD MAR 1995
PY 1995
AB This paper demonstrates that a class of two-person games with ratio
   payoff functions can be solved using equivalent primal-dual linear
   programming formulations. The game's solution contains specialized
   information which may be used to conduct the efficiency evaluation
   currently done by the CCR ratio model of Data Envelopment Analysis
   (DEA). Consequently, a rigorous connection between DEA's CCR model and
   the theory of games is established. Interpretations of these new
   solutions are discussed in the context of current ongoing applications.
RI Semple, John/F-8137-2012
ZR 0
TC 32
Z8 4
ZS 0
ZA 0
ZB 2
Z9 36
SN 0025-1909
UT WOS:A1995RN11500005
ER

PT J
AU OLESEN, OB
   PETERSEN, NC
TI CHANCE-CONSTRAINED EFFICIENCY EVALUATION
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 442
EP 457
DI 10.1287/mnsc.41.3.442
PD MAR 1995
PY 1995
AB A model for efficiency evaluation based upon the theory of chance
   constrained programming is developed. The model uses a piecewise linear
   envelopment of confidence regions for observed stochastic multiple-input
   multiple-output combinations in the Data Envelopment Analysis (DEA)
   tradition. The model allows for an exogenous decomposition of the total
   variation in data for each Decision Making Unit (DMU). By varying
   certain probability levels the model can provide estimates of the
   sensitivity of efficiency scores regarding an unknown amount of noise in
   data. An application of the method in an evaluation of the research
   activities in economic departments at Danish Universities is presented.
ZS 0
Z8 10
ZR 0
ZA 0
ZB 3
TC 163
Z9 173
SN 0025-1909
UT WOS:A1995RN11500006
ER

PT J
AU ADLER, PS
   MANDELBAUM, A
   NGUYEN, V
   SCHWERER, E
TI FROM PROJECT TO PROCESS MANAGEMENT - AN EMPIRICALLY-BASED FRAMEWORK FOR
   ANALYZING PRODUCT DEVELOPMENT TIME
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 458
EP 484
DI 10.1287/mnsc.41.3.458
PD MAR 1995
PY 1995
AB While product development efforts are often viewed as unique
   configurations of idiosyncratic tasks, in reality different projects
   within an organization often exhibit substantial similarity in the flow
   of their constituent activities. Moreover, while most of the planning
   tools available to managers assume that projects are independent
   clusters of activities, in reality many organizations must manage
   concurrent projects that place competing demands on shared human and
   technical resources. This study develops an empirically-based framework
   for analyzing development time in such contexts. We model the product
   development organization as a stochastic processing network in which
   engineering resources are ''workstations'' and projects are ''jobs''
   that flow between the workstations. At any given time, a job is either
   receiving service or queueing for access to a resource. Our model's
   spreadsheets quantify this division of time, and our simulation
   experiments investigate the determinants of development cycle time. This
   class of models provides a useful managerial framework for studying
   product development because it enables formal performance analysis, and
   it points to data that should be collected by organizations seeking to
   improve development cycle times. Such models also provide a conceptual
   framework for characterizing commonalities and differences between
   engineering and manufacturing operations.
Z8 2
ZR 1
ZS 1
ZB 1
TC 153
ZA 0
Z9 157
SN 0025-1909
UT WOS:A1995RN11500007
ER

PT J
AU TSAI, LH
TI MIXED-MODEL SEQUENCING TO MINIMIZE UTILITY WORK AND THE RISK OF CONVEYOR
   STOPPAGE
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 485
EP 495
DI 10.1287/mnsc.41.3.485
PD MAR 1995
PY 1995
AB This paper investigates the problem of sequencing N products on an
   assembly line with two objectives: minimizing (1) the risk of conveyor
   stoppage and (2) the total utility work. For a single station with
   arbitrary processing times, this problem is proved NP-hard in the strong
   sense for ach of the two objectives. For a single station with two
   product types, each of which has a constant processing time, a sequence
   minimizing both objectives can be found in O(log N) computation time.
ZB 0
ZR 0
ZA 0
TC 58
ZS 0
Z8 1
Z9 59
SN 0025-1909
UT WOS:A1995RN11500008
ER

PT J
AU SWERSEY, AJ
   THAKUR, LS
TI AN INTEGER PROGRAMMING-MODEL FOR LOCATING VEHICLE EMISSIONS TESTING
   STATIONS
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 496
EP 512
DI 10.1287/mnsc.41.3.496
PD MAR 1995
PY 1995
AB Connecticut and other states not in compliance with federal air quality
   standards are required to implement a motor vehicle inspection program
   to hydrocarbons and carbon monoxide. The problem is to determine the
   number, size, and locations of stations given constraints on the maximum
   travel distance from each town to its nearest station and the average
   waiting time at a station.
   In this paper we use simulation to find the maximum allowable arrival
   rates (in vehicles per hour) of stations of different sizes and
   formulate the station location problem as a set covering model. We
   generate a range of solutions through sensitivity analysis, varying both
   the average waiting time and maximum distance constraints. Comparing the
   current configuration of stations in Connecticut to our integer
   programming solutions we find that the integer programming approach
   reduces the objective function by at least $3 million. The current
   configuration has more stations than the IP solutions but they are
   not-as well distributed.
ZS 0
Z8 0
TC 11
ZA 0
ZR 0
ZB 1
Z9 11
SN 0025-1909
UT WOS:A1995RN11500009
ER

PT J
AU MOINZADEH, K
   KLASTORIN, TD
TI MEASURING THE IMPACT OF A DELAY BUFFER ON QUALITY COSTS WITH AN
   UNRELIABLE PRODUCTION PROCESS
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 513
EP 523
DI 10.1287/mnsc.41.3.513
PD MAR 1995
PY 1995
AB In this paper, we consider an unreliable production process which
   produces nondefective items when operating in control, but produces
   defective items with a probability oc when the process has shifted to an
   out-of-control state. Following a JIT philosophy, we stop the entire
   line and repair the machine as soon as we detect that the process has
   shifted to an out-of-control state. To test whether a process shift has
   occurred, we inspect the last m units for every n units produced and
   stop the machine if a defective unit is found. More important, we place
   a ''delay buffer'' immediately after the unreliable process, which
   serves to delay the movement of items from the unreliable machine to
   other processes (or customers) downstream in the production system. When
   we detect that the machine has shifted to an out-of-control state, we
   stop the entire line and examine all previously uninspected items in the
   delay buffer; in this way, the buffer serves to reduce the expected
   rework and penalty (e.g., warranty) costs downstream when a process
   shift has occurred. In this paper, we develop a model for this approach
   and use this model to test the operating characteristics of our system.
   Computational results illustrate our hypothesis that a delay buffer may
   significantly reduce expected total costs of a quality control process.
TC 7
ZS 0
Z8 0
ZB 0
ZR 0
ZA 0
Z9 7
SN 0025-1909
UT WOS:A1995RN11500010
ER

PT J
AU NAKAYAMA, MK
TI ASYMPTOTICS OF LIKELIHOOD RATIO DERIVATIVE ESTIMATORS IN SIMULATIONS OF
   HIGHLY RELIABLE MARKOVIAN SYSTEMS
SO MANAGEMENT SCIENCE
VL 41
IS 3
BP 524
EP 554
DI 10.1287/mnsc.41.3.524
PD MAR 1995
PY 1995
AB We discuss the estimation of derivatives of a performance measure using
   the likelihood ratio method in simulations of highly reliable Markovian
   systems. We compare the difficulties of estimating the performance
   measure and of estimating its partial derivatives with respect to
   component failure rates as the component failure rates tend to 0 and the
   component repair rates remain fixed. We first consider the case when the
   quantities are estimated using naive simulation; i.e., when no variance
   reduction technique is used. In particular, we prove that in the limit;
   some of the partial derivatives can be estimated as accurately as the
   performance measure itself. This result is of particular interest in
   light of the somewhat pessimistic empirical results others have obtained
   when applying the likelihood ratio method to other types of systems.
   However, the result only holds for certain partial derivatives of the
   performance measure when using naive simulation. More specifically, we
   can estimate a certain partial derivative with the same relative
   accuracy as the performance measure if the partial derivative is
   associated with a component either having one of the largest failure
   rates or whose failure can trigger a failure transition on one of the
   ''most likely paths to failure.'' Also, we develop a simple criterion to
   determine which partial derivatives will satisfy either of these
   properties. In particular, we can identify these derivatives using a
   sensitivity measure which can be calculated for each type of component.
   We also examine the limiting behavior of the estimates of the
   performance measure and its derivatives which are obtained when an
   importance sampling scheme known as balanced failure biasing is used. In
   particular, we show that the estimates of all derivatives can be
   improved. In contrast to the situation that arose when using naive
   simulation, we prove that in the limit, all derivatives can be estimated
   as accurately as the performance measure when balanced failure biasing
   is employed.
   Finally, we formalize the notion of a ''most likely path to failure'' in
   the setting of highly reliable Markovian systems. We accomplish this by
   proving a conditional limit theorem for the distribution of the sample
   paths leading to a system failure, given that a system failure occurs
   before the system returns to the state with all components operational.
   We use this result to establish our other results.
ZS 0
TC 9
ZB 0
ZR 0
Z8 1
ZA 0
Z9 10
SN 0025-1909
UT WOS:A1995RN11500011
ER

EF